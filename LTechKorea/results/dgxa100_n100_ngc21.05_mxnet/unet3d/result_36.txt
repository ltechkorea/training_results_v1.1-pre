+ echo 'Beginning trial 4 of 10'
Beginning trial 4 of 10
+ '[' 1 -eq 1 ']'
+ srun --ntasks=100 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on luna-0504
Clearing cache on luna-0475
Clearing cache on luna-0442
Clearing cache on luna-0068
Clearing cache on luna-0450
Clearing cache on luna-0445
Clearing cache on luna-0439
Clearing cache on luna-0335
Clearing cache on luna-0332
Clearing cache on luna-0231
Clearing cache on luna-0240
Clearing cache on luna-0062
Clearing cache on luna-0467
Clearing cache on luna-0239
Clearing cache on luna-0227
Clearing cache on luna-0441
Clearing cache on luna-0331
Clearing cache on luna-0230
Clearing cache on luna-0520
Clearing cache on luna-0509
Clearing cache on luna-0075
Clearing cache on luna-0476
Clearing cache on luna-0434
Clearing cache on luna-0063
Clearing cache on luna-0443
Clearing cache on luna-0235
Clearing cache on luna-0446
Clearing cache on luna-0234
Clearing cache on luna-0465
Clearing cache on luna-0468
Clearing cache on luna-0481
Clearing cache on luna-0067
Clearing cache on luna-0448
Clearing cache on luna-0236
Clearing cache on luna-0470
Clearing cache on luna-0073
Clearing cache on luna-0438
Clearing cache on luna-0334
Clearing cache on luna-0072
Clearing cache on luna-0324
Clearing cache on luna-0519
Clearing cache on luna-0069
Clearing cache on luna-0333
Clearing cache on luna-0226
Clearing cache on luna-0321
Clearing cache on luna-0071
Clearing cache on luna-0436
Clearing cache on luna-0074
Clearing cache on luna-0228
Clearing cache on luna-0471
Clearing cache on luna-0323
Clearing cache on luna-0065
Clearing cache on luna-0444
Clearing cache on luna-0325
Clearing cache on luna-0477
Clearing cache on luna-0322
Clearing cache on luna-0064
Clearing cache on luna-0452
Clearing cache on luna-0061
Clearing cache on luna-0070
Clearing cache on luna-0510
Clearing cache on luna-0513
Clearing cache on luna-0517
Clearing cache on luna-0507
Clearing cache on luna-0473
Clearing cache on luna-0484
Clearing cache on luna-0440
Clearing cache on luna-0515
Clearing cache on luna-0066
Clearing cache on luna-0480
Clearing cache on luna-0330
Clearing cache on luna-0232
Clearing cache on luna-0512
Clearing cache on luna-0472
Clearing cache on luna-0505
Clearing cache on luna-0451
Clearing cache on luna-0483
Clearing cache on luna-0469
Clearing cache on luna-0502
Clearing cache on luna-0503
Clearing cache on luna-0479
Clearing cache on luna-0518
Clearing cache on luna-0482
Clearing cache on luna-0508
Clearing cache on luna-0511
Clearing cache on luna-0501
Clearing cache on luna-0514
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
Clearing cache on luna-0437
Clearing cache on luna-0327
Clearing cache on luna-0466
Clearing cache on luna-0238
Clearing cache on luna-0435
Clearing cache on luna-0076
Clearing cache on luna-0233
Clearing cache on luna-0328
Clearing cache on luna-0329
Clearing cache on luna-0225
Clearing cache on luna-0237
Clearing cache on luna-0326
Clearing cache on luna-0229
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --mpi=pmix --ntasks=800 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/lustre/fsw/mlperf/mlperft-unet3d/dataset/:/data,/lustre/fsw/mlperf-ci/23360859/results:/results,/lustre/fsw/mlperf/mlperft-unet3d/rachitg/logs/single_node:/profile_dir ./run_and_time.sh
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ echo 'running benchmark'
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ SEED=-1
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ '[' '' = apiLog.sh ']'
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
running benchmark
+ echo 'running benchmark'
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ SEED=-1
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ SEED=-1
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 4 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 5 ']'
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
running benchmark
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 2 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' -n 4 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ '[' -n 0 ']'
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ TARGET_DIR=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ OPTIMIZER=nag
running benchmark
+ BATCH_SIZE=1
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 2 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ TARGET_DIR=
+ cluster=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ echo 'running benchmark'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ '[' -n 1 ']'
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ LR=1.5
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 4 ']'
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ EVALUATE_EVERY=14
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
running benchmark
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 1 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 6 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ EVALUATE_EVERY=14
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ '[' -n 2 ']'
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ cluster=
+ '[' -n 7 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=selene
+ TARGET_DIR=
+ '[' -n 4 ']'
running benchmark
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' -n 0 ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ LR=1.5
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR=1.5
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 7 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ QUALITY_THRESHOLD=0.908
running benchmark
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 6 ']'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ VAL_BATCH_SIZE=1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 1 ']'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 6 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 3 ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
running benchmark
+ MAX_EPOCHS=7000
running benchmark
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' -n 0 ']'
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ TARGET_DIR=
+ echo 'running benchmark'
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ DATASET_DIR=/data
running benchmark
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR=1.5
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ SEED=-1
+ EVALUATE_EVERY=14
running benchmark
+ START_EVAL_AT=700
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
running benchmark
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
running benchmark
+ QUALITY_THRESHOLD=0.908
running benchmark
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 7 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ TARGET_DIR=
+ cluster=
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 5 ']'
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ cluster=
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=selene
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 6 ']'
+ BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 1 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ TARGET_DIR=
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ OPTIMIZER=nag
+ cluster=selene
+ '[' -n 4 ']'
+ '[' -n 1 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ cluster=
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ LR=1.5
running benchmark
+ '[' -n 4 ']'
+ cluster=
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 7 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 1 ']'
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 6 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ declare -a CMD
+ declare -a CMD
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 2 ']'
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 1 ']'
+ cluster=
+ '[' -n 2 ']'
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ declare -a CMD
+ '[' -n 7 ']'
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
running benchmark
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ cluster=selene
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 1 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ declare -a CMD
+ SEED=-1
+ '[' -n 7 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ declare -a CMD
+ LR=1.5
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ QUALITY_THRESHOLD=0.908
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ START_EVAL_AT=700
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ TARGET_DIR=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
running benchmark
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 3 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' 800 -gt 100 ']'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 6 ']'
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ SEED=-1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR=1.5
running benchmark
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ SEED=-1
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ TARGET_DIR=
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ EVALUATE_EVERY=14
running benchmark
+ OPTIMIZER=nag
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR=1.5
running benchmark
+ SEED=-1
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
+ echo 'running benchmark'
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
+ SEED=-1
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 0 ']'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ BATCH_SIZE=1
+ '[' -n 7 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
running benchmark
+ echo 'running benchmark'
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 6 ']'
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 1 ']'
+ PROFILING_PREFIX=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ declare -a CMD
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
running benchmark
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
running benchmark
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ declare -a CMD
+ declare -a CMD
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 0 ']'
+ DATASET_DIR=/data
+ SEED=-1
+ SEED=-1
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ OPTIMIZER=nag
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' -n 4 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ DATASET_DIR=/data
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ SEED=-1
running benchmark
+ PROFILING_PREFIX=
running benchmark
+ '[' '' = apiLog.sh ']'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
running benchmark
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
running benchmark
+ DATASET_DIR=/data
+ START_EVAL_AT=700
running benchmark
+ SEED=-1
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ TARGET_DIR=
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ QUALITY_THRESHOLD=0.908
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ '[' 800 -gt 100 ']'
running benchmark
+ START_EVAL_AT=700
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ declare -a CMD
running benchmark
+ '[' -n 0 ']'
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ SEED=-1
+ VAL_BATCH_SIZE=1
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR=1.5
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR=1.5
+ SEED=-1
+ echo 'running benchmark'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ '[' -n 5 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ SEED=-1
+ LR=1.5
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
running benchmark
+ '[' -n 2 ']'
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ LR=1.5
+ PROFILING_PREFIX=
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ MAX_EPOCHS=7000
+ declare -a CMD
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ BATCH_SIZE=1
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ '[' -n 0 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ cluster=
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ declare -a CMD
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 7 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
running benchmark
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
running benchmark
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ '[' -n 1 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ cluster=
+ '[' 800 -gt 100 ']'
running benchmark
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ declare -a CMD
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ '[' -n 4 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 2 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ PROFILING_PREFIX=
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
running benchmark
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ '[' -n 7 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ '[' -n 1 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ '[' -n 0 ']'
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ cluster=
+ cluster=
+ declare -a CMD
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 3 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ cluster=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 2 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
running benchmark
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
running benchmark
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' -n 4 ']'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
running benchmark
+ SEED=-1
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ SEED=-1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' -n 1 ']'
running benchmark
+ echo 'running benchmark'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ cluster=
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
running benchmark
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 0 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 3 ']'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' -n 0 ']'
+ TARGET_DIR=
+ '[' -n 1 ']'
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
running benchmark
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
running benchmark
+ PROFILING_PREFIX=
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 0 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 7 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ declare -a CMD
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ '[' -n 5 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ '[' -n 1 ']'
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ '[' -n 2 ']'
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 6 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' -n 6 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ cluster=
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 3 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ QUALITY_THRESHOLD=0.908
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ declare -a CMD
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ PROFILING_PREFIX=
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ TARGET_DIR=
+ '[' -n 1 ']'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ '[' -n 3 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ '[' -n 1 ']'
+ declare -a CMD
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ '[' -n 3 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 0 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
running benchmark
+ MAX_EPOCHS=7000
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ cluster=selene
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ declare -a CMD
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 7 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ declare -a CMD
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ SEED=-1
+ SEED=-1
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 2 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ LR=1.5
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
running benchmark
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 5 ']'
+ DATASET_DIR=/data
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
running benchmark
+ SEED=-1
+ declare -a CMD
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' -n 1 ']'
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 1 ']'
+ START_EVAL_AT=700
+ SEED=-1
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ OPTIMIZER=nag
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ '[' -n 0 ']'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ EVALUATE_EVERY=14
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ cluster=
+ TARGET_DIR=
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ cluster=
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 0 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 6 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
running benchmark
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 3 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ declare -a CMD
+ '[' -n 1 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ '[' -n 1 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ '[' -n 4 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
+ '[' -n 1 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
running benchmark
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' 800 -gt 100 ']'
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR=1.5
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
running benchmark
+ TARGET_DIR=
+ '[' -n 4 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 3 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' -n 6 ']'
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
running benchmark
+ '[' -n 2 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 1 ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ cluster=selene
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
running benchmark
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 6 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ '[' -n 5 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ TARGET_DIR=
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ '[' -n 6 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 6 ']'
+ SEED=-1
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 1 ']'
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 3 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' -n 7 ']'
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ '[' -n 7 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ SEED=-1
running benchmark
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ declare -a CMD
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ BATCH_SIZE=1
running benchmark
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ SEED=-1
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ '[' -n 4 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 6 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 3 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' -n 4 ']'
+ cluster=
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 4 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ declare -a CMD
+ MAX_EPOCHS=7000
+ declare -a CMD
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 7 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 1 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 5 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' -n 0 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ TARGET_DIR=
running benchmark
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ SEED=-1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' -n 3 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ '[' -n 4 ']'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 0 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 4 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ BATCH_SIZE=1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 0 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ TARGET_DIR=
+ '[' -n 2 ']'
+ SEED=-1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ declare -a CMD
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ SEED=-1
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' -n 5 ']'
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' -n 0 ']'
+ EVALUATE_EVERY=14
+ '[' -n 1 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ cluster=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 7 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ declare -a CMD
+ EVALUATE_EVERY=14
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 6 ']'
+ PROFILING_PREFIX=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' -n 2 ']'
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ '[' '' = apiLog.sh ']'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ declare -a CMD
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ TARGET_DIR=
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 6 ']'
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 7 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 2 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ QUALITY_THRESHOLD=0.908
running benchmark
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
running benchmark
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ TARGET_DIR=
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' -n 7 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ '[' -n 1 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 2 ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 2 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 6 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ SEED=-1
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
+ TARGET_DIR=
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
running benchmark
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
running benchmark
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' -n 0 ']'
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ SEED=-1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ OPTIMIZER=nag
+ '[' -n 1 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ cluster=
running benchmark
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ '[' -n 3 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ cluster=selene
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
running benchmark
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=selene
+ VAL_BATCH_SIZE=1
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' -n 3 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 6 ']'
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
running benchmark
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
running benchmark
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
running benchmark
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
running benchmark
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
running benchmark
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ TARGET_DIR=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 0 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 6 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ declare -a CMD
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ '[' -n 5 ']'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ declare -a CMD
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 0 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ '[' -n 5 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ DATASET_DIR=/data
+ SEED=-1
+ LR=1.5
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
running benchmark
+ cluster=selene
+ EVALUATE_EVERY=14
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 4 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
running benchmark
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 7 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
running benchmark
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
running benchmark
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 0 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ echo 'running benchmark'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ DATASET_DIR=/data
+ DATASET_DIR=/data
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
running benchmark
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ LR=1.5
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
running benchmark
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ cluster=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ TARGET_DIR=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 7 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
running benchmark
+ TARGET_DIR=
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ '[' -n 1 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
+ declare -a CMD
running benchmark
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ cluster=
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ LR=1.5
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 6 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' -n 5 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 4 ']'
+ cluster=
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ '[' -n 7 ']'
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 3 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 2 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ '[' -n 5 ']'
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' -n 4 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ DATASET_DIR=/data
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ '[' -n 6 ']'
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ cluster=
running benchmark
+ LR=1.5
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ EVALUATE_EVERY=14
+ cluster=selene
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 1 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 0 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' -n 7 ']'
+ cluster=
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 5 ']'
running benchmark
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ cluster=
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ DATASET_DIR=/data
+ TARGET_DIR=
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 6 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ DATASET_DIR=/data
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
running benchmark
+ LR=1.5
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
running benchmark
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 4 ']'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 0 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
+ SEED=-1
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ declare -a CMD
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' -n 6 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ '[' -n 1 ']'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' -n 5 ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 5 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 1 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ EVALUATE_EVERY=14
running benchmark
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 0 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
running benchmark
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' -n 4 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ declare -a CMD
+ PROFILING_PREFIX=
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
running benchmark
+ QUALITY_THRESHOLD=0.908
+ '[' -n 3 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ SEED=-1
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ OPTIMIZER=nag
+ declare -a CMD
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 2 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 6 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ PROFILING_PREFIX=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ declare -a CMD
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ declare -a CMD
+ DATASET_DIR=/data
+ '[' -n 1 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ cluster=
+ declare -a CMD
+ EVALUATE_EVERY=14
running benchmark
+ TARGET_DIR=
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ SEED=-1
+ declare -a CMD
running benchmark
+ OPTIMIZER=nag
+ '[' -n 5 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 0 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR=1.5
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR=1.5
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ '[' -n 7 ']'
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ DATASET_DIR=/data
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ SEED=-1
+ TARGET_DIR=
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ TARGET_DIR=
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ TARGET_DIR=
+ cluster=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=selene
+ SEED=-1
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
running benchmark
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ TARGET_DIR=
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 7 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ SEED=-1
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 0 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' -n 1 ']'
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 4 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ SEED=-1
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
running benchmark
+ '[' -n 4 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ DATASET_DIR=/data
+ TARGET_DIR=
+ SEED=-1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ '[' -n 3 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ DATASET_DIR=/data
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ '[' -n 0 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' -n 1 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 1 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 2 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
running benchmark
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
running benchmark
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' -n 6 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 7 ']'
+ DATASET_DIR=/data
running benchmark
+ '[' 800 -gt 100 ']'
+ SEED=-1
running benchmark
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
running benchmark
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ '[' -n 6 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 6 ']'
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ TARGET_DIR=
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
running benchmark
+ LR=1.5
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 0 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ cluster=selene
running benchmark
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
running benchmark
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' -n 3 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
running benchmark
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 3 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' -n 0 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ cluster=selene
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 2 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ declare -a CMD
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 3 ']'
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 1 ']'
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ LR=1.5
running benchmark
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 7 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ declare -a CMD
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 6 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
running benchmark
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ VAL_BATCH_SIZE=1
running benchmark
+ TARGET_DIR=
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ '[' -n 1 ']'
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ declare -a CMD
+ DATASET_DIR=/data
+ '[' -n 1 ']'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ cluster=selene
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ '[' -n 2 ']'
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 7 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ TARGET_DIR=
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ SEED=-1
+ SEED=-1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ TARGET_DIR=
+ TARGET_DIR=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ '[' -n 0 ']'
running benchmark
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 1 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
running benchmark
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ '[' -n 4 ']'
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 1 ']'
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 6 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ TARGET_DIR=
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' -n 2 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 4 ']'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 2 ']'
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ cluster=
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ declare -a CMD
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ LR=1.5
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ '[' -n 7 ']'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ SEED=-1
+ '[' -n 7 ']'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR=1.5
+ SEED=-1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 0 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ '[' -n 4 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 1 ']'
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ SEED=-1
+ START_EVAL_AT=700
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 3 ']'
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 0 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
+ declare -a CMD
+ '[' -n 2 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ declare -a CMD
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' -n 7 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 2 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ '[' -n 0 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 7 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' -n 3 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ '[' -n 4 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
running benchmark
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 6 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ TARGET_DIR=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ TARGET_DIR=
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' -n 7 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' -n 0 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 6 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 4 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 1 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ EVALUATE_EVERY=14
+ '[' -n 6 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 6 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 5 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ declare -a CMD
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 1 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
running benchmark
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 5 ']'
+ VAL_BATCH_SIZE=1
+ '[' -n 2 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 3 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ DATASET_DIR=/data
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
running benchmark
num_sockets = 2 num_nodes=8 cores_per_socket=64
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' -n 6 ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 09:41:10 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
:::MLLOG {"namespace": "", "time_ms": 1621442472690, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 30}}
:::MLLOG {"namespace": "", "time_ms": 1621442472732, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 31}}
:::MLLOG {"namespace": "", "time_ms": 1621442472732, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 101}}
:::MLLOG {"namespace": "", "time_ms": 1621442472733, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "nvidia", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 106}}
:::MLLOG {"namespace": "", "time_ms": 1621442472733, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 110}}
:::MLLOG {"namespace": "", "time_ms": 1621442472733, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 114}}
:::MLLOG {"namespace": "", "time_ms": 1621442472733, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "100xNVIDIA DGX A100", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 118}}
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[09:41:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[luna-0061:0:3695315 - context.c:581] INFO job (ID: 17873379022534284900) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0061:0:3695315 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x11 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0061:0:3695315 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x50 caps:0x16
[luna-0061:0:3695315 - comm.c:385] INFO [group#:0] group id:18 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xc71500000018) mlid:c016
[luna-0061:0:3695315 - comm.c:385] INFO [group#:1] group id:18 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0061:0:3695316 - context.c:581] INFO job (ID: 17873379397554147713) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0061:0:3695316 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x10 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0061:0:3695316 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x4f caps:0x16
[luna-0061:0:3695316 - comm.c:385] INFO [group#:0] group id:19 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xc81500000019) mlid:c017
[luna-0061:0:3695316 - comm.c:385] INFO [group#:1] group id:19 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0061:0:3695308 - context.c:581] INFO job (ID: 17873378569356856579) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0061:0:3695308 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x16 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0061:0:3695308 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x55 caps:0x16
[luna-0061:0:3695308 - comm.c:385] INFO [group#:0] group id:1a tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xc9150000001a) mlid:c018
[luna-0061:0:3695308 - comm.c:385] INFO [group#:1] group id:1a tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0061:0:3695301 - context.c:581] INFO job (ID: 17873379432819305411) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0061:0:3695301 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x14 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0061:0:3695301 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x53 caps:0x16
[luna-0061:0:3695301 - comm.c:385] INFO [group#:0] group id:1b tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xca150000001b) mlid:c019
[luna-0061:0:3695301 - comm.c:385] INFO [group#:1] group id:1b tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0061:0:3695311 - context.c:581] INFO job (ID: 17873379102089775301) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0061:0:3695311 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x13 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0061:0:3695311 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x52 caps:0x16
[luna-0061:0:3695311 - comm.c:385] INFO [group#:0] group id:1c tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xcb150000001c) mlid:c01a
[luna-0061:0:3695311 - comm.c:385] INFO [group#:1] group id:1c tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0061:0:3695314 - context.c:581] INFO job (ID: 17873378471238448288) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0061:0:3695314 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x15 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0061:0:3695314 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x54 caps:0x16
[luna-0061:0:3695314 - comm.c:385] INFO [group#:0] group id:1d tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xcc150000001d) mlid:c01b
[luna-0061:0:3695314 - comm.c:385] INFO [group#:1] group id:1d tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0061:0:3695309 - context.c:581] INFO job (ID: 17873378728486982808) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0061:0:3695309 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x1c caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0061:0:3695309 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x5b caps:0x16
[luna-0061:0:3695309 - comm.c:385] INFO [group#:0] group id:1e tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xcd150000001e) mlid:c01c
[luna-0061:0:3695309 - comm.c:385] INFO [group#:1] group id:1e tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0061:0:3695293 - context.c:581] INFO job (ID: 17873378686090842826) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0061:0:3695293 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x1e caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0061:0:3695293 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x5d caps:0x16
[luna-0061:0:3695293 - comm.c:385] INFO [group#:0] group id:1f tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xce150000001f) mlid:c01d
[luna-0061:0:3695293 - comm.c:385] INFO [group#:1] group id:1f tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
Using random master seed: 4118531916. Worker seeds 640: [2298406267, 2623971909, 527321106, 423817774, 71518628, 2313697302, 2367252236, 4161516893, 737361860, 2374946715, 3112695597, 2114399089, 3958697042, 1959960372, 2775118690, 4119576055, 3195928840, 2278708655, 3186732051, 2954697271, 2470236741, 1109040967, 3692552574, 3329080521, 720314240, 2990587701, 1719901378, 3855798856, 4122888395, 1232424739, 4180045130, 1891063103, 2160739288, 2592863939, 457310215, 2301442178, 3706959592, 2241025598, 51729101, 1481037988, 3363877478, 212606429, 2260718603, 829951606, 850584529, 3668404128, 2193199410, 3251982716, 247222979, 563823736, 964205959, 2723997665, 3098453371, 4119673246, 1151308849, 649015308, 900417642, 552412248, 1951590518, 2395392267, 1020642129, 905574747, 113612440, 952445186, 1097658107, 2499061885, 406301673, 2156194432, 2793126214, 631422370, 145245246, 2178494478, 4060354878, 234923213, 1021195036, 3588050239, 3713842812, 4059082595, 1489874070, 2863339340, 3268107875, 2245202145, 30838642[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
20, 223279377, 582918977, 4239781263, 3338361302, 1084349464, 3713456668, 1844511296, 1757423238, 2245278930, 2700698952, 1802188825, 1423842138, 1442426440, 1561636861, 4009781944, 741115237, 2723638842, 906513482, 3532119565, 17280590, 2029688437, 935806079, 3634028026, 3111959252, 201743975, 2114704714, 912135097, 2102689954, 1985415498, 2009021144, 2157315535, 1559683330, 4078152025, 146226846, 1949078312, 2540347082, 645394372, 3690407545, 598040737, 322930076, 1232497812, 2214714655, 2655208253, 2452549803, 4231005673, 719649496, 4034686282, 2153974524, 917594718, 2978395331, 1010175081, 505622981, 4069766520, 984582583, 1563029587, 1514516215, 2982264659, 4179399938, 1243175168, 3270461710, 364195078, 2239449491, 249784208, 629456193, 2960039749, 1035246347, 517567635, 3719271078, 953231782, 2572545821, 1816626736, 3288860879, 494228965, 2229351865, 3414095242, 159987826, 3955707022, 1416310161, 2386093707, 3187483236, 3558594848, 1064376921, 501888416, 2400248964, 1536622963, 2278274030, 2161525635, 4[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
130508786, 2722039497, 729070778, 83986247, 53643285, 2521922194, 593556940, 1890768998, 1171592994, 213892388, 70272131, 2590966048, 910476062, 250242506, 952545089, 154957879, 647135930, 746520612, 1762650787, 4068798409, 2907615425, 2733221323, 2965522005, 3427943863, 1943129278, 3965137266, 1890789515, 1293150985, 412713357, 297485770, 2606644470, 2436379022, 2532341977, 1122039097, 413505620, 293838744, 3001861829, 770443599, 4091568203, 1673883810, 2613751945, 702274973, 2108349170, 2631718901, 4185932531, 849189039, 2812407213, 1259283605, 2816095148, 3487555249, 1479327057, 3674666386, 2226112576, 882231327, 761355383, 1125622041, 3358699776, 3185446611, 4039713852, 1101270581, 3664051329, 3522752761, 4147318266, 1754346423, 3824546366, 793043609, 1059544289, 1309139125, 113925230, 1452641017, 3763686304, 3283224885, 1219599358, 3530403204, 124774648, 1219088562, 3774629151, 3222449634, 4227513641, 141010158, 2885675905, 533071139, 736216360, 152848255, 3755645738, 1579866097, 3614559157, 37472441, 24[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
17981830, 2753308115, 1593911111, 735549938, 54730871, 1448519317, 1899041634, 2561424139, 1876420458, 665030258, 3378806097, 4264570025, 3699140012, 1522046710, 39735769, 2106321256, 1746089505, 2001760589, 4046614688, 1129696344, 2708560840, 661224300, 559336763, 1127039321, 427631022, 3671951552, 3954758024, 1023704211, 3686813574, 3057494482, 3982593901, 491113696, 1314896637, 1746218171, 1330098344, 2417126844, 399740290, 827162441, 1121191334, 3234975534, 1095503947, 1266158306, 2965048649, 2886314698, 2062142889, 3901864294, 634597796, 939617641, 2018820470, 2754921196, 1728087452, 1798270841, 449961086, 1793437373, 3839650996, 3233240791, 1524781874, 2684512110, 1255313666, 3884469644, 953868450, 1867348701, 4155010402, 1653405505, 2730598371, 656537154, 1218935220, 572700504, 3814425308, 482722517, 3252781237, 3510181253, 259398387, 1208522574, 1793898862, 4245655260, 1976421669, 61728728, 266436149, 2320866748, 2700266230, 854693171, 226204766, 329041564, 860303496, 3832172568, 1444195359, 332364422[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
5, 1693406521, 376968432, 2173824326, 455430709, 827929013, 2095150314, 1417790175, 850207898, 3602859869, 4214232162, 2272710406, 3776009734, 2643413900, 3873981971, 3634922836, 1396427992, 2058565625, 2148096268, 96365134, 3746830796, 1992393925, 1639235921, 1881694125, 842876951, 1031857005, 1201378225, 2979654910, 3216789142, 931429722, 2723245217, 3859398354, 621178455, 4218363287, 2134768980, 2056661126, 2525377814, 2620777327, 3817784071, 523598313, 2423991930, 3030430719, 1286316304, 622780973, 2748168008, 432406905, 3720560813, 3337382543, 3338528370, 1589414563, 2276728733, 2571594291, 1233974584, 3379960925, 1594404593, 1748236461, 750745776, 3364139454, 2831053460, 623256305, 436506418, 1398228606, 400684020, 2836157339, 2765139666, 635189100, 1394648188, 3462249649, 1128660341, 3470034438, 653355994, 1286907153, 797025024, 1106765352, 2669732629, 1124566667, 4204950369, 1417401216, 3300068962, 1677996226, 1022708962, 1303509959, 317971392, 2012900378, 3763185513, 3915073049, 1710253119, 147924742[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
4, 1400145694, 3654449284, 609581253, 4106491292, 3227914838, 2158120299, 2479798353, 1414714192, 3508941196, 1749994371, 3846941900, 380485655, 3091741402, 320548163, 2259162770, 2251691280, 1772206652, 861703682, 1947730577, 3970329621, 79586134, 1126717379, 2253525550, 245451247, 3569039838, 4093227375, 4051080729, 2621872159, 4172603596, 967326860, 3209527752, 3939254684, 2358044075, 1634533850, 2514008728, 238465487, 4043831884, 407806659, 878434982, 4191285661, 3031014971, 2442486706, 576869418, 3613874409, 85555837, 1551953526, 2572072875, 1355922735, 2155860200, 495719731, 2902174641, 221780358, 3658660803, 2769958436, 4249261252, 435484433, 1445812919, 1708259411, 2228114242, 2019505358, 2437398084, 852188992, 3269740157, 2911400145, 3258357523, 810108684, 4014098348, 621532907, 3935175022, 888164940, 1119990916, 2789295362, 3628729112, 3309389228, 944678297, 3666348193, 2851637212, 3637651836, 2094032691, 1677006162, 293955765, 3749470627, 1045897651, 3949032467, 2665928548, 1785536502, 3661157094, [09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
3217283005, 946433212, 3581252498, 1542467911, 1849643196, 3796604585, 4244257877, 3380582307, 213661786, 2413018679, 92459556, 2842441642, 1385723274, 3980383215, 2763624743, 2468740074, 1996044899, 1132323957, 3252572541, 329700358, 1608887572, 2904911985, 2775076309, 28155524, 3727541188, 1474801127, 427510458, 3698079708, 2722855971, 4075562517, 2390156337, 1032310011, 968926571, 959564915, 69249948, 2446489795, 3148903379, 2786505977, 3836385150, 3033016461, 1573232249, 2340915002, 3518971064, 513457874, 2954088084, 735385730, 4015662940, 4226439767, 1680936969, 3884860821, 2683299475, 3135892383, 1433886842, 1966718484, 1490195732, 807205635, 1739572557, 3921974036, 331448014, 2757774154, 1439670885, 803878655, 91103166, 2584168658, 1327711140, 1503879190, 750384431, 3065452554, 1592264814, 4032967709, 2280177407, 2374704202, 1268846511, 897607680, 1825464655, 2761325497, 4228111861, 3667205457, 995991966, 44463570, 2504108709, 1630764351, 941334735, 530856105, 885636729, 3091302182, 3299458987, 3253926[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
051, 1038446975, 3273099279, 3997860620, 3390007289, 145961093, 58016746, 3636398982, 2817449477, 4015095718, 1334193879, 2657198700, 1930147355, 1638509131, 1157820566, 755121500, 1642006151, 1644490749, 4214526768, 3925424685, 3161151755, 760843589, 3946220906, 2231001476, 3319741984, 2339794857, 81347992, 1199257057, 1823721402, 3696148181, 3719910451, 1845843752, 4276972690]
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 8. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 9. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 10. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 14. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 11. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 12. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 15. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 13. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 16. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 22. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 21. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 18. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 20. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 23. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 17. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 19. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 26. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 31. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 25. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 28. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 29. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 24. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 27. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 30. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 36. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 37. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 32. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 33. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 34. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 35. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 38. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 39. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 40. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 42. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 46. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 47. SEED 2298406267
[09:46:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 45. SEED 2298406267
RANK 44. SEED 2298406267
RANK 41. SEED 2298406267
RANK 43. SEED 2298406267
RANK 50. SEED 2298406267
RANK 48. SEED 2298406267
RANK 49. SEED 2298406267
RANK 54. SEED 2298406267
RANK 55. SEED 2298406267
RANK 52. SEED 2298406267
RANK 53. SEED 2298406267
RANK 51. SEED 2298406267
RANK 56. SEED 2298406267
RANK 61. SEED 2298406267
RANK 60. SEED 2298406267
RANK 58. SEED 2298406267
RANK 59. SEED 2298406267
RANK 62. SEED 2298406267
RANK 63. SEED 2298406267
RANK 57. SEED 2298406267
RANK 69. SEED 2298406267
RANK 64. SEED 2298406267
RANK 65. SEED 2298406267
RANK 66. SEED 2298406267
RANK 68. SEED 2298406267
RANK 71. SEED 2298406267
RANK 67. SEED 2298406267
RANK 70. SEED 2298406267
RANK 76. SEED 2298406267
RANK 72. SEED 2298406267
RANK 79. SEED 2298406267
RANK 75. SEED 2298406267
RANK 78. SEED 2298406267
RANK 73. SEED 2298406267
RANK 74. SEED 2298406267
RANK 77. SEED 2298406267
RANK 82. SEED 2298406267
RANK 81. SEED 2298406267
RANK 85. SEED 2298406267
RANK 83. SEED 2298406267
RANK 86. SEED 2298406267
RANK 84. SEED 2298406267
RANK 80. SEED 2298406267
RANK 87. SEED 2298406267
RANK 94. SEED 2298406267
RANK 88. SEED 2298406267
RANK 92. SEED 2298406267
RANK 89. SEED 2298406267
RANK 90. SEED 2298406267
RANK 91. SEED 2298406267
RANK 95. SEED 2298406267
RANK 93. SEED 2298406267
RANK 96. SEED 2298406267
RANK 97. SEED 2298406267
RANK 103. SEED 2298406267
RANK 100. SEED 2298406267
RANK 102. SEED 2298406267
RANK 99. SEED 2298406267
RANK 101. SEED 2298406267
RANK 98. SEED 2298406267
RANK 104. SEED 2298406267
RANK 106. SEED 2298406267
RANK 107. SEED 2298406267
RANK 109. SEED 2298406267
RANK 108. SEED 2298406267
RANK 110. SEED 2298406267
RANK 111. SEED 2298406267
RANK 105. SEED 2298406267
RANK 115. SEED 2298406267
RANK 117. SEED 2298406267
RANK 116. SEED 2298406267
RANK 118. SEED 2298406267
RANK 119. SEED 2298406267
RANK 112. SEED 2298406267
RANK 113. SEED 2298406267
RANK 114. SEED 2298406267
RANK 122. SEED 2298406267
RANK 125. SEED 2298406267
RANK 121. SEED 2298406267
RANK 123. SEED 2298406267
RANK 127. SEED 2298406267
RANK 126. SEED 2298406267
RANK 120. SEED 2298406267
RANK 124. SEED 2298406267
RANK 130. SEED 2298406267
RANK 129. SEED 2298406267
RANK 134. SEED 2298406267
RANK 128. SEED 2298406267
RANK 133. SEED 2298406267
RANK 131. SEED 2298406267
RANK 135. SEED 2298406267
RANK 132. SEED 2298406267
RANK 140. SEED 2298406267
RANK 136. SEED 2298406267
RANK 138. SEED 2298406267
RANK 142. SEED 2298406267
RANK 137. SEED 2298406267
RANK 139. SEED 2298406267
RANK 141. SEED 2298406267
RANK 143. SEED 2298406267
RANK 145. SEED 2298406267
RANK 148. SEED 2298406267
RANK 144. SEED 2298406267
RANK 147. SEED 2298406267
RANK 149. SEED 2298406267
RANK 151. SEED 2298406267
RANK 146. SEED 2298406267
RANK 150. SEED 2298406267
RANK 156. SEED 2298406267
RANK 157. SEED 2298406267
RANK 152. SEED 2298406267
RANK 159. SEED 2298406267
RANK 158. SEED 2298406267
RANK 155. SEED 2298406267
RANK 153. SEED 2298406267
RANK 154. SEED 2298406267
RANK 165. SEED 2298406267
RANK 167. SEED 2298406267
RANK 166. SEED 2298406267
RANK 160. SEED 2298406267
RANK 161. SEED 2298406267
RANK 162. SEED 2298406267
RANK 164. SEED 2298406267
RANK 163. SEED 2298406267
RANK 5. SEED 2298406267
RANK 6. SEED 2298406267
RANK 0. SEED 2298406267
RANK 7. SEED 2298406267
RANK 1. SEED 2298406267
RANK 3. SEED 2298406267
:::MLLOG {"namespace": "", "time_ms": 1621442790190, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2298406267, "metadata": {"file": "main.py", "lineno": 57}}
:::MLLOG {"namespace": "", "time_ms": 1621442790190, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
RANK 2. SEED 2298406267
RANK 4. SEED 2298406267
:::MLLOG {"namespace": "", "time_ms": 1621442790190, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 125}}
:::MLLOG {"namespace": "", "time_ms": 1621442790191, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1000, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 126}}
:::MLLOG {"namespace": "", "time_ms": 1621442790191, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1621442790191, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 129}}
:::MLLOG {"namespace": "", "time_ms": 1621442790191, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 130}}
:::MLLOG {"namespace": "", "time_ms": 1621442790191, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 131}}
:::MLLOG {"namespace": "", "time_ms": 1621442790191, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
:::MLLOG {"namespace": "", "time_ms": 1621442790191, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 133}}
:::MLLOG {"namespace": "", "time_ms": 1621442790191, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 134}}
:::MLLOG {"namespace": "", "time_ms": 1621442790191, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 135}}
RANK 170. SEED 2298406267
RANK 169. SEED 2298406267
RANK 172. SEED 2298406267
RANK 174. SEED 2298406267
RANK 175. SEED 2298406267
RANK 168. SEED 2298406267
RANK 173. SEED 2298406267
RANK 171. SEED 2298406267
RANK 177. SEED 2298406267
RANK 180. SEED 2298406267
RANK 181. SEED 2298406267
RANK 182. SEED 2298406267
RANK 183. SEED 2298406267
RANK 178. SEED 2298406267
RANK 179. SEED 2298406267
RANK 176. SEED 2298406267
RANK 189. SEED 2298406267
RANK 186. SEED 2298406267
RANK 191. SEED 2298406267
RANK 187. SEED 2298406267
RANK 190. SEED 2298406267
RANK 184. SEED 2298406267
RANK 185. SEED 2298406267
RANK 188. SEED 2298406267
RANK 194. SEED 2298406267
RANK 193. SEED 2298406267
RANK 192. SEED 2298406267
RANK 196. SEED 2298406267
RANK 197. SEED 2298406267
RANK 198. SEED 2298406267
RANK 195. SEED 2298406267
RANK 199. SEED 2298406267
RANK 205. SEED 2298406267
RANK 200. SEED 2298406267
RANK 204. SEED 2298406267
RANK 203. SEED 2298406267
RANK 201. SEED 2298406267
RANK 206. SEED 2298406267
RANK 202. SEED 2298406267
RANK 207. SEED 2298406267
RANK 212. SEED 2298406267
RANK 213. SEED 2298406267
RANK 210. SEED 2298406267
RANK 215. SEED 2298406267
RANK 211. SEED 2298406267
RANK 208. SEED 2298406267
RANK 209. SEED 2298406267
RANK 214. SEED 2298406267
RANK 217. SEED 2298406267
RANK 220. SEED 2298406267
RANK 222. SEED 2298406267
RANK 216. SEED 2298406267
RANK 218. SEED 2298406267
RANK 219. SEED 2298406267
RANK 221. SEED 2298406267
RANK 223. SEED 2298406267
RANK 224. SEED 2298406267
RANK 226. SEED 2298406267
RANK 227. SEED 2298406267
RANK 225. SEED 2298406267
RANK 229. SEED 2298406267
RANK 228. SEED 2298406267
RANK 230. SEED 2298406267
RANK 231. SEED 2298406267
RANK 238. SEED 2298406267
RANK 237. SEED 2298406267
RANK 233. SEED 2298406267
RANK 234. SEED 2298406267
RANK 239. SEED 2298406267
RANK 236. SEED 2298406267
RANK 232. SEED 2298406267
RANK 235. SEED 2298406267
RANK 247. SEED 2298406267
RANK 240. SEED 2298406267
RANK 244. SEED 2298406267
RANK 246. SEED 2298406267
RANK 243. SEED 2298406267
RANK 242. SEED 2298406267
RANK 241. SEED 2298406267
RANK 245. SEED 2298406267
RANK 250. SEED 2298406267
RANK 255. SEED 2298406267
RANK 252. SEED 2298406267
RANK 254. SEED 2298406267
RANK 248. SEED 2298406267
RANK 253. SEED 2298406267
RANK 251. SEED 2298406267
RANK 249. SEED 2298406267
RANK 261. SEED 2298406267
RANK 257. SEED 2298406267
RANK 260. SEED 2298406267
RANK 259. SEED 2298406267
RANK 262. SEED 2298406267
RANK 263. SEED 2298406267
RANK 258. SEED 2298406267
RANK 256. SEED 2298406267
RANK 268. SEED 2298406267
RANK 270. SEED 2298406267
RANK 266. SEED 2298406267
RANK 265. SEED 2298406267
RANK 269. SEED 2298406267
RANK 264. SEED 2298406267
RANK 271. SEED 2298406267
RANK 267. SEED 2298406267
RANK 272. SEED 2298406267
RANK 279. SEED 2298406267
RANK 273. SEED 2298406267
RANK 275. SEED 2298406267
RANK 276. SEED 2298406267
RANK 277. SEED 2298406267
RANK 278. SEED 2298406267
RANK 274. SEED 2298406267
RANK 280. SEED 2298406267
RANK 281. SEED 2298406267
RANK 283. SEED 2298406267
RANK 285. SEED 2298406267
RANK 287. SEED 2298406267
RANK 286. SEED 2298406267
RANK 282. SEED 2298406267
RANK 284. SEED 2298406267
RANK 293. SEED 2298406267
RANK 288. SEED 2298406267
RANK 292. SEED 2298406267
RANK 290. SEED 2298406267
RANK 291. SEED 2298406267
RANK 294. SEED 2298406267
RANK 289. SEED 2298406267
RANK 295. SEED 2298406267
RANK 301. SEED 2298406267
RANK 302. SEED 2298406267
RANK 296. SEED 2298406267
RANK 300. SEED 2298406267
RANK 303. SEED 2298406267
RANK 297. SEED 2298406267
RANK 299. SEED 2298406267
RANK 298. SEED 2298406267
RANK 309. SEED 2298406267
RANK 306. SEED 2298406267
RANK 308. SEED 2298406267
RANK 310. SEED 2298406267
RANK 305. SEED 2298406267
RANK 307. SEED 2298406267
RANK 311. SEED 2298406267
RANK 314. SEED 2298406267
RANK 317. SEED 2298406267
RANK 313. SEED 2298406267
RANK 316. SEED 2298406267
RANK 319. SEED 2298406267
RANK 315. SEED 2298406267
RANK 318. SEED 2298406267
RANK 312. SEED 2298406267
RANK 325. SEED 2298406267
RANK 321. SEED 2298406267
RANK 320. SEED 2298406267
RANK 324. SEED 2298406267
RANK 326. SEED 2298406267
RANK 327. SEED 2298406267
RANK 323. SEED 2298406267
RANK 322. SEED 2298406267
RANK 332. SEED 2298406267
RANK 329. SEED 2298406267
RANK 330. SEED 2298406267
RANK 333. SEED 2298406267
RANK 334. SEED 2298406267
RANK 335. SEED 2298406267
RANK 328. SEED 2298406267
RANK 331. SEED 2298406267
RANK 341. SEED 2298406267
RANK 337. SEED 2298406267
RANK 340. SEED 2298406267
RANK 336. SEED 2298406267
RANK 338. SEED 2298406267
RANK 339. SEED 2298406267
RANK 342. SEED 2298406267
RANK 343. SEED 2298406267
RANK 347. SEED 2298406267
RANK 344. SEED 2298406267
RANK 346. SEED 2298406267
RANK 348. SEED 2298406267
RANK 349. SEED 2298406267
RANK 350. SEED 2298406267
RANK 345. SEED 2298406267
RANK 351. SEED 2298406267
RANK 353. SEED 2298406267
RANK 354. SEED 2298406267
RANK 355. SEED 2298406267
RANK 352. SEED 2298406267
RANK 357. SEED 2298406267
RANK 358. SEED 2298406267
RANK 359. SEED 2298406267
RANK 356. SEED 2298406267
RANK 366. SEED 2298406267
RANK 362. SEED 2298406267
RANK 360. SEED 2298406267
RANK 364. SEED 2298406267
RANK 365. SEED 2298406267
RANK 367. SEED 2298406267
RANK 363. SEED 2298406267
RANK 361. SEED 2298406267
RANK 370. SEED 2298406267
RANK 369. SEED 2298406267
RANK 368. SEED 2298406267
RANK 371. SEED 2298406267
RANK 373. SEED 2298406267
RANK 374. SEED 2298406267
RANK 372. SEED 2298406267
RANK 375. SEED 2298406267
RANK 377. SEED 2298406267
RANK 383. SEED 2298406267
RANK 382. SEED 2298406267
RANK 376. SEED 2298406267
RANK 380. SEED 2298406267
RANK 381. SEED 2298406267
RANK 378. SEED 2298406267
RANK 379. SEED 2298406267
RANK 304. SEED 2298406267
RANK 389. SEED 2298406267
RANK 390. SEED 2298406267
RANK 388. SEED 2298406267
RANK 391. SEED 2298406267
RANK 384. SEED 2298406267
RANK 386. SEED 2298406267
RANK 387. SEED 2298406267
RANK 385. SEED 2298406267
RANK 394. SEED 2298406267
RANK 399. SEED 2298406267
RANK 395. SEED 2298406267
RANK 397. SEED 2298406267
RANK 392. SEED 2298406267
RANK 398. SEED 2298406267
RANK 396. SEED 2298406267
RANK 393. SEED 2298406267
RANK 400. SEED 2298406267
RANK 402. SEED 2298406267
RANK 403. SEED 2298406267
RANK 405. SEED 2298406267
RANK 406. SEED 2298406267
RANK 401. SEED 2298406267
RANK 404. SEED 2298406267
RANK 407. SEED 2298406267
RANK 408. SEED 2298406267
RANK 409. SEED 2298406267
RANK 410. SEED 2298406267
RANK 412. SEED 2298406267
RANK 413. SEED 2298406267
RANK 414. SEED 2298406267
RANK 415. SEED 2298406267
RANK 411. SEED 2298406267
RANK 417. SEED 2298406267
RANK 418. SEED 2298406267
RANK 422. SEED 2298406267
RANK 423. SEED 2298406267
RANK 419. SEED 2298406267
RANK 420. SEED 2298406267
RANK 421. SEED 2298406267
RANK 416. SEED 2298406267
RANK 424. SEED 2298406267
RANK 429. SEED 2298406267
RANK 428. SEED 2298406267
RANK 430. SEED 2298406267
RANK 431. SEED 2298406267
RANK 426. SEED 2298406267
RANK 425. SEED 2298406267
RANK 427. SEED 2298406267
RANK 432. SEED 2298406267
RANK 438. SEED 2298406267
RANK 436. SEED 2298406267
RANK 437. SEED 2298406267
RANK 433. SEED 2298406267
RANK 435. SEED 2298406267
RANK 439. SEED 2298406267
RANK 434. SEED 2298406267
RANK 440. SEED 2298406267
RANK 441. SEED 2298406267
RANK 446. SEED 2298406267
RANK 442. SEED 2298406267
RANK 445. SEED 2298406267
RANK 447. SEED 2298406267
RANK 443. SEED 2298406267
RANK 444. SEED 2298406267
RANK 455. SEED 2298406267
RANK 453. SEED 2298406267
RANK 454. SEED 2298406267
RANK 449. SEED 2298406267
RANK 448. SEED 2298406267
RANK 450. SEED 2298406267
RANK 452. SEED 2298406267
RANK 451. SEED 2298406267
RANK 461. SEED 2298406267
RANK 463. SEED 2298406267
RANK 460. SEED 2298406267
RANK 462. SEED 2298406267
RANK 456. SEED 2298406267
RANK 457. SEED 2298406267
RANK 459. SEED 2298406267
RANK 458. SEED 2298406267
RANK 468. SEED 2298406267
RANK 465. SEED 2298406267
RANK 466. SEED 2298406267
RANK 469. SEED 2298406267
RANK 470. SEED 2298406267
RANK 471. SEED 2298406267
RANK 464. SEED 2298406267
RANK 467. SEED 2298406267
RANK 475. SEED 2298406267
RANK 477. SEED 2298406267
RANK 478. SEED 2298406267
RANK 473. SEED 2298406267
RANK 474. SEED 2298406267
RANK 476. SEED 2298406267
RANK 479. SEED 2298406267
RANK 472. SEED 2298406267
RANK 482. SEED 2298406267
RANK 485. SEED 2298406267
RANK 486. SEED 2298406267
RANK 487. SEED 2298406267
RANK 484. SEED 2298406267
RANK 480. SEED 2298406267
RANK 483. SEED 2298406267
RANK 481. SEED 2298406267
RANK 494. SEED 2298406267
RANK 493. SEED 2298406267
RANK 489. SEED 2298406267
RANK 491. SEED 2298406267
RANK 492. SEED 2298406267
RANK 495. SEED 2298406267
RANK 488. SEED 2298406267
RANK 490. SEED 2298406267
RANK 497. SEED 2298406267
RANK 498. SEED 2298406267
RANK 502. SEED 2298406267
RANK 501. SEED 2298406267
RANK 503. SEED 2298406267
RANK 500. SEED 2298406267
RANK 496. SEED 2298406267
RANK 499. SEED 2298406267
RANK 509. SEED 2298406267
RANK 510. SEED 2298406267
RANK 506. SEED 2298406267
RANK 504. SEED 2298406267
RANK 507. SEED 2298406267
RANK 508. SEED 2298406267
RANK 511. SEED 2298406267
RANK 505. SEED 2298406267
RANK 515. SEED 2298406267
RANK 512. SEED 2298406267
RANK 518. SEED 2298406267
RANK 513. SEED 2298406267
RANK 517. SEED 2298406267
RANK 516. SEED 2298406267
RANK 514. SEED 2298406267
RANK 522. SEED 2298406267
RANK 525. SEED 2298406267
RANK 527. SEED 2298406267
RANK 523. SEED 2298406267
RANK 526. SEED 2298406267
RANK 520. SEED 2298406267
RANK 521. SEED 2298406267
RANK 524. SEED 2298406267
RANK 530. SEED 2298406267
RANK 529. SEED 2298406267
RANK 531. SEED 2298406267
RANK 533. SEED 2298406267
RANK 535. SEED 2298406267
RANK 532. SEED 2298406267
RANK 534. SEED 2298406267
RANK 528. SEED 2298406267
RANK 537. SEED 2298406267
RANK 538. SEED 2298406267
RANK 539. SEED 2298406267
RANK 541. SEED 2298406267
RANK 543. SEED 2298406267
RANK 542. SEED 2298406267
RANK 540. SEED 2298406267
RANK 536. SEED 2298406267
RANK 544. SEED 2298406267
RANK 545. SEED 2298406267
RANK 547. SEED 2298406267
RANK 546. SEED 2298406267
RANK 548. SEED 2298406267
RANK 549. SEED 2298406267
RANK 550. SEED 2298406267
RANK 551. SEED 2298406267
RANK 519. SEED 2298406267
RANK 557. SEED 2298406267
RANK 552. SEED 2298406267
RANK 553. SEED 2298406267
RANK 556. SEED 2298406267
RANK 558. SEED 2298406267
RANK 554. SEED 2298406267
RANK 559. SEED 2298406267
RANK 555. SEED 2298406267
RANK 561. SEED 2298406267
RANK 560. SEED 2298406267
RANK 562. SEED 2298406267
RANK 563. SEED 2298406267
RANK 564. SEED 2298406267
RANK 565. SEED 2298406267
RANK 567. SEED 2298406267
RANK 569. SEED 2298406267
RANK 572. SEED 2298406267
RANK 573. SEED 2298406267
RANK 574. SEED 2298406267
RANK 568. SEED 2298406267
RANK 570. SEED 2298406267
RANK 571. SEED 2298406267
RANK 575. SEED 2298406267
RANK 581. SEED 2298406267
RANK 577. SEED 2298406267
RANK 578. SEED 2298406267
RANK 582. SEED 2298406267
RANK 576. SEED 2298406267
RANK 579. SEED 2298406267
RANK 583. SEED 2298406267
RANK 580. SEED 2298406267
RANK 585. SEED 2298406267
RANK 586. SEED 2298406267
RANK 584. SEED 2298406267
RANK 588. SEED 2298406267
RANK 589. SEED 2298406267
RANK 590. SEED 2298406267
RANK 591. SEED 2298406267
RANK 587. SEED 2298406267
RANK 592. SEED 2298406267
RANK 594. SEED 2298406267
RANK 593. SEED 2298406267
RANK 597. SEED 2298406267
RANK 596. SEED 2298406267
RANK 598. SEED 2298406267
RANK 595. SEED 2298406267
RANK 599. SEED 2298406267
RANK 602. SEED 2298406267
RANK 605. SEED 2298406267
RANK 601. SEED 2298406267
RANK 603. SEED 2298406267
RANK 606. SEED 2298406267
RANK 604. SEED 2298406267
RANK 607. SEED 2298406267
RANK 600. SEED 2298406267
RANK 613. SEED 2298406267
RANK 608. SEED 2298406267
RANK 610. SEED 2298406267
RANK 611. SEED 2298406267
RANK 612. SEED 2298406267
RANK 614. SEED 2298406267
RANK 609. SEED 2298406267
RANK 615. SEED 2298406267
RANK 616. SEED 2298406267
RANK 618. SEED 2298406267
RANK 617. SEED 2298406267
RANK 619. SEED 2298406267
RANK 621. SEED 2298406267
RANK 623. SEED 2298406267
RANK 620. SEED 2298406267
RANK 622. SEED 2298406267
RANK 631. SEED 2298406267
RANK 628. SEED 2298406267
RANK 630. SEED 2298406267
RANK 625. SEED 2298406267
RANK 627. SEED 2298406267
RANK 624. SEED 2298406267
RANK 626. SEED 2298406267
RANK 629. SEED 2298406267
RANK 633. SEED 2298406267
RANK 632. SEED 2298406267
RANK 636. SEED 2298406267
RANK 638. SEED 2298406267
RANK 639. SEED 2298406267
RANK 634. SEED 2298406267
RANK 635. SEED 2298406267
RANK 637. SEED 2298406267
RANK 566. SEED 2298406267
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[09:46:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
:::MLLOG {"namespace": "", "time_ms": 1621442814736, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 99}}
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
:::MLLOG {"namespace": "", "time_ms": 1621442814746, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 101}}
RANK 8, VAL CASES ['00189', '00056']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 8, VAL CASES ['00189', '00056']
RANK 15, VAL CASES ['00005', '00024']
RANK 2, VAL CASES ['00169', '00206']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 2, VAL CASES ['00169', '00206']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 2, VAL CASES ['00169', '00206']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 8, VAL CASES ['00189', '00056']
RANK 2, VAL CASES ['00169', '00206']
RANK 2, VAL CASES ['00169', '00206']
RANK 8, VAL CASES ['00189', '00056']
RANK 13, VAL CASES ['00044', '00070']
RANK 2, VAL CASES ['00169', '00206']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 13, VAL CASES ['00044', '00070']
RANK 9, VAL CASES ['00198', '00203']
RANK 13, VAL CASES ['00044', '00070']
RANK 9, VAL CASES ['00198', '00203']
:::MLLOG {"namespace": "", "time_ms": 1621442814795, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 104}}
:::MLLOG {"namespace": "", "time_ms": 1621442814795, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 105}}
RANK 17, VAL CASES ['00084']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 17, VAL CASES ['00084']
RANK 11, VAL CASES ['00128', '00061']
RANK 17, VAL CASES ['00084']
RANK 17, VAL CASES ['00084']
RANK 17, VAL CASES ['00084']
RANK 10, VAL CASES ['00207', '00162']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 13, VAL CASES ['00044', '00070']
RANK 8, VAL CASES ['00189', '00056']
RANK 8, VAL CASES ['00189', '00056']
RANK 8, VAL CASES ['00189', '00056']
RANK 9, VAL CASES ['00198', '00203']
RANK 9, VAL CASES ['00198', '00203']
RANK 9, VAL CASES ['00198', '00203']
RANK 9, VAL CASES ['00198', '00203']
RANK 9, VAL CASES ['00198', '00203']
RANK 8, VAL CASES ['00189', '00056']
RANK 14, VAL CASES ['00034', '00076']
RANK 9, VAL CASES ['00198', '00203']
RANK 2, VAL CASES ['00169', '00206']
RANK 17, VAL CASES ['00084']
RANK 2, VAL CASES ['00169', '00206']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 17, VAL CASES ['00084']
RANK 17, VAL CASES ['00084']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 11, VAL CASES ['00128', '00061']
RANK 11, VAL CASES ['00128', '00061']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 11, VAL CASES ['00128', '00061']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 13, VAL CASES ['00044', '00070']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 11, VAL CASES ['00128', '00061']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 11, VAL CASES ['00128', '00061']
RANK 11, VAL CASES ['00128', '00061']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 13, VAL CASES ['00044', '00070']
RANK 13, VAL CASES ['00044', '00070']
RANK 12, VAL CASES ['00066', '00065']
RANK 19, VAL CASES ['00125']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 13, VAL CASES ['00044', '00070']
RANK 19, VAL CASES ['00125']
RANK 12, VAL CASES ['00066', '00065']
RANK 19, VAL CASES ['00125']
RANK 19, VAL CASES ['00125']
RANK 19, VAL CASES ['00125']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 16, VAL CASES ['00185']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 19, VAL CASES ['00125']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 16, VAL CASES ['00185']
RANK 16, VAL CASES ['00185']
RANK 16, VAL CASES ['00185']
RANK 16, VAL CASES ['00185']
RANK 16, VAL CASES ['00185']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 16, VAL CASES ['00185']
RANK 19, VAL CASES ['00125']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 19, VAL CASES ['00125']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 18, VAL CASES ['00176']
RANK 11, VAL CASES ['00128', '00061']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 16, VAL CASES ['00185']
RANK 18, VAL CASES ['00176']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 14, VAL CASES ['00034', '00076']
RANK 18, VAL CASES ['00176']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 18, VAL CASES ['00176']
RANK 18, VAL CASES ['00176']
RANK 18, VAL CASES ['00176']
RANK 18, VAL CASES ['00176']
RANK 18, VAL CASES ['00176']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
RANK 1, VAL CASES ['00000', '00003']
RANK 10, VAL CASES ['00207', '00162']
RANK 14, VAL CASES ['00034', '00076']
RANK 14, VAL CASES ['00034', '00076']
RANK 14, VAL CASES ['00034', '00076']
RANK 14, VAL CASES ['00034', '00076']
RANK 14, VAL CASES ['00034', '00076']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 14, VAL CASES ['00034', '00076']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 12, VAL CASES ['00066', '00065']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
EVALUATION TIME: 14.711 s.
EVAL WARMUP done at epoch 14, cycle 1. Score: 0.006580981891602278
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1621442842512, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 80, "metadata": {"file": "main.py", "lineno": 107}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1621442842513, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 108}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1621442842513, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 24}}
:::MLLOG {"namespace": "", "time_ms": 1621442842513, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1, "epoch_count": 14}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1621442845743, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1040.3440455201687, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442845743, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.03089264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442845743, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1040.3440455201687, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1621442845743, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 14, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442845743, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 14, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442847970, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1508.8463116840542, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442847971, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.05175218543046358, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442847971, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1508.8463116840542, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442847971, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 28, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442847971, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 28, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442850291, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1448.5982020060399, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442850291, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.07261172185430464, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442850291, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1448.5982020060399, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 28}}
:::MLLOG {"namespace": "", "time_ms": 1621442850291, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 42, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442850292, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 42, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442852136, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1822.1940373211455, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442852136, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0934712582781457, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442852136, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1822.1940373211455, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 42}}
:::MLLOG {"namespace": "", "time_ms": 1621442852136, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 56, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442852136, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 56, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442853456, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2546.3363401344714, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442853457, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.11433079470198675, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442853457, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2546.3363401344714, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 56}}
:::MLLOG {"namespace": "", "time_ms": 1621442853457, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 70, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442853457, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 70, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442854659, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2796.6460238438594, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442854659, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.13519033112582782, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442854659, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2796.6460238438594, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 70}}
:::MLLOG {"namespace": "", "time_ms": 1621442854659, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 84, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442854659, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 84, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442855856, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2809.1095216653184, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442855856, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.15604986754966885, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442855856, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2809.1095216653184, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 84}}
:::MLLOG {"namespace": "", "time_ms": 1621442855856, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 98, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442855856, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 98, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442857202, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2497.599307265156, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442857202, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.1769094039735099, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442857202, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2497.599307265156, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 98}}
:::MLLOG {"namespace": "", "time_ms": 1621442857202, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 112, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442857202, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 112, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442858270, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3146.471072856045, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442858271, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.197768940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442858271, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3146.471072856045, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 112}}
:::MLLOG {"namespace": "", "time_ms": 1621442858271, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 126, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442858271, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 126, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442859315, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3219.3490514100354, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442859316, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.21862847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442859316, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3219.3490514100354, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 126}}
:::MLLOG {"namespace": "", "time_ms": 1621442859316, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 140, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442859316, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 140, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442860389, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3132.7062909486503, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442860389, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.2394880132450331, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442860389, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3132.7062909486503, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1621442860390, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 154, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442860390, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 154, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442861612, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2749.543888852795, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442861612, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26034754966887413, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442861613, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2749.543888852795, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 154}}
:::MLLOG {"namespace": "", "time_ms": 1621442861613, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 168, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442861613, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 168, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442862564, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3533.6085862543205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442862564, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.2812070860927152, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442862564, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3533.6085862543205, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 168}}
:::MLLOG {"namespace": "", "time_ms": 1621442862565, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 182, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442862565, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 182, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442863616, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3196.806981552112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442863617, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3020666225165563, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442863617, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3196.806981552112, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 182}}
:::MLLOG {"namespace": "", "time_ms": 1621442863617, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 196, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442863618, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 196, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442864630, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3319.2851207512826, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442864631, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32292615894039733, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442864631, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3319.2851207512826, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 196}}
:::MLLOG {"namespace": "", "time_ms": 1621442864631, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 210, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442864631, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 210, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442865618, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3404.0909009661405, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442865619, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3437856953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442865619, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3404.0909009661405, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 210}}
:::MLLOG {"namespace": "", "time_ms": 1621442865619, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 224, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442865620, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 224, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442866472, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3940.5633833535076, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442866473, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36464523178807945, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442866473, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3940.5633833535076, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 224}}
:::MLLOG {"namespace": "", "time_ms": 1621442866473, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 238, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442866473, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 238, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442867463, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3394.6416116383903, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442867464, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3855047682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442867464, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3394.6416116383903, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 238}}
:::MLLOG {"namespace": "", "time_ms": 1621442867464, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 252, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442867464, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 252, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442868549, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3097.590884513432, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442868549, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4063643046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442868549, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3097.590884513432, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 252}}
:::MLLOG {"namespace": "", "time_ms": 1621442868550, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 266, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442868550, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 266, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442869491, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3570.0987898327817, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442869491, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442869491, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3570.0987898327817, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 266}}
:::MLLOG {"namespace": "", "time_ms": 1621442869491, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 280, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442869492, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 280, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442870358, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3876.410638958021, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442870359, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4480833774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442870359, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3876.410638958021, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1621442870359, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 294, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442870360, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 294, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442871422, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3161.6505804455383, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442871423, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.46894291390728476, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442871423, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3161.6505804455383, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 294}}
:::MLLOG {"namespace": "", "time_ms": 1621442871424, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 308, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442871424, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 308, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442872352, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3620.9958260373564, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442872352, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4898024503311258, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442872352, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3620.9958260373564, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 308}}
:::MLLOG {"namespace": "", "time_ms": 1621442872352, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 322, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442872353, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 322, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442873243, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3775.4149675390954, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442873243, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5106619867549669, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442873243, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3775.4149675390954, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 322}}
:::MLLOG {"namespace": "", "time_ms": 1621442873243, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 336, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442873244, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 336, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442874143, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3735.3634600307146, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442874144, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.531521523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442874144, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3735.3634600307146, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 336}}
:::MLLOG {"namespace": "", "time_ms": 1621442874144, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 350, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442874144, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 350, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442875088, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3558.8411392242037, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442875089, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5523810596026489, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442875089, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3558.8411392242037, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 350}}
:::MLLOG {"namespace": "", "time_ms": 1621442875089, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 364, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442875089, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 364, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442875988, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3739.67028059346, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442875988, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5732405960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442875988, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3739.67028059346, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 364}}
:::MLLOG {"namespace": "", "time_ms": 1621442875988, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 378, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442875988, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 378, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442876832, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3983.535830551219, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442876833, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5941001324503311, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442876833, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3983.535830551219, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 378}}
:::MLLOG {"namespace": "", "time_ms": 1621442876833, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 392, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442876833, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 392, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442877726, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3764.4879826628303, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442877726, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6149596688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442877726, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3764.4879826628303, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 392}}
:::MLLOG {"namespace": "", "time_ms": 1621442877726, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 406, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442877726, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 406, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442878576, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3952.917227180675, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442878577, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6358192052980133, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442878577, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3952.917227180675, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 406}}
:::MLLOG {"namespace": "", "time_ms": 1621442878577, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 420, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442878577, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 420, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442879457, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3821.1639304391115, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442879457, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6566787417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442879457, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3821.1639304391115, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1621442879458, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 434, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442879458, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 434, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442880333, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3839.795979032268, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442880334, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6775382781456953, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442880334, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3839.795979032268, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 434}}
:::MLLOG {"namespace": "", "time_ms": 1621442880334, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 448, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442880334, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 448, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442881272, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3581.2868211262676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442881273, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6983978145695363, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442881273, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3581.2868211262676, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 448}}
:::MLLOG {"namespace": "", "time_ms": 1621442881273, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 462, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442881273, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 462, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442882121, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3961.7047670237193, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442882122, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7192573509933775, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442882122, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3961.7047670237193, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 462}}
:::MLLOG {"namespace": "", "time_ms": 1621442882122, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 476, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442882122, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 476, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442882928, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4172.3112012839465, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442882928, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7401168874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442882928, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4172.3112012839465, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 476}}
:::MLLOG {"namespace": "", "time_ms": 1621442882928, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 490, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442882929, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 490, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442883780, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3945.6670841113173, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442883781, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7609764238410596, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442883781, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3945.6670841113173, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 490}}
:::MLLOG {"namespace": "", "time_ms": 1621442883781, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 504, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442883781, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 504, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442884586, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4178.511465150018, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442884586, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7818359602649007, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442884586, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4178.511465150018, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 504}}
:::MLLOG {"namespace": "", "time_ms": 1621442884586, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 518, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442884586, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 518, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442885401, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4124.531896293621, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442885402, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8026954966887417, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442885402, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4124.531896293621, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 518}}
:::MLLOG {"namespace": "", "time_ms": 1621442885402, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 532, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442885402, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 532, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442886264, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3900.477328131539, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442886264, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8235550331125828, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442886264, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3900.477328131539, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 532}}
:::MLLOG {"namespace": "", "time_ms": 1621442886264, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 546, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442886265, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 546, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442887093, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4055.367822571525, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442887094, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442887094, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4055.367822571525, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 546}}
:::MLLOG {"namespace": "", "time_ms": 1621442887094, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 560, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442887094, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 560, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442887938, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3981.5876782874907, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442887939, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8652741059602649, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442887939, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3981.5876782874907, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1621442887939, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 574, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442887939, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 574, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442888776, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4015.3588172795753, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442888776, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.886133642384106, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442888776, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4015.3588172795753, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 574}}
:::MLLOG {"namespace": "", "time_ms": 1621442888777, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 588, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442888777, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 588, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442889602, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4071.1222605306984, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442889602, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9069931788079469, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442889603, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4071.1222605306984, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 588}}
:::MLLOG {"namespace": "", "time_ms": 1621442889603, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 602, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442889603, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 602, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442890502, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3737.9334724584296, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442890502, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9278527152317881, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442890503, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3737.9334724584296, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 602}}
:::MLLOG {"namespace": "", "time_ms": 1621442890503, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 616, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442890503, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 616, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442891315, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4137.102402877828, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442891316, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9487122516556292, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442891316, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4137.102402877828, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 616}}
:::MLLOG {"namespace": "", "time_ms": 1621442891316, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 630, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442891316, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 630, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442892114, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4209.7548024475545, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442892115, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9695717880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442892115, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4209.7548024475545, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 630}}
:::MLLOG {"namespace": "", "time_ms": 1621442892115, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 644, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442892115, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 644, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442892977, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3901.381107473822, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442892977, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9904313245033113, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442892977, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3901.381107473822, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 644}}
:::MLLOG {"namespace": "", "time_ms": 1621442892977, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 658, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442892977, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 658, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442893871, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3761.871296450278, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442893871, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0112908609271523, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442893871, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3761.871296450278, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 658}}
:::MLLOG {"namespace": "", "time_ms": 1621442893872, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 672, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442893872, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 672, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442894721, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3955.1226652956116, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442894722, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0321503973509933, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442894722, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3955.1226652956116, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 672}}
:::MLLOG {"namespace": "", "time_ms": 1621442894722, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 686, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442894722, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 686, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442895509, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4267.275684222734, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442895510, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0530099337748344, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442895510, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4267.275684222734, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 686}}
rank 0: cycle = 50: time to send the model = 0.03987002372741699
:::MLLOG {"namespace": "", "time_ms": 1621442895554, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 700, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442895554, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 700, "epoch_count": 14}}
rank 640: cycle = 50: time to receive the model = 0.05082130432128906
:::MLLOG {"namespace": "", "time_ms": 1621442895565, "event_type": "INTERVAL_START", "key": "eval_start", "value": 700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 700}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.721 s.
:::MLLOG {"namespace": "", "time_ms": 1621442896327, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8615988492965698, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 700}}
:::MLLOG {"namespace": "", "time_ms": 1621442896327, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 700}}
:::MLLOG {"namespace": "", "time_ms": 1621442896385, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4045.9860971511303, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442896389, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0738694701986755, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442896389, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4045.9860971511303, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 700}}
rank 0: cycle = 51: time to send the model = 0.0410304069519043
:::MLLOG {"namespace": "", "time_ms": 1621442896431, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 714, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442896431, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 714, "epoch_count": 14}}
rank 640: cycle = 51: time to receive the model = 0.05142402648925781
:::MLLOG {"namespace": "", "time_ms": 1621442896441, "event_type": "INTERVAL_START", "key": "eval_start", "value": 714, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 714}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621442897205, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8720300197601318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 714}}
:::MLLOG {"namespace": "", "time_ms": 1621442897206, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 714}}
:::MLLOG {"namespace": "", "time_ms": 1621442897221, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4251.875148777872, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442897223, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0947290066225166, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442897224, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4251.875148777872, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 714}}
rank 0: cycle = 52: time to send the model = 0.051044464111328125
:::MLLOG {"namespace": "", "time_ms": 1621442897276, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 728, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442897276, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 728, "epoch_count": 14}}
rank 640: cycle = 52: time to receive the model = 0.0576786994934082
:::MLLOG {"namespace": "", "time_ms": 1621442897282, "event_type": "INTERVAL_START", "key": "eval_start", "value": 728, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 728}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621442898047, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8802937269210815, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 728}}
:::MLLOG {"namespace": "", "time_ms": 1621442898047, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 728}}
:::MLLOG {"namespace": "", "time_ms": 1621442898054, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4319.83506423722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442898055, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1155885430463577, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442898056, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4319.83506423722, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 728}}
rank 0: cycle = 53: time to send the model = 0.04018115997314453
:::MLLOG {"namespace": "", "time_ms": 1621442898099, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 742, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442898099, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 742, "epoch_count": 14}}
rank 640: cycle = 53: time to receive the model = 0.04983186721801758
:::MLLOG {"namespace": "", "time_ms": 1621442898108, "event_type": "INTERVAL_START", "key": "eval_start", "value": 742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 742}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621442898873, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8930171728134155, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 742}}
:::MLLOG {"namespace": "", "time_ms": 1621442898874, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 742}}
:::MLLOG {"namespace": "", "time_ms": 1621442898896, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4216.309118063799, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442898898, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1364480794701988, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442898899, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4216.309118063799, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 742}}
rank 0: cycle = 54: time to send the model = 0.043125152587890625
:::MLLOG {"namespace": "", "time_ms": 1621442898943, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 756, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442898943, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 756, "epoch_count": 14}}
rank 640: cycle = 54: time to receive the model = 0.05238819122314453
:::MLLOG {"namespace": "", "time_ms": 1621442898952, "event_type": "INTERVAL_START", "key": "eval_start", "value": 756, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 756}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.758 s.
:::MLLOG {"namespace": "", "time_ms": 1621442899711, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8766425848007202, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 756}}
:::MLLOG {"namespace": "", "time_ms": 1621442899711, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 756}}
:::MLLOG {"namespace": "", "time_ms": 1621442899768, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4074.048044348095, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442899770, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1573076158940396, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442899770, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4074.048044348095, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 756}}
rank 0: cycle = 55: time to send the model = 0.04029345512390137
:::MLLOG {"namespace": "", "time_ms": 1621442899812, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 770, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442899812, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 770, "epoch_count": 14}}
rank 640: cycle = 55: time to receive the model = 0.050127506256103516
:::MLLOG {"namespace": "", "time_ms": 1621442899821, "event_type": "INTERVAL_START", "key": "eval_start", "value": 770, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 770}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621442900585, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8643572330474854, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 770}}
:::MLLOG {"namespace": "", "time_ms": 1621442900586, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 770}}
:::MLLOG {"namespace": "", "time_ms": 1621442900617, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4172.990698400225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442900619, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1781671523178807, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442900620, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4172.990698400225, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 770}}
rank 0: cycle = 56: time to send the model = 0.04850459098815918
:::MLLOG {"namespace": "", "time_ms": 1621442900684, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 784, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442900684, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 784, "epoch_count": 14}}
rank 640: cycle = 56: time to receive the model = 0.05702400207519531
:::MLLOG {"namespace": "", "time_ms": 1621442900692, "event_type": "INTERVAL_START", "key": "eval_start", "value": 784, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 784}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442901443, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4429.484583714561, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442901444, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1990266887417218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442901445, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4429.484583714561, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 784}}
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621442901458, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8806930780410767, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 784}}
:::MLLOG {"namespace": "", "time_ms": 1621442901460, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 784}}
rank 0: cycle = 57: time to send the model = 0.036726951599121094
:::MLLOG {"namespace": "", "time_ms": 1621442901497, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 798, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442901498, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 798, "epoch_count": 14}}
rank 640: cycle = 57: time to receive the model = 0.05325484275817871
:::MLLOG {"namespace": "", "time_ms": 1621442901513, "event_type": "INTERVAL_START", "key": "eval_start", "value": 798, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 798}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.759 s.
:::MLLOG {"namespace": "", "time_ms": 1621442902274, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.871347963809967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 798}}
:::MLLOG {"namespace": "", "time_ms": 1621442902274, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 798}}
:::MLLOG {"namespace": "", "time_ms": 1621442902292, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4230.940672279756, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442902295, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2198862251655629, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442902295, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4230.940672279756, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 798}}
rank 0: cycle = 58: time to send the model = 0.04648470878601074
:::MLLOG {"namespace": "", "time_ms": 1621442902342, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 812, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442902343, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 812, "epoch_count": 14}}
rank 640: cycle = 58: time to receive the model = 0.052182912826538086
:::MLLOG {"namespace": "", "time_ms": 1621442902348, "event_type": "INTERVAL_START", "key": "eval_start", "value": 812, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 812}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621442903114, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8878772258758545, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 812}}
:::MLLOG {"namespace": "", "time_ms": 1621442903115, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 812}}
:::MLLOG {"namespace": "", "time_ms": 1621442903115, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4348.785546572085, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442903117, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.240745761589404, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442903117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4348.785546572085, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 812}}
rank 0: cycle = 59: time to send the model = 0.042116403579711914
:::MLLOG {"namespace": "", "time_ms": 1621442903162, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 826, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442903163, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 826, "epoch_count": 14}}
rank 640: cycle = 59: time to receive the model = 0.052333831787109375
:::MLLOG {"namespace": "", "time_ms": 1621442903172, "event_type": "INTERVAL_START", "key": "eval_start", "value": 826, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 826}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442903923, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4419.300311859602, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442903925, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442903926, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4419.300311859602, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 826}}
EVALUATION TIME: 0.762 s.
:::MLLOG {"namespace": "", "time_ms": 1621442903936, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8858864307403564, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 826}}
:::MLLOG {"namespace": "", "time_ms": 1621442903937, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 826}}
rank 0: cycle = 60: time to send the model = 0.039487600326538086
:::MLLOG {"namespace": "", "time_ms": 1621442903977, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 840, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442903978, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 840, "epoch_count": 14}}
rank 640: cycle = 60: time to receive the model = 0.049978017807006836
:::MLLOG {"namespace": "", "time_ms": 1621442903987, "event_type": "INTERVAL_START", "key": "eval_start", "value": 840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 840}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621442904752, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8700408935546875, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 840}}
:::MLLOG {"namespace": "", "time_ms": 1621442904752, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 840}}
:::MLLOG {"namespace": "", "time_ms": 1621442904779, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4198.167313492058, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442904780, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2824648344370861, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442904780, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4198.167313492058, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 840}}
rank 0: cycle = 61: time to send the model = 0.040462493896484375
:::MLLOG {"namespace": "", "time_ms": 1621442904824, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 854, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442904824, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 854, "epoch_count": 14}}
rank 640: cycle = 61: time to receive the model = 0.050432682037353516
:::MLLOG {"namespace": "", "time_ms": 1621442904833, "event_type": "INTERVAL_START", "key": "eval_start", "value": 854, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 854}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621442905599, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8896104097366333, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 854}}
:::MLLOG {"namespace": "", "time_ms": 1621442905599, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 854}}
:::MLLOG {"namespace": "", "time_ms": 1621442905612, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4264.332977691385, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442905615, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3033243708609272, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442905616, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4264.332977691385, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 854}}
rank 0: cycle = 62: time to send the model = 0.042724609375
:::MLLOG {"namespace": "", "time_ms": 1621442905659, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 868, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442905660, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 868, "epoch_count": 14}}
rank 640: cycle = 62: time to receive the model = 0.04932975769042969
:::MLLOG {"namespace": "", "time_ms": 1621442905666, "event_type": "INTERVAL_START", "key": "eval_start", "value": 868, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 868}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621442906431, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8891383409500122, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 868}}
:::MLLOG {"namespace": "", "time_ms": 1621442906431, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 868}}
:::MLLOG {"namespace": "", "time_ms": 1621442906486, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4066.560740177311, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442906487, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3241839072847683, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442906487, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4066.560740177311, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 868}}
rank 0: cycle = 63: time to send the model = 0.0391240119934082
:::MLLOG {"namespace": "", "time_ms": 1621442906529, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 882, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442906529, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 882, "epoch_count": 14}}
rank 640: cycle = 63: time to receive the model = 0.05025529861450195
:::MLLOG {"namespace": "", "time_ms": 1621442906540, "event_type": "INTERVAL_START", "key": "eval_start", "value": 882, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 882}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.761 s.
:::MLLOG {"namespace": "", "time_ms": 1621442907303, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8692489862442017, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 882}}
:::MLLOG {"namespace": "", "time_ms": 1621442907303, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 882}}
:::MLLOG {"namespace": "", "time_ms": 1621442907317, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4267.567722904857, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442907319, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3450434437086094, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442907320, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4267.567722904857, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 882}}
rank 0: cycle = 64: time to send the model = 0.038500070571899414
:::MLLOG {"namespace": "", "time_ms": 1621442907359, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 896, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442907359, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 896, "epoch_count": 14}}
rank 640: cycle = 64: time to receive the model = 0.05085897445678711
:::MLLOG {"namespace": "", "time_ms": 1621442907371, "event_type": "INTERVAL_START", "key": "eval_start", "value": 896, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 896}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.76 s.
:::MLLOG {"namespace": "", "time_ms": 1621442908132, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8897144794464111, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 896}}
:::MLLOG {"namespace": "", "time_ms": 1621442908132, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 896}}
:::MLLOG {"namespace": "", "time_ms": 1621442908176, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4114.377322443298, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442908178, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3659029801324505, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442908178, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4114.377322443298, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 896}}
rank 0: cycle = 65: time to send the model = 0.03963041305541992
:::MLLOG {"namespace": "", "time_ms": 1621442908220, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 910, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442908221, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 910, "epoch_count": 14}}
rank 640: cycle = 65: time to receive the model = 0.05024075508117676
:::MLLOG {"namespace": "", "time_ms": 1621442908231, "event_type": "INTERVAL_START", "key": "eval_start", "value": 910, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 910}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.761 s.
:::MLLOG {"namespace": "", "time_ms": 1621442908993, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8925150632858276, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 910}}
:::MLLOG {"namespace": "", "time_ms": 1621442908993, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 910}}
:::MLLOG {"namespace": "", "time_ms": 1621442909007, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4272.64472123243, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442909009, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3867625165562913, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442909010, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4272.64472123243, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 910}}
rank 0: cycle = 66: time to send the model = 0.04986214637756348
:::MLLOG {"namespace": "", "time_ms": 1621442909060, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 924, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442909061, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 924, "epoch_count": 14}}
rank 640: cycle = 66: time to receive the model = 0.059662580490112305
:::MLLOG {"namespace": "", "time_ms": 1621442909070, "event_type": "INTERVAL_START", "key": "eval_start", "value": 924, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 924}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442909828, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4377.363790369021, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442909830, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4076220529801324, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442909830, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4377.363790369021, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 924}}
EVALUATION TIME: 0.762 s.
:::MLLOG {"namespace": "", "time_ms": 1621442909833, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8843380212783813, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 924}}
:::MLLOG {"namespace": "", "time_ms": 1621442909835, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 924}}
rank 0: cycle = 67: time to send the model = 0.040509700775146484
:::MLLOG {"namespace": "", "time_ms": 1621442909875, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 938, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442909876, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 938, "epoch_count": 14}}
rank 640: cycle = 67: time to receive the model = 0.049773454666137695
:::MLLOG {"namespace": "", "time_ms": 1621442909885, "event_type": "INTERVAL_START", "key": "eval_start", "value": 938, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 938}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442910645, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4372.770290312852, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
EVALUATION TIME: 0.761 s.
:::MLLOG {"namespace": "", "time_ms": 1621442910646, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8923143148422241, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 938}}
:::MLLOG {"namespace": "", "time_ms": 1621442910647, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 938}}
:::MLLOG {"namespace": "", "time_ms": 1621442910647, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4284815894039735, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442910649, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4372.770290312852, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 938}}
rank 0: cycle = 68: time to send the model = 0.04595589637756348
:::MLLOG {"namespace": "", "time_ms": 1621442910696, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 952, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442910696, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 952, "epoch_count": 14}}
rank 640: cycle = 68: time to receive the model = 0.0517115592956543
:::MLLOG {"namespace": "", "time_ms": 1621442910701, "event_type": "INTERVAL_START", "key": "eval_start", "value": 952, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 952}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621442911466, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8729340434074402, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 952}}
:::MLLOG {"namespace": "", "time_ms": 1621442911466, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 952}}
:::MLLOG {"namespace": "", "time_ms": 1621442911485, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4260.943379055351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442911486, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4493411258278146, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442911487, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4260.943379055351, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 952}}
rank 0: cycle = 69: time to send the model = 0.0378422737121582
:::MLLOG {"namespace": "", "time_ms": 1621442911528, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 966, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442911528, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 966, "epoch_count": 14}}
rank 640: cycle = 69: time to receive the model = 0.04982256889343262
:::MLLOG {"namespace": "", "time_ms": 1621442911540, "event_type": "INTERVAL_START", "key": "eval_start", "value": 966, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 966}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.76 s.
:::MLLOG {"namespace": "", "time_ms": 1621442912301, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8898595571517944, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 966}}
:::MLLOG {"namespace": "", "time_ms": 1621442912301, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 966}}
:::MLLOG {"namespace": "", "time_ms": 1621442912328, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4198.024749316507, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442912330, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4702006622516555, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442912331, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4198.024749316507, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 966}}
rank 0: cycle = 70: time to send the model = 0.05062079429626465
:::MLLOG {"namespace": "", "time_ms": 1621442912382, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 980, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442912382, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 980, "epoch_count": 14}}
rank 640: cycle = 70: time to receive the model = 0.05672430992126465
:::MLLOG {"namespace": "", "time_ms": 1621442912388, "event_type": "INTERVAL_START", "key": "eval_start", "value": 980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 980}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442913131, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4482.840137607019, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442913133, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4910601986754968, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442913133, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4482.840137607019, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 980}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621442913155, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8842743039131165, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 980}}
:::MLLOG {"namespace": "", "time_ms": 1621442913156, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 980}}
rank 0: cycle = 71: time to send the model = 0.03755664825439453
:::MLLOG {"namespace": "", "time_ms": 1621442913194, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 994, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442913195, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 994, "epoch_count": 14}}
rank 640: cycle = 71: time to receive the model = 0.05020570755004883
:::MLLOG {"namespace": "", "time_ms": 1621442913207, "event_type": "INTERVAL_START", "key": "eval_start", "value": 994, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 994}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.759 s.
:::MLLOG {"namespace": "", "time_ms": 1621442913967, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8871467113494873, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 994}}
:::MLLOG {"namespace": "", "time_ms": 1621442913967, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 994}}
:::MLLOG {"namespace": "", "time_ms": 1621442913996, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4199.4433187281575, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442913998, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442913999, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4199.4433187281575, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 994}}
rank 0: cycle = 72: time to send the model = 0.05066537857055664
:::MLLOG {"namespace": "", "time_ms": 1621442914050, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1008, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442914050, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1008, "epoch_count": 14}}
rank 640: cycle = 72: time to receive the model = 0.057195186614990234
:::MLLOG {"namespace": "", "time_ms": 1621442914056, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1008, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1008}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621442914822, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8092592358589172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1008}}
:::MLLOG {"namespace": "", "time_ms": 1621442914822, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1008}}
:::MLLOG {"namespace": "", "time_ms": 1621442914832, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4300.495521557312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442914833, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442914833, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4300.495521557312, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1008}}
rank 0: cycle = 73: time to send the model = 0.03948664665222168
:::MLLOG {"namespace": "", "time_ms": 1621442914873, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1022, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442914873, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1022, "epoch_count": 14}}
rank 640: cycle = 73: time to receive the model = 0.049896955490112305
:::MLLOG {"namespace": "", "time_ms": 1621442914883, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1022, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1022}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442915635, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4412.481512200116, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442915637, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442915637, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4412.481512200116, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1022}}
EVALUATION TIME: 0.76 s.
:::MLLOG {"namespace": "", "time_ms": 1621442915644, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8633925318717957, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1022}}
:::MLLOG {"namespace": "", "time_ms": 1621442915646, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1022}}
rank 0: cycle = 74: time to send the model = 0.04449009895324707
:::MLLOG {"namespace": "", "time_ms": 1621442915691, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1036, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442915692, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1036, "epoch_count": 14}}
rank 640: cycle = 74: time to receive the model = 0.052751779556274414
:::MLLOG {"namespace": "", "time_ms": 1621442915699, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1036, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1036}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.761 s.
:::MLLOG {"namespace": "", "time_ms": 1621442916461, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8758734464645386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1036}}
:::MLLOG {"namespace": "", "time_ms": 1621442916461, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1036}}
:::MLLOG {"namespace": "", "time_ms": 1621442916462, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4363.7269994832095, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442916464, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442916464, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4363.7269994832095, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1036}}
rank 0: cycle = 75: time to send the model = 0.03851127624511719
:::MLLOG {"namespace": "", "time_ms": 1621442916503, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1050, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442916503, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1050, "epoch_count": 14}}
rank 640: cycle = 75: time to receive the model = 0.050318002700805664
:::MLLOG {"namespace": "", "time_ms": 1621442916514, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1050, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1050}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.759 s.
:::MLLOG {"namespace": "", "time_ms": 1621442917275, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8725247383117676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1050}}
:::MLLOG {"namespace": "", "time_ms": 1621442917275, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1050}}
:::MLLOG {"namespace": "", "time_ms": 1621442917308, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4172.018468016678, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442917310, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442917311, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4172.018468016678, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1050}}
rank 0: cycle = 76: time to send the model = 0.04366254806518555
:::MLLOG {"namespace": "", "time_ms": 1621442917355, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1064, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442917355, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1064, "epoch_count": 14}}
rank 640: cycle = 76: time to receive the model = 0.049451589584350586
:::MLLOG {"namespace": "", "time_ms": 1621442917360, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1064, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1064}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442918116, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4418.904001949065, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442918117, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442918117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4418.904001949065, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1064}}
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621442918127, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8832315802574158, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1064}}
:::MLLOG {"namespace": "", "time_ms": 1621442918128, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1064}}
rank 0: cycle = 77: time to send the model = 0.03678321838378906
:::MLLOG {"namespace": "", "time_ms": 1621442918165, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1078, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442918166, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1078, "epoch_count": 14}}
rank 640: cycle = 77: time to receive the model = 0.051604270935058594
:::MLLOG {"namespace": "", "time_ms": 1621442918180, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1078, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1078}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.758 s.
:::MLLOG {"namespace": "", "time_ms": 1621442918939, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8895050287246704, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1078}}
:::MLLOG {"namespace": "", "time_ms": 1621442918939, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1078}}
:::MLLOG {"namespace": "", "time_ms": 1621442918972, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4169.818725164436, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442918974, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442918976, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4169.818725164436, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1078}}
rank 0: cycle = 78: time to send the model = 0.04961276054382324
:::MLLOG {"namespace": "", "time_ms": 1621442919026, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1092, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442919026, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1092, "epoch_count": 14}}
rank 640: cycle = 78: time to receive the model = 0.0537714958190918
:::MLLOG {"namespace": "", "time_ms": 1621442919030, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1092}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442919794, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4377.240066008671, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442919795, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442919795, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4377.240066008671, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1092}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621442919799, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8990826606750488, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1092}}
:::MLLOG {"namespace": "", "time_ms": 1621442919800, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1092}}
rank 0: cycle = 79: time to send the model = 0.03792285919189453
:::MLLOG {"namespace": "", "time_ms": 1621442919838, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1106, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442919839, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1106, "epoch_count": 14}}
rank 640: cycle = 79: time to receive the model = 0.05025887489318848
:::MLLOG {"namespace": "", "time_ms": 1621442919850, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1106, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1106}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.758 s.
:::MLLOG {"namespace": "", "time_ms": 1621442920609, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8880234360694885, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1106}}
:::MLLOG {"namespace": "", "time_ms": 1621442920609, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1106}}
:::MLLOG {"namespace": "", "time_ms": 1621442920612, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4348.876801184975, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442920614, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442920615, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4348.876801184975, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1106}}
rank 0: cycle = 80: time to send the model = 0.04104900360107422
:::MLLOG {"namespace": "", "time_ms": 1621442920657, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1120, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442920657, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1120, "epoch_count": 14}}
rank 640: cycle = 80: time to receive the model = 0.04978036880493164
:::MLLOG {"namespace": "", "time_ms": 1621442920665, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1120}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442921409, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4467.45142593398, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442921411, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442921411, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4467.45142593398, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1120}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621442921431, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8891254663467407, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1621442921432, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1120}}
rank 0: cycle = 81: time to send the model = 0.036547183990478516
:::MLLOG {"namespace": "", "time_ms": 1621442921469, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1134, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442921470, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1134, "epoch_count": 14}}
rank 640: cycle = 81: time to receive the model = 0.05157613754272461
:::MLLOG {"namespace": "", "time_ms": 1621442921484, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1134, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1134}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621442922250, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8931987285614014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1134}}
:::MLLOG {"namespace": "", "time_ms": 1621442922250, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1134}}
:::MLLOG {"namespace": "", "time_ms": 1621442922254, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4288.820150501239, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442922257, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442922258, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4288.820150501239, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1134}}
rank 0: cycle = 82: time to send the model = 0.05014324188232422
:::MLLOG {"namespace": "", "time_ms": 1621442922309, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1148, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442922309, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1148, "epoch_count": 14}}
rank 640: cycle = 82: time to receive the model = 0.054985761642456055
:::MLLOG {"namespace": "", "time_ms": 1621442922313, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1148, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1148}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621442923081, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8985648155212402, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1148}}
:::MLLOG {"namespace": "", "time_ms": 1621442923081, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1148}}
:::MLLOG {"namespace": "", "time_ms": 1621442923130, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4095.4357920138655, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442923131, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442923131, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4095.4357920138655, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1148}}
rank 0: cycle = 83: time to send the model = 0.03801536560058594
:::MLLOG {"namespace": "", "time_ms": 1621442923170, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1162, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442923170, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1162, "epoch_count": 14}}
rank 640: cycle = 83: time to receive the model = 0.05031561851501465
:::MLLOG {"namespace": "", "time_ms": 1621442923182, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1162, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1162}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442923934, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4395.511138752053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442923936, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442923937, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4395.511138752053, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1162}}
EVALUATION TIME: 0.761 s.
:::MLLOG {"namespace": "", "time_ms": 1621442923944, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8899519443511963, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1162}}
:::MLLOG {"namespace": "", "time_ms": 1621442923945, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1162}}
rank 0: cycle = 84: time to send the model = 0.04217362403869629
:::MLLOG {"namespace": "", "time_ms": 1621442923988, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1176, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442923989, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1176, "epoch_count": 14}}
rank 640: cycle = 84: time to receive the model = 0.051818132400512695
:::MLLOG {"namespace": "", "time_ms": 1621442923997, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1176, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1176}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442924755, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4388.389675894945, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442924756, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442924756, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4388.389675894945, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1176}}
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621442924764, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8953202962875366, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1176}}
:::MLLOG {"namespace": "", "time_ms": 1621442924765, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1176}}
rank 0: cycle = 85: time to send the model = 0.037108421325683594
:::MLLOG {"namespace": "", "time_ms": 1621442924802, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1190, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442924803, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1190, "epoch_count": 14}}
rank 640: cycle = 85: time to receive the model = 0.05291581153869629
:::MLLOG {"namespace": "", "time_ms": 1621442924818, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1190, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1190}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.756 s.
:::MLLOG {"namespace": "", "time_ms": 1621442925575, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8926266431808472, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1190}}
:::MLLOG {"namespace": "", "time_ms": 1621442925575, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1190}}
:::MLLOG {"namespace": "", "time_ms": 1621442925578, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4340.239382277433, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442925580, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442925581, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4340.239382277433, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1190}}
rank 0: cycle = 86: time to send the model = 0.04785966873168945
:::MLLOG {"namespace": "", "time_ms": 1621442925630, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1204, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442925630, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1204, "epoch_count": 14}}
rank 640: cycle = 86: time to receive the model = 0.052564144134521484
:::MLLOG {"namespace": "", "time_ms": 1621442925634, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1204, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1204}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621442926401, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9024093747138977, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1204}}
:::MLLOG {"namespace": "", "time_ms": 1621442926402, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1204}}
:::MLLOG {"namespace": "", "time_ms": 1621442926411, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4303.522534855577, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442926413, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442926413, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4303.522534855577, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1204}}
rank 0: cycle = 87: time to send the model = 0.038231611251831055
:::MLLOG {"namespace": "", "time_ms": 1621442926451, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1218, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442926451, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1218, "epoch_count": 14}}
rank 640: cycle = 87: time to receive the model = 0.05005502700805664
:::MLLOG {"namespace": "", "time_ms": 1621442926463, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1218}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442927213, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4413.994828311985, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442927215, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442927216, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4413.994828311985, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1218}}
EVALUATION TIME: 0.761 s.
:::MLLOG {"namespace": "", "time_ms": 1621442927225, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8905032873153687, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1218}}
:::MLLOG {"namespace": "", "time_ms": 1621442927226, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1218}}
rank 0: cycle = 88: time to send the model = 0.047914743423461914
:::MLLOG {"namespace": "", "time_ms": 1621442927275, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1232, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442927276, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1232, "epoch_count": 14}}
rank 640: cycle = 88: time to receive the model = 0.05398249626159668
:::MLLOG {"namespace": "", "time_ms": 1621442927281, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1232, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1232}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621442928049, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8969299793243408, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1232}}
:::MLLOG {"namespace": "", "time_ms": 1621442928049, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1232}}
:::MLLOG {"namespace": "", "time_ms": 1621442928147, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3856.9473738946713, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442928149, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442928149, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3856.9473738946713, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1232}}
rank 0: cycle = 89: time to send the model = 0.03858470916748047
:::MLLOG {"namespace": "", "time_ms": 1621442928188, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1246, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442928188, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1246, "epoch_count": 14}}
rank 640: cycle = 89: time to receive the model = 0.050553083419799805
:::MLLOG {"namespace": "", "time_ms": 1621442928199, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1246, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1246}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442928958, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4365.067790389199, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
EVALUATION TIME: 0.758 s.
:::MLLOG {"namespace": "", "time_ms": 1621442928959, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8872441053390503, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1246}}
:::MLLOG {"namespace": "", "time_ms": 1621442928959, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442928960, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1246}}
:::MLLOG {"namespace": "", "time_ms": 1621442928961, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4365.067790389199, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1246}}
rank 0: cycle = 90: time to send the model = 0.047042131423950195
:::MLLOG {"namespace": "", "time_ms": 1621442929010, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1260, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442929010, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1260, "epoch_count": 14}}
rank 640: cycle = 90: time to receive the model = 0.05678725242614746
:::MLLOG {"namespace": "", "time_ms": 1621442929020, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1260}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442929781, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4362.567987605269, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442929782, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442929782, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4362.567987605269, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1260}}
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621442929785, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8959848880767822, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1621442929786, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1260}}
rank 0: cycle = 91: time to send the model = 0.03768515586853027
:::MLLOG {"namespace": "", "time_ms": 1621442929824, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1274, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442929826, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1274, "epoch_count": 14}}
rank 640: cycle = 91: time to receive the model = 0.04960060119628906
:::MLLOG {"namespace": "", "time_ms": 1621442929836, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1274, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1274}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.758 s.
:::MLLOG {"namespace": "", "time_ms": 1621442930596, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8957473635673523, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1274}}
:::MLLOG {"namespace": "", "time_ms": 1621442930596, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1274}}
:::MLLOG {"namespace": "", "time_ms": 1621442930603, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4322.926502471758, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442930605, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442930607, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4322.926502471758, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1274}}
rank 0: cycle = 92: time to send the model = 0.05113649368286133
:::MLLOG {"namespace": "", "time_ms": 1621442930658, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1288, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442930659, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1288, "epoch_count": 14}}
rank 640: cycle = 92: time to receive the model = 0.05874013900756836
:::MLLOG {"namespace": "", "time_ms": 1621442930666, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1288, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1288}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442931425, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4386.332684180008, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442931426, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442931426, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4386.332684180008, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1288}}
EVALUATION TIME: 0.762 s.
:::MLLOG {"namespace": "", "time_ms": 1621442931429, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9008355140686035, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1288}}
:::MLLOG {"namespace": "", "time_ms": 1621442931431, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1288}}
rank 0: cycle = 93: time to send the model = 0.039273977279663086
:::MLLOG {"namespace": "", "time_ms": 1621442931470, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1302, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442931471, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1302, "epoch_count": 14}}
rank 640: cycle = 93: time to receive the model = 0.050962209701538086
:::MLLOG {"namespace": "", "time_ms": 1621442931482, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1302, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1302}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442932225, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4456.869313427285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442932227, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442932227, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4456.869313427285, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1302}}
EVALUATION TIME: 0.758 s.
:::MLLOG {"namespace": "", "time_ms": 1621442932241, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8916990756988525, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1302}}
:::MLLOG {"namespace": "", "time_ms": 1621442932242, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1302}}
rank 0: cycle = 94: time to send the model = 0.04976010322570801
:::MLLOG {"namespace": "", "time_ms": 1621442932292, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1316, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442932293, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1316, "epoch_count": 14}}
rank 640: cycle = 94: time to receive the model = 0.059603214263916016
:::MLLOG {"namespace": "", "time_ms": 1621442932302, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1316, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1316}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.76 s.
:::MLLOG {"namespace": "", "time_ms": 1621442933064, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8942108750343323, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1316}}
:::MLLOG {"namespace": "", "time_ms": 1621442933064, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1316}}
:::MLLOG {"namespace": "", "time_ms": 1621442933067, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4341.595201493526, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442933069, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442933069, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4341.595201493526, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1316}}
rank 0: cycle = 95: time to send the model = 0.04071640968322754
:::MLLOG {"namespace": "", "time_ms": 1621442933111, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1330, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442933111, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1330, "epoch_count": 14}}
rank 640: cycle = 95: time to receive the model = 0.051015615463256836
:::MLLOG {"namespace": "", "time_ms": 1621442933121, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1330, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1330}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442933883, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4353.753752380717, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442933885, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442933886, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4353.753752380717, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1330}}
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621442933886, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8994210362434387, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1330}}
:::MLLOG {"namespace": "", "time_ms": 1621442933887, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1330}}
rank 0: cycle = 96: time to send the model = 0.04861807823181152
:::MLLOG {"namespace": "", "time_ms": 1621442933936, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1344, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442933938, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1344, "epoch_count": 14}}
rank 640: cycle = 96: time to receive the model = 0.054566144943237305
:::MLLOG {"namespace": "", "time_ms": 1621442933942, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1344, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1344}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.762 s.
:::MLLOG {"namespace": "", "time_ms": 1621442934705, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8790065050125122, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1344}}
:::MLLOG {"namespace": "", "time_ms": 1621442934705, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1344}}
:::MLLOG {"namespace": "", "time_ms": 1621442934737, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4201.291147300928, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442934739, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442934739, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4201.291147300928, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1344}}
rank 0: cycle = 97: time to send the model = 0.03912758827209473
:::MLLOG {"namespace": "", "time_ms": 1621442934778, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1358, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442934779, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1358, "epoch_count": 14}}
rank 640: cycle = 97: time to receive the model = 0.05002951622009277
:::MLLOG {"namespace": "", "time_ms": 1621442934789, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1358, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1358}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621442935553, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.897811770439148, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1358}}
:::MLLOG {"namespace": "", "time_ms": 1621442935554, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1358}}
:::MLLOG {"namespace": "", "time_ms": 1621442935579, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4199.086709773304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442935581, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442935582, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4199.086709773304, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1358}}
rank 0: cycle = 98: time to send the model = 0.04851078987121582
:::MLLOG {"namespace": "", "time_ms": 1621442935631, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1372, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442935631, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1372, "epoch_count": 14}}
rank 640: cycle = 98: time to receive the model = 0.05488252639770508
:::MLLOG {"namespace": "", "time_ms": 1621442935637, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1372}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621442936402, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.895638108253479, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1372}}
:::MLLOG {"namespace": "", "time_ms": 1621442936402, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1372}}
:::MLLOG {"namespace": "", "time_ms": 1621442936403, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4353.858666420338, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442936405, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442936405, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4353.858666420338, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1372}}
rank 0: cycle = 99: time to send the model = 0.03829169273376465
:::MLLOG {"namespace": "", "time_ms": 1621442936443, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1386, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442936443, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1386, "epoch_count": 14}}
rank 640: cycle = 99: time to receive the model = 0.05047416687011719
:::MLLOG {"namespace": "", "time_ms": 1621442936455, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1386}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442937213, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4364.333767510308, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442937215, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442937215, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4364.333767510308, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1386}}
EVALUATION TIME: 0.76 s.
:::MLLOG {"namespace": "", "time_ms": 1621442937217, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8957513570785522, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1386}}
:::MLLOG {"namespace": "", "time_ms": 1621442937219, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1386}}
rank 0: cycle = 100: time to send the model = 0.04862713813781738
:::MLLOG {"namespace": "", "time_ms": 1621442937267, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1400, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442937269, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1400, "epoch_count": 14}}
rank 640: cycle = 100: time to receive the model = 0.05399966239929199
:::MLLOG {"namespace": "", "time_ms": 1621442937273, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1400}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442938002, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4581.752540015546, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442938004, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442938004, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4581.752540015546, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1400}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621442938038, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8957926034927368, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1621442938040, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1400}}
rank 0: cycle = 101: time to send the model = 0.03722023963928223
:::MLLOG {"namespace": "", "time_ms": 1621442938077, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1414, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442938078, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1414, "epoch_count": 14}}
rank 640: cycle = 101: time to receive the model = 0.05259299278259277
:::MLLOG {"namespace": "", "time_ms": 1621442938092, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1414, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1414}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.756 s.
:::MLLOG {"namespace": "", "time_ms": 1621442938849, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8984987735748291, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1414}}
:::MLLOG {"namespace": "", "time_ms": 1621442938850, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1414}}
:::MLLOG {"namespace": "", "time_ms": 1621442938867, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4261.21780168225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442938868, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442938869, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4261.21780168225, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1414}}
rank 0: cycle = 102: time to send the model = 0.04056429862976074
:::MLLOG {"namespace": "", "time_ms": 1621442938910, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1428, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442938910, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1428, "epoch_count": 14}}
rank 640: cycle = 102: time to receive the model = 0.049971580505371094
:::MLLOG {"namespace": "", "time_ms": 1621442938919, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1428, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1428}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.76 s.
:::MLLOG {"namespace": "", "time_ms": 1621442939680, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8961942791938782, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1428}}
:::MLLOG {"namespace": "", "time_ms": 1621442939680, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1428}}
:::MLLOG {"namespace": "", "time_ms": 1621442939713, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4181.772373206602, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442939715, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442939715, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4181.772373206602, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1428}}
rank 0: cycle = 103: time to send the model = 0.0379483699798584
:::MLLOG {"namespace": "", "time_ms": 1621442939753, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1442, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442939753, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1442, "epoch_count": 14}}
rank 640: cycle = 103: time to receive the model = 0.049719810485839844
:::MLLOG {"namespace": "", "time_ms": 1621442939765, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1442, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1442}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442940507, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4461.57632305258, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442940508, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442940508, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4461.57632305258, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1442}}
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621442940529, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.887640118598938, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1442}}
:::MLLOG {"namespace": "", "time_ms": 1621442940530, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1442}}
rank 0: cycle = 104: time to send the model = 0.043886661529541016
:::MLLOG {"namespace": "", "time_ms": 1621442940574, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1456, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442940575, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1456, "epoch_count": 14}}
rank 640: cycle = 104: time to receive the model = 0.05541038513183594
:::MLLOG {"namespace": "", "time_ms": 1621442940586, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1456, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1456}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.759 s.
:::MLLOG {"namespace": "", "time_ms": 1621442941346, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9012451171875, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1456}}
:::MLLOG {"namespace": "", "time_ms": 1621442941347, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1456}}
:::MLLOG {"namespace": "", "time_ms": 1621442941368, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4241.378249307492, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442941369, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442941369, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4241.378249307492, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1456}}
rank 0: cycle = 105: time to send the model = 0.040351152420043945
:::MLLOG {"namespace": "", "time_ms": 1621442941412, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1470, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442941412, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1470, "epoch_count": 14}}
rank 640: cycle = 105: time to receive the model = 0.05054879188537598
:::MLLOG {"namespace": "", "time_ms": 1621442941422, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1470, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1470}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442942165, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4460.206653315137, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442942167, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442942167, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4460.206653315137, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1470}}
EVALUATION TIME: 0.761 s.
:::MLLOG {"namespace": "", "time_ms": 1621442942184, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9027590751647949, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1470}}
:::MLLOG {"namespace": "", "time_ms": 1621442942185, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1470}}
rank 0: cycle = 106: time to send the model = 0.03981447219848633
:::MLLOG {"namespace": "", "time_ms": 1621442942225, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1484, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442942226, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1484, "epoch_count": 14}}
rank 640: cycle = 106: time to receive the model = 0.05077719688415527
:::MLLOG {"namespace": "", "time_ms": 1621442942236, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1484}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.761 s.
:::MLLOG {"namespace": "", "time_ms": 1621442942999, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8972642421722412, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1484}}
:::MLLOG {"namespace": "", "time_ms": 1621442942999, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1484}}
:::MLLOG {"namespace": "", "time_ms": 1621442943016, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4257.768832269812, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442943017, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442943017, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4257.768832269812, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1484}}
rank 0: cycle = 107: time to send the model = 0.04073452949523926
:::MLLOG {"namespace": "", "time_ms": 1621442943061, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1498, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442943062, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1498, "epoch_count": 14}}
rank 640: cycle = 107: time to receive the model = 0.05069231986999512
:::MLLOG {"namespace": "", "time_ms": 1621442943071, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1498, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1498}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442943815, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4458.368100383709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442943817, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442943817, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4458.368100383709, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1498}}
EVALUATION TIME: 0.761 s.
:::MLLOG {"namespace": "", "time_ms": 1621442943833, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.904436469078064, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1498}}
:::MLLOG {"namespace": "", "time_ms": 1621442943834, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1498}}
rank 0: cycle = 108: time to send the model = 0.03760409355163574
:::MLLOG {"namespace": "", "time_ms": 1621442943872, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1512, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442943873, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1512, "epoch_count": 14}}
rank 640: cycle = 108: time to receive the model = 0.050437211990356445
:::MLLOG {"namespace": "", "time_ms": 1621442943885, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1512, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1512}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.762 s.
:::MLLOG {"namespace": "", "time_ms": 1621442944648, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9038221836090088, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1512}}
:::MLLOG {"namespace": "", "time_ms": 1621442944648, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1512}}
:::MLLOG {"namespace": "", "time_ms": 1621442944649, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4335.169927842843, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442944650, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442944650, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4335.169927842843, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1512}}
rank 0: cycle = 109: time to send the model = 0.03844571113586426
:::MLLOG {"namespace": "", "time_ms": 1621442944689, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1526, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442944689, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1526, "epoch_count": 14}}
rank 640: cycle = 109: time to receive the model = 0.05027198791503906
:::MLLOG {"namespace": "", "time_ms": 1621442944701, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1526, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1526}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442945449, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4423.71301738929, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442945450, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442945450, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4423.71301738929, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1526}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621442945466, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8996307849884033, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1526}}
:::MLLOG {"namespace": "", "time_ms": 1621442945467, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1526}}
rank 0: cycle = 110: time to send the model = 0.047652244567871094
:::MLLOG {"namespace": "", "time_ms": 1621442945519, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1540, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442945520, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1540, "epoch_count": 14}}
rank 640: cycle = 110: time to receive the model = 0.05840349197387695
:::MLLOG {"namespace": "", "time_ms": 1621442945530, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1540}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442946263, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4526.055808522159, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442946264, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442946264, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4526.055808522159, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1540}}
EVALUATION TIME: 0.759 s.
:::MLLOG {"namespace": "", "time_ms": 1621442946290, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9042178988456726, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1621442946291, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1540}}
rank 0: cycle = 111: time to send the model = 0.03681039810180664
:::MLLOG {"namespace": "", "time_ms": 1621442946328, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1554, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442946329, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1554, "epoch_count": 14}}
rank 640: cycle = 111: time to receive the model = 0.05178332328796387
:::MLLOG {"namespace": "", "time_ms": 1621442946343, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1554, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1554}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.758 s.
:::MLLOG {"namespace": "", "time_ms": 1621442947102, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9021273851394653, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1554}}
:::MLLOG {"namespace": "", "time_ms": 1621442947102, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1554}}
:::MLLOG {"namespace": "", "time_ms": 1621442947128, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4203.322378281259, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442947130, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442947130, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4203.322378281259, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1554}}
rank 0: cycle = 112: time to send the model = 0.048509836196899414
:::MLLOG {"namespace": "", "time_ms": 1621442947179, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1568, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442947179, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1568, "epoch_count": 14}}
rank 640: cycle = 112: time to receive the model = 0.05516672134399414
:::MLLOG {"namespace": "", "time_ms": 1621442947185, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1568, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1568}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621442947951, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8950511813163757, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1568}}
:::MLLOG {"namespace": "", "time_ms": 1621442947951, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1568}}
:::MLLOG {"namespace": "", "time_ms": 1621442947974, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4225.259052630821, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442947976, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442947976, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4225.259052630821, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1568}}
rank 0: cycle = 113: time to send the model = 0.03816986083984375
:::MLLOG {"namespace": "", "time_ms": 1621442948014, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1582, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442948014, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1582, "epoch_count": 14}}
rank 640: cycle = 113: time to receive the model = 0.04976177215576172
:::MLLOG {"namespace": "", "time_ms": 1621442948026, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1582, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1582}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442948782, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4379.434151531838, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442948783, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442948783, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4379.434151531838, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1582}}
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621442948790, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9066900014877319, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1582}}
:::MLLOG {"namespace": "", "time_ms": 1621442948792, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1582}}
rank 0: cycle = 114: time to send the model = 0.04578685760498047
:::MLLOG {"namespace": "", "time_ms": 1621442948838, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1596, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442948839, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1596, "epoch_count": 14}}
rank 640: cycle = 114: time to receive the model = 0.05187559127807617
:::MLLOG {"namespace": "", "time_ms": 1621442948844, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1596, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1596}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442949588, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4487.390712509636, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442949589, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442949589, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4487.390712509636, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1596}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621442949611, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9049997925758362, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1596}}
:::MLLOG {"namespace": "", "time_ms": 1621442949612, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1596}}
rank 0: cycle = 115: time to send the model = 0.03770112991333008
:::MLLOG {"namespace": "", "time_ms": 1621442949650, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1610, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442949651, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1610, "epoch_count": 14}}
rank 640: cycle = 115: time to receive the model = 0.04991483688354492
:::MLLOG {"namespace": "", "time_ms": 1621442949662, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1610, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1610}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442950405, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4454.233725514985, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442950407, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442950407, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4454.233725514985, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1610}}
EVALUATION TIME: 0.76 s.
:::MLLOG {"namespace": "", "time_ms": 1621442950423, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.904876708984375, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1610}}
:::MLLOG {"namespace": "", "time_ms": 1621442950424, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1610}}
rank 0: cycle = 116: time to send the model = 0.04371476173400879
:::MLLOG {"namespace": "", "time_ms": 1621442950468, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1624, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621442950469, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1624, "epoch_count": 14}}
rank 640: cycle = 116: time to receive the model = 0.054624080657958984
:::MLLOG {"namespace": "", "time_ms": 1621442950479, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1624, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1624}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621442951209, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4544.030726758649, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621442951210, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621442951210, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4544.030726758649, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1624}}
EVALUATION TIME: 0.76 s.
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
:::MLLOG {"namespace": "", "time_ms": 1621442951241, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9108392596244812, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1624}}
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
:::MLLOG {"namespace": "", "time_ms": 1621442951242, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1624}}
STOP TRAINING TRIGGERED AFTER EVAL
:::MLLOG {"namespace": "", "time_ms": 1621442951242, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 102, "status": "success"}}
rank 0: cycle = 117: time to send the model = 0.03649330139160156
rank 640: cycle = 117: time to receive the model = 0.05059313774108887
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
+ set +x
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
+ ret_code=0
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
+ ret_code=0
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
+ ret_code=0
+ set +x
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
+ ret_code=0
+ set +x
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
+ ret_code=0
+ set +x
+ set +x
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
+ set +x
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
+ ret_code=0
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ set +x
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
+ set +x
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
+ set +x
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:34 AM
RESULT,image_segmentation,,504,nvidia,2021-05-19 09:41:10 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:35 AM
RESULT,image_segmentation,,505,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:36 AM
RESULT,image_segmentation,,506,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
ENDING TIMING RUN AT 2021-05-19 09:49:37 AM
RESULT,image_segmentation,,507,nvidia,2021-05-19 09:41:10 AM
