+ echo 'Beginning trial 8 of 10'
Beginning trial 8 of 10
+ '[' 1 -eq 1 ']'
+ srun --ntasks=100 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on luna-0186
Clearing cache on luna-0038
Clearing cache on luna-0264
Clearing cache on luna-0080
Clearing cache on luna-0026
Clearing cache on luna-0183
Clearing cache on luna-0210
Clearing cache on luna-0083
Clearing cache on luna-0086
Clearing cache on luna-0023
Clearing cache on luna-0180
Clearing cache on luna-0032
Clearing cache on luna-0077
Clearing cache on luna-0213
Clearing cache on luna-0189
Clearing cache on luna-0211
Clearing cache on luna-0190
Clearing cache on luna-0027
Clearing cache on luna-0081
Clearing cache on luna-0033
Clearing cache on luna-0087
Clearing cache on luna-0036
Clearing cache on luna-0030
Clearing cache on luna-0084
Clearing cache on luna-0214
Clearing cache on luna-0205
Clearing cache on luna-0184
Clearing cache on luna-0024
Clearing cache on luna-0187
Clearing cache on luna-0039
Clearing cache on luna-0040
Clearing cache on luna-0215
Clearing cache on luna-0028
Clearing cache on luna-0212
Clearing cache on luna-0176
Clearing cache on luna-0191
Clearing cache on luna-0188
Clearing cache on luna-0031
Clearing cache on luna-0025
Clearing cache on luna-0079
Clearing cache on luna-0206
Clearing cache on luna-0088
Clearing cache on luna-0022
Clearing cache on luna-0037
Clearing cache on luna-0085
Clearing cache on luna-0035
Clearing cache on luna-0177
Clearing cache on luna-0192
Clearing cache on luna-0207
Clearing cache on luna-0029
Clearing cache on luna-0276
Clearing cache on luna-0222
Clearing cache on luna-0261
Clearing cache on luna-0279
Clearing cache on luna-0096
Clearing cache on luna-0021
Clearing cache on luna-0208
Clearing cache on luna-0223
Clearing cache on luna-0277
Clearing cache on luna-0274
Clearing cache on luna-0078
Clearing cache on luna-0268
Clearing cache on luna-0265
Clearing cache on luna-0271
Clearing cache on luna-0220
Clearing cache on luna-0262
Clearing cache on luna-0185
Clearing cache on luna-0218
Clearing cache on luna-0221
Clearing cache on luna-0094
Clearing cache on luna-0209
Clearing cache on luna-0082
Clearing cache on luna-0034
Clearing cache on luna-0091
Clearing cache on luna-0275
Clearing cache on luna-0278
Clearing cache on luna-0269
Clearing cache on luna-0224
Clearing cache on luna-0272
Clearing cache on luna-0263
Clearing cache on luna-0266
Clearing cache on luna-0267
Clearing cache on luna-0270
Clearing cache on luna-0273
Clearing cache on luna-0280
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
Clearing cache on luna-0174
Clearing cache on luna-0095
Clearing cache on luna-0181
Clearing cache on luna-0093
Clearing cache on luna-0090
Clearing cache on luna-0178
Clearing cache on luna-0173
Clearing cache on luna-0179
Clearing cache on luna-0182
Clearing cache on luna-0175
Clearing cache on luna-0217
Clearing cache on luna-0092
Clearing cache on luna-0089
Clearing cache on luna-0216
Clearing cache on luna-0219
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --mpi=pmix --ntasks=800 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/lustre/fsw/mlperf/mlperft-unet3d/dataset/:/data,/lustre/fsw/mlperf-ci/23360856/results:/results,/lustre/fsw/mlperf/mlperft-unet3d/rachitg/logs/single_node:/profile_dir ./run_and_time.sh
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 3 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 7 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=
running benchmark
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 0 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 3 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR=1.5
+ OPTIMIZER=nag
running benchmark
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
running benchmark
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ LR=1.5
+ '[' -n 7 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
running benchmark
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 6 ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ cluster=
+ '[' -n 2 ']'
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
+ EVALUATE_EVERY=14
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
+ '[' -n 5 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 6 ']'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ LR=1.5
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ '[' -n 5 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 3 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 1 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 5 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 5 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ START_EVAL_AT=700
+ declare -a CMD
running benchmark
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' -n 0 ']'
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' -n 1 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
running benchmark
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
running benchmark
+ '[' -n 2 ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
running benchmark
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 5 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' -n 6 ']'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ TARGET_DIR=
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ MAX_EPOCHS=7000
+ declare -a CMD
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
running benchmark
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 6 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ PROFILING_PREFIX=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 5 ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 0 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ DATASET_DIR=/data
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ VAL_BATCH_SIZE=1
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ '[' -n 6 ']'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR=1.5
+ cluster=
+ '[' -n 5 ']'
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
running benchmark
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
running benchmark
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ START_EVAL_AT=700
running benchmark
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
+ declare -a CMD
running benchmark
+ SEED=-1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 5 ']'
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 7 ']'
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ PROFILING_PREFIX=
+ cluster=
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ '[' -n 6 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR=1.5
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
running benchmark
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' -n 7 ']'
+ BATCH_SIZE=1
+ '[' -n 0 ']'
+ '[' -n 6 ']'
+ EVALUATE_EVERY=14
+ '[' -n 1 ']'
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ cluster=
+ cluster=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ cluster=
running benchmark
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 3 ']'
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=
+ TARGET_DIR=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 3 ']'
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ SEED=-1
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ PROFILING_PREFIX=
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 7 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ OPTIMIZER=nag
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ PROFILING_PREFIX=
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ BATCH_SIZE=1
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ DATASET_DIR=/data
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ SEED=-1
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ LR=1.5
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' -n 6 ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ '[' -n 2 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ '[' -n 0 ']'
+ LR=1.5
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 0 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ '[' -n 3 ']'
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 7 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ '[' -n 1 ']'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 4 ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ cluster=
+ declare -a CMD
+ declare -a CMD
+ TARGET_DIR=
+ cluster=
+ '[' -n 5 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 3 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ SEED=-1
+ '[' -n 7 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 4 ']'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR=1.5
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ TARGET_DIR=
running benchmark
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ '[' -n 1 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 6 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ cluster=selene
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR=1.5
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ '[' -n 5 ']'
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
running benchmark
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ LR=1.5
+ SEED=-1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ '[' -n 7 ']'
+ '[' -n 4 ']'
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
running benchmark
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 1 ']'
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ '[' -n 1 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ '[' -n 5 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 6 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ '[' -n 6 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
+ echo 'running benchmark'
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
running benchmark
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ '[' -n 0 ']'
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ TARGET_DIR=
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 2 ']'
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ cluster=
+ EVALUATE_EVERY=14
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
running benchmark
+ '[' -n 6 ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 3 ']'
+ DATASET_DIR=/data
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 1 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
+ TARGET_DIR=
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ declare -a CMD
+ DATASET_DIR=/data
+ '[' -n 5 ']'
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 1 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ QUALITY_THRESHOLD=0.908
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 5 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 5 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 4 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 6 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ declare -a CMD
running benchmark
+ PROFILING_PREFIX=
+ '[' -n 0 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 3 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR=1.5
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ DATASET_DIR=/data
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ TARGET_DIR=
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ declare -a CMD
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 5 ']'
+ LR=1.5
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
running benchmark
+ cluster=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 0 ']'
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=
running benchmark
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 2 ']'
running benchmark
+ LR=1.5
+ cluster=
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
running benchmark
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
+ '[' -n 5 ']'
running benchmark
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 3 ']'
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
running benchmark
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ BATCH_SIZE=1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=
+ '[' -n 6 ']'
running benchmark
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 3 ']'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ VAL_BATCH_SIZE=1
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ START_EVAL_AT=700
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
running benchmark
+ PROFILING_PREFIX=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 4 ']'
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ '[' -n 7 ']'
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=selene
+ TARGET_DIR=
+ cluster=
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 7 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ SEED=-1
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ LR=1.5
+ LR=1.5
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 5 ']'
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 0 ']'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ QUALITY_THRESHOLD=0.908
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ declare -a CMD
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ '[' -n 7 ']'
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ cluster=
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ declare -a CMD
+ SEED=-1
+ '[' -n 2 ']'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 2 ']'
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ SEED=-1
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 4 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' -n 5 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' -n 0 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ declare -a CMD
+ EVALUATE_EVERY=14
running benchmark
+ TARGET_DIR=
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ SEED=-1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' -n 6 ']'
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 4 ']'
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
running benchmark
+ TARGET_DIR=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 6 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ MAX_EPOCHS=7000
running benchmark
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ echo 'running benchmark'
+ '[' -n 0 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ '[' -n 2 ']'
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ DATASET_DIR=/data
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 3 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 5 ']'
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 3 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ cluster=selene
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ '[' -n 3 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ '[' -n 3 ']'
+ '[' -n 0 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ cluster=
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
running benchmark
+ LR=1.5
+ cluster=selene
running benchmark
+ cluster=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 2 ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ cluster=selene
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 7 ']'
+ echo 'running benchmark'
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 2 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ cluster=
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 4 ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ OPTIMIZER=nag
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
+ cluster=
+ LR=1.5
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
running benchmark
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 5 ']'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ '[' -n 7 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
+ MAX_EPOCHS=7000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ cluster=
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
running benchmark
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ cluster=
+ cluster=
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ START_EVAL_AT=700
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 3 ']'
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR=1.5
+ cluster=
+ '[' -n 5 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 7 ']'
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' -n 7 ']'
+ cluster=
+ '[' -n 6 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 7 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 7 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ declare -a CMD
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
+ TARGET_DIR=
+ BATCH_SIZE=1
+ SEED=-1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ cluster=
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ LR=1.5
+ '[' -n 1 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
+ SEED=-1
running benchmark
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ TARGET_DIR=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
running benchmark
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
running benchmark
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' -n 1 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ SEED=-1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ '[' -n 0 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
+ declare -a CMD
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ '[' -n 7 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ QUALITY_THRESHOLD=0.908
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
running benchmark
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 4 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' -n 6 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ '[' -n 2 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
running benchmark
+ DATASET_DIR=/data
+ cluster=
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
running benchmark
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 6 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
running benchmark
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 6 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
+ echo 'running benchmark'
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ TARGET_DIR=
+ '[' -n 0 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ '[' -n 1 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ '[' -n 5 ']'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ '[' -n 3 ']'
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ LR=1.5
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ echo 'running benchmark'
+ '[' -n 1 ']'
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ '[' '' = apiLog.sh ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ DATASET_DIR=/data
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ declare -a CMD
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
running benchmark
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 2 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ '[' -n 4 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ '[' -n 3 ']'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 0 ']'
+ DATASET_DIR=/data
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ '[' -n 0 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 0 ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' -n 0 ']'
+ echo 'running benchmark'
+ '[' -n 2 ']'
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ cluster=
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 5 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ START_EVAL_AT=700
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
running benchmark
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ '[' -n 6 ']'
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
running benchmark
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
running benchmark
+ echo 'running benchmark'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ '[' -n 1 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
+ QUALITY_THRESHOLD=0.908
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' -n 4 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 5 ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 7 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 7 ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ SEED=-1
+ '[' -n 5 ']'
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 6 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 2 ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ cluster=
+ TARGET_DIR=
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
running benchmark
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ LR=1.5
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
running benchmark
+ TARGET_DIR=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ declare -a CMD
+ '[' -n 7 ']'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' -n 1 ']'
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' -n 5 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
+ LR=1.5
running benchmark
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
running benchmark
+ declare -a CMD
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ '[' -n 3 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 6 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ SEED=-1
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' -n 5 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 0 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
running benchmark
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 4 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
running benchmark
+ BATCH_SIZE=1
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=selene
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ declare -a CMD
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ OPTIMIZER=nag
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=selene
+ '[' -n 3 ']'
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ START_EVAL_AT=700
running benchmark
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' -n 5 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ DATASET_DIR=/data
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ SEED=-1
+ '[' -n 4 ']'
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
running benchmark
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ SEED=-1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
running benchmark
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ declare -a CMD
running benchmark
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' -n 4 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ SEED=-1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' -n 6 ']'
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ SEED=-1
+ VAL_BATCH_SIZE=1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ SEED=-1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
running benchmark
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ TARGET_DIR=
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ '[' -n 2 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ EVALUATE_EVERY=14
+ '[' -n 1 ']'
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
running benchmark
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ LR=1.5
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ cluster=
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ SEED=-1
+ echo 'running benchmark'
+ TARGET_DIR=
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 3 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ VAL_BATCH_SIZE=1
running benchmark
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
running benchmark
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ START_EVAL_AT=700
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 2 ']'
running benchmark
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ '[' -n 4 ']'
+ declare -a CMD
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 1 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 5 ']'
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
running benchmark
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
running benchmark
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 7 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' -n 4 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
+ TARGET_DIR=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ VAL_BATCH_SIZE=1
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
+ OPTIMIZER=nag
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ '[' -n 0 ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' -n 1 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ START_EVAL_AT=700
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ declare -a CMD
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ cluster=
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 1 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
running benchmark
+ echo 'running benchmark'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
running benchmark
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ '[' -n 3 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ declare -a CMD
+ DATASET_DIR=/data
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ SEED=-1
+ '[' 800 -gt 100 ']'
running benchmark
+ OPTIMIZER=nag
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
running benchmark
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 5 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
running benchmark
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 2 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ SEED=-1
running benchmark
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 7 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
running benchmark
+ DATASET_DIR=/data
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ SEED=-1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 7 ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' -n 2 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' -n 0 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ OPTIMIZER=nag
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
running benchmark
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 6 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ LR=1.5
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ SEED=-1
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ declare -a CMD
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 3 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ SEED=-1
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 0 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 1 ']'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
running benchmark
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ declare -a CMD
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ '[' -n 3 ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ LR=1.5
+ '[' -n 1 ']'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ echo 'running benchmark'
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ LR=1.5
+ '[' -n 4 ']'
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
running benchmark
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
running benchmark
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
running benchmark
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ echo 'running benchmark'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 7 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ LR=1.5
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
running benchmark
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ LR=1.5
running benchmark
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ echo 'running benchmark'
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 0 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
running benchmark
+ declare -a CMD
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 7 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
+ START_EVAL_AT=700
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ '[' -n 7 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 6 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' -n 0 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ SEED=-1
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ '[' -n 1 ']'
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 6 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ '[' -n 5 ']'
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ PROFILING_PREFIX=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
running benchmark
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ '[' -n 3 ']'
+ MAX_EPOCHS=7000
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' 800 -gt 100 ']'
+ '[' -n 1 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ TARGET_DIR=
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 6 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ OPTIMIZER=nag
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ declare -a CMD
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ declare -a CMD
+ START_EVAL_AT=700
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ '[' -n 2 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 7 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 0 ']'
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ MAX_EPOCHS=7000
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
+ TARGET_DIR=
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ TARGET_DIR=
+ PROFILING_PREFIX=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 0 ']'
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' -n 6 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ '[' -n 1 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
running benchmark
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ EVALUATE_EVERY=14
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ '[' -n 7 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ declare -a CMD
+ '[' -n 3 ']'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' '' = apiLog.sh ']'
running benchmark
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 7 ']'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ '[' -n 2 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 1 ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ '[' -n 1 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
running benchmark
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ EVALUATE_EVERY=14
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ TARGET_DIR=
running benchmark
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ OPTIMIZER=nag
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR=1.5
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ TARGET_DIR=
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 2 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ declare -a CMD
+ echo 'running benchmark'
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' -n 5 ']'
+ VAL_BATCH_SIZE=1
+ '[' -n 1 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ '[' -n 4 ']'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ '[' -n 2 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 6 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 5 ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ declare -a CMD
+ declare -a CMD
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 2 ']'
+ TARGET_DIR=
+ '[' -n 7 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 5 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 0 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ TARGET_DIR=
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ LR=1.5
+ declare -a CMD
+ '[' -n 3 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' -n 4 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 4 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ DATASET_DIR=/data
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ LR=1.5
+ START_EVAL_AT=700
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 2 ']'
+ '[' -n 6 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 0 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 1 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ BATCH_SIZE=1
+ '[' -n 7 ']'
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ LR=1.5
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ '[' -n 7 ']'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ MAX_EPOCHS=7000
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ SEED=-1
+ '[' -n 1 ']'
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ '[' -n 6 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ cluster=selene
+ DATASET_DIR=/data
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 4 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' -n 1 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' -n 5 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ declare -a CMD
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 2 ']'
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 4 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 6 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ DATASET_DIR=/data
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ declare -a CMD
+ '[' -n 1 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 5 ']'
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' -n 0 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 7 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ '[' -n 0 ']'
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ '[' -n 0 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ '[' -n 6 ']'
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ declare -a CMD
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 0 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 1 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
+ cluster=
+ echo 'running benchmark'
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 6 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 0 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ '[' -n 7 ']'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ echo 'running benchmark'
+ '[' -n 3 ']'
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ declare -a CMD
+ TARGET_DIR=
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ declare -a CMD
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 7 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ echo 'running benchmark'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
num_sockets = 2 num_nodes=8 cores_per_socket=64
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ declare -a CMD
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' '' = apiLog.sh ']'
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 10:13:56 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ declare -a CMD
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
:::MLLOG {"namespace": "", "time_ms": 1621444438394, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 30}}
:::MLLOG {"namespace": "", "time_ms": 1621444438436, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 31}}
:::MLLOG {"namespace": "", "time_ms": 1621444438437, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 101}}
:::MLLOG {"namespace": "", "time_ms": 1621444438437, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "nvidia", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 106}}
:::MLLOG {"namespace": "", "time_ms": 1621444438437, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 110}}
:::MLLOG {"namespace": "", "time_ms": 1621444438437, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 114}}
:::MLLOG {"namespace": "", "time_ms": 1621444438437, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "100xNVIDIA DGX A100", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 118}}
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:14:03] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[luna-0021:0:4066657 - context.c:581] INFO job (ID: 17873238599150591820) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066657 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x7 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0021:0:4066657 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x46 caps:0x16
[luna-0021:0:4066657 - comm.c:385] INFO [group#:0] group id:1 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x661600000001) mlid:c00e
[luna-0021:0:4066657 - comm.c:385] INFO [group#:1] group id:1 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0021:0:4066673 - context.c:581] INFO job (ID: 17873238110966900658) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066673 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x8 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0021:0:4066673 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x47 caps:0x16
[luna-0021:0:4066673 - comm.c:385] INFO [group#:0] group id:2 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x671600000002) mlid:c00f
[luna-0021:0:4066673 - comm.c:385] INFO [group#:1] group id:2 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0021:0:4066680 - context.c:581] INFO job (ID: 17873237864896941618) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066680 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x1 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0021:0:4066680 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x40 caps:0x16
[luna-0021:0:4066680 - comm.c:385] INFO [group#:0] group id:3 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x681600000003) mlid:c007
[luna-0021:0:4066680 - comm.c:385] INFO [group#:1] group id:3 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0021:0:4066677 - context.c:581] INFO job (ID: 17873238597316281034) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066677 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0021:0:4066677 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
[luna-0021:0:4066677 - comm.c:385] INFO [group#:0] group id:4 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x691600000004) mlid:c006
[luna-0021:0:4066677 - comm.c:385] INFO [group#:1] group id:4 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0021:0:4066663 - context.c:581] INFO job (ID: 17873238317790006300) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066663 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x2 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0021:0:4066663 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x41 caps:0x16
[luna-0021:0:4066663 - comm.c:385] INFO [group#:0] group id:5 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x6a1600000005) mlid:c008
[luna-0021:0:4066663 - comm.c:385] INFO [group#:1] group id:5 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0021:0:4066731 - context.c:581] INFO job (ID: 17873238399537637924) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066731 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x3 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0021:0:4066731 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x42 caps:0x16
[luna-0021:0:4066731 - comm.c:385] INFO [group#:0] group id:6 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x6b1600000006) mlid:c009
[luna-0021:0:4066731 - comm.c:385] INFO [group#:1] group id:6 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0021:0:4066682 - context.c:581] INFO job (ID: 17873237852194535904) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066682 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x5 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0021:0:4066682 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x44 caps:0x16
[luna-0021:0:4066682 - comm.c:385] INFO [group#:0] group id:7 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x6c1600000007) mlid:c00a
[luna-0021:0:4066682 - comm.c:385] INFO [group#:1] group id:7 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238691582287306) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0xa caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0021:0:4066678 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x49 caps:0x16
[luna-0021:0:4066678 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0027:6:1025826 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0093:36:3192584 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0214:69:748999 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0086:29:1863167 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0083:26:2910041 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0035:14:2588412 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0210:65:1266865 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0183:50:1044734 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0213:68:2631115 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0089:32:2530715 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0034:13:2497558 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0031:10:3242492 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0088:31:1788266 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0094:37:2144603 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0082:25:3015346 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0025:4:998221 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0209:64:3253913 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0037:16:1810355 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0176:43:2080098 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0218:73:2389345 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0185:52:729668 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0182:49:3566174 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0028:7:1994708 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0040:19:1558491 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0079:22:743598 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0191:58:3307073 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0022:1:320314 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0215:70:751676 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0217:72:2340052 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0208:63:715984 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0030:9:3306883 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0205:60:20620 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0220:75:3348138 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0038:17:1629846 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0026:5:928295 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0207:62:3346254 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0092:35:2176361 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0095:38:1337056 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0032:11:2964925 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0177:44:2023594 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0192:59:3296420 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0080:23:2012027 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0184:51:1051884 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0077:20:3942811 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0224:79:3827008 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0173:40:2873980 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0087:30:1845596 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0096:39:2122840 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0178:45:1116156 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0211:66:3206261 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0033:12:2730821 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0081:24:1329599 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0084:27:2877984 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0024:3:1027580 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0187:54:872756 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0036:15:2504746 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0039:18:1527700 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0186:53:786247 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0174:41:1436677 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0216:71:4008280 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0023:2:543889 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0180:47:753935 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0189:56:3789689 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0029:8:2437940 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0188:55:3180161 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0212:67:2778659 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0206:61:2694090 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0085:28:2367821 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0091:34:2286891 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0179:46:1131400 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0221:76:3272949 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0181:48:1115283 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0090:33:2320175 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0223:78:3906644 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0175:42:1930880 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0078:21:2102236 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0219:74:3674804 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0190:57:3434211 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0222:77:3581055 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238692444364442) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0xb caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0021:0:4066678 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x4a caps:0x16
[luna-0021:0:4066678 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0027:6:1025826 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0178:45:1116156 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0211:66:3206261 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0081:24:1329599 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0093:36:3192584 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0036:15:2504746 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0039:18:1527700 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0086:29:1863167 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0083:26:2910041 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0186:53:786247 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0035:14:2588412 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0023:2:543889 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0210:65:1266865 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0180:47:753935 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0183:50:1044734 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0213:68:2631115 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0189:56:3789689 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0034:13:2497558 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0031:10:3242492 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0094:37:2144603 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0082:25:3015346 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0188:55:3180161 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0025:4:998221 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0209:64:3253913 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0037:16:1810355 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0176:43:2080098 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0091:34:2286891 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0218:73:2389345 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0182:49:3566174 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0028:7:1994708 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0040:19:1558491 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0179:46:1131400 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0079:22:743598 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0022:1:320314 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0215:70:751676 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0181:48:1115283 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0217:72:2340052 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0208:63:715984 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0030:9:3306883 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0205:60:20620 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0090:33:2320175 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0223:78:3906644 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0220:75:3348138 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0038:17:1629846 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0026:5:928295 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0095:38:1337056 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0032:11:2964925 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0177:44:2023594 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0192:59:3296420 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0080:23:2012027 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0184:51:1051884 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0077:20:3942811 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0224:79:3827008 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0173:40:2873980 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0087:30:1845596 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0096:39:2122840 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0033:12:2730821 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0084:27:2877984 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0024:3:1027580 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0187:54:872756 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0214:69:748999 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0174:41:1436677 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0216:71:4008280 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0089:32:2530715 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0029:8:2437940 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0088:31:1788266 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0212:67:2778659 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0206:61:2694090 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0085:28:2367821 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0185:52:729668 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0191:58:3307073 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0221:76:3272949 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0175:42:1930880 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0078:21:2102236 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0207:62:3346254 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0092:35:2176361 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0219:74:3674804 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0190:57:3434211 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0222:77:3581055 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238691716472893) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0xd caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0021:0:4066678 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x4c caps:0x16
[luna-0021:0:4066678 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0027:6:1025826 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0093:36:3192584 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0086:29:1863167 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0035:14:2588412 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0213:68:2631115 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0189:56:3789689 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0029:8:2437940 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0037:16:1810355 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0179:46:1131400 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0221:76:3272949 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0215:70:751676 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0217:72:2340052 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0030:9:3306883 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0026:5:928295 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0219:74:3674804 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0184:51:1051884 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0224:79:3827008 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0173:40:2873980 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0087:30:1845596 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0096:39:2122840 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0178:45:1116156 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0211:66:3206261 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0033:12:2730821 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0081:24:1329599 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0084:27:2877984 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0024:3:1027580 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0187:54:872756 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0214:69:748999 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0036:15:2504746 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0039:18:1527700 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0083:26:2910041 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0186:53:786247 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0174:41:1436677 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0216:71:4008280 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0023:2:543889 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0210:65:1266865 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0180:47:753935 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0183:50:1044734 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0089:32:2530715 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0034:13:2497558 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0031:10:3242492 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0088:31:1788266 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0094:37:2144603 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0082:25:3015346 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0188:55:3180161 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0025:4:998221 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0209:64:3253913 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0212:67:2778659 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0206:61:2694090 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0085:28:2367821 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0176:43:2080098 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0091:34:2286891 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0218:73:2389345 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0185:52:729668 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0182:49:3566174 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0028:7:1994708 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0040:19:1558491 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0079:22:743598 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0191:58:3307073 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0022:1:320314 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0181:48:1115283 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0208:63:715984 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0205:60:20620 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0090:33:2320175 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0223:78:3906644 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0175:42:1930880 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0078:21:2102236 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0220:75:3348138 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0038:17:1629846 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0207:62:3346254 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0092:35:2176361 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0095:38:1337056 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0032:11:2964925 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0177:44:2023594 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0192:59:3296420 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0080:23:2012027 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0190:57:3434211 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0222:77:3581055 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0077:20:3942811 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238691263185788) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x20 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0021:0:4066678 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x5f caps:0x16
[luna-0021:0:4066678 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0027:6:1025826 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0036:15:2504746 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0083:26:2910041 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0221:76:3272949 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0038:17:1629846 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0173:40:2873980 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0087:30:1845596 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0211:66:3206261 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0093:36:3192584 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0214:69:748999 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0086:29:1863167 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0035:14:2588412 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0210:65:1266865 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0180:47:753935 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0183:50:1044734 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0213:68:2631115 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0189:56:3789689 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0029:8:2437940 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0031:10:3242492 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0082:25:3015346 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0188:55:3180161 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0025:4:998221 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0209:64:3253913 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0212:67:2778659 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0037:16:1810355 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0176:43:2080098 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0091:34:2286891 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0218:73:2389345 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0185:52:729668 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0028:7:1994708 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0040:19:1558491 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0179:46:1131400 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0191:58:3307073 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0022:1:320314 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0215:70:751676 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0181:48:1115283 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0217:72:2340052 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0208:63:715984 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0030:9:3306883 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0205:60:20620 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0090:33:2320175 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0223:78:3906644 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0220:75:3348138 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0026:5:928295 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0207:62:3346254 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0092:35:2176361 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0095:38:1337056 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0032:11:2964925 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0177:44:2023594 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0192:59:3296420 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0219:74:3674804 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0184:51:1051884 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0190:57:3434211 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0077:20:3942811 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0224:79:3827008 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0096:39:2122840 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0178:45:1116156 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0033:12:2730821 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0081:24:1329599 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0084:27:2877984 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0024:3:1027580 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0187:54:872756 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0039:18:1527700 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0186:53:786247 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0174:41:1436677 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0216:71:4008280 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0023:2:543889 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0089:32:2530715 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0034:13:2497558 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0088:31:1788266 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0094:37:2144603 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0206:61:2694090 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0085:28:2367821 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0182:49:3566174 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0079:22:743598 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0175:42:1930880 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0078:21:2102236 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0080:23:2012027 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0222:77:3581055 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238691051213519) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x26 caps:0x6 quota: ( osts:28 user_data_per_ost:1024 max_groups:28 max_qps:1 max_group_channels:1)
[luna-0021:0:4066678 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x65 caps:0x16
[luna-0087:30:1845596 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0027:6:1025826 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0178:45:1116156 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0211:66:3206261 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0093:36:3192584 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0036:15:2504746 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0086:29:1863167 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0083:26:2910041 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0186:53:786247 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0035:14:2588412 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0023:2:543889 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0210:65:1266865 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0180:47:753935 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0183:50:1044734 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0213:68:2631115 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0189:56:3789689 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0034:13:2497558 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0094:37:2144603 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0188:55:3180161 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0025:4:998221 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0209:64:3253913 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0212:67:2778659 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0176:43:2080098 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0091:34:2286891 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0218:73:2389345 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0182:49:3566174 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0028:7:1994708 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0040:19:1558491 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0179:46:1131400 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0079:22:743598 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0191:58:3307073 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0221:76:3272949 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0022:1:320314 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0215:70:751676 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0181:48:1115283 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0217:72:2340052 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0208:63:715984 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0030:9:3306883 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0021:0:4066678 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0205:60:20620 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0090:33:2320175 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0223:78:3906644 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0220:75:3348138 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0038:17:1629846 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0026:5:928295 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0207:62:3346254 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0092:35:2176361 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0095:38:1337056 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0032:11:2964925 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0177:44:2023594 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0192:59:3296420 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0219:74:3674804 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0184:51:1051884 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0190:57:3434211 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0077:20:3942811 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0224:79:3827008 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0173:40:2873980 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0096:39:2122840 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0033:12:2730821 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0081:24:1329599 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0084:27:2877984 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0024:3:1027580 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0187:54:872756 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0214:69:748999 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0039:18:1527700 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0174:41:1436677 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0216:71:4008280 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0089:32:2530715 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0029:8:2437940 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0031:10:3242492 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0088:31:1788266 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0082:25:3015346 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0206:61:2694090 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0085:28:2367821 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0037:16:1810355 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0185:52:729668 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0175:42:1930880 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0078:21:2102236 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0080:23:2012027 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0222:77:3581055 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238692082075561) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x24 caps:0x6 quota: ( osts:10 user_data_per_ost:96 max_groups:10 max_qps:1 max_group_channels:1)
[luna-0021:0:4066678 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x63 caps:0x16
[luna-0021:0:4066678 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0173:40:2873980 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0027:6:1025826 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0093:36:3192584 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0214:69:748999 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0086:29:1863167 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0083:26:2910041 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0210:65:1266865 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0213:68:2631115 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0189:56:3789689 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0025:4:998221 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0218:73:2389345 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0179:46:1131400 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0079:22:743598 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0221:76:3272949 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0215:70:751676 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0181:48:1115283 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0217:72:2340052 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0030:9:3306883 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0223:78:3906644 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0078:21:2102236 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0026:5:928295 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0207:62:3346254 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0192:59:3296420 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0077:20:3942811 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0224:79:3827008 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0087:30:1845596 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0096:39:2122840 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0178:45:1116156 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0211:66:3206261 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0033:12:2730821 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0081:24:1329599 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0084:27:2877984 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0024:3:1027580 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0187:54:872756 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0036:15:2504746 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0039:18:1527700 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0186:53:786247 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0174:41:1436677 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0216:71:4008280 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0035:14:2588412 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0023:2:543889 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0180:47:753935 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0183:50:1044734 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0089:32:2530715 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0029:8:2437940 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0034:13:2497558 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0031:10:3242492 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0088:31:1788266 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0094:37:2144603 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0082:25:3015346 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0188:55:3180161 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0209:64:3253913 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0212:67:2778659 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0206:61:2694090 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0085:28:2367821 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0037:16:1810355 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0176:43:2080098 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0091:34:2286891 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0185:52:729668 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0182:49:3566174 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0028:7:1994708 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0040:19:1558491 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0191:58:3307073 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0022:1:320314 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0208:63:715984 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0205:60:20620 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0090:33:2320175 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0175:42:1930880 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0220:75:3348138 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0038:17:1629846 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0092:35:2176361 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0095:38:1337056 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0032:11:2964925 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0177:44:2023594 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0080:23:2012027 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0219:74:3674804 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0184:51:1051884 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0190:57:3434211 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0222:77:3581055 - comm.c:364] ERROR Failed to lock SAT tree. ret:0x4
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238692444119765) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238692500418499) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238692164194685) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238692394781365) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238691641752802) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238691364853110) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238690798656802) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238691066707963) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238690919855002) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238691601965342) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238690657522943) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238691268344826) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238692083324695) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238690615023409) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238692642502651) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238690653127736) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238690728088461) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[luna-0021:0:4066678 - context.c:581] INFO job (ID: 17873238691869531153) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0021:0:4066678 unique id 13] ERROR Job error in sharp_get_job_data_len.

[luna-0021:0:4066678 - context.c:610] ERROR sharp_get_job_data_len failed: Job error(-35)
[luna-0021:0:4066678 - context.c:621] ERROR SHArP Job init error: No resource
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
Using random master seed: 1993590900. Worker seeds 640: [3764478074, 2498708358, 3339491309, 2750934537, 2523549913, 4287976431, 2543238805, 4168786795, 4273494557, 3267755715, 1778825827, 3043463971, 3229828298, 1749030385, 139619219, 71258884, 2124207701, 301634766, 4088233150, 3919337339, 3755152183, 624420695, 138511092, 1381231451, 2444098032, 378234542, 4089892784, 2585123589, 3378377696, 2675231622, 1171277689, 929012846, 3045398926, 4132178150, 3747454269, 3713679045, 2913963693, 426908744, 4225059417, 2223536440, 1173873749, 1274396445, 773248182, 1000166279, 3472101301, 3609485205, 2819110314, 1342115934, 1969211114, 2809881599, 2086882004, 771967827, 2902382839, 1036458155, 566773689, 3026147643, 3566781073, 4160942633, 62397688, 1056519370, 2229237701, 3030327658, 4271052695, 1731815864, 2593062210, 2834903296, 761991916, 2065021311, 2374319733, 1773715770, 4744920, 1792971636, 2183502001, 1654377070, 976694838, 3946843757, 4223035789, 2778318240, 2104369444, 2589243213, 2382687683, 2858059951, 13[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
64873762, 2583573360, 3087273039, 322795751, 1129840248, 2714030450, 4119546975, 1126424853, 1455576690, 1786676104, 2548834104, 2054425598, 2009607997, 2512940580, 704387642, 3341759501, 2801607825, 790282685, 4229436996, 1149633969, 518077245, 909458575, 2543078283, 1505912947, 973373233, 1665192953, 2728864392, 4093908449, 509046978, 2878944955, 1164443720, 1635803286, 456584889, 2277866213, 3834793178, 848003218, 2501695792, 2072368233, 2722214668, 669005023, 2116501135, 4094201365, 3054588139, 3973118681, 1358538910, 195873046, 694494517, 2547378454, 4070946796, 1230534751, 2028331495, 2141524170, 2697591581, 2157273164, 350576045, 1125782306, 323995757, 148785221, 522513115, 343652784, 3276208211, 3942628226, 3369979963, 2324085012, 775840633, 1446869471, 3888216946, 274119205, 2035443955, 2988726515, 527227400, 309565817, 2853197507, 639812289, 3094208885, 1887640229, 2647647081, 1262470026, 489523901, 1858089967, 2092288526, 3648687598, 354654325, 3533596489, 3147421955, 2239893566, 3195198490, 362968[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
8637, 1728850740, 1399292243, 578349488, 3574679216, 1302335416, 1009079222, 3281918483, 3935872254, 711910002, 1992854474, 3139972796, 1687422531, 1917538634, 527136945, 1120963141, 1855068517, 3957394550, 2867155037, 706305799, 3116852441, 3031359519, 1366312867, 1529537310, 1684690737, 117546646, 1929134390, 2539679369, 1210055400, 2253708135, 2786537483, 2095050224, 126885468, 4051349198, 1012858091, 3959026870, 3496952367, 1167606355, 1945693474, 1042380773, 2124476669, 1174201345, 3579431839, 1796513512, 1516629655, 3155216490, 2070840382, 2336527982, 443882111, 4085055061, 531514249, 774758730, 2615085221, 2336389172, 743136399, 3388294253, 2616691744, 173217101, 3628055921, 3383954315, 3153550807, 993137631, 3649688596, 1488831682, 802075809, 580816330, 2283104716, 2161600661, 4092088171, 926598016, 1542228253, 1784570207, 21181140, 2288630830, 1958281748, 284019328, 2911217542, 1222105120, 4041468347, 249147326, 203226428, 3010683758, 2891391821, 588543421, 284342423, 3841047946, 2060481160, 10967967[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
5, 4240079574, 3227644413, 2627291462, 493080499, 2742382104, 324347654, 185098060, 1112831959, 3895074013, 1457397168, 1680277968, 164749014, 1601892582, 2946893998, 816088108, 1159725888, 4052164193, 399217095, 1857654497, 2299565569, 2536134918, 715025630, 3323872709, 2815497747, 2688173517, 2140614838, 155785149, 3184004113, 4118567882, 328888258, 3102588061, 3168821570, 1677833076, 1217511948, 1383778673, 3099079444, 1756781908, 1932084113, 3123423332, 1354440830, 2697564334, 2450275642, 1017476410, 925978375, 566076770, 1455014504, 3618343017, 3838985857, 1373423127, 458812725, 237572613, 1731699858, 1854098152, 1167234414, 3770265987, 2848290358, 2191234886, 263208592, 3647218565, 1311501486, 2376949657, 821253820, 3705941745, 3784451132, 3646560811, 4026575581, 915988229, 2976642394, 3852620979, 3555885642, 235170448, 775470115, 2148741883, 3702937145, 1952614488, 937933042, 3536231440, 980032214, 2372888811, 3446404069, 754239458, 2851895152, 2043802399, 3580889922, 2777241710, 311070469, 3543282692,[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
 766907248, 1210999166, 999872034, 3554053472, 3639977954, 2590629462, 3563306637, 149437782, 115749245, 305625112, 1712587706, 2973115077, 2222347427, 2159577590, 1435632436, 3708034907, 2439965083, 2974645555, 2471901792, 1521139380, 3170596981, 2114521791, 1936774258, 4196827784, 1097735316, 4137982370, 4282199357, 3344236199, 119951595, 1212732117, 2237395585, 2126404748, 79495995, 2820765653, 1715450038, 2985111481, 3577484565, 470789585, 1593731449, 3984197271, 2804273448, 1688377834, 2954000773, 2964865115, 3021068644, 3098007409, 4270079761, 3904225911, 2195579998, 940526037, 3251673195, 2303811158, 1076074403, 1641172453, 78390817, 772866956, 2653507274, 2587277433, 1721998148, 1853110220, 1772866569, 107891206, 4223381790, 3958582284, 1694260895, 3195615621, 535669408, 484507831, 3316202095, 2237922653, 3803731454, 2915750149, 1513015370, 1925278707, 2143241312, 2081418134, 1820857804, 3651266614, 2342097665, 1700028214, 4110202936, 114180071, 309401762, 3372307342, 3806976727, 567678589, 2267491076[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
, 3648301199, 1425061435, 2504547121, 1510265902, 1370188672, 3335466086, 2888853687, 861225562, 3391853409, 2945948623, 2592649144, 521141857, 1213227352, 2167706324, 4091151821, 3659352511, 2788503440, 51663000, 619273688, 4292170771, 215665224, 3331273028, 1376825055, 1551889917, 4024581572, 1072812037, 3496239358, 3656768367, 624837156, 3613606451, 1216149492, 1511160451, 4015702614, 4071218788, 2060498639, 3899570088, 434213720, 12008132, 3747652044, 2324268829, 3843798630, 1822644653, 3529383118, 1666567873, 4129116930, 790561340, 1828423049, 4182425759, 3270769029, 806847753, 2583430255, 2832315341, 109640585, 2488008905, 3874345940, 3246447808, 3145763010, 1687611675, 1976347399, 2665764594, 3261761719, 1614559362, 3960843563, 2706795010, 2411776947, 3867960630, 192881645, 3830095344, 1941164548, 1798820334, 487499467, 2397116467, 938386410, 223829438, 272792511, 1726779750, 734573251, 2935442690, 3311820266, 2952255839, 3333633159, 2907121565, 2440662327, 305142490, 1969410783, 1448858401, 513256266,[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
 3960100857, 40969299, 3455069079, 3012327375, 1632396576, 1014952240, 3394115433, 1933748884, 1718226900, 3984635069, 2908449589, 2452658351, 3236162886, 3445721885, 662353417, 4260634642, 2725588435, 2850582841, 2273619026, 1948097180, 1857479573, 485314896, 3271632006, 3475497139, 3449211457, 2812231493, 1639431190, 461303930, 2411498444, 1885077079, 4227948763, 3817558414, 786786501, 3823373939, 3333348589, 2890674863, 3018473581, 4170669724, 922646112, 2727603031, 3309216215, 847314201, 2035402544, 2441361200, 298873397, 1628263048, 1341479772, 312661407, 1822885447, 3596280385, 2659962070, 1106177579, 3733123667, 567327205, 400350429, 2135933527, 3441583630, 1861036062, 2879650983, 473378280, 158185972, 2483622492, 3332263159, 179010902, 1858191869, 4192340472, 4196737433, 2923384283, 2437163721, 1093055009, 3415899653, 1068296798, 2391072456, 57946288, 358192060, 27021629, 3096033088, 712832315, 602081828, 2662858793, 1422754741, 2339972745, 905928586, 1132520546, 868184234, 2929674858, 10436535, 73176[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
7976, 1179609833, 3644147434, 346446864, 337136279, 1409265510, 3381946364, 2534683559, 412511492, 2724459129, 3222508480, 3215393213, 1354117102, 2555918413, 47098487, 3189692061, 744567837, 4074079899, 2174829242, 3327139921, 2946577142, 1048990990, 832505605, 3817754628, 3705191691, 2206409097, 708357036, 914501921, 2888675377, 3044175962, 1079798718, 370695137, 4021944987, 3398030587, 3512806570]
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 3. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 1. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 4. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 6. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 5. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 2. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 7. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 0. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1621444768888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3764478074, "metadata": {"file": "main.py", "lineno": 57}}
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1621444768888, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1621444768888, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 125}}
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1621444768888, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1000, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 126}}
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1621444768888, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 10. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1621444768889, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 129}}
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 9. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 14. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 12. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1621444768889, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 130}}
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1621444768889, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 131}}
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1621444768889, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 13. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 8. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 15. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 11. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1621444768889, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 133}}
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1621444768889, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 134}}
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1621444768889, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 135}}
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 20. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 19. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 22. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 16. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 17. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 21. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 18. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 23. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 31. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 30. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 24. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 25. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 26. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 27. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 28. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 29. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 36. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 35. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 32. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 38. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 39. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 37. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 34. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 33. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 42. SEED 3764478074
[10:19:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 45. SEED 3764478074
RANK 41. SEED 3764478074
RANK 43. SEED 3764478074
RANK 44. SEED 3764478074
RANK 46. SEED 3764478074
RANK 47. SEED 3764478074
RANK 40. SEED 3764478074
RANK 49. SEED 3764478074
RANK 50. SEED 3764478074
RANK 52. SEED 3764478074
RANK 54. SEED 3764478074
RANK 55. SEED 3764478074
RANK 48. SEED 3764478074
RANK 53. SEED 3764478074
RANK 51. SEED 3764478074
RANK 59. SEED 3764478074
RANK 56. SEED 3764478074
RANK 57. SEED 3764478074
RANK 61. SEED 3764478074
RANK 62. SEED 3764478074
RANK 58. SEED 3764478074
RANK 60. SEED 3764478074
RANK 63. SEED 3764478074
RANK 64. SEED 3764478074
RANK 67. SEED 3764478074
RANK 70. SEED 3764478074
RANK 65. SEED 3764478074
RANK 71. SEED 3764478074
RANK 66. SEED 3764478074
RANK 68. SEED 3764478074
RANK 69. SEED 3764478074
RANK 74. SEED 3764478074
RANK 75. SEED 3764478074
RANK 76. SEED 3764478074
RANK 78. SEED 3764478074
RANK 79. SEED 3764478074
RANK 77. SEED 3764478074
RANK 72. SEED 3764478074
RANK 73. SEED 3764478074
RANK 82. SEED 3764478074
RANK 80. SEED 3764478074
RANK 81. SEED 3764478074
RANK 84. SEED 3764478074
RANK 85. SEED 3764478074
RANK 86. SEED 3764478074
RANK 87. SEED 3764478074
RANK 83. SEED 3764478074
RANK 92. SEED 3764478074
RANK 89. SEED 3764478074
RANK 93. SEED 3764478074
RANK 88. SEED 3764478074
RANK 95. SEED 3764478074
RANK 90. SEED 3764478074
RANK 91. SEED 3764478074
RANK 94. SEED 3764478074
RANK 103. SEED 3764478074
RANK 101. SEED 3764478074
RANK 99. SEED 3764478074
RANK 100. SEED 3764478074
RANK 96. SEED 3764478074
RANK 102. SEED 3764478074
RANK 97. SEED 3764478074
RANK 98. SEED 3764478074
RANK 105. SEED 3764478074
RANK 106. SEED 3764478074
RANK 104. SEED 3764478074
RANK 110. SEED 3764478074
RANK 107. SEED 3764478074
RANK 108. SEED 3764478074
RANK 111. SEED 3764478074
RANK 109. SEED 3764478074
RANK 117. SEED 3764478074
RANK 112. SEED 3764478074
RANK 113. SEED 3764478074
RANK 115. SEED 3764478074
RANK 116. SEED 3764478074
RANK 118. SEED 3764478074
RANK 114. SEED 3764478074
RANK 119. SEED 3764478074
RANK 124. SEED 3764478074
RANK 121. SEED 3764478074
RANK 123. SEED 3764478074
RANK 120. SEED 3764478074
RANK 125. SEED 3764478074
RANK 126. SEED 3764478074
RANK 127. SEED 3764478074
RANK 122. SEED 3764478074
RANK 128. SEED 3764478074
RANK 131. SEED 3764478074
RANK 134. SEED 3764478074
RANK 130. SEED 3764478074
RANK 132. SEED 3764478074
RANK 129. SEED 3764478074
RANK 135. SEED 3764478074
RANK 133. SEED 3764478074
RANK 140. SEED 3764478074
RANK 141. SEED 3764478074
RANK 137. SEED 3764478074
RANK 142. SEED 3764478074
RANK 138. SEED 3764478074
RANK 139. SEED 3764478074
RANK 143. SEED 3764478074
RANK 136. SEED 3764478074
RANK 146. SEED 3764478074
RANK 145. SEED 3764478074
RANK 150. SEED 3764478074
RANK 147. SEED 3764478074
RANK 148. SEED 3764478074
RANK 144. SEED 3764478074
RANK 149. SEED 3764478074
RANK 151. SEED 3764478074
RANK 154. SEED 3764478074
RANK 152. SEED 3764478074
RANK 157. SEED 3764478074
RANK 155. SEED 3764478074
RANK 158. SEED 3764478074
RANK 159. SEED 3764478074
RANK 153. SEED 3764478074
RANK 156. SEED 3764478074
RANK 165. SEED 3764478074
RANK 161. SEED 3764478074
RANK 162. SEED 3764478074
RANK 166. SEED 3764478074
RANK 164. SEED 3764478074
RANK 167. SEED 3764478074
RANK 163. SEED 3764478074
RANK 160. SEED 3764478074
RANK 173. SEED 3764478074
RANK 170. SEED 3764478074
RANK 172. SEED 3764478074
RANK 171. SEED 3764478074
RANK 174. SEED 3764478074
RANK 175. SEED 3764478074
RANK 169. SEED 3764478074
RANK 168. SEED 3764478074
RANK 176. SEED 3764478074
RANK 180. SEED 3764478074
RANK 177. SEED 3764478074
RANK 181. SEED 3764478074
RANK 182. SEED 3764478074
RANK 183. SEED 3764478074
RANK 178. SEED 3764478074
RANK 179. SEED 3764478074
RANK 186. SEED 3764478074
RANK 185. SEED 3764478074
RANK 188. SEED 3764478074
RANK 189. SEED 3764478074
RANK 187. SEED 3764478074
RANK 190. SEED 3764478074
RANK 184. SEED 3764478074
RANK 191. SEED 3764478074
RANK 194. SEED 3764478074
RANK 196. SEED 3764478074
RANK 197. SEED 3764478074
RANK 193. SEED 3764478074
RANK 192. SEED 3764478074
RANK 198. SEED 3764478074
RANK 199. SEED 3764478074
RANK 195. SEED 3764478074
RANK 205. SEED 3764478074
RANK 202. SEED 3764478074
RANK 207. SEED 3764478074
RANK 201. SEED 3764478074
RANK 206. SEED 3764478074
RANK 204. SEED 3764478074
RANK 200. SEED 3764478074
RANK 203. SEED 3764478074
RANK 212. SEED 3764478074
RANK 213. SEED 3764478074
RANK 210. SEED 3764478074
RANK 215. SEED 3764478074
RANK 214. SEED 3764478074
RANK 211. SEED 3764478074
RANK 209. SEED 3764478074
RANK 208. SEED 3764478074
RANK 218. SEED 3764478074
RANK 217. SEED 3764478074
RANK 219. SEED 3764478074
RANK 221. SEED 3764478074
RANK 216. SEED 3764478074
RANK 222. SEED 3764478074
RANK 220. SEED 3764478074
RANK 223. SEED 3764478074
RANK 228. SEED 3764478074
RANK 224. SEED 3764478074
RANK 229. SEED 3764478074
RANK 230. SEED 3764478074
RANK 225. SEED 3764478074
RANK 227. SEED 3764478074
RANK 226. SEED 3764478074
RANK 231. SEED 3764478074
RANK 236. SEED 3764478074
RANK 237. SEED 3764478074
RANK 239. SEED 3764478074
RANK 234. SEED 3764478074
RANK 235. SEED 3764478074
RANK 233. SEED 3764478074
RANK 232. SEED 3764478074
RANK 238. SEED 3764478074
RANK 241. SEED 3764478074
RANK 244. SEED 3764478074
RANK 245. SEED 3764478074
RANK 246. SEED 3764478074
RANK 240. SEED 3764478074
RANK 242. SEED 3764478074
RANK 243. SEED 3764478074
RANK 247. SEED 3764478074
RANK 250. SEED 3764478074
RANK 252. SEED 3764478074
RANK 251. SEED 3764478074
RANK 253. SEED 3764478074
RANK 255. SEED 3764478074
RANK 248. SEED 3764478074
RANK 249. SEED 3764478074
RANK 254. SEED 3764478074
RANK 257. SEED 3764478074
RANK 258. SEED 3764478074
RANK 261. SEED 3764478074
RANK 260. SEED 3764478074
RANK 262. SEED 3764478074
RANK 256. SEED 3764478074
RANK 259. SEED 3764478074
RANK 263. SEED 3764478074
RANK 269. SEED 3764478074
RANK 265. SEED 3764478074
RANK 266. SEED 3764478074
RANK 270. SEED 3764478074
RANK 264. SEED 3764478074
RANK 267. SEED 3764478074
RANK 271. SEED 3764478074
RANK 273. SEED 3764478074
RANK 276. SEED 3764478074
RANK 272. SEED 3764478074
RANK 277. SEED 3764478074
RANK 275. SEED 3764478074
RANK 274. SEED 3764478074
RANK 278. SEED 3764478074
RANK 279. SEED 3764478074
RANK 284. SEED 3764478074
RANK 285. SEED 3764478074
RANK 287. SEED 3764478074
RANK 282. SEED 3764478074
RANK 286. SEED 3764478074
RANK 281. SEED 3764478074
RANK 280. SEED 3764478074
RANK 283. SEED 3764478074
RANK 293. SEED 3764478074
RANK 290. SEED 3764478074
RANK 292. SEED 3764478074
RANK 294. SEED 3764478074
RANK 291. SEED 3764478074
RANK 288. SEED 3764478074
RANK 295. SEED 3764478074
RANK 289. SEED 3764478074
RANK 298. SEED 3764478074
RANK 300. SEED 3764478074
RANK 296. SEED 3764478074
RANK 302. SEED 3764478074
RANK 297. SEED 3764478074
RANK 299. SEED 3764478074
RANK 301. SEED 3764478074
RANK 303. SEED 3764478074
RANK 306. SEED 3764478074
RANK 304. SEED 3764478074
RANK 305. SEED 3764478074
RANK 308. SEED 3764478074
RANK 307. SEED 3764478074
RANK 311. SEED 3764478074
RANK 310. SEED 3764478074
RANK 309. SEED 3764478074
RANK 317. SEED 3764478074
RANK 318. SEED 3764478074
RANK 319. SEED 3764478074
RANK 312. SEED 3764478074
RANK 315. SEED 3764478074
RANK 313. SEED 3764478074
RANK 316. SEED 3764478074
RANK 314. SEED 3764478074
RANK 326. SEED 3764478074
RANK 324. SEED 3764478074
RANK 322. SEED 3764478074
RANK 325. SEED 3764478074
RANK 323. SEED 3764478074
RANK 320. SEED 3764478074
RANK 321. SEED 3764478074
RANK 327. SEED 3764478074
RANK 333. SEED 3764478074
RANK 334. SEED 3764478074
RANK 332. SEED 3764478074
RANK 335. SEED 3764478074
RANK 328. SEED 3764478074
RANK 329. SEED 3764478074
RANK 330. SEED 3764478074
RANK 331. SEED 3764478074
RANK 337. SEED 3764478074
RANK 340. SEED 3764478074
RANK 341. SEED 3764478074
RANK 342. SEED 3764478074
RANK 336. SEED 3764478074
RANK 338. SEED 3764478074
RANK 343. SEED 3764478074
RANK 339. SEED 3764478074
RANK 348. SEED 3764478074
RANK 350. SEED 3764478074
RANK 351. SEED 3764478074
RANK 346. SEED 3764478074
RANK 349. SEED 3764478074
RANK 345. SEED 3764478074
RANK 344. SEED 3764478074
RANK 347. SEED 3764478074
RANK 353. SEED 3764478074
RANK 354. SEED 3764478074
RANK 356. SEED 3764478074
RANK 357. SEED 3764478074
RANK 352. SEED 3764478074
RANK 355. SEED 3764478074
RANK 358. SEED 3764478074
RANK 359. SEED 3764478074
RANK 366. SEED 3764478074
RANK 361. SEED 3764478074
RANK 363. SEED 3764478074
RANK 365. SEED 3764478074
RANK 360. SEED 3764478074
RANK 364. SEED 3764478074
RANK 367. SEED 3764478074
RANK 362. SEED 3764478074
RANK 371. SEED 3764478074
RANK 374. SEED 3764478074
RANK 369. SEED 3764478074
RANK 370. SEED 3764478074
RANK 373. SEED 3764478074
RANK 375. SEED 3764478074
RANK 368. SEED 3764478074
RANK 372. SEED 3764478074
RANK 382. SEED 3764478074
RANK 380. SEED 3764478074
RANK 381. SEED 3764478074
RANK 376. SEED 3764478074
RANK 377. SEED 3764478074
RANK 379. SEED 3764478074
RANK 383. SEED 3764478074
RANK 378. SEED 3764478074
RANK 386. SEED 3764478074
RANK 390. SEED 3764478074
RANK 387. SEED 3764478074
RANK 388. SEED 3764478074
RANK 389. SEED 3764478074
RANK 391. SEED 3764478074
RANK 384. SEED 3764478074
RANK 385. SEED 3764478074
RANK 397. SEED 3764478074
RANK 399. SEED 3764478074
RANK 268. SEED 3764478074
RANK 396. SEED 3764478074
RANK 398. SEED 3764478074
RANK 394. SEED 3764478074
RANK 392. SEED 3764478074
RANK 393. SEED 3764478074
RANK 395. SEED 3764478074
RANK 401. SEED 3764478074
RANK 400. SEED 3764478074
RANK 407. SEED 3764478074
RANK 402. SEED 3764478074
RANK 404. SEED 3764478074
RANK 405. SEED 3764478074
RANK 406. SEED 3764478074
RANK 403. SEED 3764478074
RANK 408. SEED 3764478074
RANK 411. SEED 3764478074
RANK 412. SEED 3764478074
RANK 415. SEED 3764478074
RANK 409. SEED 3764478074
RANK 414. SEED 3764478074
RANK 410. SEED 3764478074
RANK 413. SEED 3764478074
RANK 417. SEED 3764478074
RANK 419. SEED 3764478074
RANK 422. SEED 3764478074
RANK 416. SEED 3764478074
RANK 418. SEED 3764478074
RANK 421. SEED 3764478074
RANK 423. SEED 3764478074
RANK 420. SEED 3764478074
RANK 426. SEED 3764478074
RANK 429. SEED 3764478074
RANK 430. SEED 3764478074
RANK 424. SEED 3764478074
RANK 427. SEED 3764478074
RANK 428. SEED 3764478074
RANK 425. SEED 3764478074
RANK 431. SEED 3764478074
RANK 433. SEED 3764478074
RANK 436. SEED 3764478074
RANK 434. SEED 3764478074
RANK 438. SEED 3764478074
RANK 432. SEED 3764478074
RANK 435. SEED 3764478074
RANK 439. SEED 3764478074
RANK 437. SEED 3764478074
RANK 440. SEED 3764478074
RANK 445. SEED 3764478074
RANK 447. SEED 3764478074
RANK 441. SEED 3764478074
RANK 443. SEED 3764478074
RANK 442. SEED 3764478074
RANK 444. SEED 3764478074
RANK 446. SEED 3764478074
RANK 449. SEED 3764478074
RANK 451. SEED 3764478074
RANK 450. SEED 3764478074
RANK 448. SEED 3764478074
RANK 452. SEED 3764478074
RANK 453. SEED 3764478074
RANK 454. SEED 3764478074
RANK 455. SEED 3764478074
RANK 457. SEED 3764478074
RANK 459. SEED 3764478074
RANK 462. SEED 3764478074
RANK 463. SEED 3764478074
RANK 456. SEED 3764478074
RANK 461. SEED 3764478074
RANK 460. SEED 3764478074
RANK 458. SEED 3764478074
RANK 466. SEED 3764478074
RANK 469. SEED 3764478074
RANK 467. SEED 3764478074
RANK 470. SEED 3764478074
RANK 468. SEED 3764478074
RANK 464. SEED 3764478074
RANK 471. SEED 3764478074
RANK 465. SEED 3764478074
RANK 477. SEED 3764478074
RANK 474. SEED 3764478074
RANK 473. SEED 3764478074
RANK 475. SEED 3764478074
RANK 472. SEED 3764478074
RANK 479. SEED 3764478074
RANK 476. SEED 3764478074
RANK 485. SEED 3764478074
RANK 480. SEED 3764478074
RANK 486. SEED 3764478074
RANK 483. SEED 3764478074
RANK 481. SEED 3764478074
RANK 482. SEED 3764478074
RANK 484. SEED 3764478074
RANK 487. SEED 3764478074
RANK 492. SEED 3764478074
RANK 493. SEED 3764478074
RANK 490. SEED 3764478074
RANK 494. SEED 3764478074
RANK 489. SEED 3764478074
RANK 491. SEED 3764478074
RANK 495. SEED 3764478074
RANK 488. SEED 3764478074
RANK 501. SEED 3764478074
RANK 498. SEED 3764478074
RANK 500. SEED 3764478074
RANK 502. SEED 3764478074
RANK 497. SEED 3764478074
RANK 503. SEED 3764478074
RANK 496. SEED 3764478074
RANK 499. SEED 3764478074
RANK 509. SEED 3764478074
RANK 505. SEED 3764478074
RANK 508. SEED 3764478074
RANK 510. SEED 3764478074
RANK 511. SEED 3764478074
RANK 506. SEED 3764478074
RANK 507. SEED 3764478074
RANK 504. SEED 3764478074
RANK 517. SEED 3764478074
RANK 512. SEED 3764478074
RANK 513. SEED 3764478074
RANK 518. SEED 3764478074
RANK 515. SEED 3764478074
RANK 514. SEED 3764478074
RANK 516. SEED 3764478074
RANK 519. SEED 3764478074
RANK 525. SEED 3764478074
RANK 526. SEED 3764478074
RANK 521. SEED 3764478074
RANK 523. SEED 3764478074
RANK 527. SEED 3764478074
RANK 522. SEED 3764478074
RANK 520. SEED 3764478074
RANK 524. SEED 3764478074
RANK 528. SEED 3764478074
RANK 530. SEED 3764478074
RANK 531. SEED 3764478074
RANK 535. SEED 3764478074
RANK 529. SEED 3764478074
RANK 533. SEED 3764478074
RANK 534. SEED 3764478074
RANK 532. SEED 3764478074
RANK 536. SEED 3764478074
RANK 541. SEED 3764478074
RANK 537. SEED 3764478074
RANK 538. SEED 3764478074
RANK 542. SEED 3764478074
RANK 539. SEED 3764478074
RANK 540. SEED 3764478074
RANK 543. SEED 3764478074
RANK 548. SEED 3764478074
RANK 549. SEED 3764478074
RANK 550. SEED 3764478074
RANK 551. SEED 3764478074
RANK 547. SEED 3764478074
RANK 544. SEED 3764478074
RANK 545. SEED 3764478074
RANK 546. SEED 3764478074
RANK 557. SEED 3764478074
RANK 559. SEED 3764478074
RANK 555. SEED 3764478074
RANK 556. SEED 3764478074
RANK 558. SEED 3764478074
RANK 553. SEED 3764478074
RANK 554. SEED 3764478074
RANK 552. SEED 3764478074
RANK 561. SEED 3764478074
RANK 564. SEED 3764478074
RANK 565. SEED 3764478074
RANK 566. SEED 3764478074
RANK 560. SEED 3764478074
RANK 562. SEED 3764478074
RANK 563. SEED 3764478074
RANK 567. SEED 3764478074
RANK 570. SEED 3764478074
RANK 574. SEED 3764478074
RANK 572. SEED 3764478074
RANK 571. SEED 3764478074
RANK 575. SEED 3764478074
RANK 573. SEED 3764478074
RANK 569. SEED 3764478074
RANK 568. SEED 3764478074
RANK 578. SEED 3764478074
RANK 576. SEED 3764478074
RANK 581. SEED 3764478074
RANK 583. SEED 3764478074
RANK 577. SEED 3764478074
RANK 580. SEED 3764478074
RANK 582. SEED 3764478074
RANK 579. SEED 3764478074
RANK 588. SEED 3764478074
RANK 585. SEED 3764478074
RANK 589. SEED 3764478074
RANK 584. SEED 3764478074
RANK 590. SEED 3764478074
RANK 586. SEED 3764478074
RANK 587. SEED 3764478074
RANK 591. SEED 3764478074
RANK 478. SEED 3764478074
RANK 597. SEED 3764478074
RANK 598. SEED 3764478074
RANK 596. SEED 3764478074
RANK 592. SEED 3764478074
RANK 595. SEED 3764478074
RANK 594. SEED 3764478074
RANK 593. SEED 3764478074
RANK 599. SEED 3764478074
RANK 607. SEED 3764478074
RANK 600. SEED 3764478074
RANK 603. SEED 3764478074
RANK 601. SEED 3764478074
RANK 605. SEED 3764478074
RANK 606. SEED 3764478074
RANK 602. SEED 3764478074
RANK 604. SEED 3764478074
RANK 610. SEED 3764478074
RANK 611. SEED 3764478074
RANK 608. SEED 3764478074
RANK 609. SEED 3764478074
RANK 615. SEED 3764478074
RANK 614. SEED 3764478074
RANK 613. SEED 3764478074
RANK 612. SEED 3764478074
RANK 616. SEED 3764478074
RANK 621. SEED 3764478074
RANK 617. SEED 3764478074
RANK 619. SEED 3764478074
RANK 620. SEED 3764478074
RANK 622. SEED 3764478074
RANK 618. SEED 3764478074
RANK 623. SEED 3764478074
RANK 626. SEED 3764478074
RANK 624. SEED 3764478074
RANK 625. SEED 3764478074
RANK 628. SEED 3764478074
RANK 627. SEED 3764478074
RANK 631. SEED 3764478074
RANK 630. SEED 3764478074
RANK 629. SEED 3764478074
RANK 634. SEED 3764478074
RANK 637. SEED 3764478074
RANK 633. SEED 3764478074
RANK 638. SEED 3764478074
RANK 639. SEED 3764478074
RANK 632. SEED 3764478074
RANK 635. SEED 3764478074
RANK 636. SEED 3764478074
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:19:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
:::MLLOG {"namespace": "", "time_ms": 1621444789655, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 99}}
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
:::MLLOG {"namespace": "", "time_ms": 1621444789668, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 101}}
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 19, VAL CASES ['00125']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 19, VAL CASES ['00125']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 19, VAL CASES ['00125']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 19, VAL CASES ['00125']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 9, VAL CASES ['00198', '00203']
RANK 9, VAL CASES ['00198', '00203']
RANK 19, VAL CASES ['00125']
RANK 9, VAL CASES ['00198', '00203']
RANK 19, VAL CASES ['00125']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 8, VAL CASES ['00189', '00056']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 19, VAL CASES ['00125']
RANK 19, VAL CASES ['00125']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 1, VAL CASES ['00000', '00003']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 8, VAL CASES ['00189', '00056']
RANK 8, VAL CASES ['00189', '00056']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 8, VAL CASES ['00189', '00056']
RANK 8, VAL CASES ['00189', '00056']
RANK 8, VAL CASES ['00189', '00056']
RANK 16, VAL CASES ['00185']
:::MLLOG {"namespace": "", "time_ms": 1621444789723, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 104}}
:::MLLOG {"namespace": "", "time_ms": 1621444789723, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 105}}
RANK 15, VAL CASES ['00005', '00024']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 8, VAL CASES ['00189', '00056']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 18, VAL CASES ['00176']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 11, VAL CASES ['00128', '00061']
RANK 17, VAL CASES ['00084']
RANK 8, VAL CASES ['00189', '00056']
RANK 17, VAL CASES ['00084']
RANK 17, VAL CASES ['00084']
RANK 17, VAL CASES ['00084']
RANK 11, VAL CASES ['00128', '00061']
RANK 11, VAL CASES ['00128', '00061']
RANK 11, VAL CASES ['00128', '00061']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 17, VAL CASES ['00084']
RANK 11, VAL CASES ['00128', '00061']
RANK 17, VAL CASES ['00084']
RANK 11, VAL CASES ['00128', '00061']
RANK 17, VAL CASES ['00084']
RANK 11, VAL CASES ['00128', '00061']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 17, VAL CASES ['00084']
RANK 18, VAL CASES ['00176']
RANK 18, VAL CASES ['00176']
RANK 18, VAL CASES ['00176']
RANK 18, VAL CASES ['00176']
RANK 18, VAL CASES ['00176']
RANK 11, VAL CASES ['00128', '00061']
RANK 16, VAL CASES ['00185']
RANK 16, VAL CASES ['00185']
RANK 16, VAL CASES ['00185']
RANK 18, VAL CASES ['00176']
RANK 16, VAL CASES ['00185']
RANK 16, VAL CASES ['00185']
RANK 12, VAL CASES ['00066', '00065']
RANK 16, VAL CASES ['00185']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 16, VAL CASES ['00185']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 9, VAL CASES ['00198', '00203']
RANK 10, VAL CASES ['00207', '00162']
RANK 9, VAL CASES ['00198', '00203']
RANK 9, VAL CASES ['00198', '00203']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 18, VAL CASES ['00176']
RANK 14, VAL CASES ['00034', '00076']
RANK 14, VAL CASES ['00034', '00076']
RANK 14, VAL CASES ['00034', '00076']
RANK 14, VAL CASES ['00034', '00076']
RANK 9, VAL CASES ['00198', '00203']
RANK 15, VAL CASES ['00005', '00024']
RANK 14, VAL CASES ['00034', '00076']
RANK 15, VAL CASES ['00005', '00024']
RANK 14, VAL CASES ['00034', '00076']
RANK 9, VAL CASES ['00198', '00203']
RANK 14, VAL CASES ['00034', '00076']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 13, VAL CASES ['00044', '00070']
RANK 13, VAL CASES ['00044', '00070']
RANK 13, VAL CASES ['00044', '00070']
RANK 13, VAL CASES ['00044', '00070']
RANK 13, VAL CASES ['00044', '00070']
RANK 13, VAL CASES ['00044', '00070']
RANK 14, VAL CASES ['00034', '00076']
RANK 13, VAL CASES ['00044', '00070']
RANK 13, VAL CASES ['00044', '00070']
RANK 2, VAL CASES ['00169', '00206']
RANK 2, VAL CASES ['00169', '00206']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 2, VAL CASES ['00169', '00206']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 2, VAL CASES ['00169', '00206']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 2, VAL CASES ['00169', '00206']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 2, VAL CASES ['00169', '00206']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 2, VAL CASES ['00169', '00206']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 2, VAL CASES ['00169', '00206']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
EVALUATION TIME: 14.592 s.
EVAL WARMUP done at epoch 14, cycle 1. Score: 0.006580981891602278
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1621444817128, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 80, "metadata": {"file": "main.py", "lineno": 107}}
:::MLLOG {"namespace": "", "time_ms": 1621444817129, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 108}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1621444817129, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 24}}
:::MLLOG {"namespace": "", "time_ms": 1621444817129, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1, "epoch_count": 14}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1621444820890, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 893.3183365771088, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444820891, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.03089264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444820891, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 893.3183365771088, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1621444820891, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 14, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444820891, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 14, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444823347, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1368.3852458403562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444823347, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.05175218543046358, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444823347, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1368.3852458403562, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444823347, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 28, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444823347, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 28, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444825876, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1328.6939469113054, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444825877, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.07261172185430464, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444825877, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1328.6939469113054, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 28}}
:::MLLOG {"namespace": "", "time_ms": 1621444825877, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 42, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444825877, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 42, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444827893, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1667.1382491504821, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444827893, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0934712582781457, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444827893, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1667.1382491504821, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 42}}
:::MLLOG {"namespace": "", "time_ms": 1621444827893, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 56, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444827893, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 56, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444829099, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2787.0204297151945, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444829100, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.11433079470198675, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444829100, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2787.0204297151945, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 56}}
:::MLLOG {"namespace": "", "time_ms": 1621444829100, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 70, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444829100, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 70, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444830322, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2750.269885448855, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444830323, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.13519033112582782, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444830323, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2750.269885448855, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 70}}
:::MLLOG {"namespace": "", "time_ms": 1621444830323, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 84, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444830323, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 84, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444831518, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2813.9141345416797, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444831518, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.15604986754966885, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444831518, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2813.9141345416797, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 84}}
:::MLLOG {"namespace": "", "time_ms": 1621444831518, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 98, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444831518, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 98, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444832907, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2420.590012808144, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444832907, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.1769094039735099, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444832907, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2420.590012808144, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 98}}
:::MLLOG {"namespace": "", "time_ms": 1621444832908, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 112, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444832908, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 112, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444833989, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3108.834873647882, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444833989, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.197768940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444833989, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3108.834873647882, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 112}}
:::MLLOG {"namespace": "", "time_ms": 1621444833989, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 126, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444833989, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 126, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444835079, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3082.966913946685, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444835080, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.21862847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444835080, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3082.966913946685, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 126}}
:::MLLOG {"namespace": "", "time_ms": 1621444835081, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 140, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444835081, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 140, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444836204, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2992.4701126949035, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444836204, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.2394880132450331, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444836204, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2992.4701126949035, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1621444836205, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 154, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444836205, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 154, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444837478, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2639.2119703382095, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444837478, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26034754966887413, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444837479, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2639.2119703382095, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 154}}
:::MLLOG {"namespace": "", "time_ms": 1621444837479, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 168, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444837479, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 168, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444838462, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3417.475258040955, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444838462, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.2812070860927152, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444838462, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3417.475258040955, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 168}}
:::MLLOG {"namespace": "", "time_ms": 1621444838463, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 182, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444838463, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 182, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444839502, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3232.400341752917, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444839503, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3020666225165563, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444839503, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3232.400341752917, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 182}}
:::MLLOG {"namespace": "", "time_ms": 1621444839503, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 196, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444839503, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 196, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444840575, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3135.2738213519297, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444840576, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32292615894039733, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444840576, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3135.2738213519297, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 196}}
:::MLLOG {"namespace": "", "time_ms": 1621444840576, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 210, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444840576, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 210, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444841596, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3293.891350300714, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444841597, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3437856953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444841597, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3293.891350300714, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 210}}
:::MLLOG {"namespace": "", "time_ms": 1621444841597, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 224, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444841597, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 224, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444842558, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3498.0885896604686, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444842558, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36464523178807945, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444842559, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3498.0885896604686, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 224}}
:::MLLOG {"namespace": "", "time_ms": 1621444842559, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 238, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444842559, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 238, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444843585, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3276.256090297509, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444843585, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3855047682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444843585, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3276.256090297509, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 238}}
:::MLLOG {"namespace": "", "time_ms": 1621444843585, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 252, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444843586, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 252, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444844665, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3113.48535721813, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444844665, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4063643046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444844665, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3113.48535721813, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 252}}
:::MLLOG {"namespace": "", "time_ms": 1621444844666, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 266, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444844666, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 266, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444845639, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3452.081763187753, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444845640, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444845640, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3452.081763187753, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 266}}
:::MLLOG {"namespace": "", "time_ms": 1621444845640, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 280, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444845640, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 280, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444846565, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3634.212383159555, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444846565, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4480833774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444846565, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3634.212383159555, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1621444846566, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 294, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444846566, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 294, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444847671, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3041.6394323627314, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444847671, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.46894291390728476, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444847671, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3041.6394323627314, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 294}}
:::MLLOG {"namespace": "", "time_ms": 1621444847671, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 308, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444847671, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 308, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444848614, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3567.1384272392033, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444848614, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4898024503311258, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444848614, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3567.1384272392033, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 308}}
:::MLLOG {"namespace": "", "time_ms": 1621444848614, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 322, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444848614, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 322, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444849525, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3691.956218988887, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444849525, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5106619867549669, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444849526, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3691.956218988887, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 322}}
:::MLLOG {"namespace": "", "time_ms": 1621444849526, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 336, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444849526, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 336, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444850461, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3592.7879013150146, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444850461, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.531521523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444850462, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3592.7879013150146, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 336}}
:::MLLOG {"namespace": "", "time_ms": 1621444850462, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 350, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444850462, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 350, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444851435, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3453.0409355865427, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444851436, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5523810596026489, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444851436, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3453.0409355865427, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 350}}
:::MLLOG {"namespace": "", "time_ms": 1621444851436, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 364, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444851436, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 364, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444852383, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3547.1042201466325, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444852384, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5732405960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444852384, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3547.1042201466325, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 364}}
:::MLLOG {"namespace": "", "time_ms": 1621444852384, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 378, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444852384, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 378, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444853237, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3941.9698294947725, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444853237, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5941001324503311, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444853237, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3941.9698294947725, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 378}}
:::MLLOG {"namespace": "", "time_ms": 1621444853237, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 392, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444853238, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 392, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444854142, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3715.6958356798896, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444854142, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6149596688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444854142, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3715.6958356798896, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 392}}
:::MLLOG {"namespace": "", "time_ms": 1621444854143, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 406, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444854143, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 406, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444855051, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3700.558132524505, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444855051, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6358192052980133, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444855052, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3700.558132524505, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 406}}
:::MLLOG {"namespace": "", "time_ms": 1621444855052, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 420, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444855052, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 420, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444855917, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3885.2797205592674, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444855917, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6566787417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444855917, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3885.2797205592674, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1621444855917, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 434, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444855917, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 434, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444856813, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3752.251876477199, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444856814, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6775382781456953, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444856814, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3752.251876477199, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 434}}
:::MLLOG {"namespace": "", "time_ms": 1621444856814, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 448, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444856814, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 448, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444857774, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3500.514523316294, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444857774, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6983978145695363, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444857774, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3500.514523316294, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 448}}
:::MLLOG {"namespace": "", "time_ms": 1621444857774, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 462, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444857775, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 462, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444858638, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3894.084028820871, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444858638, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7192573509933775, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444858638, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3894.084028820871, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 462}}
:::MLLOG {"namespace": "", "time_ms": 1621444858639, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 476, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444858639, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 476, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444859512, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3845.956490841987, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444859513, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7401168874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444859513, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3845.956490841987, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 476}}
:::MLLOG {"namespace": "", "time_ms": 1621444859513, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 490, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444859514, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 490, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444860359, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3972.539355107863, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444860360, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7609764238410596, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444860360, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3972.539355107863, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 490}}
:::MLLOG {"namespace": "", "time_ms": 1621444860361, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 504, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444860361, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 504, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444861183, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4088.3239360621974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444861183, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7818359602649007, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444861183, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4088.3239360621974, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 504}}
:::MLLOG {"namespace": "", "time_ms": 1621444861183, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 518, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444861183, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 518, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444862045, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3901.530157909293, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444862045, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8026954966887417, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444862046, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3901.530157909293, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 518}}
:::MLLOG {"namespace": "", "time_ms": 1621444862046, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 532, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444862046, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 532, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444862931, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3796.4557731317227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444862931, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8235550331125828, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444862932, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3796.4557731317227, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 532}}
:::MLLOG {"namespace": "", "time_ms": 1621444862932, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 546, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444862932, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 546, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444863783, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3948.2438056816272, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444863784, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444863784, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3948.2438056816272, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 546}}
:::MLLOG {"namespace": "", "time_ms": 1621444863784, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 560, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444863784, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 560, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444864648, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3891.2282740149653, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444864648, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8652741059602649, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444864648, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3891.2282740149653, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1621444864648, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 574, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444864648, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 574, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444865578, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3616.099393034328, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444865578, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.886133642384106, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444865578, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3616.099393034328, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 574}}
:::MLLOG {"namespace": "", "time_ms": 1621444865579, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 588, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444865579, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 588, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444866435, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3924.1201522661577, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444866435, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9069931788079469, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444866435, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3924.1201522661577, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 588}}
:::MLLOG {"namespace": "", "time_ms": 1621444866436, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 602, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444866436, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 602, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444867335, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3734.908082671796, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444867336, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9278527152317881, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444867336, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3734.908082671796, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 602}}
:::MLLOG {"namespace": "", "time_ms": 1621444867337, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 616, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444867337, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 616, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444868182, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3976.6510022003995, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444868182, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9487122516556292, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444868182, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3976.6510022003995, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 616}}
:::MLLOG {"namespace": "", "time_ms": 1621444868182, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 630, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444868183, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 630, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444869016, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4033.1115734526898, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444869016, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9695717880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444869017, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4033.1115734526898, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 630}}
:::MLLOG {"namespace": "", "time_ms": 1621444869017, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 644, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444869017, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 644, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444869922, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3714.2220126679595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444869922, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9904313245033113, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444869922, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3714.2220126679595, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 644}}
:::MLLOG {"namespace": "", "time_ms": 1621444869922, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 658, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444869922, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 658, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444870866, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3561.5528047788407, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444870867, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0112908609271523, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444870867, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3561.5528047788407, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 658}}
:::MLLOG {"namespace": "", "time_ms": 1621444870867, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 672, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444870867, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 672, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444871780, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3679.4436160777577, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444871781, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0321503973509933, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444871781, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3679.4436160777577, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 672}}
:::MLLOG {"namespace": "", "time_ms": 1621444871781, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 686, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444871781, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 686, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444872613, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4037.535855578962, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444872614, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0530099337748344, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444872614, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4037.535855578962, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 686}}
rank 0: cycle = 50: time to send the model = 0.04372286796569824
:::MLLOG {"namespace": "", "time_ms": 1621444872659, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 700, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444872659, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 700, "epoch_count": 14}}
rank 640: cycle = 50: time to receive the model = 0.05161404609680176
:::MLLOG {"namespace": "", "time_ms": 1621444872667, "event_type": "INTERVAL_START", "key": "eval_start", "value": 700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 700}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.728 s.
:::MLLOG {"namespace": "", "time_ms": 1621444873435, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8751242160797119, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 700}}
:::MLLOG {"namespace": "", "time_ms": 1621444873435, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 700}}
:::MLLOG {"namespace": "", "time_ms": 1621444873482, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4083.469403957698, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444873484, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0738694701986755, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444873484, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4083.469403957698, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 700}}
rank 0: cycle = 51: time to send the model = 0.039115190505981445
:::MLLOG {"namespace": "", "time_ms": 1621444873523, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 714, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444873524, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 714, "epoch_count": 14}}
rank 640: cycle = 51: time to receive the model = 0.05119895935058594
:::MLLOG {"namespace": "", "time_ms": 1621444873535, "event_type": "INTERVAL_START", "key": "eval_start", "value": 714, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 714}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.762 s.
:::MLLOG {"namespace": "", "time_ms": 1621444874299, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8778499364852905, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 714}}
:::MLLOG {"namespace": "", "time_ms": 1621444874299, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 714}}
:::MLLOG {"namespace": "", "time_ms": 1621444874372, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3962.2728312999297, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444874374, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0947290066225166, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444874375, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3962.2728312999297, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 714}}
rank 0: cycle = 52: time to send the model = 0.043941497802734375
:::MLLOG {"namespace": "", "time_ms": 1621444874419, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 728, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444874419, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 728, "epoch_count": 14}}
rank 640: cycle = 52: time to receive the model = 0.0567784309387207
:::MLLOG {"namespace": "", "time_ms": 1621444874432, "event_type": "INTERVAL_START", "key": "eval_start", "value": 728, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 728}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.77 s.
:::MLLOG {"namespace": "", "time_ms": 1621444875203, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8837466239929199, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 728}}
:::MLLOG {"namespace": "", "time_ms": 1621444875204, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 728}}
:::MLLOG {"namespace": "", "time_ms": 1621444875247, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4060.5078493935252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444875249, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1155885430463577, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444875249, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4060.5078493935252, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 728}}
rank 0: cycle = 53: time to send the model = 0.039916276931762695
:::MLLOG {"namespace": "", "time_ms": 1621444875291, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 742, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444875291, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 742, "epoch_count": 14}}
rank 640: cycle = 53: time to receive the model = 0.050653934478759766
:::MLLOG {"namespace": "", "time_ms": 1621444875301, "event_type": "INTERVAL_START", "key": "eval_start", "value": 742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 742}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444876070, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8957000970840454, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 742}}
:::MLLOG {"namespace": "", "time_ms": 1621444876071, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 742}}
:::MLLOG {"namespace": "", "time_ms": 1621444876105, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4125.727290638432, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444876108, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1364480794701988, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444876108, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4125.727290638432, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 742}}
rank 0: cycle = 54: time to send the model = 0.04382944107055664
:::MLLOG {"namespace": "", "time_ms": 1621444876152, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 756, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444876153, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 756, "epoch_count": 14}}
rank 640: cycle = 54: time to receive the model = 0.05408167839050293
:::MLLOG {"namespace": "", "time_ms": 1621444876162, "event_type": "INTERVAL_START", "key": "eval_start", "value": 756, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 756}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444876929, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8837392330169678, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 756}}
:::MLLOG {"namespace": "", "time_ms": 1621444876929, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 756}}
:::MLLOG {"namespace": "", "time_ms": 1621444877018, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3883.093687547995, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444877019, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1573076158940396, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444877020, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3883.093687547995, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 756}}
rank 0: cycle = 55: time to send the model = 0.038071632385253906
:::MLLOG {"namespace": "", "time_ms": 1621444877059, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 770, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444877060, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 770, "epoch_count": 14}}
rank 640: cycle = 55: time to receive the model = 0.051256418228149414
:::MLLOG {"namespace": "", "time_ms": 1621444877073, "event_type": "INTERVAL_START", "key": "eval_start", "value": 770, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 770}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444877835, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4336.717411446917, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444877837, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1781671523178807, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444877837, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4336.717411446917, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 770}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444877838, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8690192699432373, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 770}}
:::MLLOG {"namespace": "", "time_ms": 1621444877839, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 770}}
rank 0: cycle = 56: time to send the model = 0.04643869400024414
:::MLLOG {"namespace": "", "time_ms": 1621444877886, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 784, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444877887, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 784, "epoch_count": 14}}
rank 640: cycle = 56: time to receive the model = 0.05580902099609375
:::MLLOG {"namespace": "", "time_ms": 1621444877895, "event_type": "INTERVAL_START", "key": "eval_start", "value": 784, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 784}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444878654, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4384.373098170417, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444878656, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1990266887417218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444878656, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4384.373098170417, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 784}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444878662, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8928298950195312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 784}}
:::MLLOG {"namespace": "", "time_ms": 1621444878664, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 784}}
rank 0: cycle = 57: time to send the model = 0.039571523666381836
:::MLLOG {"namespace": "", "time_ms": 1621444878703, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 798, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444878704, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 798, "epoch_count": 14}}
rank 640: cycle = 57: time to receive the model = 0.049417972564697266
:::MLLOG {"namespace": "", "time_ms": 1621444878713, "event_type": "INTERVAL_START", "key": "eval_start", "value": 798, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 798}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444879480, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8876006603240967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 798}}
:::MLLOG {"namespace": "", "time_ms": 1621444879480, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 798}}
:::MLLOG {"namespace": "", "time_ms": 1621444879525, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4097.063371230501, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444879527, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2198862251655629, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444879527, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4097.063371230501, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 798}}
rank 0: cycle = 58: time to send the model = 0.04706883430480957
:::MLLOG {"namespace": "", "time_ms": 1621444879575, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 812, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444879575, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 812, "epoch_count": 14}}
rank 640: cycle = 58: time to receive the model = 0.055020809173583984
:::MLLOG {"namespace": "", "time_ms": 1621444879583, "event_type": "INTERVAL_START", "key": "eval_start", "value": 812, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 812}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444880351, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8857305645942688, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 812}}
:::MLLOG {"namespace": "", "time_ms": 1621444880352, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 812}}
:::MLLOG {"namespace": "", "time_ms": 1621444880412, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4013.2239892516413, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444880414, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.240745761589404, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444880414, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4013.2239892516413, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 812}}
rank 0: cycle = 59: time to send the model = 0.04201054573059082
:::MLLOG {"namespace": "", "time_ms": 1621444880458, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 826, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444880458, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 826, "epoch_count": 14}}
rank 640: cycle = 59: time to receive the model = 0.05487680435180664
:::MLLOG {"namespace": "", "time_ms": 1621444880471, "event_type": "INTERVAL_START", "key": "eval_start", "value": 826, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 826}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444881240, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8816244006156921, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 826}}
:::MLLOG {"namespace": "", "time_ms": 1621444881240, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 826}}
:::MLLOG {"namespace": "", "time_ms": 1621444881250, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4245.0436421766235, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444881252, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444881253, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4245.0436421766235, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 826}}
rank 0: cycle = 60: time to send the model = 0.043027639389038086
:::MLLOG {"namespace": "", "time_ms": 1621444881296, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 840, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444881296, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 840, "epoch_count": 14}}
rank 640: cycle = 60: time to receive the model = 0.05369901657104492
:::MLLOG {"namespace": "", "time_ms": 1621444881307, "event_type": "INTERVAL_START", "key": "eval_start", "value": 840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 840}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621444882077, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.870600700378418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 840}}
:::MLLOG {"namespace": "", "time_ms": 1621444882077, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 840}}
:::MLLOG {"namespace": "", "time_ms": 1621444882167, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3860.012024139213, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444882170, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2824648344370861, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444882170, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3860.012024139213, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 840}}
rank 0: cycle = 61: time to send the model = 0.03942108154296875
:::MLLOG {"namespace": "", "time_ms": 1621444882211, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 854, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444882211, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 854, "epoch_count": 14}}
rank 640: cycle = 61: time to receive the model = 0.05043792724609375
:::MLLOG {"namespace": "", "time_ms": 1621444882221, "event_type": "INTERVAL_START", "key": "eval_start", "value": 854, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 854}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444882989, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.879742443561554, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 854}}
:::MLLOG {"namespace": "", "time_ms": 1621444882990, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 854}}
:::MLLOG {"namespace": "", "time_ms": 1621444882997, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4274.350110719282, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444882999, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3033243708609272, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444883000, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4274.350110719282, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 854}}
rank 0: cycle = 62: time to send the model = 0.043023109436035156
:::MLLOG {"namespace": "", "time_ms": 1621444883043, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 868, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444883044, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 868, "epoch_count": 14}}
rank 640: cycle = 62: time to receive the model = 0.0504000186920166
:::MLLOG {"namespace": "", "time_ms": 1621444883051, "event_type": "INTERVAL_START", "key": "eval_start", "value": 868, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 868}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444883808, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4397.405227699713, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444883810, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3241839072847683, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444883810, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4397.405227699713, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 868}}
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444883820, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8688431978225708, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 868}}
:::MLLOG {"namespace": "", "time_ms": 1621444883821, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 868}}
rank 0: cycle = 63: time to send the model = 0.03736376762390137
:::MLLOG {"namespace": "", "time_ms": 1621444883859, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 882, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444883860, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 882, "epoch_count": 14}}
rank 640: cycle = 63: time to receive the model = 0.049237966537475586
:::MLLOG {"namespace": "", "time_ms": 1621444883870, "event_type": "INTERVAL_START", "key": "eval_start", "value": 882, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 882}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444884637, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8846300840377808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 882}}
:::MLLOG {"namespace": "", "time_ms": 1621444884638, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 882}}
:::MLLOG {"namespace": "", "time_ms": 1621444884656, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4218.0695579768035, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444884659, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3450434437086094, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444884659, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4218.0695579768035, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 882}}
rank 0: cycle = 64: time to send the model = 0.047725677490234375
:::MLLOG {"namespace": "", "time_ms": 1621444884707, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 896, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444884707, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 896, "epoch_count": 14}}
rank 640: cycle = 64: time to receive the model = 0.0557706356048584
:::MLLOG {"namespace": "", "time_ms": 1621444884715, "event_type": "INTERVAL_START", "key": "eval_start", "value": 896, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 896}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444885482, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8744375705718994, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 896}}
:::MLLOG {"namespace": "", "time_ms": 1621444885482, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 896}}
:::MLLOG {"namespace": "", "time_ms": 1621444885582, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3840.484505878509, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444885584, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3659029801324505, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444885584, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3840.484505878509, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 896}}
rank 0: cycle = 65: time to send the model = 0.04109501838684082
:::MLLOG {"namespace": "", "time_ms": 1621444885641, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 910, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444885641, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 910, "epoch_count": 14}}
rank 640: cycle = 65: time to receive the model = 0.049895286560058594
:::MLLOG {"namespace": "", "time_ms": 1621444885649, "event_type": "INTERVAL_START", "key": "eval_start", "value": 910, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 910}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444886415, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8726129531860352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 910}}
:::MLLOG {"namespace": "", "time_ms": 1621444886415, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 910}}
:::MLLOG {"namespace": "", "time_ms": 1621444886422, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4302.412354239199, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444886424, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3867625165562913, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444886425, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4302.412354239199, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 910}}
rank 0: cycle = 66: time to send the model = 0.04683041572570801
:::MLLOG {"namespace": "", "time_ms": 1621444886472, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 924, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444886472, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 924, "epoch_count": 14}}
rank 640: cycle = 66: time to receive the model = 0.05843472480773926
:::MLLOG {"namespace": "", "time_ms": 1621444886483, "event_type": "INTERVAL_START", "key": "eval_start", "value": 924, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 924}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444887251, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8851560354232788, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 924}}
:::MLLOG {"namespace": "", "time_ms": 1621444887252, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 924}}
:::MLLOG {"namespace": "", "time_ms": 1621444887259, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4270.8125563669155, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444887261, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4076220529801324, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444887261, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4270.8125563669155, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 924}}
rank 0: cycle = 67: time to send the model = 0.039122581481933594
:::MLLOG {"namespace": "", "time_ms": 1621444887302, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 938, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444887302, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 938, "epoch_count": 14}}
rank 640: cycle = 67: time to receive the model = 0.05051088333129883
:::MLLOG {"namespace": "", "time_ms": 1621444887313, "event_type": "INTERVAL_START", "key": "eval_start", "value": 938, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 938}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444888080, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8813102841377258, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 938}}
:::MLLOG {"namespace": "", "time_ms": 1621444888081, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 938}}
:::MLLOG {"namespace": "", "time_ms": 1621444888103, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4198.131046248411, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444888106, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4284815894039735, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444888107, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4198.131046248411, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 938}}
rank 0: cycle = 68: time to send the model = 0.03930211067199707
:::MLLOG {"namespace": "", "time_ms": 1621444888158, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 952, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444888159, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 952, "epoch_count": 14}}
rank 640: cycle = 68: time to receive the model = 0.05137991905212402
:::MLLOG {"namespace": "", "time_ms": 1621444888170, "event_type": "INTERVAL_START", "key": "eval_start", "value": 952, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 952}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444888934, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4335.341964111026, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444888935, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4493411258278146, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444888935, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4335.341964111026, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 952}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444888936, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8976048827171326, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 952}}
:::MLLOG {"namespace": "", "time_ms": 1621444888938, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 952}}
rank 0: cycle = 69: time to send the model = 0.038313865661621094
:::MLLOG {"namespace": "", "time_ms": 1621444888976, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 966, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444888977, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 966, "epoch_count": 14}}
rank 640: cycle = 69: time to receive the model = 0.0498044490814209
:::MLLOG {"namespace": "", "time_ms": 1621444888988, "event_type": "INTERVAL_START", "key": "eval_start", "value": 966, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 966}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444889752, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4336.52791876923, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444889753, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.880176305770874, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 966}}
:::MLLOG {"namespace": "", "time_ms": 1621444889753, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 966}}
:::MLLOG {"namespace": "", "time_ms": 1621444889755, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4702006622516555, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444889757, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4336.52791876923, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 966}}
rank 0: cycle = 70: time to send the model = 0.04959702491760254
:::MLLOG {"namespace": "", "time_ms": 1621444889807, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 980, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444889807, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 980, "epoch_count": 14}}
rank 640: cycle = 70: time to receive the model = 0.05751323699951172
:::MLLOG {"namespace": "", "time_ms": 1621444889815, "event_type": "INTERVAL_START", "key": "eval_start", "value": 980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 980}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444890585, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8892170190811157, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 980}}
:::MLLOG {"namespace": "", "time_ms": 1621444890585, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 980}}
:::MLLOG {"namespace": "", "time_ms": 1621444890633, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4070.5919270180434, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444890634, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4910601986754968, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444890635, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4070.5919270180434, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 980}}
rank 0: cycle = 71: time to send the model = 0.03996753692626953
:::MLLOG {"namespace": "", "time_ms": 1621444890675, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 994, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444890675, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 994, "epoch_count": 14}}
rank 640: cycle = 71: time to receive the model = 0.049889326095581055
:::MLLOG {"namespace": "", "time_ms": 1621444890685, "event_type": "INTERVAL_START", "key": "eval_start", "value": 994, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 994}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444891451, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.891301691532135, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 994}}
:::MLLOG {"namespace": "", "time_ms": 1621444891451, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 994}}
:::MLLOG {"namespace": "", "time_ms": 1621444891512, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4015.691766910352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444891515, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444891515, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4015.691766910352, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 994}}
rank 0: cycle = 72: time to send the model = 0.04391217231750488
:::MLLOG {"namespace": "", "time_ms": 1621444891559, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1008, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444891560, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1008, "epoch_count": 14}}
rank 640: cycle = 72: time to receive the model = 0.05687594413757324
:::MLLOG {"namespace": "", "time_ms": 1621444891572, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1008, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1008}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444892339, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.890789270401001, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1008}}
:::MLLOG {"namespace": "", "time_ms": 1621444892340, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1008}}
:::MLLOG {"namespace": "", "time_ms": 1621444892380, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4095.5321962910557, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444892382, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444892382, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4095.5321962910557, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1008}}
rank 0: cycle = 73: time to send the model = 0.03837847709655762
:::MLLOG {"namespace": "", "time_ms": 1621444892420, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1022, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444892420, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1022, "epoch_count": 14}}
rank 640: cycle = 73: time to receive the model = 0.05050039291381836
:::MLLOG {"namespace": "", "time_ms": 1621444892432, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1022, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1022}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444893199, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8676388263702393, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1022}}
:::MLLOG {"namespace": "", "time_ms": 1621444893200, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1022}}
:::MLLOG {"namespace": "", "time_ms": 1621444893253, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4038.103892010533, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444893255, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444893256, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4038.103892010533, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1022}}
rank 0: cycle = 74: time to send the model = 0.043608903884887695
:::MLLOG {"namespace": "", "time_ms": 1621444893300, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1036, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444893300, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1036, "epoch_count": 14}}
rank 640: cycle = 74: time to receive the model = 0.051343679428100586
:::MLLOG {"namespace": "", "time_ms": 1621444893307, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1036, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1036}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444894077, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8594520092010498, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1036}}
:::MLLOG {"namespace": "", "time_ms": 1621444894077, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1036}}
:::MLLOG {"namespace": "", "time_ms": 1621444894093, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4237.730649320657, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444894095, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444894095, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4237.730649320657, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1036}}
rank 0: cycle = 75: time to send the model = 0.0394749641418457
:::MLLOG {"namespace": "", "time_ms": 1621444894136, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1050, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444894136, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1050, "epoch_count": 14}}
rank 640: cycle = 75: time to receive the model = 0.05120134353637695
:::MLLOG {"namespace": "", "time_ms": 1621444894147, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1050, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1050}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444894912, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4327.648377645617, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444894913, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8583866357803345, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1050}}
:::MLLOG {"namespace": "", "time_ms": 1621444894913, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1050}}
:::MLLOG {"namespace": "", "time_ms": 1621444894915, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444894915, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4327.648377645617, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1050}}
rank 0: cycle = 76: time to send the model = 0.04863762855529785
:::MLLOG {"namespace": "", "time_ms": 1621444894964, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1064, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444894964, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1064, "epoch_count": 14}}
rank 640: cycle = 76: time to receive the model = 0.05898427963256836
:::MLLOG {"namespace": "", "time_ms": 1621444894974, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1064, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1064}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444895742, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8929860591888428, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1064}}
:::MLLOG {"namespace": "", "time_ms": 1621444895742, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1064}}
:::MLLOG {"namespace": "", "time_ms": 1621444895765, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4195.813743695276, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444895767, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444895767, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4195.813743695276, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1064}}
rank 0: cycle = 77: time to send the model = 0.039452314376831055
:::MLLOG {"namespace": "", "time_ms": 1621444895808, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1078, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444895808, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1078, "epoch_count": 14}}
rank 640: cycle = 77: time to receive the model = 0.049356937408447266
:::MLLOG {"namespace": "", "time_ms": 1621444895818, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1078, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1078}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444896587, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8811994194984436, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1078}}
:::MLLOG {"namespace": "", "time_ms": 1621444896587, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1078}}
:::MLLOG {"namespace": "", "time_ms": 1621444896643, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4025.3886296291853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444896645, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444896646, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4025.3886296291853, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1078}}
rank 0: cycle = 78: time to send the model = 0.05006265640258789
:::MLLOG {"namespace": "", "time_ms": 1621444896696, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1092, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444896697, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1092, "epoch_count": 14}}
rank 640: cycle = 78: time to receive the model = 0.06046891212463379
:::MLLOG {"namespace": "", "time_ms": 1621444896707, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1092}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444897476, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8832807540893555, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1092}}
:::MLLOG {"namespace": "", "time_ms": 1621444897476, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1092}}
:::MLLOG {"namespace": "", "time_ms": 1621444897488, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4245.2571940842345, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444897490, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444897490, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4245.2571940842345, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1092}}
rank 0: cycle = 79: time to send the model = 0.03862929344177246
:::MLLOG {"namespace": "", "time_ms": 1621444897529, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1106, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444897529, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1106, "epoch_count": 14}}
rank 640: cycle = 79: time to receive the model = 0.05008220672607422
:::MLLOG {"namespace": "", "time_ms": 1621444897540, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1106, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1106}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444898305, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8788734078407288, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1106}}
:::MLLOG {"namespace": "", "time_ms": 1621444898306, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1106}}
:::MLLOG {"namespace": "", "time_ms": 1621444898365, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4021.925012178907, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444898367, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444898367, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4021.925012178907, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1106}}
rank 0: cycle = 80: time to send the model = 0.04792428016662598
:::MLLOG {"namespace": "", "time_ms": 1621444898416, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1120, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444898416, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1120, "epoch_count": 14}}
rank 640: cycle = 80: time to receive the model = 0.05463242530822754
:::MLLOG {"namespace": "", "time_ms": 1621444898422, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1120}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444899192, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8861260414123535, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1621444899192, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1621444899222, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4170.045751707478, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444899223, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444899223, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4170.045751707478, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1120}}
rank 0: cycle = 81: time to send the model = 0.037935495376586914
:::MLLOG {"namespace": "", "time_ms": 1621444899262, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1134, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444899263, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1134, "epoch_count": 14}}
rank 640: cycle = 81: time to receive the model = 0.04971432685852051
:::MLLOG {"namespace": "", "time_ms": 1621444899274, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1134, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1134}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444900041, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8899863958358765, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1134}}
:::MLLOG {"namespace": "", "time_ms": 1621444900041, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1134}}
:::MLLOG {"namespace": "", "time_ms": 1621444900074, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4140.476572275721, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444900077, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444900077, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4140.476572275721, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1134}}
rank 0: cycle = 82: time to send the model = 0.05001020431518555
:::MLLOG {"namespace": "", "time_ms": 1621444900127, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1148, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444900128, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1148, "epoch_count": 14}}
rank 640: cycle = 82: time to receive the model = 0.05979156494140625
:::MLLOG {"namespace": "", "time_ms": 1621444900137, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1148, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1148}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444900906, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.889072060585022, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1148}}
:::MLLOG {"namespace": "", "time_ms": 1621444900906, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1148}}
:::MLLOG {"namespace": "", "time_ms": 1621444900908, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4308.494491505215, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444900909, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444900909, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4308.494491505215, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1148}}
rank 0: cycle = 83: time to send the model = 0.03982806205749512
:::MLLOG {"namespace": "", "time_ms": 1621444900952, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1162, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444900952, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1162, "epoch_count": 14}}
rank 640: cycle = 83: time to receive the model = 0.05088496208190918
:::MLLOG {"namespace": "", "time_ms": 1621444900963, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1162, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1162}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444901729, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8889354467391968, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1162}}
:::MLLOG {"namespace": "", "time_ms": 1621444901730, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1162}}
:::MLLOG {"namespace": "", "time_ms": 1621444901768, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4118.206649918602, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444901770, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444901771, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4118.206649918602, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1162}}
rank 0: cycle = 84: time to send the model = 0.04153084754943848
:::MLLOG {"namespace": "", "time_ms": 1621444901813, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1176, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444901813, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1176, "epoch_count": 14}}
rank 640: cycle = 84: time to receive the model = 0.05458688735961914
:::MLLOG {"namespace": "", "time_ms": 1621444901826, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1176, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1176}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444902593, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8844411373138428, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1176}}
:::MLLOG {"namespace": "", "time_ms": 1621444902593, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1176}}
:::MLLOG {"namespace": "", "time_ms": 1621444902626, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4130.496435275894, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444902628, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444902628, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4130.496435275894, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1176}}
rank 0: cycle = 85: time to send the model = 0.04105353355407715
:::MLLOG {"namespace": "", "time_ms": 1621444902672, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1190, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444902673, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1190, "epoch_count": 14}}
rank 640: cycle = 85: time to receive the model = 0.05041909217834473
:::MLLOG {"namespace": "", "time_ms": 1621444902682, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1190, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1190}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444903449, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8790856003761292, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1190}}
:::MLLOG {"namespace": "", "time_ms": 1621444903450, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1190}}
:::MLLOG {"namespace": "", "time_ms": 1621444903496, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4082.469841771959, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444903498, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444903498, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4082.469841771959, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1190}}
rank 0: cycle = 86: time to send the model = 0.050243377685546875
:::MLLOG {"namespace": "", "time_ms": 1621444903549, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1204, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444903549, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1204, "epoch_count": 14}}
rank 640: cycle = 86: time to receive the model = 0.05855083465576172
:::MLLOG {"namespace": "", "time_ms": 1621444903557, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1204, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1204}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444904325, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8908831477165222, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1204}}
:::MLLOG {"namespace": "", "time_ms": 1621444904325, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1204}}
:::MLLOG {"namespace": "", "time_ms": 1621444904373, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4081.4542202472007, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444904375, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444904375, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4081.4542202472007, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1204}}
rank 0: cycle = 87: time to send the model = 0.039666175842285156
:::MLLOG {"namespace": "", "time_ms": 1621444904416, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1218, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444904416, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1218, "epoch_count": 14}}
rank 640: cycle = 87: time to receive the model = 0.05124926567077637
:::MLLOG {"namespace": "", "time_ms": 1621444904427, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1218}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444905189, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4346.233311724799, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444905191, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444905192, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4346.233311724799, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1218}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444905196, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8894512057304382, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1218}}
:::MLLOG {"namespace": "", "time_ms": 1621444905197, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1218}}
rank 0: cycle = 88: time to send the model = 0.044353485107421875
:::MLLOG {"namespace": "", "time_ms": 1621444905242, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1232, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444905243, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1232, "epoch_count": 14}}
rank 640: cycle = 88: time to receive the model = 0.0565800666809082
:::MLLOG {"namespace": "", "time_ms": 1621444905254, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1232, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1232}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444906023, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8751965761184692, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1232}}
:::MLLOG {"namespace": "", "time_ms": 1621444906023, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1232}}
:::MLLOG {"namespace": "", "time_ms": 1621444906069, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4068.8102662176584, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444906071, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444906071, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4068.8102662176584, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1232}}
rank 0: cycle = 89: time to send the model = 0.038756370544433594
:::MLLOG {"namespace": "", "time_ms": 1621444906111, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1246, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444906111, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1246, "epoch_count": 14}}
rank 640: cycle = 89: time to receive the model = 0.04963517189025879
:::MLLOG {"namespace": "", "time_ms": 1621444906122, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1246, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1246}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444906890, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.882370114326477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1246}}
:::MLLOG {"namespace": "", "time_ms": 1621444906890, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1246}}
:::MLLOG {"namespace": "", "time_ms": 1621444906916, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4174.210641987054, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444906918, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444906919, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4174.210641987054, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1246}}
rank 0: cycle = 90: time to send the model = 0.047736167907714844
:::MLLOG {"namespace": "", "time_ms": 1621444906967, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1260, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444906967, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1260, "epoch_count": 14}}
rank 640: cycle = 90: time to receive the model = 0.05936837196350098
:::MLLOG {"namespace": "", "time_ms": 1621444906979, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1260}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444907744, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8932123184204102, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1621444907745, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1621444907762, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4231.253166415415, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444907763, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444907763, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4231.253166415415, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1260}}
rank 0: cycle = 91: time to send the model = 0.03887057304382324
:::MLLOG {"namespace": "", "time_ms": 1621444907802, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1274, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444907803, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1274, "epoch_count": 14}}
rank 640: cycle = 91: time to receive the model = 0.05025768280029297
:::MLLOG {"namespace": "", "time_ms": 1621444907814, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1274, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1274}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444908582, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8968000411987305, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1274}}
:::MLLOG {"namespace": "", "time_ms": 1621444908582, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1274}}
:::MLLOG {"namespace": "", "time_ms": 1621444908596, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4238.412502973655, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444908598, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444908599, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4238.412502973655, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1274}}
rank 0: cycle = 92: time to send the model = 0.04334712028503418
:::MLLOG {"namespace": "", "time_ms": 1621444908642, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1288, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444908643, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1288, "epoch_count": 14}}
rank 640: cycle = 92: time to receive the model = 0.055394649505615234
:::MLLOG {"namespace": "", "time_ms": 1621444908654, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1288, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1288}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444909420, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8907001614570618, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1288}}
:::MLLOG {"namespace": "", "time_ms": 1621444909420, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1288}}
:::MLLOG {"namespace": "", "time_ms": 1621444909459, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4117.931085265066, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444909460, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444909460, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4117.931085265066, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1288}}
rank 0: cycle = 93: time to send the model = 0.03908729553222656
:::MLLOG {"namespace": "", "time_ms": 1621444909501, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1302, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444909502, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1302, "epoch_count": 14}}
rank 640: cycle = 93: time to receive the model = 0.049833059310913086
:::MLLOG {"namespace": "", "time_ms": 1621444909512, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1302, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1302}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444910279, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8951844573020935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1302}}
:::MLLOG {"namespace": "", "time_ms": 1621444910279, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1302}}
:::MLLOG {"namespace": "", "time_ms": 1621444910295, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4238.626663037447, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444910297, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444910298, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4238.626663037447, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1302}}
rank 0: cycle = 94: time to send the model = 0.04283308982849121
:::MLLOG {"namespace": "", "time_ms": 1621444910341, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1316, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444910341, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1316, "epoch_count": 14}}
rank 640: cycle = 94: time to receive the model = 0.05050206184387207
:::MLLOG {"namespace": "", "time_ms": 1621444910349, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1316, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1316}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621444911119, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8959280252456665, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1316}}
:::MLLOG {"namespace": "", "time_ms": 1621444911120, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1316}}
:::MLLOG {"namespace": "", "time_ms": 1621444911150, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4152.926759191237, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444911152, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444911152, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4152.926759191237, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1316}}
rank 0: cycle = 95: time to send the model = 0.03922724723815918
:::MLLOG {"namespace": "", "time_ms": 1621444911194, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1330, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444911194, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1330, "epoch_count": 14}}
rank 640: cycle = 95: time to receive the model = 0.04997658729553223
:::MLLOG {"namespace": "", "time_ms": 1621444911204, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1330, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1330}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444911974, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.886136531829834, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1330}}
:::MLLOG {"namespace": "", "time_ms": 1621444911974, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1330}}
:::MLLOG {"namespace": "", "time_ms": 1621444911984, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4250.741448439384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444911987, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444911987, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4250.741448439384, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1330}}
rank 0: cycle = 96: time to send the model = 0.0453181266784668
:::MLLOG {"namespace": "", "time_ms": 1621444912033, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1344, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444912033, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1344, "epoch_count": 14}}
rank 640: cycle = 96: time to receive the model = 0.058498382568359375
:::MLLOG {"namespace": "", "time_ms": 1621444912046, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1344, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1344}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444912800, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4381.363443469037, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444912802, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444912802, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4381.363443469037, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1344}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444912812, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8778623342514038, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1344}}
:::MLLOG {"namespace": "", "time_ms": 1621444912814, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1344}}
rank 0: cycle = 97: time to send the model = 0.037793874740600586
:::MLLOG {"namespace": "", "time_ms": 1621444912852, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1358, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444912853, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1358, "epoch_count": 14}}
rank 640: cycle = 97: time to receive the model = 0.05033564567565918
:::MLLOG {"namespace": "", "time_ms": 1621444912864, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1358, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1358}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621444913628, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9015582799911499, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1358}}
:::MLLOG {"namespace": "", "time_ms": 1621444913629, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1358}}
:::MLLOG {"namespace": "", "time_ms": 1621444913656, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4184.168598742511, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444913659, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444913659, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4184.168598742511, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1358}}
rank 0: cycle = 98: time to send the model = 0.046411752700805664
:::MLLOG {"namespace": "", "time_ms": 1621444913706, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1372, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444913706, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1372, "epoch_count": 14}}
rank 640: cycle = 98: time to receive the model = 0.05547642707824707
:::MLLOG {"namespace": "", "time_ms": 1621444913715, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1372}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444914478, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4353.582941621317, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444914480, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444914480, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4353.582941621317, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1372}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444914484, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8930959701538086, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1372}}
:::MLLOG {"namespace": "", "time_ms": 1621444914485, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1372}}
rank 0: cycle = 99: time to send the model = 0.03726506233215332
:::MLLOG {"namespace": "", "time_ms": 1621444914522, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1386, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444914523, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1386, "epoch_count": 14}}
rank 640: cycle = 99: time to receive the model = 0.049530029296875
:::MLLOG {"namespace": "", "time_ms": 1621444914535, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1386}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444915303, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8922407031059265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1386}}
:::MLLOG {"namespace": "", "time_ms": 1621444915303, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1386}}
:::MLLOG {"namespace": "", "time_ms": 1621444915345, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4093.1032405625783, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444915347, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444915348, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4093.1032405625783, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1386}}
rank 0: cycle = 100: time to send the model = 0.0478062629699707
:::MLLOG {"namespace": "", "time_ms": 1621444915396, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1400, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444915396, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1400, "epoch_count": 14}}
rank 640: cycle = 100: time to receive the model = 0.05751919746398926
:::MLLOG {"namespace": "", "time_ms": 1621444915405, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1400}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444916174, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8909404277801514, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1621444916175, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1621444916200, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4179.019484984828, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444916202, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444916202, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4179.019484984828, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1400}}
rank 0: cycle = 101: time to send the model = 0.04195904731750488
:::MLLOG {"namespace": "", "time_ms": 1621444916246, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1414, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444916246, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1414, "epoch_count": 14}}
rank 640: cycle = 101: time to receive the model = 0.055193424224853516
:::MLLOG {"namespace": "", "time_ms": 1621444916259, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1414, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1414}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621444917024, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.892696738243103, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1414}}
:::MLLOG {"namespace": "", "time_ms": 1621444917024, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1414}}
:::MLLOG {"namespace": "", "time_ms": 1621444917044, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4213.836889749359, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444917046, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444917047, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4213.836889749359, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1414}}
rank 0: cycle = 102: time to send the model = 0.0473322868347168
:::MLLOG {"namespace": "", "time_ms": 1621444917094, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1428, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444917095, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1428, "epoch_count": 14}}
rank 640: cycle = 102: time to receive the model = 0.05658149719238281
:::MLLOG {"namespace": "", "time_ms": 1621444917104, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1428, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1428}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444917873, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8967055082321167, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1428}}
:::MLLOG {"namespace": "", "time_ms": 1621444917873, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1428}}
:::MLLOG {"namespace": "", "time_ms": 1621444917895, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4200.80524621438, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444917896, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444917896, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4200.80524621438, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1428}}
rank 0: cycle = 103: time to send the model = 0.03890872001647949
:::MLLOG {"namespace": "", "time_ms": 1621444917938, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1442, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444917938, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1442, "epoch_count": 14}}
rank 640: cycle = 103: time to receive the model = 0.05048656463623047
:::MLLOG {"namespace": "", "time_ms": 1621444917949, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1442, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1442}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444918709, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4360.330055447558, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444918711, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444918711, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4360.330055447558, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1442}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444918715, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8872506618499756, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1442}}
:::MLLOG {"namespace": "", "time_ms": 1621444918716, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1442}}
rank 0: cycle = 104: time to send the model = 0.046033382415771484
:::MLLOG {"namespace": "", "time_ms": 1621444918763, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1456, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444918764, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1456, "epoch_count": 14}}
rank 640: cycle = 104: time to receive the model = 0.05703878402709961
:::MLLOG {"namespace": "", "time_ms": 1621444918773, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1456, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1456}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444919542, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8893433809280396, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1456}}
:::MLLOG {"namespace": "", "time_ms": 1621444919543, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1456}}
:::MLLOG {"namespace": "", "time_ms": 1621444919579, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4123.261191401016, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444919580, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444919580, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4123.261191401016, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1456}}
rank 0: cycle = 105: time to send the model = 0.03984832763671875
:::MLLOG {"namespace": "", "time_ms": 1621444919622, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1470, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444919622, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1470, "epoch_count": 14}}
rank 640: cycle = 105: time to receive the model = 0.05170750617980957
:::MLLOG {"namespace": "", "time_ms": 1621444919634, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1470, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1470}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444920399, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8968373537063599, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1470}}
:::MLLOG {"namespace": "", "time_ms": 1621444920399, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1470}}
:::MLLOG {"namespace": "", "time_ms": 1621444920427, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4177.172619435766, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444920429, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444920430, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4177.172619435766, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1470}}
rank 0: cycle = 106: time to send the model = 0.04980301856994629
:::MLLOG {"namespace": "", "time_ms": 1621444920480, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1484, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444920480, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1484, "epoch_count": 14}}
rank 640: cycle = 106: time to receive the model = 0.06018853187561035
:::MLLOG {"namespace": "", "time_ms": 1621444920490, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1484}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444921258, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9000662565231323, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1484}}
:::MLLOG {"namespace": "", "time_ms": 1621444921258, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1484}}
:::MLLOG {"namespace": "", "time_ms": 1621444921301, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4094.927661765471, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444921303, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444921303, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4094.927661765471, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1484}}
rank 0: cycle = 107: time to send the model = 0.039906978607177734
:::MLLOG {"namespace": "", "time_ms": 1621444921343, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1498, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444921343, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1498, "epoch_count": 14}}
rank 640: cycle = 107: time to receive the model = 0.05106949806213379
:::MLLOG {"namespace": "", "time_ms": 1621444921354, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1498, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1498}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444922121, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8972795605659485, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1498}}
:::MLLOG {"namespace": "", "time_ms": 1621444922121, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1498}}
:::MLLOG {"namespace": "", "time_ms": 1621444922130, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4268.6910228481565, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444922132, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444922133, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4268.6910228481565, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1498}}
rank 0: cycle = 108: time to send the model = 0.04309535026550293
:::MLLOG {"namespace": "", "time_ms": 1621444922176, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1512, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444922176, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1512, "epoch_count": 14}}
rank 640: cycle = 108: time to receive the model = 0.05705118179321289
:::MLLOG {"namespace": "", "time_ms": 1621444922190, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1512, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1512}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444922955, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8985036611557007, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1512}}
:::MLLOG {"namespace": "", "time_ms": 1621444922955, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1512}}
:::MLLOG {"namespace": "", "time_ms": 1621444922973, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4218.367526901225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444922975, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444922975, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4218.367526901225, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1512}}
rank 0: cycle = 109: time to send the model = 0.03785061836242676
:::MLLOG {"namespace": "", "time_ms": 1621444923013, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1526, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444923013, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1526, "epoch_count": 14}}
rank 640: cycle = 109: time to receive the model = 0.05052471160888672
:::MLLOG {"namespace": "", "time_ms": 1621444923026, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1526, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1526}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444923792, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.888475775718689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1526}}
:::MLLOG {"namespace": "", "time_ms": 1621444923793, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1526}}
:::MLLOG {"namespace": "", "time_ms": 1621444923806, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4238.503008455435, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444923808, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444923808, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4238.503008455435, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1526}}
rank 0: cycle = 110: time to send the model = 0.04708456993103027
:::MLLOG {"namespace": "", "time_ms": 1621444923856, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1540, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444923856, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1540, "epoch_count": 14}}
rank 640: cycle = 110: time to receive the model = 0.05614829063415527
:::MLLOG {"namespace": "", "time_ms": 1621444923865, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1540}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444924631, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8848510384559631, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1621444924632, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1621444924632, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4332.111563190492, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444924634, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444924634, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4332.111563190492, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1540}}
rank 0: cycle = 111: time to send the model = 0.03938007354736328
:::MLLOG {"namespace": "", "time_ms": 1621444924691, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1554, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444924691, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1554, "epoch_count": 14}}
rank 640: cycle = 111: time to receive the model = 0.051724910736083984
:::MLLOG {"namespace": "", "time_ms": 1621444924703, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1554, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1554}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444925461, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4359.937506844857, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444925463, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444925463, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4359.937506844857, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1554}}
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621444925467, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9012646079063416, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1554}}
:::MLLOG {"namespace": "", "time_ms": 1621444925469, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1554}}
rank 0: cycle = 112: time to send the model = 0.04345440864562988
:::MLLOG {"namespace": "", "time_ms": 1621444925513, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1568, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444925514, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1568, "epoch_count": 14}}
rank 640: cycle = 112: time to receive the model = 0.057015180587768555
:::MLLOG {"namespace": "", "time_ms": 1621444925526, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1568, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1568}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444926292, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8968787789344788, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1568}}
:::MLLOG {"namespace": "", "time_ms": 1621444926292, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1568}}
:::MLLOG {"namespace": "", "time_ms": 1621444926310, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4221.926203491475, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444926312, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444926312, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4221.926203491475, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1568}}
rank 0: cycle = 113: time to send the model = 0.03841352462768555
:::MLLOG {"namespace": "", "time_ms": 1621444926351, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1582, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444926351, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1582, "epoch_count": 14}}
rank 640: cycle = 113: time to receive the model = 0.05022120475769043
:::MLLOG {"namespace": "", "time_ms": 1621444926362, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1582, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1582}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444927129, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8917909860610962, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1582}}
:::MLLOG {"namespace": "", "time_ms": 1621444927130, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1582}}
:::MLLOG {"namespace": "", "time_ms": 1621444927149, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4211.367558912809, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444927151, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444927152, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4211.367558912809, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1582}}
rank 0: cycle = 114: time to send the model = 0.043366193771362305
:::MLLOG {"namespace": "", "time_ms": 1621444927196, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1596, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444927196, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1596, "epoch_count": 14}}
rank 640: cycle = 114: time to receive the model = 0.052265167236328125
:::MLLOG {"namespace": "", "time_ms": 1621444927205, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1596, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1596}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444927975, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4317.077310231908, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621444927975, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8955758213996887, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1596}}
:::MLLOG {"namespace": "", "time_ms": 1621444927976, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444927977, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1596}}
:::MLLOG {"namespace": "", "time_ms": 1621444927978, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4317.077310231908, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1596}}
rank 0: cycle = 115: time to send the model = 0.04083371162414551
:::MLLOG {"namespace": "", "time_ms": 1621444928021, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1610, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444928021, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1610, "epoch_count": 14}}
rank 640: cycle = 115: time to receive the model = 0.05140042304992676
:::MLLOG {"namespace": "", "time_ms": 1621444928031, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1610, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1610}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444928799, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8990395069122314, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1610}}
:::MLLOG {"namespace": "", "time_ms": 1621444928799, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1610}}
:::MLLOG {"namespace": "", "time_ms": 1621444928809, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4264.140726196993, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444928811, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444928812, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4264.140726196993, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1610}}
rank 0: cycle = 116: time to send the model = 0.046379804611206055
:::MLLOG {"namespace": "", "time_ms": 1621444928859, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1624, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444928859, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1624, "epoch_count": 14}}
rank 640: cycle = 116: time to receive the model = 0.05830740928649902
:::MLLOG {"namespace": "", "time_ms": 1621444928871, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1624, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1624}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444929636, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8945802450180054, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1624}}
:::MLLOG {"namespace": "", "time_ms": 1621444929637, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1624}}
:::MLLOG {"namespace": "", "time_ms": 1621444929641, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4296.711515348859, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444929643, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444929643, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4296.711515348859, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1624}}
rank 0: cycle = 117: time to send the model = 0.03879094123840332
:::MLLOG {"namespace": "", "time_ms": 1621444929683, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1638, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444929683, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1638, "epoch_count": 14}}
rank 640: cycle = 117: time to receive the model = 0.04963231086730957
:::MLLOG {"namespace": "", "time_ms": 1621444929694, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1638, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1638}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444930459, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.900244951248169, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1638}}
:::MLLOG {"namespace": "", "time_ms": 1621444930459, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1638}}
:::MLLOG {"namespace": "", "time_ms": 1621444930466, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4293.794803765585, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444930468, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444930469, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4293.794803765585, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1638}}
rank 0: cycle = 118: time to send the model = 0.04955291748046875
:::MLLOG {"namespace": "", "time_ms": 1621444930519, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1652, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444930519, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1652, "epoch_count": 14}}
rank 640: cycle = 118: time to receive the model = 0.058304548263549805
:::MLLOG {"namespace": "", "time_ms": 1621444930528, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1652, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1652}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444931296, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8838328719139099, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1652}}
:::MLLOG {"namespace": "", "time_ms": 1621444931296, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1652}}
:::MLLOG {"namespace": "", "time_ms": 1621444931349, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4048.9758917933377, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444931351, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444931351, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4048.9758917933377, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1652}}
rank 0: cycle = 119: time to send the model = 0.03887009620666504
:::MLLOG {"namespace": "", "time_ms": 1621444931393, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1666, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444931393, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1666, "epoch_count": 14}}
rank 640: cycle = 119: time to receive the model = 0.05018186569213867
:::MLLOG {"namespace": "", "time_ms": 1621444931404, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1666, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1666}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444932162, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4371.842439644219, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444932164, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444932164, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4371.842439644219, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1666}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444932171, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8886591196060181, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1666}}
:::MLLOG {"namespace": "", "time_ms": 1621444932172, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1666}}
rank 0: cycle = 120: time to send the model = 0.04145216941833496
:::MLLOG {"namespace": "", "time_ms": 1621444932214, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1680, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444932215, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1680, "epoch_count": 14}}
rank 640: cycle = 120: time to receive the model = 0.05452084541320801
:::MLLOG {"namespace": "", "time_ms": 1621444932227, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1680}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444932993, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8910150527954102, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1621444932993, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1621444933006, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4252.416562892359, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444933007, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444933007, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4252.416562892359, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1680}}
rank 0: cycle = 121: time to send the model = 0.038645029067993164
:::MLLOG {"namespace": "", "time_ms": 1621444933048, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1694, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444933048, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1694, "epoch_count": 14}}
rank 640: cycle = 121: time to receive the model = 0.05046558380126953
:::MLLOG {"namespace": "", "time_ms": 1621444933060, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1694, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1694}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444933813, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4390.430816622553, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444933815, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444933816, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4390.430816622553, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1694}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444933825, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8969359397888184, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1694}}
:::MLLOG {"namespace": "", "time_ms": 1621444933826, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1694}}
rank 0: cycle = 122: time to send the model = 0.046021461486816406
:::MLLOG {"namespace": "", "time_ms": 1621444933872, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1708, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444933874, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1708, "epoch_count": 14}}
rank 640: cycle = 122: time to receive the model = 0.05845046043395996
:::MLLOG {"namespace": "", "time_ms": 1621444933885, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1708, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1708}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444934651, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9020975232124329, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1708}}
:::MLLOG {"namespace": "", "time_ms": 1621444934652, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1708}}
:::MLLOG {"namespace": "", "time_ms": 1621444934665, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4243.891855429813, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444934667, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444934667, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4243.891855429813, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1708}}
rank 0: cycle = 123: time to send the model = 0.03942251205444336
:::MLLOG {"namespace": "", "time_ms": 1621444934708, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1722, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444934708, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1722, "epoch_count": 14}}
rank 640: cycle = 123: time to receive the model = 0.05068850517272949
:::MLLOG {"namespace": "", "time_ms": 1621444934720, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1722}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444935483, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4336.407826349975, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444935486, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444935486, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4336.407826349975, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1722}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444935487, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8902282118797302, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1722}}
:::MLLOG {"namespace": "", "time_ms": 1621444935489, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1722}}
rank 0: cycle = 124: time to send the model = 0.045935869216918945
:::MLLOG {"namespace": "", "time_ms": 1621444935535, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1736, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444935537, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1736, "epoch_count": 14}}
rank 640: cycle = 124: time to receive the model = 0.05707883834838867
:::MLLOG {"namespace": "", "time_ms": 1621444935546, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1736, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1736}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444936313, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8871903419494629, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1736}}
:::MLLOG {"namespace": "", "time_ms": 1621444936313, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1736}}
:::MLLOG {"namespace": "", "time_ms": 1621444936335, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4210.308183368447, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444936336, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444936336, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4210.308183368447, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1736}}
rank 0: cycle = 125: time to send the model = 0.041434526443481445
:::MLLOG {"namespace": "", "time_ms": 1621444936381, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1750, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444936381, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1750, "epoch_count": 14}}
rank 640: cycle = 125: time to receive the model = 0.050347089767456055
:::MLLOG {"namespace": "", "time_ms": 1621444936390, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1750, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1750}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444937155, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4342.76316839628, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444937157, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444937157, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4342.76316839628, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1750}}
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444937159, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8933413028717041, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1750}}
:::MLLOG {"namespace": "", "time_ms": 1621444937161, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1750}}
rank 0: cycle = 126: time to send the model = 0.049097299575805664
:::MLLOG {"namespace": "", "time_ms": 1621444937210, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1764, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444937211, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1764, "epoch_count": 14}}
rank 640: cycle = 126: time to receive the model = 0.06547021865844727
:::MLLOG {"namespace": "", "time_ms": 1621444937227, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1764, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1764}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444937993, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8992393016815186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1764}}
:::MLLOG {"namespace": "", "time_ms": 1621444937993, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1764}}
:::MLLOG {"namespace": "", "time_ms": 1621444938022, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4145.624985659461, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444938024, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444938024, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4145.624985659461, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1764}}
rank 0: cycle = 127: time to send the model = 0.03979945182800293
:::MLLOG {"namespace": "", "time_ms": 1621444938064, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1778, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444938064, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1778, "epoch_count": 14}}
rank 640: cycle = 127: time to receive the model = 0.05164361000061035
:::MLLOG {"namespace": "", "time_ms": 1621444938076, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1778, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1778}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444938830, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4390.57990930885, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444938831, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444938832, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4390.57990930885, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1778}}
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621444938846, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8895866870880127, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1778}}
:::MLLOG {"namespace": "", "time_ms": 1621444938848, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1778}}
rank 0: cycle = 128: time to send the model = 0.03726673126220703
:::MLLOG {"namespace": "", "time_ms": 1621444938885, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1792, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444938887, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1792, "epoch_count": 14}}
rank 640: cycle = 128: time to receive the model = 0.05200624465942383
:::MLLOG {"namespace": "", "time_ms": 1621444938900, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1792, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1792}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.76 s.
:::MLLOG {"namespace": "", "time_ms": 1621444939661, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8819713592529297, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1792}}
:::MLLOG {"namespace": "", "time_ms": 1621444939661, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1792}}
:::MLLOG {"namespace": "", "time_ms": 1621444939674, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4265.510089560551, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444939676, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444939676, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4265.510089560551, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1792}}
rank 0: cycle = 129: time to send the model = 0.03873419761657715
:::MLLOG {"namespace": "", "time_ms": 1621444939715, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1806, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444939715, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1806, "epoch_count": 14}}
rank 640: cycle = 129: time to receive the model = 0.05016803741455078
:::MLLOG {"namespace": "", "time_ms": 1621444939726, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1806, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1806}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444940493, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8921623229980469, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1806}}
:::MLLOG {"namespace": "", "time_ms": 1621444940493, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1806}}
:::MLLOG {"namespace": "", "time_ms": 1621444940515, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4203.976900421774, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444940517, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444940518, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4203.976900421774, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1806}}
rank 0: cycle = 130: time to send the model = 0.04327750205993652
:::MLLOG {"namespace": "", "time_ms": 1621444940561, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1820, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444940562, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1820, "epoch_count": 14}}
rank 640: cycle = 130: time to receive the model = 0.051874399185180664
:::MLLOG {"namespace": "", "time_ms": 1621444940570, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1820}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444941339, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8945667743682861, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1621444941339, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1621444941341, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4313.2574794878765, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444941342, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444941342, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4313.2574794878765, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1820}}
rank 0: cycle = 131: time to send the model = 0.0384829044342041
:::MLLOG {"namespace": "", "time_ms": 1621444941381, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1834, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444941381, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1834, "epoch_count": 14}}
rank 640: cycle = 131: time to receive the model = 0.05021095275878906
:::MLLOG {"namespace": "", "time_ms": 1621444941393, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1834, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1834}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621444942157, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8861491680145264, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1834}}
:::MLLOG {"namespace": "", "time_ms": 1621444942157, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1834}}
:::MLLOG {"namespace": "", "time_ms": 1621444942186, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4175.657699961244, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444942188, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444942189, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4175.657699961244, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1834}}
rank 0: cycle = 132: time to send the model = 0.04790544509887695
:::MLLOG {"namespace": "", "time_ms": 1621444942237, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1848, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444942238, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1848, "epoch_count": 14}}
rank 640: cycle = 132: time to receive the model = 0.05580282211303711
:::MLLOG {"namespace": "", "time_ms": 1621444942245, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1848, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1848}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444943013, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8966814279556274, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1848}}
:::MLLOG {"namespace": "", "time_ms": 1621444943013, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1848}}
:::MLLOG {"namespace": "", "time_ms": 1621444943042, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4176.635340852714, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444943044, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444943044, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4176.635340852714, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1848}}
rank 0: cycle = 133: time to send the model = 0.03790163993835449
:::MLLOG {"namespace": "", "time_ms": 1621444943084, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1862, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444943084, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1862, "epoch_count": 14}}
rank 640: cycle = 133: time to receive the model = 0.05078840255737305
:::MLLOG {"namespace": "", "time_ms": 1621444943097, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1862, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1862}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444943865, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8886681795120239, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1862}}
:::MLLOG {"namespace": "", "time_ms": 1621444943865, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1862}}
:::MLLOG {"namespace": "", "time_ms": 1621444943879, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4231.809672691392, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444943880, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444943881, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4231.809672691392, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1862}}
rank 0: cycle = 134: time to send the model = 0.04896950721740723
:::MLLOG {"namespace": "", "time_ms": 1621444943930, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1876, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444943931, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1876, "epoch_count": 14}}
rank 640: cycle = 134: time to receive the model = 0.061124324798583984
:::MLLOG {"namespace": "", "time_ms": 1621444943942, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1876, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1876}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444944710, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8841992020606995, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1876}}
:::MLLOG {"namespace": "", "time_ms": 1621444944711, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1876}}
:::MLLOG {"namespace": "", "time_ms": 1621444944727, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4218.093545442301, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444944729, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444944729, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4218.093545442301, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1876}}
rank 0: cycle = 135: time to send the model = 0.03934335708618164
:::MLLOG {"namespace": "", "time_ms": 1621444944771, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1890, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444944771, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1890, "epoch_count": 14}}
rank 640: cycle = 135: time to receive the model = 0.049791574478149414
:::MLLOG {"namespace": "", "time_ms": 1621444944781, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1890, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1890}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444945547, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9069998860359192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1890}}
:::MLLOG {"namespace": "", "time_ms": 1621444945548, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1890}}
:::MLLOG {"namespace": "", "time_ms": 1621444945569, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4210.997597619133, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444945571, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444945571, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4210.997597619133, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1890}}
rank 0: cycle = 136: time to send the model = 0.054818153381347656
:::MLLOG {"namespace": "", "time_ms": 1621444945627, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1904, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444945627, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1904, "epoch_count": 14}}
rank 640: cycle = 136: time to receive the model = 0.07064628601074219
:::MLLOG {"namespace": "", "time_ms": 1621444945642, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1904, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1904}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621444946407, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8831970691680908, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1904}}
:::MLLOG {"namespace": "", "time_ms": 1621444946408, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1904}}
:::MLLOG {"namespace": "", "time_ms": 1621444946413, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4275.399160505153, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444946415, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444946415, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4275.399160505153, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1904}}
rank 0: cycle = 137: time to send the model = 0.039398908615112305
:::MLLOG {"namespace": "", "time_ms": 1621444946470, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1918, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444946470, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1918, "epoch_count": 14}}
rank 640: cycle = 137: time to receive the model = 0.051142215728759766
:::MLLOG {"namespace": "", "time_ms": 1621444946482, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1918, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1918}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444947240, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4363.771589161713, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444947242, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444947242, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4363.771589161713, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1918}}
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621444947246, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8946152925491333, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1918}}
:::MLLOG {"namespace": "", "time_ms": 1621444947248, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1918}}
rank 0: cycle = 138: time to send the model = 0.042313337326049805
:::MLLOG {"namespace": "", "time_ms": 1621444947290, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1932, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444947292, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1932, "epoch_count": 14}}
rank 640: cycle = 138: time to receive the model = 0.050206899642944336
:::MLLOG {"namespace": "", "time_ms": 1621444947298, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1932, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1932}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444948065, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9039392471313477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1932}}
:::MLLOG {"namespace": "", "time_ms": 1621444948065, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1932}}
:::MLLOG {"namespace": "", "time_ms": 1621444948090, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4207.961087995413, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444948092, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444948092, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4207.961087995413, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1932}}
rank 0: cycle = 139: time to send the model = 0.040029048919677734
:::MLLOG {"namespace": "", "time_ms": 1621444948136, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1946, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444948136, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1946, "epoch_count": 14}}
rank 640: cycle = 139: time to receive the model = 0.05088067054748535
:::MLLOG {"namespace": "", "time_ms": 1621444948146, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1946, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1946}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444948915, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9029183387756348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1946}}
:::MLLOG {"namespace": "", "time_ms": 1621444948915, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1946}}
:::MLLOG {"namespace": "", "time_ms": 1621444948929, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4237.157297404885, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444948932, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444948933, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4237.157297404885, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1946}}
rank 0: cycle = 140: time to send the model = 0.04176688194274902
:::MLLOG {"namespace": "", "time_ms": 1621444948975, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1960, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444948975, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1960, "epoch_count": 14}}
rank 640: cycle = 140: time to receive the model = 0.05542302131652832
:::MLLOG {"namespace": "", "time_ms": 1621444948988, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1960}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444949739, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4398.375534392433, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444949741, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444949741, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4398.375534392433, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1960}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444949756, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8960202932357788, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1621444949758, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1960}}
rank 0: cycle = 141: time to send the model = 0.03704476356506348
:::MLLOG {"namespace": "", "time_ms": 1621444949795, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1974, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444949799, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1974, "epoch_count": 14}}
rank 640: cycle = 141: time to receive the model = 0.05327200889587402
:::MLLOG {"namespace": "", "time_ms": 1621444949811, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1974}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.761 s.
:::MLLOG {"namespace": "", "time_ms": 1621444950573, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.892507791519165, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1974}}
:::MLLOG {"namespace": "", "time_ms": 1621444950573, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1974}}
:::MLLOG {"namespace": "", "time_ms": 1621444950611, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4136.355627353927, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444950613, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444950614, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4136.355627353927, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1974}}
rank 0: cycle = 142: time to send the model = 0.047071218490600586
:::MLLOG {"namespace": "", "time_ms": 1621444950661, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1988, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444950661, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1988, "epoch_count": 14}}
rank 640: cycle = 142: time to receive the model = 0.05542802810668945
:::MLLOG {"namespace": "", "time_ms": 1621444950669, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1988, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1988}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444951440, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8918257355690002, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1988}}
:::MLLOG {"namespace": "", "time_ms": 1621444951440, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1988}}
:::MLLOG {"namespace": "", "time_ms": 1621444951470, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4157.24880816791, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444951471, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444951471, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4157.24880816791, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1988}}
rank 0: cycle = 143: time to send the model = 0.038605690002441406
:::MLLOG {"namespace": "", "time_ms": 1621444951510, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2002, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444951510, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2002, "epoch_count": 14}}
rank 640: cycle = 143: time to receive the model = 0.0518648624420166
:::MLLOG {"namespace": "", "time_ms": 1621444951523, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2002, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2002}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.762 s.
:::MLLOG {"namespace": "", "time_ms": 1621444952287, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9040968418121338, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2002}}
:::MLLOG {"namespace": "", "time_ms": 1621444952287, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2002}}
:::MLLOG {"namespace": "", "time_ms": 1621444952302, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4242.049785351916, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444952304, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444952305, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4242.049785351916, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2002}}
rank 0: cycle = 144: time to send the model = 0.04750680923461914
:::MLLOG {"namespace": "", "time_ms": 1621444952353, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2016, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444952353, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2016, "epoch_count": 14}}
rank 640: cycle = 144: time to receive the model = 0.05856132507324219
:::MLLOG {"namespace": "", "time_ms": 1621444952364, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2016, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2016}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444953130, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8928735852241516, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2016}}
:::MLLOG {"namespace": "", "time_ms": 1621444953131, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2016}}
:::MLLOG {"namespace": "", "time_ms": 1621444953137, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4285.3055237289, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444953139, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444953139, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4285.3055237289, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2016}}
rank 0: cycle = 145: time to send the model = 0.04069113731384277
:::MLLOG {"namespace": "", "time_ms": 1621444953183, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2030, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444953183, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2030, "epoch_count": 14}}
rank 640: cycle = 145: time to receive the model = 0.051110267639160156
:::MLLOG {"namespace": "", "time_ms": 1621444953193, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2030, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2030}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444953959, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8954163193702698, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2030}}
:::MLLOG {"namespace": "", "time_ms": 1621444953959, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2030}}
:::MLLOG {"namespace": "", "time_ms": 1621444953967, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4283.842686922585, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444953969, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444953970, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4283.842686922585, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2030}}
rank 0: cycle = 146: time to send the model = 0.048996925354003906
:::MLLOG {"namespace": "", "time_ms": 1621444954019, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2044, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444954020, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2044, "epoch_count": 14}}
rank 640: cycle = 146: time to receive the model = 0.06197404861450195
:::MLLOG {"namespace": "", "time_ms": 1621444954032, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2044, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2044}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444954797, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8990321159362793, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2044}}
:::MLLOG {"namespace": "", "time_ms": 1621444954797, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2044}}
:::MLLOG {"namespace": "", "time_ms": 1621444954832, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4136.57538207122, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444954833, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444954833, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4136.57538207122, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2044}}
rank 0: cycle = 147: time to send the model = 0.03790545463562012
:::MLLOG {"namespace": "", "time_ms": 1621444954872, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2058, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444954872, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2058, "epoch_count": 14}}
rank 640: cycle = 147: time to receive the model = 0.051142215728759766
:::MLLOG {"namespace": "", "time_ms": 1621444954885, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2058, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2058}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444955651, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8742259740829468, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2058}}
:::MLLOG {"namespace": "", "time_ms": 1621444955652, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2058}}
:::MLLOG {"namespace": "", "time_ms": 1621444955664, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4241.096165461254, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444955666, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444955667, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4241.096165461254, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2058}}
rank 0: cycle = 148: time to send the model = 0.046732187271118164
:::MLLOG {"namespace": "", "time_ms": 1621444955714, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2072, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444955714, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2072, "epoch_count": 14}}
rank 640: cycle = 148: time to receive the model = 0.058130502700805664
:::MLLOG {"namespace": "", "time_ms": 1621444955725, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2072, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2072}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444956491, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8891106843948364, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2072}}
:::MLLOG {"namespace": "", "time_ms": 1621444956491, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2072}}
:::MLLOG {"namespace": "", "time_ms": 1621444956501, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4268.70136667636, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444956502, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444956502, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4268.70136667636, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2072}}
rank 0: cycle = 149: time to send the model = 0.03837132453918457
:::MLLOG {"namespace": "", "time_ms": 1621444956543, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2086, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444956543, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2086, "epoch_count": 14}}
rank 640: cycle = 149: time to receive the model = 0.05037379264831543
:::MLLOG {"namespace": "", "time_ms": 1621444956555, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2086, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2086}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444957322, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8959416151046753, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2086}}
:::MLLOG {"namespace": "", "time_ms": 1621444957322, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2086}}
:::MLLOG {"namespace": "", "time_ms": 1621444957352, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4156.081654993761, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444957354, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444957355, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4156.081654993761, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2086}}
rank 0: cycle = 150: time to send the model = 0.048828840255737305
:::MLLOG {"namespace": "", "time_ms": 1621444957404, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2100, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444957404, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2100, "epoch_count": 14}}
rank 640: cycle = 150: time to receive the model = 0.05712246894836426
:::MLLOG {"namespace": "", "time_ms": 1621444957412, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2100}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444958176, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4351.785534192871, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444958178, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444958178, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4351.785534192871, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2100}}
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444958181, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.890394926071167, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1621444958183, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2100}}
rank 0: cycle = 151: time to send the model = 0.03847146034240723
:::MLLOG {"namespace": "", "time_ms": 1621444958221, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2114, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444958223, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2114, "epoch_count": 14}}
rank 640: cycle = 151: time to receive the model = 0.05021357536315918
:::MLLOG {"namespace": "", "time_ms": 1621444958233, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2114, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2114}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444958983, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4419.763225314174, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444958985, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444958985, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4419.763225314174, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2114}}
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444958999, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8944923877716064, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2114}}
:::MLLOG {"namespace": "", "time_ms": 1621444959000, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2114}}
rank 0: cycle = 152: time to send the model = 0.03699541091918945
:::MLLOG {"namespace": "", "time_ms": 1621444959038, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2128, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444959039, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2128, "epoch_count": 14}}
rank 640: cycle = 152: time to receive the model = 0.05037689208984375
:::MLLOG {"namespace": "", "time_ms": 1621444959051, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2128, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2128}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621444959815, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9003331661224365, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2128}}
:::MLLOG {"namespace": "", "time_ms": 1621444959815, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2128}}
:::MLLOG {"namespace": "", "time_ms": 1621444959839, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4202.448745902773, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444959840, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444959840, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4202.448745902773, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2128}}
rank 0: cycle = 153: time to send the model = 0.03951144218444824
:::MLLOG {"namespace": "", "time_ms": 1621444959883, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2142, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444959883, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2142, "epoch_count": 14}}
rank 640: cycle = 153: time to receive the model = 0.05108189582824707
:::MLLOG {"namespace": "", "time_ms": 1621444959894, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2142, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2142}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444960660, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8960595726966858, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2142}}
:::MLLOG {"namespace": "", "time_ms": 1621444960660, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2142}}
:::MLLOG {"namespace": "", "time_ms": 1621444960672, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4258.567816236444, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444960675, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444960675, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4258.567816236444, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2142}}
rank 0: cycle = 154: time to send the model = 0.05109000205993652
:::MLLOG {"namespace": "", "time_ms": 1621444960727, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2156, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444960727, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2156, "epoch_count": 14}}
rank 640: cycle = 154: time to receive the model = 0.05950927734375
:::MLLOG {"namespace": "", "time_ms": 1621444960735, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2156, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2156}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444961504, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8930410146713257, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2156}}
:::MLLOG {"namespace": "", "time_ms": 1621444961504, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2156}}
:::MLLOG {"namespace": "", "time_ms": 1621444961522, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4227.255202682577, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444961524, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444961524, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4227.255202682577, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2156}}
rank 0: cycle = 155: time to send the model = 0.03950643539428711
:::MLLOG {"namespace": "", "time_ms": 1621444961563, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2170, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444961564, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2170, "epoch_count": 14}}
rank 640: cycle = 155: time to receive the model = 0.051831960678100586
:::MLLOG {"namespace": "", "time_ms": 1621444961576, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2170, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2170}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444962338, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4339.532392542939, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621444962340, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8905495405197144, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2170}}
:::MLLOG {"namespace": "", "time_ms": 1621444962340, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444962341, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4339.532392542939, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2170}}
:::MLLOG {"namespace": "", "time_ms": 1621444962342, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2170}}
rank 0: cycle = 156: time to send the model = 0.04639744758605957
:::MLLOG {"namespace": "", "time_ms": 1621444962391, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2184, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444962392, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2184, "epoch_count": 14}}
rank 640: cycle = 156: time to receive the model = 0.057169198989868164
:::MLLOG {"namespace": "", "time_ms": 1621444962401, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2184, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2184}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444963169, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8807534575462341, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2184}}
:::MLLOG {"namespace": "", "time_ms": 1621444963170, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2184}}
:::MLLOG {"namespace": "", "time_ms": 1621444963182, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4254.764713092655, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444963183, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444963183, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4254.764713092655, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2184}}
rank 0: cycle = 157: time to send the model = 0.03968167304992676
:::MLLOG {"namespace": "", "time_ms": 1621444963223, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2198, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444963223, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2198, "epoch_count": 14}}
rank 640: cycle = 157: time to receive the model = 0.05114865303039551
:::MLLOG {"namespace": "", "time_ms": 1621444963235, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2198, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2198}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444964000, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8992031812667847, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2198}}
:::MLLOG {"namespace": "", "time_ms": 1621444964000, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2198}}
:::MLLOG {"namespace": "", "time_ms": 1621444964009, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4276.411092985318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444964011, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444964012, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4276.411092985318, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2198}}
rank 0: cycle = 158: time to send the model = 0.050015926361083984
:::MLLOG {"namespace": "", "time_ms": 1621444964062, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2212, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444964063, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2212, "epoch_count": 14}}
rank 640: cycle = 158: time to receive the model = 0.05950522422790527
:::MLLOG {"namespace": "", "time_ms": 1621444964072, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2212, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2212}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621444964842, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8788697719573975, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2212}}
:::MLLOG {"namespace": "", "time_ms": 1621444964842, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2212}}
:::MLLOG {"namespace": "", "time_ms": 1621444964846, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4290.656044806179, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444964848, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444964848, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4290.656044806179, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2212}}
rank 0: cycle = 159: time to send the model = 0.039705753326416016
:::MLLOG {"namespace": "", "time_ms": 1621444964888, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2226, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444964888, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2226, "epoch_count": 14}}
rank 640: cycle = 159: time to receive the model = 0.05194997787475586
:::MLLOG {"namespace": "", "time_ms": 1621444964900, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2226, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2226}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444965666, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8972809314727783, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2226}}
:::MLLOG {"namespace": "", "time_ms": 1621444965667, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2226}}
:::MLLOG {"namespace": "", "time_ms": 1621444965677, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4257.082022963034, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444965680, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444965681, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4257.082022963034, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2226}}
rank 0: cycle = 160: time to send the model = 0.04762434959411621
:::MLLOG {"namespace": "", "time_ms": 1621444965729, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2240, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444965729, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2240, "epoch_count": 14}}
rank 640: cycle = 160: time to receive the model = 0.05787825584411621
:::MLLOG {"namespace": "", "time_ms": 1621444965739, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2240}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444966506, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8911268711090088, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1621444966507, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1621444966525, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4223.730580104064, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444966526, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444966526, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4223.730580104064, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2240}}
rank 0: cycle = 161: time to send the model = 0.03982424736022949
:::MLLOG {"namespace": "", "time_ms": 1621444966568, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2254, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444966568, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2254, "epoch_count": 14}}
rank 640: cycle = 161: time to receive the model = 0.05116748809814453
:::MLLOG {"namespace": "", "time_ms": 1621444966579, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2254, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2254}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444967345, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9073041677474976, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2254}}
:::MLLOG {"namespace": "", "time_ms": 1621444967346, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2254}}
:::MLLOG {"namespace": "", "time_ms": 1621444967365, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4213.421144448547, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444967368, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444967369, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4213.421144448547, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2254}}
rank 0: cycle = 162: time to send the model = 0.0503697395324707
:::MLLOG {"namespace": "", "time_ms": 1621444967420, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2268, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444967420, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2268, "epoch_count": 14}}
rank 640: cycle = 162: time to receive the model = 0.060819149017333984
:::MLLOG {"namespace": "", "time_ms": 1621444967430, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2268, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2268}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444968194, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4342.5209609659205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444968196, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444968196, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4342.5209609659205, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2268}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444968198, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8931576013565063, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2268}}
:::MLLOG {"namespace": "", "time_ms": 1621444968200, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2268}}
rank 0: cycle = 163: time to send the model = 0.039079904556274414
:::MLLOG {"namespace": "", "time_ms": 1621444968250, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2282, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444968251, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2282, "epoch_count": 14}}
rank 640: cycle = 163: time to receive the model = 0.05142664909362793
:::MLLOG {"namespace": "", "time_ms": 1621444968262, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2282, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2282}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444969028, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8969524502754211, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2282}}
:::MLLOG {"namespace": "", "time_ms": 1621444969029, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2282}}
:::MLLOG {"namespace": "", "time_ms": 1621444969051, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4199.973964852551, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444969054, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444969055, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4199.973964852551, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2282}}
rank 0: cycle = 164: time to send the model = 0.04726219177246094
:::MLLOG {"namespace": "", "time_ms": 1621444969102, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2296, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444969103, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2296, "epoch_count": 14}}
rank 640: cycle = 164: time to receive the model = 0.058783531188964844
:::MLLOG {"namespace": "", "time_ms": 1621444969114, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2296, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2296}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444969856, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4458.923880520041, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444969858, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444969858, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4458.923880520041, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2296}}
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621444969878, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.894939124584198, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2296}}
:::MLLOG {"namespace": "", "time_ms": 1621444969879, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2296}}
rank 0: cycle = 165: time to send the model = 0.036823272705078125
:::MLLOG {"namespace": "", "time_ms": 1621444969916, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2310, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444969918, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2310, "epoch_count": 14}}
rank 640: cycle = 165: time to receive the model = 0.05074286460876465
:::MLLOG {"namespace": "", "time_ms": 1621444969930, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2310, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2310}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444970695, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9024335145950317, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2310}}
:::MLLOG {"namespace": "", "time_ms": 1621444970696, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2310}}
:::MLLOG {"namespace": "", "time_ms": 1621444970708, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4252.4101472260245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444970711, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444970712, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4252.4101472260245, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2310}}
rank 0: cycle = 166: time to send the model = 0.04971909523010254
:::MLLOG {"namespace": "", "time_ms": 1621444970762, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2324, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444970763, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2324, "epoch_count": 14}}
rank 640: cycle = 166: time to receive the model = 0.06160330772399902
:::MLLOG {"namespace": "", "time_ms": 1621444970774, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2324, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2324}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444971540, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9025061130523682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2324}}
:::MLLOG {"namespace": "", "time_ms": 1621444971540, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2324}}
:::MLLOG {"namespace": "", "time_ms": 1621444971545, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4294.115343515847, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444971547, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444971547, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4294.115343515847, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2324}}
rank 0: cycle = 167: time to send the model = 0.03976106643676758
:::MLLOG {"namespace": "", "time_ms": 1621444971589, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2338, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444971589, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2338, "epoch_count": 14}}
rank 640: cycle = 167: time to receive the model = 0.05207967758178711
:::MLLOG {"namespace": "", "time_ms": 1621444971601, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2338, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2338}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444972366, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8971211314201355, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2338}}
:::MLLOG {"namespace": "", "time_ms": 1621444972367, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2338}}
:::MLLOG {"namespace": "", "time_ms": 1621444972434, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3973.9194177204768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444972438, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444972439, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3973.9194177204768, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2338}}
rank 0: cycle = 168: time to send the model = 0.04043126106262207
:::MLLOG {"namespace": "", "time_ms": 1621444972480, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2352, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444972480, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2352, "epoch_count": 14}}
rank 640: cycle = 168: time to receive the model = 0.05403733253479004
:::MLLOG {"namespace": "", "time_ms": 1621444972493, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2352}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444973249, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4369.062603178382, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444973251, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444973251, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4369.062603178382, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2352}}
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444973259, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8916195631027222, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2352}}
:::MLLOG {"namespace": "", "time_ms": 1621444973261, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2352}}
rank 0: cycle = 169: time to send the model = 0.03685355186462402
:::MLLOG {"namespace": "", "time_ms": 1621444973298, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2366, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444973299, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2366, "epoch_count": 14}}
rank 640: cycle = 169: time to receive the model = 0.05280923843383789
:::MLLOG {"namespace": "", "time_ms": 1621444973314, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2366, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2366}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444974074, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4333.365037244305, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
EVALUATION TIME: 0.761 s.
:::MLLOG {"namespace": "", "time_ms": 1621444974076, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8662850856781006, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2366}}
:::MLLOG {"namespace": "", "time_ms": 1621444974077, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444974078, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2366}}
:::MLLOG {"namespace": "", "time_ms": 1621444974079, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4333.365037244305, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2366}}
rank 0: cycle = 170: time to send the model = 0.05077171325683594
:::MLLOG {"namespace": "", "time_ms": 1621444974131, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2380, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444974131, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2380, "epoch_count": 14}}
rank 640: cycle = 170: time to receive the model = 0.059696197509765625
:::MLLOG {"namespace": "", "time_ms": 1621444974140, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2380}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444974907, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8933883905410767, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1621444974907, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1621444974913, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4299.830281195738, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444974914, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444974914, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4299.830281195738, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2380}}
rank 0: cycle = 171: time to send the model = 0.04044461250305176
:::MLLOG {"namespace": "", "time_ms": 1621444974956, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2394, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444974956, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2394, "epoch_count": 14}}
rank 640: cycle = 171: time to receive the model = 0.052301883697509766
:::MLLOG {"namespace": "", "time_ms": 1621444974968, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2394, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2394}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444975735, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8881533145904541, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2394}}
:::MLLOG {"namespace": "", "time_ms": 1621444975735, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2394}}
:::MLLOG {"namespace": "", "time_ms": 1621444975772, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4120.345032951682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444975775, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444975776, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4120.345032951682, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2394}}
rank 0: cycle = 172: time to send the model = 0.04125475883483887
:::MLLOG {"namespace": "", "time_ms": 1621444975817, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2408, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444975818, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2408, "epoch_count": 14}}
rank 640: cycle = 172: time to receive the model = 0.05392289161682129
:::MLLOG {"namespace": "", "time_ms": 1621444975830, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2408, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2408}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444976596, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8914018869400024, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2408}}
:::MLLOG {"namespace": "", "time_ms": 1621444976596, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2408}}
:::MLLOG {"namespace": "", "time_ms": 1621444976596, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4316.010353871616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444976598, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444976598, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4316.010353871616, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2408}}
rank 0: cycle = 173: time to send the model = 0.03999519348144531
:::MLLOG {"namespace": "", "time_ms": 1621444976640, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2422, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444976640, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2422, "epoch_count": 14}}
rank 640: cycle = 173: time to receive the model = 0.050830841064453125
:::MLLOG {"namespace": "", "time_ms": 1621444976651, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2422, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2422}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444977419, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8859666585922241, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2422}}
:::MLLOG {"namespace": "", "time_ms": 1621444977419, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2422}}
:::MLLOG {"namespace": "", "time_ms": 1621444977435, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4231.751219947229, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444977437, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444977438, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4231.751219947229, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2422}}
rank 0: cycle = 174: time to send the model = 0.042005300521850586
:::MLLOG {"namespace": "", "time_ms": 1621444977481, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2436, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444977481, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2436, "epoch_count": 14}}
rank 640: cycle = 174: time to receive the model = 0.05084729194641113
:::MLLOG {"namespace": "", "time_ms": 1621444977490, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2436, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2436}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444978259, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8892059326171875, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2436}}
:::MLLOG {"namespace": "", "time_ms": 1621444978259, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2436}}
:::MLLOG {"namespace": "", "time_ms": 1621444978300, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4103.494640625491, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444978302, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444978302, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4103.494640625491, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2436}}
rank 0: cycle = 175: time to send the model = 0.037758827209472656
:::MLLOG {"namespace": "", "time_ms": 1621444978340, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2450, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444978340, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2450, "epoch_count": 14}}
rank 640: cycle = 175: time to receive the model = 0.05054950714111328
:::MLLOG {"namespace": "", "time_ms": 1621444978352, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2450, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2450}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444979112, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4350.678521736473, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444979115, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444979116, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4350.678521736473, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2450}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444979118, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8828493356704712, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2450}}
:::MLLOG {"namespace": "", "time_ms": 1621444979120, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2450}}
rank 0: cycle = 176: time to send the model = 0.03727269172668457
:::MLLOG {"namespace": "", "time_ms": 1621444979167, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2464, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444979169, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2464, "epoch_count": 14}}
rank 640: cycle = 176: time to receive the model = 0.05164790153503418
:::MLLOG {"namespace": "", "time_ms": 1621444979182, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2464, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2464}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444979931, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4409.586302707168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444979932, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444979932, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4409.586302707168, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2464}}
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621444979946, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8746549487113953, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2464}}
:::MLLOG {"namespace": "", "time_ms": 1621444979947, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2464}}
rank 0: cycle = 177: time to send the model = 0.038176536560058594
:::MLLOG {"namespace": "", "time_ms": 1621444979986, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2478, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444979987, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2478, "epoch_count": 14}}
rank 640: cycle = 177: time to receive the model = 0.051009416580200195
:::MLLOG {"namespace": "", "time_ms": 1621444979999, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2478, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2478}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621444980763, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8812270164489746, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2478}}
:::MLLOG {"namespace": "", "time_ms": 1621444980763, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2478}}
:::MLLOG {"namespace": "", "time_ms": 1621444980769, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4295.72923563128, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444980771, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444980772, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4295.72923563128, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2478}}
rank 0: cycle = 178: time to send the model = 0.04949522018432617
:::MLLOG {"namespace": "", "time_ms": 1621444980822, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2492, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444980822, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2492, "epoch_count": 14}}
rank 640: cycle = 178: time to receive the model = 0.05865478515625
:::MLLOG {"namespace": "", "time_ms": 1621444980831, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2492, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2492}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444981597, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8935439586639404, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2492}}
:::MLLOG {"namespace": "", "time_ms": 1621444981597, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4334.900565145186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444981597, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2492}}
:::MLLOG {"namespace": "", "time_ms": 1621444981599, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444981599, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4334.900565145186, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2492}}
rank 0: cycle = 179: time to send the model = 0.04022932052612305
:::MLLOG {"namespace": "", "time_ms": 1621444981642, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2506, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444981642, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2506, "epoch_count": 14}}
rank 640: cycle = 179: time to receive the model = 0.052565813064575195
:::MLLOG {"namespace": "", "time_ms": 1621444981654, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2506, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2506}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444982422, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.895746648311615, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2506}}
:::MLLOG {"namespace": "", "time_ms": 1621444982422, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2506}}
:::MLLOG {"namespace": "", "time_ms": 1621444982422, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4308.429949645322, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444982424, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444982424, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4308.429949645322, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2506}}
rank 0: cycle = 180: time to send the model = 0.048499345779418945
:::MLLOG {"namespace": "", "time_ms": 1621444982473, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2520, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444982473, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2520, "epoch_count": 14}}
rank 640: cycle = 180: time to receive the model = 0.05906033515930176
:::MLLOG {"namespace": "", "time_ms": 1621444982484, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2520}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444983251, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8975622653961182, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2520}}
:::MLLOG {"namespace": "", "time_ms": 1621444983251, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2520}}
:::MLLOG {"namespace": "", "time_ms": 1621444983271, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4213.1175762243065, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444983272, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444983273, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4213.1175762243065, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2520}}
rank 0: cycle = 181: time to send the model = 0.03950166702270508
:::MLLOG {"namespace": "", "time_ms": 1621444983315, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2534, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444983315, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2534, "epoch_count": 14}}
rank 640: cycle = 181: time to receive the model = 0.05136394500732422
:::MLLOG {"namespace": "", "time_ms": 1621444983327, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2534, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2534}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444984093, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8999395370483398, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2534}}
:::MLLOG {"namespace": "", "time_ms": 1621444984093, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2534}}
:::MLLOG {"namespace": "", "time_ms": 1621444984133, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4107.204374843716, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444984135, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444984135, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4107.204374843716, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2534}}
rank 0: cycle = 182: time to send the model = 0.045151710510253906
:::MLLOG {"namespace": "", "time_ms": 1621444984193, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2548, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444984193, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2548, "epoch_count": 14}}
rank 640: cycle = 182: time to receive the model = 0.05798172950744629
:::MLLOG {"namespace": "", "time_ms": 1621444984206, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2548, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2548}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444984965, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4356.045526115203, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444984967, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444984967, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4356.045526115203, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2548}}
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621444984971, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8880608081817627, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2548}}
:::MLLOG {"namespace": "", "time_ms": 1621444984972, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2548}}
rank 0: cycle = 183: time to send the model = 0.03878641128540039
:::MLLOG {"namespace": "", "time_ms": 1621444985011, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2562, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444985012, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2562, "epoch_count": 14}}
rank 640: cycle = 183: time to receive the model = 0.05126786231994629
:::MLLOG {"namespace": "", "time_ms": 1621444985024, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2562}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.762 s.
:::MLLOG {"namespace": "", "time_ms": 1621444985787, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8885339498519897, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2562}}
:::MLLOG {"namespace": "", "time_ms": 1621444985787, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2562}}
:::MLLOG {"namespace": "", "time_ms": 1621444985797, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4283.398692810458, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444985799, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444985800, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4283.398692810458, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2562}}
rank 0: cycle = 184: time to send the model = 0.04629707336425781
:::MLLOG {"namespace": "", "time_ms": 1621444985847, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2576, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444985847, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2576, "epoch_count": 14}}
rank 640: cycle = 184: time to receive the model = 0.05912446975708008
:::MLLOG {"namespace": "", "time_ms": 1621444985859, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2576}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621444986624, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8972369432449341, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2576}}
:::MLLOG {"namespace": "", "time_ms": 1621444986624, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2576}}
:::MLLOG {"namespace": "", "time_ms": 1621444986629, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4294.697670790039, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444986631, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444986631, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4294.697670790039, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2576}}
rank 0: cycle = 185: time to send the model = 0.04608011245727539
:::MLLOG {"namespace": "", "time_ms": 1621444986680, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2590, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444986681, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2590, "epoch_count": 14}}
rank 640: cycle = 185: time to receive the model = 0.06176948547363281
:::MLLOG {"namespace": "", "time_ms": 1621444986696, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2590, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2590}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444987463, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9004445672035217, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2590}}
:::MLLOG {"namespace": "", "time_ms": 1621444987463, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2590}}
:::MLLOG {"namespace": "", "time_ms": 1621444987467, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4275.1060490327, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444987469, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444987470, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4275.1060490327, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2590}}
rank 0: cycle = 186: time to send the model = 0.04953169822692871
:::MLLOG {"namespace": "", "time_ms": 1621444987520, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2604, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444987520, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2604, "epoch_count": 14}}
rank 640: cycle = 186: time to receive the model = 0.05789804458618164
:::MLLOG {"namespace": "", "time_ms": 1621444987528, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2604, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2604}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444988291, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4356.605715423333, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444988293, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444988293, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4356.605715423333, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2604}}
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621444988297, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.899938702583313, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2604}}
:::MLLOG {"namespace": "", "time_ms": 1621444988298, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2604}}
rank 0: cycle = 187: time to send the model = 0.03760671615600586
:::MLLOG {"namespace": "", "time_ms": 1621444988336, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2618, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444988337, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2618, "epoch_count": 14}}
rank 640: cycle = 187: time to receive the model = 0.051473140716552734
:::MLLOG {"namespace": "", "time_ms": 1621444988350, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2618, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2618}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.762 s.
:::MLLOG {"namespace": "", "time_ms": 1621444989114, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9009609818458557, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2618}}
:::MLLOG {"namespace": "", "time_ms": 1621444989114, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2618}}
:::MLLOG {"namespace": "", "time_ms": 1621444989150, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4134.427401258148, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444989153, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444989153, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4134.427401258148, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2618}}
rank 0: cycle = 188: time to send the model = 0.04792141914367676
:::MLLOG {"namespace": "", "time_ms": 1621444989202, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2632, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444989202, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2632, "epoch_count": 14}}
rank 640: cycle = 188: time to receive the model = 0.05933046340942383
:::MLLOG {"namespace": "", "time_ms": 1621444989213, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2632, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2632}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.762 s.
:::MLLOG {"namespace": "", "time_ms": 1621444989977, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8924821615219116, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2632}}
:::MLLOG {"namespace": "", "time_ms": 1621444989977, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2632}}
:::MLLOG {"namespace": "", "time_ms": 1621444989990, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4265.894856902081, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444989991, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444989991, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4265.894856902081, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2632}}
rank 0: cycle = 189: time to send the model = 0.0399477481842041
:::MLLOG {"namespace": "", "time_ms": 1621444990034, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2646, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444990035, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2646, "epoch_count": 14}}
rank 640: cycle = 189: time to receive the model = 0.051268577575683594
:::MLLOG {"namespace": "", "time_ms": 1621444990046, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2646, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2646}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444990811, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8919129371643066, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2646}}
:::MLLOG {"namespace": "", "time_ms": 1621444990811, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2646}}
:::MLLOG {"namespace": "", "time_ms": 1621444990856, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4093.7119930702793, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444990858, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444990858, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4093.7119930702793, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2646}}
rank 0: cycle = 190: time to send the model = 0.04948997497558594
:::MLLOG {"namespace": "", "time_ms": 1621444990908, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2660, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444990908, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2660, "epoch_count": 14}}
rank 640: cycle = 190: time to receive the model = 0.06157636642456055
:::MLLOG {"namespace": "", "time_ms": 1621444990920, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2660}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444991686, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9002399444580078, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2660}}
:::MLLOG {"namespace": "", "time_ms": 1621444991686, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2660}}
:::MLLOG {"namespace": "", "time_ms": 1621444991700, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4244.5948695707175, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444991701, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444991702, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4244.5948695707175, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2660}}
rank 0: cycle = 191: time to send the model = 0.03974270820617676
:::MLLOG {"namespace": "", "time_ms": 1621444991744, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2674, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444991744, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2674, "epoch_count": 14}}
rank 640: cycle = 191: time to receive the model = 0.05049633979797363
:::MLLOG {"namespace": "", "time_ms": 1621444991755, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2674, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2674}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444992514, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4363.016390032052, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444992516, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444992516, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4363.016390032052, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2674}}
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621444992519, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9056013822555542, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2674}}
:::MLLOG {"namespace": "", "time_ms": 1621444992520, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2674}}
rank 0: cycle = 192: time to send the model = 0.045851945877075195
:::MLLOG {"namespace": "", "time_ms": 1621444992566, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2688, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444992567, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2688, "epoch_count": 14}}
rank 640: cycle = 192: time to receive the model = 0.05845999717712402
:::MLLOG {"namespace": "", "time_ms": 1621444992579, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2688, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2688}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444993345, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8972853422164917, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2688}}
:::MLLOG {"namespace": "", "time_ms": 1621444993346, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2688}}
:::MLLOG {"namespace": "", "time_ms": 1621444993348, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4306.744642950459, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444993349, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444993349, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4306.744642950459, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2688}}
rank 0: cycle = 193: time to send the model = 0.038057565689086914
:::MLLOG {"namespace": "", "time_ms": 1621444993389, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2702, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444993389, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2702, "epoch_count": 14}}
rank 640: cycle = 193: time to receive the model = 0.05090904235839844
:::MLLOG {"namespace": "", "time_ms": 1621444993402, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2702}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621444994155, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4387.490699879049, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444994157, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444994158, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4387.490699879049, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2702}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621444994169, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9016772508621216, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2702}}
:::MLLOG {"namespace": "", "time_ms": 1621444994170, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2702}}
rank 0: cycle = 194: time to send the model = 0.04426264762878418
:::MLLOG {"namespace": "", "time_ms": 1621444994215, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2716, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444994216, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2716, "epoch_count": 14}}
rank 640: cycle = 194: time to receive the model = 0.057540178298950195
:::MLLOG {"namespace": "", "time_ms": 1621444994228, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2716, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2716}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444994994, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.896888017654419, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2716}}
:::MLLOG {"namespace": "", "time_ms": 1621444994994, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2716}}
:::MLLOG {"namespace": "", "time_ms": 1621444995022, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4167.245430488994, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444995024, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444995024, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4167.245430488994, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2716}}
rank 0: cycle = 195: time to send the model = 0.04031181335449219
:::MLLOG {"namespace": "", "time_ms": 1621444995065, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2730, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444995065, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2730, "epoch_count": 14}}
rank 640: cycle = 195: time to receive the model = 0.05147576332092285
:::MLLOG {"namespace": "", "time_ms": 1621444995076, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2730, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2730}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444995842, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8870275616645813, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2730}}
:::MLLOG {"namespace": "", "time_ms": 1621444995842, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2730}}
:::MLLOG {"namespace": "", "time_ms": 1621444995850, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4283.43254249281, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444995852, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444995852, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4283.43254249281, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2730}}
rank 0: cycle = 196: time to send the model = 0.04819464683532715
:::MLLOG {"namespace": "", "time_ms": 1621444995903, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2744, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444995903, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2744, "epoch_count": 14}}
rank 640: cycle = 196: time to receive the model = 0.05932950973510742
:::MLLOG {"namespace": "", "time_ms": 1621444995914, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2744, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2744}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621444996681, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8693532943725586, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2744}}
:::MLLOG {"namespace": "", "time_ms": 1621444996681, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2744}}
:::MLLOG {"namespace": "", "time_ms": 1621444996683, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4309.300769095285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444996685, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444996685, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4309.300769095285, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2744}}
rank 0: cycle = 197: time to send the model = 0.03992724418640137
:::MLLOG {"namespace": "", "time_ms": 1621444996728, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2758, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444996729, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2758, "epoch_count": 14}}
rank 640: cycle = 197: time to receive the model = 0.05148720741271973
:::MLLOG {"namespace": "", "time_ms": 1621444996740, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2758, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2758}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444997505, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8959614038467407, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2758}}
:::MLLOG {"namespace": "", "time_ms": 1621444997506, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2758}}
:::MLLOG {"namespace": "", "time_ms": 1621444997510, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4299.097049569598, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444997512, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444997513, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4299.097049569598, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2758}}
rank 0: cycle = 198: time to send the model = 0.049955129623413086
:::MLLOG {"namespace": "", "time_ms": 1621444997563, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2772, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444997563, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2772, "epoch_count": 14}}
rank 640: cycle = 198: time to receive the model = 0.05940747261047363
:::MLLOG {"namespace": "", "time_ms": 1621444997572, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2772, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2772}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621444998341, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9005454778671265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2772}}
:::MLLOG {"namespace": "", "time_ms": 1621444998341, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2772}}
:::MLLOG {"namespace": "", "time_ms": 1621444998353, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4253.090315606366, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444998355, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444998355, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4253.090315606366, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2772}}
rank 0: cycle = 199: time to send the model = 0.03927731513977051
:::MLLOG {"namespace": "", "time_ms": 1621444998395, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2786, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444998395, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2786, "epoch_count": 14}}
rank 640: cycle = 199: time to receive the model = 0.051273345947265625
:::MLLOG {"namespace": "", "time_ms": 1621444998407, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2786, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2786}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621444999171, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.905184268951416, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2786}}
:::MLLOG {"namespace": "", "time_ms": 1621444999172, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2786}}
:::MLLOG {"namespace": "", "time_ms": 1621444999194, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4204.492386013966, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444999196, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444999196, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4204.492386013966, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2786}}
rank 0: cycle = 200: time to send the model = 0.04767298698425293
:::MLLOG {"namespace": "", "time_ms": 1621444999244, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2800, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444999245, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2800, "epoch_count": 14}}
rank 640: cycle = 200: time to receive the model = 0.058691978454589844
:::MLLOG {"namespace": "", "time_ms": 1621444999255, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2800}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.762 s.
:::MLLOG {"namespace": "", "time_ms": 1621445000019, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8903477191925049, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2800}}
:::MLLOG {"namespace": "", "time_ms": 1621445000019, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2800}}
:::MLLOG {"namespace": "", "time_ms": 1621445000062, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4110.166686061314, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445000064, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445000064, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4110.166686061314, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2800}}
rank 0: cycle = 201: time to send the model = 0.03933453559875488
:::MLLOG {"namespace": "", "time_ms": 1621445000103, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2814, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445000103, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2814, "epoch_count": 14}}
rank 640: cycle = 201: time to receive the model = 0.05119776725769043
:::MLLOG {"namespace": "", "time_ms": 1621445000115, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2814, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2814}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.762 s.
:::MLLOG {"namespace": "", "time_ms": 1621445000878, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.898306131362915, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2814}}
:::MLLOG {"namespace": "", "time_ms": 1621445000879, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2814}}
:::MLLOG {"namespace": "", "time_ms": 1621445000884, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4305.959056168982, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445000886, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445000886, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4305.959056168982, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2814}}
rank 0: cycle = 202: time to send the model = 0.04923605918884277
:::MLLOG {"namespace": "", "time_ms": 1621445000936, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2828, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445000936, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2828, "epoch_count": 14}}
rank 640: cycle = 202: time to receive the model = 0.06159543991088867
:::MLLOG {"namespace": "", "time_ms": 1621445000948, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2828, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2828}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445001702, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4389.3546404808185, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445001703, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445001703, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4389.3546404808185, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2828}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445001716, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9020859003067017, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2828}}
:::MLLOG {"namespace": "", "time_ms": 1621445001717, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2828}}
rank 0: cycle = 203: time to send the model = 0.03839564323425293
:::MLLOG {"namespace": "", "time_ms": 1621445001756, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2842, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445001757, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2842, "epoch_count": 14}}
rank 640: cycle = 203: time to receive the model = 0.05044436454772949
:::MLLOG {"namespace": "", "time_ms": 1621445001768, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2842, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2842}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445002524, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4380.820019981685, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445002525, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445002526, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4380.820019981685, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2842}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445002533, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9051269888877869, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2842}}
:::MLLOG {"namespace": "", "time_ms": 1621445002534, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2842}}
rank 0: cycle = 204: time to send the model = 0.04541969299316406
:::MLLOG {"namespace": "", "time_ms": 1621445002580, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2856, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445002581, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2856, "epoch_count": 14}}
rank 640: cycle = 204: time to receive the model = 0.056768178939819336
:::MLLOG {"namespace": "", "time_ms": 1621445002592, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2856, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2856}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445003358, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8996647596359253, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2856}}
:::MLLOG {"namespace": "", "time_ms": 1621445003359, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2856}}
:::MLLOG {"namespace": "", "time_ms": 1621445003368, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4274.770187514806, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445003369, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445003369, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4274.770187514806, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2856}}
rank 0: cycle = 205: time to send the model = 0.03891158103942871
:::MLLOG {"namespace": "", "time_ms": 1621445003408, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2870, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445003408, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2870, "epoch_count": 14}}
rank 640: cycle = 205: time to receive the model = 0.0518033504486084
:::MLLOG {"namespace": "", "time_ms": 1621445003421, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2870, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2870}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445004184, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4334.464588555523, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445004186, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445004186, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4334.464588555523, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2870}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445004188, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9075791239738464, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2870}}
:::MLLOG {"namespace": "", "time_ms": 1621445004190, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2870}}
rank 0: cycle = 206: time to send the model = 0.042525529861450195
:::MLLOG {"namespace": "", "time_ms": 1621445004233, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2884, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445004234, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2884, "epoch_count": 14}}
rank 640: cycle = 206: time to receive the model = 0.050823211669921875
:::MLLOG {"namespace": "", "time_ms": 1621445004241, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2884, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2884}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445005008, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.898360013961792, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2884}}
:::MLLOG {"namespace": "", "time_ms": 1621445005009, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2884}}
:::MLLOG {"namespace": "", "time_ms": 1621445005026, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4244.991216549995, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445005027, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445005027, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4244.991216549995, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2884}}
rank 0: cycle = 207: time to send the model = 0.03888869285583496
:::MLLOG {"namespace": "", "time_ms": 1621445005066, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2898, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445005067, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2898, "epoch_count": 14}}
rank 640: cycle = 207: time to receive the model = 0.05031585693359375
:::MLLOG {"namespace": "", "time_ms": 1621445005078, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2898, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2898}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445005845, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.890720784664154, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2898}}
:::MLLOG {"namespace": "", "time_ms": 1621445005845, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2898}}
:::MLLOG {"namespace": "", "time_ms": 1621445005886, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4099.377783207599, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445005889, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445005889, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4099.377783207599, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2898}}
rank 0: cycle = 208: time to send the model = 0.0452272891998291
:::MLLOG {"namespace": "", "time_ms": 1621445005935, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2912, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445005935, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2912, "epoch_count": 14}}
rank 640: cycle = 208: time to receive the model = 0.05788087844848633
:::MLLOG {"namespace": "", "time_ms": 1621445005948, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2912, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2912}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445006701, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4389.003322383296, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445006703, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445006703, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4389.003322383296, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2912}}
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445006712, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8991568088531494, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2912}}
:::MLLOG {"namespace": "", "time_ms": 1621445006713, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2912}}
rank 0: cycle = 209: time to send the model = 0.03697562217712402
:::MLLOG {"namespace": "", "time_ms": 1621445006750, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2926, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445006751, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2926, "epoch_count": 14}}
rank 640: cycle = 209: time to receive the model = 0.0505366325378418
:::MLLOG {"namespace": "", "time_ms": 1621445006764, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2926, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2926}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445007530, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8911824226379395, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2926}}
:::MLLOG {"namespace": "", "time_ms": 1621445007530, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2926}}
:::MLLOG {"namespace": "", "time_ms": 1621445007541, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4254.044201079746, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445007544, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445007545, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4254.044201079746, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2926}}
rank 0: cycle = 210: time to send the model = 0.04838275909423828
:::MLLOG {"namespace": "", "time_ms": 1621445007594, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2940, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445007594, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2940, "epoch_count": 14}}
rank 640: cycle = 210: time to receive the model = 0.06050443649291992
:::MLLOG {"namespace": "", "time_ms": 1621445007606, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2940}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445008373, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8922891616821289, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2940}}
:::MLLOG {"namespace": "", "time_ms": 1621445008373, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2940}}
:::MLLOG {"namespace": "", "time_ms": 1621445008378, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4287.576657196768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445008379, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445008380, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4287.576657196768, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2940}}
rank 0: cycle = 211: time to send the model = 0.037908077239990234
:::MLLOG {"namespace": "", "time_ms": 1621445008420, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2954, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445008420, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2954, "epoch_count": 14}}
rank 640: cycle = 211: time to receive the model = 0.05070233345031738
:::MLLOG {"namespace": "", "time_ms": 1621445008433, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2954, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2954}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445009198, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8982952833175659, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2954}}
:::MLLOG {"namespace": "", "time_ms": 1621445009199, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2954}}
:::MLLOG {"namespace": "", "time_ms": 1621445009210, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4252.770737704399, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445009213, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445009214, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4252.770737704399, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2954}}
rank 0: cycle = 212: time to send the model = 0.04300093650817871
:::MLLOG {"namespace": "", "time_ms": 1621445009257, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2968, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445009258, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2968, "epoch_count": 14}}
rank 640: cycle = 212: time to receive the model = 0.05603384971618652
:::MLLOG {"namespace": "", "time_ms": 1621445009270, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2968, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2968}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445010012, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4453.37089963843, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445010014, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445010014, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4453.37089963843, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2968}}
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445010037, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.893024206161499, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2968}}
:::MLLOG {"namespace": "", "time_ms": 1621445010038, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2968}}
rank 0: cycle = 213: time to send the model = 0.03647279739379883
:::MLLOG {"namespace": "", "time_ms": 1621445010075, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2982, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445010076, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2982, "epoch_count": 14}}
rank 640: cycle = 213: time to receive the model = 0.05230975151062012
:::MLLOG {"namespace": "", "time_ms": 1621445010091, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2982, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2982}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445010855, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9007346630096436, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2982}}
:::MLLOG {"namespace": "", "time_ms": 1621445010855, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2982}}
:::MLLOG {"namespace": "", "time_ms": 1621445010892, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4118.838542162907, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445010894, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445010895, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4118.838542162907, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2982}}
rank 0: cycle = 214: time to send the model = 0.040497541427612305
:::MLLOG {"namespace": "", "time_ms": 1621445010936, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2996, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445010936, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2996, "epoch_count": 14}}
rank 640: cycle = 214: time to receive the model = 0.05136394500732422
:::MLLOG {"namespace": "", "time_ms": 1621445010947, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2996, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2996}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445011716, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8963298797607422, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2996}}
:::MLLOG {"namespace": "", "time_ms": 1621445011716, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2996}}
:::MLLOG {"namespace": "", "time_ms": 1621445011736, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4203.220832766655, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445011738, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445011738, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4203.220832766655, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2996}}
rank 0: cycle = 215: time to send the model = 0.03874993324279785
:::MLLOG {"namespace": "", "time_ms": 1621445011777, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3010, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445011778, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3010, "epoch_count": 14}}
rank 640: cycle = 215: time to receive the model = 0.051473379135131836
:::MLLOG {"namespace": "", "time_ms": 1621445011790, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3010, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3010}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445012556, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4315.768478012884, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445012557, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.904537558555603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3010}}
:::MLLOG {"namespace": "", "time_ms": 1621445012558, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445012559, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3010}}
:::MLLOG {"namespace": "", "time_ms": 1621445012560, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4315.768478012884, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3010}}
rank 0: cycle = 216: time to send the model = 0.04536318778991699
:::MLLOG {"namespace": "", "time_ms": 1621445012607, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3024, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445012608, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3024, "epoch_count": 14}}
rank 640: cycle = 216: time to receive the model = 0.05876803398132324
:::MLLOG {"namespace": "", "time_ms": 1621445012621, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3024, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3024}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445013386, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8993468880653381, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3024}}
:::MLLOG {"namespace": "", "time_ms": 1621445013387, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3024}}
:::MLLOG {"namespace": "", "time_ms": 1621445013389, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4302.682949020048, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445013390, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445013391, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4302.682949020048, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3024}}
rank 0: cycle = 217: time to send the model = 0.037489891052246094
:::MLLOG {"namespace": "", "time_ms": 1621445013428, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3038, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445013428, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3038, "epoch_count": 14}}
rank 640: cycle = 217: time to receive the model = 0.0506134033203125
:::MLLOG {"namespace": "", "time_ms": 1621445013441, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3038, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3038}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445014186, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4434.613878309827, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445014188, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445014189, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4434.613878309827, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3038}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445014206, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8967958092689514, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3038}}
:::MLLOG {"namespace": "", "time_ms": 1621445014208, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3038}}
rank 0: cycle = 218: time to send the model = 0.04010725021362305
:::MLLOG {"namespace": "", "time_ms": 1621445014248, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3052, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445014249, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3052, "epoch_count": 14}}
rank 640: cycle = 218: time to receive the model = 0.05366182327270508
:::MLLOG {"namespace": "", "time_ms": 1621445014262, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3052, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3052}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445015027, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8869435787200928, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3052}}
:::MLLOG {"namespace": "", "time_ms": 1621445015027, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3052}}
:::MLLOG {"namespace": "", "time_ms": 1621445015052, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4186.724284576465, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445015053, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445015054, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4186.724284576465, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3052}}
rank 0: cycle = 219: time to send the model = 0.038471221923828125
:::MLLOG {"namespace": "", "time_ms": 1621445015092, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3066, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445015093, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3066, "epoch_count": 14}}
rank 640: cycle = 219: time to receive the model = 0.05015158653259277
:::MLLOG {"namespace": "", "time_ms": 1621445015104, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3066, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3066}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445015871, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9065289497375488, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3066}}
:::MLLOG {"namespace": "", "time_ms": 1621445015871, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3066}}
:::MLLOG {"namespace": "", "time_ms": 1621445015885, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4239.118803277145, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445015887, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445015887, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4239.118803277145, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3066}}
rank 0: cycle = 220: time to send the model = 0.0462946891784668
:::MLLOG {"namespace": "", "time_ms": 1621445015934, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3080, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445015934, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3080, "epoch_count": 14}}
rank 640: cycle = 220: time to receive the model = 0.05910062789916992
:::MLLOG {"namespace": "", "time_ms": 1621445015947, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3080}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445016710, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4333.735490392223, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445016711, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445016711, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4333.735490392223, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3080}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445016714, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9047572612762451, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3080}}
:::MLLOG {"namespace": "", "time_ms": 1621445016715, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3080}}
rank 0: cycle = 221: time to send the model = 0.03896141052246094
:::MLLOG {"namespace": "", "time_ms": 1621445016754, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3094, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445016755, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3094, "epoch_count": 14}}
rank 640: cycle = 221: time to receive the model = 0.05170726776123047
:::MLLOG {"namespace": "", "time_ms": 1621445016767, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3094, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3094}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445017534, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8840709328651428, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3094}}
:::MLLOG {"namespace": "", "time_ms": 1621445017534, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3094}}
:::MLLOG {"namespace": "", "time_ms": 1621445017566, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4144.26569200625, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445017568, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445017568, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4144.26569200625, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3094}}
rank 0: cycle = 222: time to send the model = 0.0478367805480957
:::MLLOG {"namespace": "", "time_ms": 1621445017616, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3108, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445017616, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3108, "epoch_count": 14}}
rank 640: cycle = 222: time to receive the model = 0.05704927444458008
:::MLLOG {"namespace": "", "time_ms": 1621445017625, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3108, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3108}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445018394, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8952080011367798, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3108}}
:::MLLOG {"namespace": "", "time_ms": 1621445018395, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3108}}
:::MLLOG {"namespace": "", "time_ms": 1621445018438, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4090.436139458744, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445018439, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445018439, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4090.436139458744, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3108}}
rank 0: cycle = 223: time to send the model = 0.03789329528808594
:::MLLOG {"namespace": "", "time_ms": 1621445018478, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3122, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445018478, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3122, "epoch_count": 14}}
rank 640: cycle = 223: time to receive the model = 0.05074715614318848
:::MLLOG {"namespace": "", "time_ms": 1621445018491, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3122, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3122}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445019256, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.874294638633728, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3122}}
:::MLLOG {"namespace": "", "time_ms": 1621445019256, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3122}}
:::MLLOG {"namespace": "", "time_ms": 1621445019272, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4235.1148778316765, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445019273, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445019274, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4235.1148778316765, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3122}}
rank 0: cycle = 224: time to send the model = 0.047492265701293945
:::MLLOG {"namespace": "", "time_ms": 1621445019322, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3136, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445019322, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3136, "epoch_count": 14}}
rank 640: cycle = 224: time to receive the model = 0.05910301208496094
:::MLLOG {"namespace": "", "time_ms": 1621445019333, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3136, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3136}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445020099, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4323.403929479935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445020101, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.877354621887207, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3136}}
:::MLLOG {"namespace": "", "time_ms": 1621445020101, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445020101, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4323.403929479935, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3136}}
:::MLLOG {"namespace": "", "time_ms": 1621445020102, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3136}}
rank 0: cycle = 225: time to send the model = 0.03992462158203125
:::MLLOG {"namespace": "", "time_ms": 1621445020144, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3150, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445020145, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3150, "epoch_count": 14}}
rank 640: cycle = 225: time to receive the model = 0.05096793174743652
:::MLLOG {"namespace": "", "time_ms": 1621445020155, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3150, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3150}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445020917, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4355.75067664237, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445020918, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445020918, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4355.75067664237, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3150}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445020921, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8787909746170044, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3150}}
:::MLLOG {"namespace": "", "time_ms": 1621445020923, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3150}}
rank 0: cycle = 226: time to send the model = 0.04564046859741211
:::MLLOG {"namespace": "", "time_ms": 1621445020969, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3164, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445020970, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3164, "epoch_count": 14}}
rank 640: cycle = 226: time to receive the model = 0.05883073806762695
:::MLLOG {"namespace": "", "time_ms": 1621445020982, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3164, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3164}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445021748, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8709460496902466, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3164}}
:::MLLOG {"namespace": "", "time_ms": 1621445021748, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3164}}
:::MLLOG {"namespace": "", "time_ms": 1621445021754, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4286.418625984475, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445021755, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445021756, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4286.418625984475, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3164}}
rank 0: cycle = 227: time to send the model = 0.03862738609313965
:::MLLOG {"namespace": "", "time_ms": 1621445021797, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3178, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445021797, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3178, "epoch_count": 14}}
rank 640: cycle = 227: time to receive the model = 0.05097031593322754
:::MLLOG {"namespace": "", "time_ms": 1621445021809, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3178, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3178}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445022573, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8824102878570557, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3178}}
:::MLLOG {"namespace": "", "time_ms": 1621445022573, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3178}}
:::MLLOG {"namespace": "", "time_ms": 1621445022610, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4133.970181617218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445022612, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445022613, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4133.970181617218, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3178}}
rank 0: cycle = 228: time to send the model = 0.047223806381225586
:::MLLOG {"namespace": "", "time_ms": 1621445022660, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3192, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445022661, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3192, "epoch_count": 14}}
rank 640: cycle = 228: time to receive the model = 0.05891847610473633
:::MLLOG {"namespace": "", "time_ms": 1621445022672, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3192}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445023436, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8916429877281189, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3192}}
:::MLLOG {"namespace": "", "time_ms": 1621445023436, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3192}}
:::MLLOG {"namespace": "", "time_ms": 1621445023489, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4058.195037164252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445023490, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445023490, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4058.195037164252, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3192}}
rank 0: cycle = 229: time to send the model = 0.039922237396240234
:::MLLOG {"namespace": "", "time_ms": 1621445023533, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3206, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445023534, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3206, "epoch_count": 14}}
rank 640: cycle = 229: time to receive the model = 0.049710750579833984
:::MLLOG {"namespace": "", "time_ms": 1621445023543, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3206, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3206}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445024310, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4328.104251429919, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445024311, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8670259714126587, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3206}}
:::MLLOG {"namespace": "", "time_ms": 1621445024311, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445024312, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3206}}
:::MLLOG {"namespace": "", "time_ms": 1621445024313, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4328.104251429919, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3206}}
rank 0: cycle = 230: time to send the model = 0.042629241943359375
:::MLLOG {"namespace": "", "time_ms": 1621445024358, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3220, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445024359, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3220, "epoch_count": 14}}
rank 640: cycle = 230: time to receive the model = 0.05097484588623047
:::MLLOG {"namespace": "", "time_ms": 1621445024366, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3220}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445025134, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8800266981124878, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3220}}
:::MLLOG {"namespace": "", "time_ms": 1621445025134, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3220}}
:::MLLOG {"namespace": "", "time_ms": 1621445025149, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4250.811966456472, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445025151, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445025151, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4250.811966456472, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3220}}
rank 0: cycle = 231: time to send the model = 0.03898334503173828
:::MLLOG {"namespace": "", "time_ms": 1621445025190, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3234, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445025190, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3234, "epoch_count": 14}}
rank 640: cycle = 231: time to receive the model = 0.05129742622375488
:::MLLOG {"namespace": "", "time_ms": 1621445025202, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3234, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3234}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445025967, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9023061394691467, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3234}}
:::MLLOG {"namespace": "", "time_ms": 1621445025967, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3234}}
:::MLLOG {"namespace": "", "time_ms": 1621445025991, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4194.988182596448, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445025993, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445025993, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4194.988182596448, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3234}}
rank 0: cycle = 232: time to send the model = 0.047936201095581055
:::MLLOG {"namespace": "", "time_ms": 1621445026041, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3248, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445026042, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3248, "epoch_count": 14}}
rank 640: cycle = 232: time to receive the model = 0.059426069259643555
:::MLLOG {"namespace": "", "time_ms": 1621445026053, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3248, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3248}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445026820, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8995468020439148, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3248}}
:::MLLOG {"namespace": "", "time_ms": 1621445026821, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3248}}
:::MLLOG {"namespace": "", "time_ms": 1621445026822, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4305.977475357944, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445026824, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445026824, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4305.977475357944, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3248}}
rank 0: cycle = 233: time to send the model = 0.038904666900634766
:::MLLOG {"namespace": "", "time_ms": 1621445026865, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3262, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445026865, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3262, "epoch_count": 14}}
rank 640: cycle = 233: time to receive the model = 0.05093050003051758
:::MLLOG {"namespace": "", "time_ms": 1621445026877, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3262, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3262}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445027639, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4342.634701422055, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445027641, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445027641, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4342.634701422055, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3262}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445027642, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8996179103851318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3262}}
:::MLLOG {"namespace": "", "time_ms": 1621445027644, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3262}}
rank 0: cycle = 234: time to send the model = 0.04829597473144531
:::MLLOG {"namespace": "", "time_ms": 1621445027692, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3276, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445027694, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3276, "epoch_count": 14}}
rank 640: cycle = 234: time to receive the model = 0.05761408805847168
:::MLLOG {"namespace": "", "time_ms": 1621445027702, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3276, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3276}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445028470, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8947224617004395, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3276}}
:::MLLOG {"namespace": "", "time_ms": 1621445028470, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3276}}
:::MLLOG {"namespace": "", "time_ms": 1621445028485, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4248.154414530863, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445028486, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445028486, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4248.154414530863, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3276}}
rank 0: cycle = 235: time to send the model = 0.03857755661010742
:::MLLOG {"namespace": "", "time_ms": 1621445028542, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3290, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445028543, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3290, "epoch_count": 14}}
rank 640: cycle = 235: time to receive the model = 0.05063128471374512
:::MLLOG {"namespace": "", "time_ms": 1621445028555, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3290, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3290}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445029320, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9064446687698364, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3290}}
:::MLLOG {"namespace": "", "time_ms": 1621445029320, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3290}}
:::MLLOG {"namespace": "", "time_ms": 1621445029322, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4309.808140855934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445029324, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445029325, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4309.808140855934, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3290}}
rank 0: cycle = 236: time to send the model = 0.04750943183898926
:::MLLOG {"namespace": "", "time_ms": 1621445029373, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3304, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445029373, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3304, "epoch_count": 14}}
rank 640: cycle = 236: time to receive the model = 0.06333231925964355
:::MLLOG {"namespace": "", "time_ms": 1621445029388, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3304}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445030154, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8920223116874695, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3304}}
:::MLLOG {"namespace": "", "time_ms": 1621445030154, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3304}}
:::MLLOG {"namespace": "", "time_ms": 1621445030167, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4232.173132508592, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445030168, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445030169, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4232.173132508592, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3304}}
rank 0: cycle = 237: time to send the model = 0.038575172424316406
:::MLLOG {"namespace": "", "time_ms": 1621445030208, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3318, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445030208, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3318, "epoch_count": 14}}
rank 640: cycle = 237: time to receive the model = 0.050879716873168945
:::MLLOG {"namespace": "", "time_ms": 1621445030220, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3318}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.762 s.
:::MLLOG {"namespace": "", "time_ms": 1621445030983, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8975002765655518, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3318}}
:::MLLOG {"namespace": "", "time_ms": 1621445030984, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3318}}
:::MLLOG {"namespace": "", "time_ms": 1621445031000, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4242.839048111071, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445031003, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445031003, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4242.839048111071, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3318}}
rank 0: cycle = 238: time to send the model = 0.050332069396972656
:::MLLOG {"namespace": "", "time_ms": 1621445031054, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3332, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445031054, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3332, "epoch_count": 14}}
rank 640: cycle = 238: time to receive the model = 0.05966830253601074
:::MLLOG {"namespace": "", "time_ms": 1621445031063, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3332, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3332}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445031831, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8957237005233765, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3332}}
:::MLLOG {"namespace": "", "time_ms": 1621445031832, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3332}}
:::MLLOG {"namespace": "", "time_ms": 1621445031833, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4316.8022573915205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445031834, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445031834, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4316.8022573915205, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3332}}
rank 0: cycle = 239: time to send the model = 0.03900718688964844
:::MLLOG {"namespace": "", "time_ms": 1621445031875, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3346, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445031875, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3346, "epoch_count": 14}}
rank 640: cycle = 239: time to receive the model = 0.052323102951049805
:::MLLOG {"namespace": "", "time_ms": 1621445031888, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3346, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3346}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445032652, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8954068422317505, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3346}}
:::MLLOG {"namespace": "", "time_ms": 1621445032653, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3346}}
:::MLLOG {"namespace": "", "time_ms": 1621445032659, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4288.839728564568, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445032661, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445032661, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4288.839728564568, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3346}}
rank 0: cycle = 240: time to send the model = 0.03852486610412598
:::MLLOG {"namespace": "", "time_ms": 1621445032704, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3360, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445032704, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3360, "epoch_count": 14}}
rank 640: cycle = 240: time to receive the model = 0.051846981048583984
:::MLLOG {"namespace": "", "time_ms": 1621445032718, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3360}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445033482, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8891962766647339, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3360}}
:::MLLOG {"namespace": "", "time_ms": 1621445033482, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3360}}
:::MLLOG {"namespace": "", "time_ms": 1621445033501, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4219.206106038348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445033502, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445033502, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4219.206106038348, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3360}}
rank 0: cycle = 241: time to send the model = 0.038205623626708984
:::MLLOG {"namespace": "", "time_ms": 1621445033541, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3374, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445033541, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3374, "epoch_count": 14}}
rank 640: cycle = 241: time to receive the model = 0.05122637748718262
:::MLLOG {"namespace": "", "time_ms": 1621445033554, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3374, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3374}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445034319, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8952795267105103, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3374}}
:::MLLOG {"namespace": "", "time_ms": 1621445034319, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3374}}
:::MLLOG {"namespace": "", "time_ms": 1621445034330, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4261.1469379943055, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445034332, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445034333, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4261.1469379943055, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3374}}
rank 0: cycle = 242: time to send the model = 0.04729056358337402
:::MLLOG {"namespace": "", "time_ms": 1621445034380, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3388, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445034381, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3388, "epoch_count": 14}}
rank 640: cycle = 242: time to receive the model = 0.05594921112060547
:::MLLOG {"namespace": "", "time_ms": 1621445034389, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3388, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3388}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445035157, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8859140276908875, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3388}}
:::MLLOG {"namespace": "", "time_ms": 1621445035158, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3388}}
:::MLLOG {"namespace": "", "time_ms": 1621445035230, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3958.1908477346838, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445035231, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445035231, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3958.1908477346838, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3388}}
rank 0: cycle = 243: time to send the model = 0.03869128227233887
:::MLLOG {"namespace": "", "time_ms": 1621445035273, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3402, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445035273, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3402, "epoch_count": 14}}
rank 640: cycle = 243: time to receive the model = 0.050670623779296875
:::MLLOG {"namespace": "", "time_ms": 1621445035285, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3402, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3402}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445036041, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4374.477804575973, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445036044, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445036044, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4374.477804575973, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3402}}
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445036050, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8905697464942932, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3402}}
:::MLLOG {"namespace": "", "time_ms": 1621445036051, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3402}}
rank 0: cycle = 244: time to send the model = 0.042745351791381836
:::MLLOG {"namespace": "", "time_ms": 1621445036094, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3416, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445036095, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3416, "epoch_count": 14}}
rank 640: cycle = 244: time to receive the model = 0.05526900291442871
:::MLLOG {"namespace": "", "time_ms": 1621445036107, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3416, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3416}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445036871, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8880971074104309, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3416}}
:::MLLOG {"namespace": "", "time_ms": 1621445036872, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3416}}
:::MLLOG {"namespace": "", "time_ms": 1621445036876, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4306.874943844742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445036877, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445036877, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4306.874943844742, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3416}}
rank 0: cycle = 245: time to send the model = 0.039031028747558594
:::MLLOG {"namespace": "", "time_ms": 1621445036916, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3430, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445036917, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3430, "epoch_count": 14}}
rank 640: cycle = 245: time to receive the model = 0.05138230323791504
:::MLLOG {"namespace": "", "time_ms": 1621445036929, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3430, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3430}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445037693, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8954975605010986, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3430}}
:::MLLOG {"namespace": "", "time_ms": 1621445037693, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3430}}
:::MLLOG {"namespace": "", "time_ms": 1621445037704, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4267.012108405518, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445037707, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445037708, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4267.012108405518, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3430}}
rank 0: cycle = 246: time to send the model = 0.04770541191101074
:::MLLOG {"namespace": "", "time_ms": 1621445037756, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3444, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445037756, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3444, "epoch_count": 14}}
rank 640: cycle = 246: time to receive the model = 0.05642223358154297
:::MLLOG {"namespace": "", "time_ms": 1621445037764, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3444, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3444}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445038532, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8982186317443848, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3444}}
:::MLLOG {"namespace": "", "time_ms": 1621445038532, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3444}}
:::MLLOG {"namespace": "", "time_ms": 1621445038543, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4268.875926338221, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445038545, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445038545, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4268.875926338221, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3444}}
rank 0: cycle = 247: time to send the model = 0.03936266899108887
:::MLLOG {"namespace": "", "time_ms": 1621445038586, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3458, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445038586, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3458, "epoch_count": 14}}
rank 640: cycle = 247: time to receive the model = 0.05170583724975586
:::MLLOG {"namespace": "", "time_ms": 1621445038599, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3458, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3458}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445039364, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9000683426856995, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3458}}
:::MLLOG {"namespace": "", "time_ms": 1621445039365, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3458}}
:::MLLOG {"namespace": "", "time_ms": 1621445039374, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4268.533285679237, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445039376, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445039377, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4268.533285679237, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3458}}
rank 0: cycle = 248: time to send the model = 0.046039581298828125
:::MLLOG {"namespace": "", "time_ms": 1621445039424, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3472, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445039424, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3472, "epoch_count": 14}}
rank 640: cycle = 248: time to receive the model = 0.05873227119445801
:::MLLOG {"namespace": "", "time_ms": 1621445039437, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3472, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3472}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445040173, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4492.3013444841345, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445040174, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445040174, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4492.3013444841345, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3472}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445040202, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8813968896865845, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3472}}
:::MLLOG {"namespace": "", "time_ms": 1621445040203, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3472}}
rank 0: cycle = 249: time to send the model = 0.036634206771850586
:::MLLOG {"namespace": "", "time_ms": 1621445040240, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3486, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445040241, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3486, "epoch_count": 14}}
rank 640: cycle = 249: time to receive the model = 0.049930572509765625
:::MLLOG {"namespace": "", "time_ms": 1621445040253, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3486, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3486}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445041019, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.896050751209259, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3486}}
:::MLLOG {"namespace": "", "time_ms": 1621445041019, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3486}}
:::MLLOG {"namespace": "", "time_ms": 1621445041081, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3999.0662529745705, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445041084, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445041084, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3999.0662529745705, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3486}}
rank 0: cycle = 250: time to send the model = 0.04098176956176758
:::MLLOG {"namespace": "", "time_ms": 1621445041126, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3500, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445041126, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3500, "epoch_count": 14}}
rank 640: cycle = 250: time to receive the model = 0.052024126052856445
:::MLLOG {"namespace": "", "time_ms": 1621445041137, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3500}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.762 s.
:::MLLOG {"namespace": "", "time_ms": 1621445041900, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8971720933914185, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3500}}
:::MLLOG {"namespace": "", "time_ms": 1621445041901, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3500}}
:::MLLOG {"namespace": "", "time_ms": 1621445041906, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4309.487889709296, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445041907, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445041907, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4309.487889709296, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3500}}
rank 0: cycle = 251: time to send the model = 0.03982806205749512
:::MLLOG {"namespace": "", "time_ms": 1621445041950, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3514, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445041950, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3514, "epoch_count": 14}}
rank 640: cycle = 251: time to receive the model = 0.05098271369934082
:::MLLOG {"namespace": "", "time_ms": 1621445041961, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3514, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3514}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445042719, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4369.696598747029, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445042721, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445042721, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4369.696598747029, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3514}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445042726, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8988738059997559, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3514}}
:::MLLOG {"namespace": "", "time_ms": 1621445042728, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3514}}
rank 0: cycle = 252: time to send the model = 0.037026166915893555
:::MLLOG {"namespace": "", "time_ms": 1621445042765, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3528, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445042766, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3528, "epoch_count": 14}}
rank 640: cycle = 252: time to receive the model = 0.0515744686126709
:::MLLOG {"namespace": "", "time_ms": 1621445042780, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3528, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3528}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445043543, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4327.4384156132, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445043545, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445043545, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4327.4384156132, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3528}}
:::MLLOG {"namespace": "", "time_ms": 1621445043545, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.897809624671936, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3528}}
:::MLLOG {"namespace": "", "time_ms": 1621445043546, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3528}}
rank 0: cycle = 253: time to send the model = 0.03798699378967285
:::MLLOG {"namespace": "", "time_ms": 1621445043584, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 3542, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445043585, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 3542, "epoch_count": 14}}
rank 640: cycle = 253: time to receive the model = 0.05182242393493652
:::MLLOG {"namespace": "", "time_ms": 1621445043598, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3542, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 3542}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
:::MLLOG {"namespace": "", "time_ms": 1621445044363, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9101433753967285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 3542}}
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
:::MLLOG {"namespace": "", "time_ms": 1621445044363, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 3542}}
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
:::MLLOG {"namespace": "", "time_ms": 1621445044363, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 102, "status": "success"}}
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
:::MLLOG {"namespace": "", "time_ms": 1621445044370, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4283.493733660908, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445044372, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445044373, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4283.493733660908, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 3542}}
rank 0: cycle = 254: time to send the model = 0.0430598258972168
rank 640: cycle = 254: time to receive the model = 0.05620169639587402
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
+ set +x
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
+ ret_code=0
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:21 AM
RESULT,image_segmentation,,625,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:22 AM
RESULT,image_segmentation,,626,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:23 AM
RESULT,image_segmentation,,627,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:24 AM
RESULT,image_segmentation,,628,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
ENDING TIMING RUN AT 2021-05-19 10:24:25 AM
RESULT,image_segmentation,,629,nvidia,2021-05-19 10:13:56 AM
