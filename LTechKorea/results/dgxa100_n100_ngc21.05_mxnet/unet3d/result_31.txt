+ echo 'Beginning trial 9 of 10'
Beginning trial 9 of 10
+ '[' 1 -eq 1 ']'
+ srun --ntasks=100 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on luna-0241
Clearing cache on luna-0537
Clearing cache on luna-0142
Clearing cache on luna-0530
Clearing cache on luna-0544
Clearing cache on luna-0303
Clearing cache on luna-0315
Clearing cache on luna-0524
Clearing cache on luna-0250
Clearing cache on luna-0256
Clearing cache on luna-0312
Clearing cache on luna-0016
Clearing cache on luna-0521
Clearing cache on luna-0525
Clearing cache on luna-0008
Clearing cache on luna-0242
Clearing cache on luna-0542
Clearing cache on luna-0144
Clearing cache on luna-0548
Clearing cache on luna-0538
Clearing cache on luna-0522
Clearing cache on luna-0011
Clearing cache on luna-0004
Clearing cache on luna-0141
Clearing cache on luna-0018
Clearing cache on luna-0258
Clearing cache on luna-0526
Clearing cache on luna-0146
Clearing cache on luna-0539
Clearing cache on luna-0532
Clearing cache on luna-0529
Clearing cache on luna-0012
Clearing cache on luna-0005
Clearing cache on luna-0243
Clearing cache on luna-0318
Clearing cache on luna-0253
Clearing cache on luna-0545
Clearing cache on luna-0528
Clearing cache on luna-0245
Clearing cache on luna-0310
Clearing cache on luna-0313
Clearing cache on luna-0314
Clearing cache on luna-0543
Clearing cache on luna-0317
Clearing cache on luna-0523
Clearing cache on luna-0311
Clearing cache on luna-0249
Clearing cache on luna-0002
Clearing cache on luna-0308
Clearing cache on luna-0305
Clearing cache on luna-0009
Clearing cache on luna-0003
Clearing cache on luna-0547
Clearing cache on luna-0534
Clearing cache on luna-0006
Clearing cache on luna-0010
Clearing cache on luna-0247
Clearing cache on luna-0309
Clearing cache on luna-0001
Clearing cache on luna-0531
Clearing cache on luna-0316
Clearing cache on luna-0020
Clearing cache on luna-0251
Clearing cache on luna-0535
Clearing cache on luna-0554
Clearing cache on luna-0560
Clearing cache on luna-0551
Clearing cache on luna-0557
Clearing cache on luna-0549
Clearing cache on luna-0558
Clearing cache on luna-0555
Clearing cache on luna-0553
Clearing cache on luna-0556
Clearing cache on luna-0559
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
Clearing cache on luna-0019
Clearing cache on luna-0536
Clearing cache on luna-0248
Clearing cache on luna-0307
Clearing cache on luna-0319
Clearing cache on luna-0301
Clearing cache on luna-0304
Clearing cache on luna-0014
Clearing cache on luna-0254
Clearing cache on luna-0257
Clearing cache on luna-0552
Clearing cache on luna-0255
Clearing cache on luna-0252
Clearing cache on luna-0302
Clearing cache on luna-0246
Clearing cache on luna-0546
Clearing cache on luna-0320
Clearing cache on luna-0015
Clearing cache on luna-0244
Clearing cache on luna-0550
Clearing cache on luna-0527
Clearing cache on luna-0540
Clearing cache on luna-0260
Clearing cache on luna-0013
Clearing cache on luna-0306
Clearing cache on luna-0017
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --mpi=pmix --ntasks=800 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/lustre/fsw/mlperf/mlperft-unet3d/dataset/:/data,/lustre/fsw/mlperf-ci/23360858/results:/results,/lustre/fsw/mlperf/mlperft-unet3d/rachitg/logs/single_node:/profile_dir ./run_and_time.sh
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ declare -a CMD
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 1 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ declare -a CMD
+ '[' -n 1 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
running benchmark
+ '[' -n 7 ']'
+ cluster=
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ '[' -n 0 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 6 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 0 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 2 ']'
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
running benchmark
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 6 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 7 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ OPTIMIZER=nag
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ '[' -n 2 ']'
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ OPTIMIZER=nag
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
running benchmark
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ TARGET_DIR=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
running benchmark
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 7 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 0 ']'
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' -n 7 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ '[' -n 1 ']'
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 4 ']'
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
running benchmark
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
running benchmark
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ cluster=
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ echo 'running benchmark'
+ '[' -n 1 ']'
+ LR=1.5
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ '[' -n 2 ']'
+ EVALUATE_EVERY=14
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ cluster=
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ LR=1.5
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ TARGET_DIR=
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ TARGET_DIR=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 7 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ '[' -n 7 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ cluster=
running benchmark
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ SEED=-1
+ cluster=
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
running benchmark
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
running benchmark
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ '[' -n 1 ']'
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
running benchmark
+ '[' -n 6 ']'
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ echo 'running benchmark'
running benchmark
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ LR=1.5
+ SEED=-1
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ TARGET_DIR=
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 1 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ SEED=-1
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
running benchmark
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
running benchmark
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ '[' -n 4 ']'
+ DATASET_DIR=/data
+ SEED=-1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ '[' '' = apiLog.sh ']'
running benchmark
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 5 ']'
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 5 ']'
running benchmark
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ '[' -n 7 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ '[' -n 2 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ '[' -n 5 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 1 ']'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ '[' -n 0 ']'
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 3 ']'
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
running benchmark
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 5 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ LR=1.5
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 7 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
+ declare -a CMD
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 1 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ LR=1.5
+ '[' -n 7 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 7 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ DATASET_DIR=/data
+ SEED=-1
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
running benchmark
+ LR=1.5
running benchmark
+ '[' -n 1 ']'
running benchmark
+ MAX_EPOCHS=7000
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
running benchmark
+ OPTIMIZER=nag
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
running benchmark
+ VAL_BATCH_SIZE=1
+ '[' -n 2 ']'
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
running benchmark
+ MAX_EPOCHS=7000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR=1.5
running benchmark
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ DATASET_DIR=/data
running benchmark
+ EVALUATE_EVERY=14
running benchmark
+ '[' -n 4 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ SEED=-1
+ declare -a CMD
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ EVALUATE_EVERY=14
running benchmark
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 0 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 6 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ declare -a CMD
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
running benchmark
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 3 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ DATASET_DIR=/data
running benchmark
+ cluster=
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' -n 4 ']'
+ LR=1.5
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ MAX_EPOCHS=7000
running benchmark
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
running benchmark
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ '[' -n 3 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ '[' -n 1 ']'
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=selene
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
running benchmark
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 7 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 4 ']'
+ TARGET_DIR=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ EVALUATE_EVERY=14
+ cluster=
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 7 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ LR=1.5
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 4 ']'
+ '[' -n 0 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ QUALITY_THRESHOLD=0.908
+ '[' -n 6 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 4 ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
running benchmark
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 3 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ '[' -n 4 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
+ BATCH_SIZE=1
+ cluster=
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ '[' -n 1 ']'
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ SEED=-1
+ START_EVAL_AT=700
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ '[' -n 0 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
running benchmark
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ '[' -n 7 ']'
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 7 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ echo 'running benchmark'
+ '[' -n 6 ']'
+ '[' -n 3 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
running benchmark
+ DATASET_DIR=/data
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
running benchmark
+ TARGET_DIR=
+ '[' -n 7 ']'
running benchmark
+ TARGET_DIR=
+ '[' -n 2 ']'
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 4 ']'
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ '[' -n 1 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 0 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ '[' -n 2 ']'
+ EVALUATE_EVERY=14
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ cluster=selene
+ DATASET_DIR=/data
+ '[' -n 7 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ SEED=-1
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ SEED=-1
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ TARGET_DIR=
+ LR=1.5
+ START_EVAL_AT=700
+ declare -a CMD
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ '[' -n 3 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
running benchmark
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 7 ']'
running benchmark
+ PROFILING_PREFIX=
+ '[' -n 2 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
running benchmark
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 5 ']'
+ LR=1.5
+ cluster=
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 6 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 5 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ SEED=-1
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ cluster=
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ SEED=-1
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ '[' -n 3 ']'
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 0 ']'
running benchmark
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ cluster=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ '[' -n 6 ']'
+ '[' -n 4 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
running benchmark
+ '[' '' = apiLog.sh ']'
+ cluster=
+ START_EVAL_AT=700
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
running benchmark
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ '[' -n 7 ']'
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ '[' -n 0 ']'
+ OPTIMIZER=nag
+ SEED=-1
+ EVALUATE_EVERY=14
+ '[' -n 2 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ LR=1.5
running benchmark
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ cluster=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ '[' -n 1 ']'
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 2 ']'
+ '[' -n 6 ']'
running benchmark
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ declare -a CMD
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ BATCH_SIZE=1
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
running benchmark
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ '[' -n 1 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
running benchmark
+ DATASET_DIR=/data
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
running benchmark
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ TARGET_DIR=
running benchmark
+ declare -a CMD
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 6 ']'
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
running benchmark
+ cluster=
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 4 ']'
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ echo 'running benchmark'
running benchmark
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ SEED=-1
+ cluster=selene
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ TARGET_DIR=
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 2 ']'
+ MAX_EPOCHS=7000
running benchmark
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 3 ']'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
running benchmark
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ '[' -n 4 ']'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 5 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
+ SEED=-1
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ cluster=
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ LR=1.5
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 5 ']'
+ '[' -n 5 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' -n 3 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 3 ']'
+ LR=1.5
running benchmark
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ TARGET_DIR=
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ '[' -n 7 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
running benchmark
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 7 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 0 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 4 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ '[' -n 6 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ echo 'running benchmark'
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
running benchmark
+ OPTIMIZER=nag
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ OPTIMIZER=nag
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
running benchmark
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
+ LR=1.5
+ LR=1.5
running benchmark
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 4 ']'
+ TARGET_DIR=
running benchmark
+ '[' 800 -gt 100 ']'
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 1 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ cluster=
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ declare -a CMD
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 0 ']'
+ DATASET_DIR=/data
+ '[' -n 6 ']'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
running benchmark
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ '[' -n 5 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 6 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 5 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
running benchmark
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ echo 'running benchmark'
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 2 ']'
running benchmark
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' -n 6 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ '[' -n 6 ']'
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' -n 6 ']'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' -n 5 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ '[' -n 3 ']'
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ EVALUATE_EVERY=14
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ TARGET_DIR=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 0 ']'
running benchmark
+ echo 'running benchmark'
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
running benchmark
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ EVALUATE_EVERY=14
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 5 ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
running benchmark
+ BATCH_SIZE=1
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' -n 1 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ '[' -n 0 ']'
+ MAX_EPOCHS=7000
+ '[' -n 1 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 2 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 1 ']'
+ START_EVAL_AT=700
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' -n 3 ']'
running benchmark
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 7 ']'
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
running benchmark
+ '[' -n 0 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ '[' -n 7 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ '[' -n 2 ']'
+ OPTIMIZER=nag
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
running benchmark
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ TARGET_DIR=
+ '[' -n 5 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ '[' -n 4 ']'
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
running benchmark
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 7 ']'
+ '[' -n 7 ']'
running benchmark
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 3 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
running benchmark
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 7 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
running benchmark
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
running benchmark
+ '[' -n 4 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
+ declare -a CMD
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
running benchmark
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ '[' -n 0 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ '[' -n 6 ']'
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 4 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 7 ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 0 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' -n 7 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ SEED=-1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 3 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 7 ']'
+ echo 'running benchmark'
+ BATCH_SIZE=1
running benchmark
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
running benchmark
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
running benchmark
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ cluster=
+ TARGET_DIR=
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
running benchmark
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
running benchmark
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
running benchmark
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 7 ']'
+ LR=1.5
+ SEED=-1
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' -n 4 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ '[' -n 3 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 5 ']'
+ cluster=selene
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ TARGET_DIR=
+ '[' -n 6 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ '[' -n 0 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ PROFILING_PREFIX=
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 1 ']'
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 3 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 7 ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ declare -a CMD
+ MAX_EPOCHS=7000
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
running benchmark
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ cluster=
+ START_EVAL_AT=700
+ SEED=-1
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
running benchmark
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ '[' -n 3 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ EVALUATE_EVERY=14
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
running benchmark
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 1 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
running benchmark
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 2 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 1 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ '[' -n 6 ']'
+ declare -a CMD
+ MAX_EPOCHS=7000
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 3 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
running benchmark
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=selene
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ declare -a CMD
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ '[' -n 7 ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 7 ']'
running benchmark
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ TARGET_DIR=
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
running benchmark
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 7 ']'
+ SEED=-1
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ cluster=
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ cluster=selene
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 4 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 2 ']'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' -n 3 ']'
running benchmark
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
running benchmark
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ declare -a CMD
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 0 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
running benchmark
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ DATASET_DIR=/data
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ TARGET_DIR=
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 1 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR=1.5
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' -n 3 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ '[' -n 0 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ SEED=-1
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ '[' -n 7 ']'
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ SEED=-1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR=1.5
+ declare -a CMD
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
running benchmark
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ '[' -n 4 ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ cluster=
running benchmark
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ '[' -n 7 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 3 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 7 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
running benchmark
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ DATASET_DIR=/data
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ cluster=
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 3 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ echo 'running benchmark'
+ '[' -n 2 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ cluster=
+ EVALUATE_EVERY=14
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ '[' -n 0 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ declare -a CMD
+ declare -a CMD
+ SEED=-1
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' -n 6 ']'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ TARGET_DIR=
running benchmark
+ '[' -n 6 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ OPTIMIZER=nag
+ TARGET_DIR=
running benchmark
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 4 ']'
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ START_EVAL_AT=700
+ START_EVAL_AT=700
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
running benchmark
+ declare -a CMD
+ START_EVAL_AT=700
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ START_EVAL_AT=700
+ TARGET_DIR=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ OPTIMIZER=nag
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' -n 6 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ '[' -n 1 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ '[' -n 0 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 4 ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ cluster=
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
running benchmark
+ DATASET_DIR=/data
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ LR=1.5
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 7 ']'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ DATASET_DIR=/data
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' -n 0 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
running benchmark
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ SEED=-1
+ declare -a CMD
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ LR=1.5
+ '[' -n 6 ']'
+ BATCH_SIZE=1
+ SEED=-1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 3 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
running benchmark
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' -n 1 ']'
+ cluster=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ VAL_BATCH_SIZE=1
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ '[' -n 7 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 1 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ declare -a CMD
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 6 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 6 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' -n 1 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ OPTIMIZER=nag
+ declare -a CMD
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 2 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ TARGET_DIR=
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 2 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ LR=1.5
+ SEED=-1
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 5 ']'
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ LR=1.5
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
running benchmark
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ DATASET_DIR=/data
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR=1.5
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ SEED=-1
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ echo 'running benchmark'
running benchmark
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ declare -a CMD
+ LR=1.5
+ '[' -n 5 ']'
running benchmark
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 5 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ '[' -n 7 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 1 ']'
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ BATCH_SIZE=1
running benchmark
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ VAL_BATCH_SIZE=1
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ OPTIMIZER=nag
running benchmark
+ VAL_BATCH_SIZE=1
running benchmark
+ BATCH_SIZE=1
running benchmark
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 0 ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ cluster=selene
+ '[' -n 3 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' -n 1 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ TARGET_DIR=
+ SEED=-1
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 3 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ SEED=-1
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ '[' -n 2 ']'
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' -n 4 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' -n 6 ']'
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ SEED=-1
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ echo 'running benchmark'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ '[' -n 7 ']'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 4 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ cluster=
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ declare -a CMD
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ cluster=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 3 ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 2 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 5 ']'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ '[' -n 1 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 6 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ '[' -n 5 ']'
+ SEED=-1
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ TARGET_DIR=
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' -n 5 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ '[' -n 1 ']'
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' -n 7 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' -n 4 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 0 ']'
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 4 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ cluster=
+ PROFILING_PREFIX=
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 3 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 7 ']'
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ PROFILING_PREFIX=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 7 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
running benchmark
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 0 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=selene
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ BATCH_SIZE=1
+ TARGET_DIR=
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ START_EVAL_AT=700
+ echo 'running benchmark'
running benchmark
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ '[' -n 4 ']'
+ declare -a CMD
+ SEED=-1
+ '[' -n 7 ']'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ cluster=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
running benchmark
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ cluster=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=selene
+ BATCH_SIZE=1
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ '[' -n 0 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ echo 'running benchmark'
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' -n 6 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 2 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ QUALITY_THRESHOLD=0.908
running benchmark
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ OPTIMIZER=nag
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 7 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ '[' -n 1 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 7 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ SEED=-1
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ TARGET_DIR=
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ '[' -n 2 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 0 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 1 ']'
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ '[' -n 4 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 2 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ echo 'running benchmark'
+ '[' -n 0 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ DATASET_DIR=/data
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
running benchmark
+ declare -a CMD
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ LR=1.5
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 7 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=selene
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 2 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ '[' -n 6 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ '[' -n 3 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 6 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:28:42 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
:::MLLOG {"namespace": "", "time_ms": 1621445324488, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 30}}
:::MLLOG {"namespace": "", "time_ms": 1621445324530, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 31}}
:::MLLOG {"namespace": "", "time_ms": 1621445324531, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 101}}
:::MLLOG {"namespace": "", "time_ms": 1621445324531, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "nvidia", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 106}}
:::MLLOG {"namespace": "", "time_ms": 1621445324531, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 110}}
:::MLLOG {"namespace": "", "time_ms": 1621445324531, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 114}}
:::MLLOG {"namespace": "", "time_ms": 1621445324531, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "100xNVIDIA DGX A100", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 118}}
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:49] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:28:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[luna-0001:0:3450784 - context.c:581] INFO job (ID: 17873238721950122323) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0001:0:3450784 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x2 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0001:0:3450784 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x41 caps:0x16
[luna-0001:0:3450784 - comm.c:385] INFO [group#:0] group id:1f tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xa9160000001f) mlid:c007
[luna-0001:0:3450784 - comm.c:385] INFO [group#:1] group id:1f tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0001:0:3450802 - context.c:581] INFO job (ID: 17873237811099639767) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0001:0:3450802 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x3 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0001:0:3450802 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x42 caps:0x16
[luna-0001:0:3450802 - comm.c:385] INFO [group#:0] group id:20 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xab1600000020) mlid:c009
[luna-0001:0:3450802 - comm.c:385] INFO [group#:1] group id:20 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0001:0:3450796 - context.c:581] INFO job (ID: 17873237820976545440) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0001:0:3450796 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x7 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0001:0:3450796 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x46 caps:0x16
[luna-0001:0:3450796 - comm.c:385] INFO [group#:0] group id:0 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xad1600000000) mlid:c00e
[luna-0001:0:3450796 - comm.c:385] INFO [group#:1] group id:0 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0001:0:3450803 - context.c:581] INFO job (ID: 17873238283540442438) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0001:0:3450803 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0xf caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0001:0:3450803 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x4e caps:0x16
[luna-0001:0:3450803 - comm.c:385] INFO [group#:0] group id:1 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xaf1600000001) mlid:c018
[luna-0001:0:3450803 - comm.c:385] INFO [group#:1] group id:1 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0001:0:3450787 - context.c:581] INFO job (ID: 17873237835656762924) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0001:0:3450787 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x13 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0001:0:3450787 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x52 caps:0x16
[luna-0001:0:3450787 - comm.c:385] INFO [group#:0] group id:2 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xb11600000002) mlid:c01a
[luna-0001:0:3450787 - comm.c:385] INFO [group#:1] group id:2 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0001:0:3450801 - context.c:581] INFO job (ID: 17873238141683792506) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0001:0:3450801 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x15 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0001:0:3450801 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x54 caps:0x16
[luna-0001:0:3450801 - comm.c:385] INFO [group#:0] group id:3 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xb31600000003) mlid:c01c
[luna-0001:0:3450801 - comm.c:385] INFO [group#:1] group id:3 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0001:0:3450797 - context.c:581] INFO job (ID: 17873238563549818626) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0001:0:3450797 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x25 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0001:0:3450797 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x64 caps:0x16
[luna-0001:0:3450797 - comm.c:385] INFO [group#:0] group id:4 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xb51600000004) mlid:c00b
[luna-0001:0:3450797 - comm.c:385] INFO [group#:1] group id:4 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0001:0:3450800 - context.c:581] INFO job (ID: 17873238721828089816) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0001:0:3450800 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x9 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0001:0:3450800 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x48 caps:0x16
[luna-0001:0:3450800 - comm.c:385] INFO [group#:0] group id:5 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0xb71600000005) mlid:c00d
[luna-0001:0:3450800 - comm.c:385] INFO [group#:1] group id:5 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
Using random master seed: 284624891. Worker seeds 640: [495387733, 2284733037, 3761580031, 2778217377, 671795507, 4010818688, 3753603760, 246359302, 3017246683, 788183173, 1860107049, 2659575319, 4132304439, 518403661, 471985620, 3309362204, 1656418158, 2940137725, 2692214535, 2537847756, 2786891321, 2468728761, 299570414, 3157398367, 2271218006, 524307951, 1226057964, 2428532272, 1774301140, 1836557724, 2158016001, 2951732325, 2239373087, 3976208173, 2555861335, 4208203159, 2823218025, 1214251030, 3750152275, 4270687762, 2836780731, 3792331276, 3850712006, 1110587912, 982644669, 904743334, 2686670847, 4019059008, 1243416628, 240888400, 3994129905, 3743541098, 2864168570, 3989899116, 280120263, 1680846700, 3132915447, 1186497777, 22992586, 3853157749, 4057929853, 2278847628, 3306894823, 1408149661, 2123313026, 2441684340, 2810630751, 3297710944, 2362931718, 1081558111, 74204488, 3104684501, 1934575802, 2602083691, 869215280, 3154307989, 3106150970, 337667723, 3513483828, 1435726383, 3404325473, 3660341325, 15[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
62375500, 2312127508, 2842721547, 1954394899, 2218020329, 1332411636, 2321615325, 145441177, 3391868109, 4104507010, 2601154317, 1860940083, 186333204, 80368648, 121653900, 1434725500, 1628753188, 2685382292, 1427824160, 54177982, 1425824844, 3137423131, 24159376, 4067948584, 835196137, 345791197, 156694834, 1375831690, 1353105467, 3557943254, 1584405126, 2919577620, 2746122866, 3311248901, 4143548792, 1963566023, 2085451362, 881868823, 228527765, 1398579083, 3235783634, 136364436, 2447026309, 4219567773, 3842447933, 1647949258, 1927777382, 1191885948, 2942876324, 2408019437, 1000326237, 263887286, 2376708609, 3914368022, 1324028056, 820291408, 3579353141, 3733425395, 249497043, 1764153628, 2515893354, 2827069796, 2952587778, 956173100, 3835490221, 1937648089, 3076252168, 119726421, 2466530541, 3321047263, 4200334982, 558822594, 1152420770, 197077700, 3629382836, 3609504727, 1608457586, 1402350097, 895070405, 771220129, 1528849760, 2497207122, 1696643206, 3418672154, 112265501, 1563297559, 1256310010, 1920487[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 14. SEED 495387733
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 13. SEED 495387733
RANK 8. SEED 495387733
RANK 10. SEED 495387733
RANK 12. SEED 495387733
RANK 15. SEED 495387733
RANK 9. SEED 495387733
RANK 11. SEED 495387733
RANK 20. SEED 495387733
RANK 23. SEED 495387733
RANK 16. SEED 495387733
RANK 17. SEED 495387733
RANK 18. SEED 495387733
RANK 19. SEED 495387733
RANK 21. SEED 495387733
RANK 22. SEED 495387733
RANK 25. SEED 495387733
RANK 29. SEED 495387733
RANK 27. SEED 495387733
RANK 28. SEED 495387733
RANK 26. SEED 495387733
RANK 31. SEED 495387733
RANK 24. SEED 495387733
RANK 30. SEED 495387733
RANK 33. SEED 495387733
RANK 32. SEED 495387733
RANK 39. SEED 495387733
RANK 36. SEED 495387733
RANK 37. SEED 495387733
RANK 38. SEED 495387733
RANK 34. SEED 495387733
RANK 35. SEED 495387733
RANK 46. SEED 495387733
RANK 42. SEED 495387733
RANK 44. SEED 495387733
RANK 41. SEED 495387733
RANK 45. SEED 495387733
RANK 40. SEED 495387733
RANK 43. SEED 495387733
RANK 47. SEED 495387733
RANK 49. SEED 495387733
RANK 52. SEED 495387733
RANK 51. SEED 495387733
RANK 53. SEED 495387733
RANK 54. SEED 495387733
RANK 48. SEED 495387733
RANK 50. SEED 495387733
RANK 55. SEED 495387733
RANK 58. SEED 495387733
RANK 59. SEED 495387733
RANK 57. SEED 495387733
RANK 56. SEED 495387733
RANK 62. SEED 495387733
RANK 61. SEED 495387733
RANK 63. SEED 495387733
RANK 60. SEED 495387733
RANK 65. SEED 495387733
RANK 66. SEED 495387733
RANK 71. SEED 495387733
RANK 64. SEED 495387733
RANK 67. SEED 495387733
RANK 69. SEED 495387733
RANK 68. SEED 495387733
RANK 70. SEED 495387733
RANK 72. SEED 495387733
RANK 76. SEED 495387733
RANK 75. SEED 495387733
RANK 77. SEED 495387733
RANK 78. SEED 495387733
RANK 73. SEED 495387733
RANK 74. SEED 495387733
RANK 79. SEED 495387733
RANK 80. SEED 495387733
RANK 82. SEED 495387733
RANK 84. SEED 495387733
RANK 86. SEED 495387733
RANK 81. SEED 495387733
RANK 87. SEED 495387733
RANK 83. SEED 495387733
RANK 85. SEED 495387733
RANK 92. SEED 495387733
RANK 88. SEED 495387733
RANK 91. SEED 495387733
RANK 93. SEED 495387733
RANK 89. SEED 495387733
RANK 90. SEED 495387733
RANK 94. SEED 495387733
RANK 95. SEED 495387733
RANK 96. SEED 495387733
RANK 98. SEED 495387733
RANK 99. SEED 495387733
RANK 101. SEED 495387733
RANK 100. SEED 495387733
RANK 102. SEED 495387733
RANK 103. SEED 495387733
RANK 97. SEED 495387733
RANK 105. SEED 495387733
RANK 109. SEED 495387733
RANK 111. SEED 495387733
RANK 108. SEED 495387733
RANK 106. SEED 495387733
RANK 110. SEED 495387733
RANK 104. SEED 495387733
RANK 107. SEED 495387733
RANK 116. SEED 495387733
RANK 112. SEED 495387733
RANK 114. SEED 495387733
RANK 117. SEED 495387733
RANK 119. SEED 495387733
RANK 113. SEED 495387733
RANK 118. SEED 495387733
RANK 115. SEED 495387733
RANK 120. SEED 495387733
RANK 121. SEED 495387733
RANK 126. SEED 495387733
RANK 123. SEED 495387733
RANK 125. SEED 495387733
RANK 124. SEED 495387733
RANK 127. SEED 495387733
RANK 122. SEED 495387733
RANK 129. SEED 495387733
RANK 130. SEED 495387733
RANK 135. SEED 495387733
RANK 132. SEED 495387733
RANK 133. SEED 495387733
RANK 134. SEED 495387733
RANK 128. SEED 495387733
RANK 131. SEED 495387733
RANK 138. SEED 495387733
RANK 136. SEED 495387733
RANK 141. SEED 495387733
RANK 137. SEED 495387733
RANK 139. SEED 495387733
RANK 142. SEED 495387733
RANK 143. SEED 495387733
RANK 140. SEED 495387733
RANK 148. SEED 495387733
RANK 151. SEED 495387733
RANK 149. SEED 495387733
RANK 150. SEED 495387733
RANK 145. SEED 495387733
RANK 146. SEED 495387733
RANK 147. SEED 495387733
RANK 144. SEED 495387733
RANK 154. SEED 495387733
RANK 152. SEED 495387733
RANK 155. SEED 495387733
RANK 153. SEED 495387733
RANK 157. SEED 495387733
RANK 156. SEED 495387733
RANK 158. SEED 495387733
RANK 159. SEED 495387733
RANK 164. SEED 495387733
RANK 161. SEED 495387733
RANK 165. SEED 495387733
RANK 166. SEED 495387733
RANK 162. SEED 495387733
RANK 160. SEED 495387733
RANK 167. SEED 495387733
RANK 163. SEED 495387733
RANK 170. SEED 495387733
RANK 169. SEED 495387733
RANK 175. SEED 495387733
RANK 171. SEED 495387733
RANK 173. SEED 495387733
RANK 172. SEED 495387733
RANK 168. SEED 495387733
RANK 174. SEED 495387733
RANK 177. SEED 495387733
RANK 178. SEED 495387733
RANK 180. SEED 495387733
RANK 183. SEED 495387733
RANK 176. SEED 495387733
RANK 179. SEED 495387733
RANK 181. SEED 495387733
RANK 184. SEED 495387733
RANK 185. SEED 495387733
RANK 189. SEED 495387733
RANK 187. SEED 495387733
RANK 188. SEED 495387733
RANK 190. SEED 495387733
RANK 191. SEED 495387733
RANK 186. SEED 495387733
821, 1609596064, 962396026, 155325044, 4020649933, 3988134373, 3402411460, 3335801768, 1286714474, 3349725019, 2720090884, 408222377, 1536812636, 2994708975, 1008850349, 1233336701, 1637548228, 2489699593, 3924803513, 1139119615, 2123610517, 4247952616, 442945107, 246555815, 3530165279, 2073942179, 1136186209, 2159030388, 1593703875, 2008725891, 3396852896, 842180981, 3316870273, 3783867451, 167722625, 2928769036, 129857154, 829595879, 1640065563, 820649289, 4120463817, 4150442797, 4118041624, 1167613146, 3732752129, 3282933607, 93930481, 3149362835, 2829415056, 267224398, 1833887311, 3229555105, 3075725740, 1068352973, 1833795014, 2911180267, 2599382630, 794863257, 2558596702, 2583442419, 2083084435, 3247174228, 298940792, 1703873486, 1622295432, 879456586, 3016519327, 440794728, 144212473, 1771049982, 526402750, 3408369651, 3810503341, 2761059387, 4283982606, 2398329719, 579102734, 1078295614, 4182316841, 1370949746, 4053505781, 1879917051, 907906859, 743486694, 1291964422, 3547946442, 694838666, 3479786040, 757853411, 321606220, 2158969017, 1992018695, 2134714169, 3433780296, 2268744008, 955717142, 2287798536, 1214978244, 2915379945, 3831482906, 387607610, 3403887385, 4059747532, 407407921, 1349766308, 4288171077, 3409274408, 156902942, 680707944, 3111694845, 725532015, 4187462439, 2027261117, 4017045966, 1314570773, 3673057048, 2986544059, 1320994658, 1331627936, 4075239835, 1600307474, 717335424, 276446672, 2549998862, 2880298944, 2178325355, 3896225158, 2165131740, 501749278, 2509547403, 3579007148, 3750073217, 4087123981, 3008159929, 1620685494, 3850568106, 2832106209, 3548726475, 2253870996, 48638632, 2428014656, 2042235023, 365403675, 3559580156, 2671338217, 2660223306, 1417819861, 3932610217, 3050720571, 2362274434, 3759507577, 756420018, 1399852142, 3423435517, 3058928794, 2971701760, 3956498383, 1112385634, 3858498645, 876232698, 3672362003, 3963264900, 2289387058, 1251960695, 2836030553, 1790682478, 2462504152, 735284115, 3353255292, 3975283285, 974343607, 641801430, 3011298657, 54691967, 2885144766, 638554883, 4105653804, 1777270464, 4147193805, 3390198211, 49516819, 2765538670, 537470694, 3867683982, 606777781, 1066711206, 2284451595, 3405443857, 2643284071, 3735943119, 1068398674, 2064776714, 3082529496, 2050942393, 825570373, 1497206750, 3698578273, 2235346338, 580673523, 615497015, 2847704187, 501815961, 1115078662, 3424105603, 874088743, 926899661, 2598212850, 2088917220, 1687609228, 1184098678, 2589131420, 2102492170, 1724876469, 3505410156, 2576788110, 2925722085, 4006165600, 2690724803, 3883946536, 3042833844, 958364415, 2017956773, 3310629731, 3804621412, 412298268, 2544679090, 1771819639, 3266608492, 2881355948, 2814145633, 217812925, 535228326, 180465265, 1353349007, 712542259, 2171605551, 1350272860, 1900483325, 1859513455, 3782955154, 2109233373, 4146219714, 1522166037, 323381752, 2696825280, 3235695552, 310011917, 21850748, 1993172965, 2245580857, 1593275598, 3448906602, 4267703908, 2405983845, 3475714945, 3735595719, 301808882, 847165275, 2262481868, 4224177688, 4062580143, 2873144165, 771124064, 84613865, 3531959650, 4119503277, 745208468, 4020702708, 1994363498, 511672337, 2672770452, 3552302843, 1542893418, 2219736665, 2870042253, 896785540, 4187540880, 3415940562, 1085757360, 320363011, 2724364793, 2982055507, 3276527213, 2656531935, 2224897800, 1759153985, 1713703856, 1665360627, 3202525021, 4207592461, 872537043, 144926716, 2178813254, 3017635673, 367943996, 1430316314, 3952842701, 1401918469, 2284931379, 2530226376, 2523443778, 3995037954, 1918913766, 4181165674, 101867280, 3737582558, 62713473, 3482958047, 674387628, 4182864851, 1849028839, 3226037081, 2369933017, 925019448, 1120867489, 3057912200, 2782581000, 4176526586, 2314380917, 1113360031, 1804624493, 741161688, 446793342, 703872279, 2191607207, 1456434325, 1365042814, 3827440536, 3059301226, 1373401803, 983180780, 3906970567, 1675164965, 1770397025, 2042145567, 300261183, 3856678491, 2892811098, 2454279058, 2161210469, 3823669445, 2542330579, 3104568624, 3993599207, 3161233614, 3738338341, 1282450769, 3435823971, 2113464875, 4268977021, 2223600996, 3766561012, 3306371414, 3719711032, 2495654182, 4290670220, 3863705970, 1057905176, 107993659, 1033871463, 4240315350, 3002709323, 1348050324, 1176441326, 2575320659, 592060056, 586066583, 2972351723, 49913178, 509448283, 2544415314, 4083228300, 960745134, 2690156656, 2871718191, 434255660, 1736049688, 2955180909, 2031186284, 970148705, 3341198116, 3695530137, 2289432007, 1777715024, 527568785, 406822305, 3408110821, 1180056071, 3381652542, 1674534925, 2811284060, 276666153, 782682689, 3107556740, 3617769992, 3952783330, 1227132243, 449198494, 756145948, 759956810, 1507474083, 574606452, 3616469911, 2236332403, 1554089140, 4009750293, 3157758373, 26254477, 289257633, 3020035867, 306053622, 1412895666, 2436762520, 978904145, 3330302918, 2858245132, 1386490155, 1150902148, 417049384, 2654007536, 4013503912, 3782776143, 43588612, 3609910325, 2937672089, 2308720137, 1894930112, 3536575049, 1502714190, 1360916487, 3516544264, 3565402188, 3801850775, 683988946, 2606549887, 577188677, 2053807971, 3267103850, 4051388519, 1787745904, 4212388614, 663793981, 1973372967, 2442426804, 2331339781, 3994529459, 608357988, 3974913258, 3827191788, 2978900812, 2536579374, 3677903689, 3036477757, 1592939067, 1788090174, 2933360420, 4067889751, 1291206244, 1479599223, 3235459349, 2152875696, 3266847806, 4206718787, 1304549543, 2874448513, 473043761, 1720630032, 2275816730, 3454078672, 3981268118, 4094851541]
RANK 5. SEED 495387733
RANK 2. SEED 495387733
RANK 6. SEED 495387733
RANK 1. SEED 495387733
RANK 7. SEED 495387733
RANK 3. SEED 495387733
RANK 4. SEED 495387733
RANK 0. SEED 495387733
:::MLLOG {"namespace": "", "time_ms": 1621445648026, "event_type": "POINT_IN_TIME", "key": "seed", "value": 495387733, "metadata": {"file": "main.py", "lineno": 57}}
:::MLLOG {"namespace": "", "time_ms": 1621445648026, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1621445648026, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 125}}
:::MLLOG {"namespace": "", "time_ms": 1621445648026, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1000, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 126}}
:::MLLOG {"namespace": "", "time_ms": 1621445648026, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1621445648026, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 129}}
:::MLLOG {"namespace": "", "time_ms": 1621445648026, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 130}}
:::MLLOG {"namespace": "", "time_ms": 1621445648026, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 131}}
:::MLLOG {"namespace": "", "time_ms": 1621445648027, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
:::MLLOG {"namespace": "", "time_ms": 1621445648027, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 133}}
:::MLLOG {"namespace": "", "time_ms": 1621445648027, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 134}}
:::MLLOG {"namespace": "", "time_ms": 1621445648027, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 135}}
RANK 195. SEED 495387733
RANK 192. SEED 495387733
RANK 194. SEED 495387733
RANK 193. SEED 495387733
RANK 199. SEED 495387733
RANK 196. SEED 495387733
RANK 197. SEED 495387733
RANK 198. SEED 495387733
RANK 201. SEED 495387733
RANK 200. SEED 495387733
RANK 204. SEED 495387733
RANK 202. SEED 495387733
RANK 206. SEED 495387733
RANK 203. SEED 495387733
RANK 205. SEED 495387733
RANK 207. SEED 495387733
RANK 209. SEED 495387733
RANK 211. SEED 495387733
RANK 210. SEED 495387733
RANK 212. SEED 495387733
RANK 213. SEED 495387733
RANK 208. SEED 495387733
RANK 215. SEED 495387733
RANK 214. SEED 495387733
RANK 217. SEED 495387733
RANK 216. SEED 495387733
RANK 221. SEED 495387733
RANK 219. SEED 495387733
RANK 223. SEED 495387733
RANK 220. SEED 495387733
RANK 222. SEED 495387733
RANK 218. SEED 495387733
RANK 229. SEED 495387733
RANK 226. SEED 495387733
RANK 225. SEED 495387733
RANK 228. SEED 495387733
RANK 230. SEED 495387733
RANK 231. SEED 495387733
RANK 227. SEED 495387733
RANK 224. SEED 495387733
RANK 233. SEED 495387733
RANK 238. SEED 495387733
RANK 239. SEED 495387733
RANK 232. SEED 495387733
RANK 234. SEED 495387733
RANK 235. SEED 495387733
RANK 236. SEED 495387733
RANK 237. SEED 495387733
RANK 244. SEED 495387733
RANK 241. SEED 495387733
RANK 242. SEED 495387733
RANK 245. SEED 495387733
RANK 246. SEED 495387733
RANK 247. SEED 495387733
RANK 240. SEED 495387733
RANK 243. SEED 495387733
RANK 253. SEED 495387733
RANK 252. SEED 495387733
RANK 254. SEED 495387733
RANK 255. SEED 495387733
RANK 251. SEED 495387733
RANK 248. SEED 495387733
RANK 249. SEED 495387733
RANK 250. SEED 495387733
RANK 258. SEED 495387733
RANK 256. SEED 495387733
RANK 259. SEED 495387733
RANK 262. SEED 495387733
RANK 257. SEED 495387733
RANK 261. SEED 495387733
RANK 263. SEED 495387733
RANK 182. SEED 495387733
RANK 267. SEED 495387733
RANK 266. SEED 495387733
RANK 265. SEED 495387733
RANK 269. SEED 495387733
RANK 264. SEED 495387733
RANK 268. SEED 495387733
RANK 270. SEED 495387733
RANK 271. SEED 495387733
RANK 272. SEED 495387733
RANK 274. SEED 495387733
RANK 275. SEED 495387733
RANK 278. SEED 495387733
RANK 277. SEED 495387733
RANK 276. SEED 495387733
RANK 279. SEED 495387733
RANK 282. SEED 495387733
RANK 281. SEED 495387733
RANK 283. SEED 495387733
RANK 280. SEED 495387733
RANK 285. SEED 495387733
RANK 286. SEED 495387733
RANK 284. SEED 495387733
RANK 287. SEED 495387733
RANK 288. SEED 495387733
RANK 290. SEED 495387733
RANK 289. SEED 495387733
RANK 295. SEED 495387733
RANK 291. SEED 495387733
RANK 293. SEED 495387733
RANK 294. SEED 495387733
RANK 292. SEED 495387733
RANK 298. SEED 495387733
RANK 297. SEED 495387733
RANK 301. SEED 495387733
RANK 302. SEED 495387733
RANK 299. SEED 495387733
RANK 296. SEED 495387733
RANK 300. SEED 495387733
RANK 303. SEED 495387733
RANK 306. SEED 495387733
RANK 309. SEED 495387733
RANK 308. SEED 495387733
RANK 310. SEED 495387733
RANK 311. SEED 495387733
RANK 307. SEED 495387733
RANK 304. SEED 495387733
RANK 305. SEED 495387733
RANK 312. SEED 495387733
RANK 313. SEED 495387733
RANK 314. SEED 495387733
RANK 317. SEED 495387733
RANK 319. SEED 495387733
RANK 315. SEED 495387733
RANK 316. SEED 495387733
RANK 318. SEED 495387733
RANK 322. SEED 495387733
RANK 327. SEED 495387733
RANK 326. SEED 495387733
RANK 324. SEED 495387733
RANK 320. SEED 495387733
RANK 321. SEED 495387733
RANK 323. SEED 495387733
RANK 325. SEED 495387733
RANK 331. SEED 495387733
RANK 329. SEED 495387733
RANK 332. SEED 495387733
RANK 335. SEED 495387733
RANK 330. SEED 495387733
RANK 328. SEED 495387733
RANK 333. SEED 495387733
RANK 334. SEED 495387733
RANK 337. SEED 495387733
RANK 339. SEED 495387733
RANK 336. SEED 495387733
RANK 338. SEED 495387733
RANK 343. SEED 495387733
RANK 340. SEED 495387733
RANK 341. SEED 495387733
RANK 342. SEED 495387733
RANK 345. SEED 495387733
RANK 273. SEED 495387733
RANK 349. SEED 495387733
RANK 351. SEED 495387733
RANK 346. SEED 495387733
RANK 347. SEED 495387733
RANK 348. SEED 495387733
RANK 350. SEED 495387733
RANK 344. SEED 495387733
RANK 356. SEED 495387733
RANK 352. SEED 495387733
RANK 355. SEED 495387733
RANK 260. SEED 495387733
RANK 354. SEED 495387733
RANK 357. SEED 495387733
RANK 358. SEED 495387733
RANK 359. SEED 495387733
RANK 353. SEED 495387733
RANK 365. SEED 495387733
RANK 361. SEED 495387733
RANK 363. SEED 495387733
RANK 362. SEED 495387733
RANK 360. SEED 495387733
RANK 366. SEED 495387733
RANK 367. SEED 495387733
RANK 364. SEED 495387733
RANK 375. SEED 495387733
RANK 368. SEED 495387733
RANK 369. SEED 495387733
RANK 370. SEED 495387733
RANK 371. SEED 495387733
RANK 373. SEED 495387733
RANK 374. SEED 495387733
RANK 372. SEED 495387733
RANK 378. SEED 495387733
RANK 381. SEED 495387733
RANK 382. SEED 495387733
RANK 376. SEED 495387733
RANK 379. SEED 495387733
RANK 377. SEED 495387733
RANK 380. SEED 495387733
RANK 383. SEED 495387733
RANK 388. SEED 495387733
RANK 384. SEED 495387733
RANK 386. SEED 495387733
RANK 390. SEED 495387733
RANK 387. SEED 495387733
RANK 385. SEED 495387733
RANK 391. SEED 495387733
RANK 389. SEED 495387733
RANK 395. SEED 495387733
RANK 393. SEED 495387733
RANK 396. SEED 495387733
RANK 397. SEED 495387733
RANK 399. SEED 495387733
RANK 398. SEED 495387733
RANK 392. SEED 495387733
RANK 394. SEED 495387733
RANK 404. SEED 495387733
RANK 401. SEED 495387733
RANK 402. SEED 495387733
RANK 406. SEED 495387733
RANK 400. SEED 495387733
RANK 403. SEED 495387733
RANK 405. SEED 495387733
RANK 407. SEED 495387733
RANK 411. SEED 495387733
RANK 409. SEED 495387733
RANK 410. SEED 495387733
RANK 413. SEED 495387733
RANK 412. SEED 495387733
RANK 408. SEED 495387733
RANK 414. SEED 495387733
RANK 415. SEED 495387733
RANK 419. SEED 495387733
RANK 421. SEED 495387733
RANK 422. SEED 495387733
RANK 416. SEED 495387733
RANK 417. SEED 495387733
RANK 420. SEED 495387733
RANK 418. SEED 495387733
RANK 423. SEED 495387733
RANK 428. SEED 495387733
RANK 431. SEED 495387733
RANK 424. SEED 495387733
RANK 425. SEED 495387733
RANK 430. SEED 495387733
RANK 429. SEED 495387733
RANK 426. SEED 495387733
RANK 427. SEED 495387733
RANK 437. SEED 495387733
RANK 438. SEED 495387733
RANK 433. SEED 495387733
RANK 436. SEED 495387733
RANK 432. SEED 495387733
RANK 434. SEED 495387733
RANK 439. SEED 495387733
RANK 435. SEED 495387733
RANK 444. SEED 495387733
RANK 442. SEED 495387733
RANK 447. SEED 495387733
RANK 443. SEED 495387733
RANK 440. SEED 495387733
RANK 441. SEED 495387733
RANK 446. SEED 495387733
RANK 445. SEED 495387733
RANK 449. SEED 495387733
RANK 448. SEED 495387733
RANK 451. SEED 495387733
RANK 453. SEED 495387733
RANK 454. SEED 495387733
RANK 452. SEED 495387733
RANK 450. SEED 495387733
RANK 455. SEED 495387733
RANK 459. SEED 495387733
RANK 457. SEED 495387733
RANK 460. SEED 495387733
RANK 461. SEED 495387733
RANK 456. SEED 495387733
RANK 462. SEED 495387733
RANK 458. SEED 495387733
RANK 463. SEED 495387733
RANK 468. SEED 495387733
RANK 465. SEED 495387733
RANK 466. SEED 495387733
RANK 470. SEED 495387733
RANK 464. SEED 495387733
RANK 467. SEED 495387733
RANK 469. SEED 495387733
RANK 471. SEED 495387733
RANK 476. SEED 495387733
RANK 478. SEED 495387733
RANK 475. SEED 495387733
RANK 473. SEED 495387733
RANK 472. SEED 495387733
RANK 477. SEED 495387733
RANK 474. SEED 495387733
RANK 479. SEED 495387733
RANK 485. SEED 495387733
RANK 481. SEED 495387733
RANK 484. SEED 495387733
RANK 487. SEED 495387733
RANK 480. SEED 495387733
RANK 482. SEED 495387733
RANK 486. SEED 495387733
RANK 483. SEED 495387733
RANK 488. SEED 495387733
RANK 490. SEED 495387733
RANK 493. SEED 495387733
RANK 495. SEED 495387733
RANK 489. SEED 495387733
RANK 491. SEED 495387733
RANK 492. SEED 495387733
RANK 494. SEED 495387733
RANK 497. SEED 495387733
RANK 498. SEED 495387733
RANK 499. SEED 495387733
RANK 496. SEED 495387733
RANK 501. SEED 495387733
RANK 502. SEED 495387733
RANK 503. SEED 495387733
RANK 500. SEED 495387733
RANK 509. SEED 495387733
RANK 504. SEED 495387733
RANK 505. SEED 495387733
RANK 510. SEED 495387733
RANK 506. SEED 495387733
RANK 507. SEED 495387733
RANK 511. SEED 495387733
RANK 508. SEED 495387733
RANK 513. SEED 495387733
RANK 512. SEED 495387733
RANK 517. SEED 495387733
RANK 514. SEED 495387733
RANK 516. SEED 495387733
RANK 518. SEED 495387733
RANK 515. SEED 495387733
RANK 519. SEED 495387733
RANK 526. SEED 495387733
RANK 522. SEED 495387733
RANK 520. SEED 495387733
RANK 527. SEED 495387733
RANK 524. SEED 495387733
RANK 523. SEED 495387733
RANK 525. SEED 495387733
RANK 521. SEED 495387733
RANK 530. SEED 495387733
RANK 533. SEED 495387733
RANK 528. SEED 495387733
RANK 532. SEED 495387733
RANK 534. SEED 495387733
RANK 531. SEED 495387733
RANK 535. SEED 495387733
RANK 529. SEED 495387733
RANK 538. SEED 495387733
RANK 543. SEED 495387733
RANK 537. SEED 495387733
RANK 541. SEED 495387733
RANK 542. SEED 495387733
RANK 539. SEED 495387733
RANK 536. SEED 495387733
RANK 540. SEED 495387733
RANK 546. SEED 495387733
RANK 549. SEED 495387733
RANK 544. SEED 495387733
RANK 545. SEED 495387733
RANK 550. SEED 495387733
RANK 551. SEED 495387733
RANK 547. SEED 495387733
RANK 548. SEED 495387733
RANK 552. SEED 495387733
RANK 555. SEED 495387733
RANK 554. SEED 495387733
RANK 557. SEED 495387733
RANK 558. SEED 495387733
RANK 553. SEED 495387733
RANK 559. SEED 495387733
RANK 556. SEED 495387733
RANK 561. SEED 495387733
RANK 562. SEED 495387733
RANK 565. SEED 495387733
RANK 564. SEED 495387733
RANK 567. SEED 495387733
RANK 560. SEED 495387733
RANK 563. SEED 495387733
RANK 566. SEED 495387733
RANK 575. SEED 495387733
RANK 568. SEED 495387733
RANK 573. SEED 495387733
RANK 574. SEED 495387733
RANK 569. SEED 495387733
RANK 571. SEED 495387733
RANK 572. SEED 495387733
RANK 570. SEED 495387733
RANK 577. SEED 495387733
RANK 578. SEED 495387733
RANK 576. SEED 495387733
RANK 579. SEED 495387733
RANK 581. SEED 495387733
RANK 582. SEED 495387733
RANK 583. SEED 495387733
RANK 580. SEED 495387733
RANK 585. SEED 495387733
RANK 586. SEED 495387733
RANK 587. SEED 495387733
RANK 584. SEED 495387733
RANK 590. SEED 495387733
RANK 591. SEED 495387733
RANK 589. SEED 495387733
RANK 588. SEED 495387733
RANK 594. SEED 495387733
RANK 593. SEED 495387733
RANK 599. SEED 495387733
RANK 598. SEED 495387733
RANK 595. SEED 495387733
RANK 592. SEED 495387733
RANK 596. SEED 495387733
RANK 597. SEED 495387733
RANK 604. SEED 495387733
RANK 600. SEED 495387733
RANK 601. SEED 495387733
RANK 606. SEED 495387733
RANK 603. SEED 495387733
RANK 602. SEED 495387733
RANK 605. SEED 495387733
RANK 607. SEED 495387733
RANK 608. SEED 495387733
RANK 611. SEED 495387733
RANK 614. SEED 495387733
RANK 609. SEED 495387733
RANK 612. SEED 495387733
RANK 613. SEED 495387733
RANK 615. SEED 495387733
RANK 610. SEED 495387733
RANK 621. SEED 495387733
RANK 617. SEED 495387733
RANK 622. SEED 495387733
RANK 623. SEED 495387733
RANK 616. SEED 495387733
RANK 620. SEED 495387733
RANK 618. SEED 495387733
RANK 619. SEED 495387733
RANK 626. SEED 495387733
RANK 625. SEED 495387733
RANK 628. SEED 495387733
RANK 624. SEED 495387733
RANK 629. SEED 495387733
RANK 630. SEED 495387733
RANK 627. SEED 495387733
RANK 631. SEED 495387733
RANK 633. SEED 495387733
RANK 635. SEED 495387733
RANK 637. SEED 495387733
RANK 638. SEED 495387733
RANK 639. SEED 495387733
RANK 632. SEED 495387733
RANK 636. SEED 495387733
RANK 634. SEED 495387733
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:34:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
:::MLLOG {"namespace": "", "time_ms": 1621445672734, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 99}}
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
:::MLLOG {"namespace": "", "time_ms": 1621445672779, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 101}}
RANK 12, VAL CASES ['00066', '00065']
RANK 18, VAL CASES ['00176']
RANK 18, VAL CASES ['00176']
RANK 18, VAL CASES ['00176']
RANK 8, VAL CASES ['00189', '00056']
RANK 8, VAL CASES ['00189', '00056']
RANK 18, VAL CASES ['00176']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 11, VAL CASES ['00128', '00061']
RANK 11, VAL CASES ['00128', '00061']
RANK 12, VAL CASES ['00066', '00065']
RANK 18, VAL CASES ['00176']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 18, VAL CASES ['00176']
RANK 12, VAL CASES ['00066', '00065']
RANK 13, VAL CASES ['00044', '00070']
RANK 12, VAL CASES ['00066', '00065']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 13, VAL CASES ['00044', '00070']
RANK 13, VAL CASES ['00044', '00070']
RANK 12, VAL CASES ['00066', '00065']
RANK 13, VAL CASES ['00044', '00070']
RANK 14, VAL CASES ['00034', '00076']
RANK 14, VAL CASES ['00034', '00076']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 11, VAL CASES ['00128', '00061']
RANK 14, VAL CASES ['00034', '00076']
RANK 10, VAL CASES ['00207', '00162']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 11, VAL CASES ['00128', '00061']
RANK 11, VAL CASES ['00128', '00061']
RANK 14, VAL CASES ['00034', '00076']
RANK 13, VAL CASES ['00044', '00070']
RANK 14, VAL CASES ['00034', '00076']
RANK 14, VAL CASES ['00034', '00076']
RANK 11, VAL CASES ['00128', '00061']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 1, VAL CASES ['00000', '00003']
RANK 11, VAL CASES ['00128', '00061']
RANK 11, VAL CASES ['00128', '00061']
RANK 18, VAL CASES ['00176']
RANK 9, VAL CASES ['00198', '00203']
RANK 9, VAL CASES ['00198', '00203']
RANK 14, VAL CASES ['00034', '00076']
RANK 17, VAL CASES ['00084']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 18, VAL CASES ['00176']
RANK 14, VAL CASES ['00034', '00076']
RANK 9, VAL CASES ['00198', '00203']
RANK 9, VAL CASES ['00198', '00203']
RANK 1, VAL CASES ['00000', '00003']
RANK 16, VAL CASES ['00185']
RANK 16, VAL CASES ['00185']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 16, VAL CASES ['00185']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 13, VAL CASES ['00044', '00070']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 2, VAL CASES ['00169', '00206']
RANK 2, VAL CASES ['00169', '00206']
RANK 2, VAL CASES ['00169', '00206']
RANK 13, VAL CASES ['00044', '00070']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 13, VAL CASES ['00044', '00070']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 9, VAL CASES ['00198', '00203']
RANK 9, VAL CASES ['00198', '00203']
RANK 9, VAL CASES ['00198', '00203']
RANK 9, VAL CASES ['00198', '00203']
RANK 16, VAL CASES ['00185']
RANK 16, VAL CASES ['00185']
RANK 16, VAL CASES ['00185']
RANK 16, VAL CASES ['00185']
RANK 16, VAL CASES ['00185']
RANK 17, VAL CASES ['00084']
RANK 15, VAL CASES ['00005', '00024']
RANK 17, VAL CASES ['00084']
RANK 17, VAL CASES ['00084']
RANK 17, VAL CASES ['00084']
RANK 17, VAL CASES ['00084']
RANK 17, VAL CASES ['00084']
RANK 2, VAL CASES ['00169', '00206']
RANK 2, VAL CASES ['00169', '00206']
RANK 2, VAL CASES ['00169', '00206']
RANK 2, VAL CASES ['00169', '00206']
RANK 2, VAL CASES ['00169', '00206']
RANK 19, VAL CASES ['00125']
RANK 19, VAL CASES ['00125']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
RANK 10, VAL CASES ['00207', '00162']
RANK 1, VAL CASES ['00000', '00003']
RANK 10, VAL CASES ['00207', '00162']
RANK 8, VAL CASES ['00189', '00056']
RANK 8, VAL CASES ['00189', '00056']
RANK 8, VAL CASES ['00189', '00056']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 8, VAL CASES ['00189', '00056']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 8, VAL CASES ['00189', '00056']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 17, VAL CASES ['00084']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 19, VAL CASES ['00125']
RANK 19, VAL CASES ['00125']
RANK 19, VAL CASES ['00125']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 19, VAL CASES ['00125']
RANK 19, VAL CASES ['00125']
RANK 8, VAL CASES ['00189', '00056']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 19, VAL CASES ['00125']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 0, VAL CASES ['00052', '00157', '00187']
:::MLLOG {"namespace": "", "time_ms": 1621445672854, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 104}}
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 6, VAL CASES ['00006', '00080', '00041']
:::MLLOG {"namespace": "", "time_ms": 1621445672854, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 105}}
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 6, VAL CASES ['00006', '00080', '00041']
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
EVALUATION TIME: 14.591 s.
EVAL WARMUP done at epoch 14, cycle 1. Score: 0.006580981891602278
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1621445699939, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 80, "metadata": {"file": "main.py", "lineno": 107}}
:::MLLOG {"namespace": "", "time_ms": 1621445699939, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 108}}
:::MLLOG {"namespace": "", "time_ms": 1621445699939, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 24}}
:::MLLOG {"namespace": "", "time_ms": 1621445699939, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1, "epoch_count": 14}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1621445704382, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 756.3642421518589, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445704382, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.03089264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445704382, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 756.3642421518589, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1621445704382, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 14, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445704383, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 14, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445706815, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1381.192820157283, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445706816, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.05175218543046358, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445706816, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1381.192820157283, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445706816, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 28, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445706816, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 28, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445709289, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1358.5755456118293, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445709290, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.07261172185430464, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445709290, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1358.5755456118293, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 28}}
:::MLLOG {"namespace": "", "time_ms": 1621445709290, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 42, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445709290, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 42, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445711309, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1664.724461944849, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445711309, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0934712582781457, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445711309, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1664.724461944849, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 42}}
:::MLLOG {"namespace": "", "time_ms": 1621445711310, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 56, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445711310, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 56, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445712667, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2475.051912849497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445712668, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.11433079470198675, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445712668, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2475.051912849497, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 56}}
:::MLLOG {"namespace": "", "time_ms": 1621445712669, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 70, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445712669, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 70, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445713897, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2735.8202901904356, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445713898, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.13519033112582782, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445713898, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2735.8202901904356, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 70}}
:::MLLOG {"namespace": "", "time_ms": 1621445713898, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 84, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445713898, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 84, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445715073, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2859.9117402225693, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445715073, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.15604986754966885, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445715073, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2859.9117402225693, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 84}}
:::MLLOG {"namespace": "", "time_ms": 1621445715074, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 98, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445715074, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 98, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445716442, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2456.415571105241, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445716442, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.1769094039735099, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445716442, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2456.415571105241, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 98}}
:::MLLOG {"namespace": "", "time_ms": 1621445716442, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 112, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445716443, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 112, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445717482, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3233.441599129603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445717482, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.197768940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445717482, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3233.441599129603, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 112}}
:::MLLOG {"namespace": "", "time_ms": 1621445717483, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 126, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445717483, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 126, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445718615, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2967.79354078961, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445718615, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.21862847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445718615, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2967.79354078961, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 126}}
:::MLLOG {"namespace": "", "time_ms": 1621445718616, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 140, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445718616, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 140, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445719688, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3133.975591531756, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445719688, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.2394880132450331, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445719688, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3133.975591531756, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1621445719689, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 154, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445719689, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 154, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445720907, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2757.8229637544177, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445720908, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26034754966887413, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445720908, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2757.8229637544177, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 154}}
:::MLLOG {"namespace": "", "time_ms": 1621445720908, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 168, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445720908, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 168, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445721932, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3281.3052333060527, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445721932, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.2812070860927152, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445721933, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3281.3052333060527, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 168}}
:::MLLOG {"namespace": "", "time_ms": 1621445721933, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 182, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445721933, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 182, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445722976, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3221.521483802626, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445722976, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3020666225165563, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445722976, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3221.521483802626, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 182}}
:::MLLOG {"namespace": "", "time_ms": 1621445722977, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 196, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445722977, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 196, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445724037, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3168.75879354388, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445724038, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32292615894039733, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445724038, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3168.75879354388, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 196}}
:::MLLOG {"namespace": "", "time_ms": 1621445724038, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 210, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445724038, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 210, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445725043, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3343.482290140628, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445725044, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3437856953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445725044, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3343.482290140628, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 210}}
:::MLLOG {"namespace": "", "time_ms": 1621445725044, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 224, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445725044, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 224, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445725974, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3614.68125446293, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445725975, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36464523178807945, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445725975, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3614.68125446293, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 224}}
:::MLLOG {"namespace": "", "time_ms": 1621445725975, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 238, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445725975, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 238, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445726973, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3366.1081526636895, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445726974, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3855047682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445726974, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3366.1081526636895, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 238}}
:::MLLOG {"namespace": "", "time_ms": 1621445726974, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 252, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445726974, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 252, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445728103, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2976.3887536046273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445728104, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4063643046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445728104, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2976.3887536046273, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 252}}
:::MLLOG {"namespace": "", "time_ms": 1621445728104, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 266, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445728104, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 266, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445729069, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3482.7535993709084, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445729070, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445729070, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3482.7535993709084, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 266}}
:::MLLOG {"namespace": "", "time_ms": 1621445729070, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 280, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445729070, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 280, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445729930, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3905.6248534648803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445729931, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4480833774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445729931, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3905.6248534648803, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1621445729931, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 294, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445729931, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 294, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445730973, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3225.486800847749, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445730974, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.46894291390728476, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445730974, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3225.486800847749, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 294}}
:::MLLOG {"namespace": "", "time_ms": 1621445730974, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 308, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445730974, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 308, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445731896, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3646.030059540595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445731896, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4898024503311258, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445731897, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3646.030059540595, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 308}}
:::MLLOG {"namespace": "", "time_ms": 1621445731897, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 322, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445731897, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 322, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445732774, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3832.678258821597, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445732775, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5106619867549669, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445732775, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3832.678258821597, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 322}}
:::MLLOG {"namespace": "", "time_ms": 1621445732776, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 336, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445732776, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 336, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445733649, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3851.541982029058, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445733649, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.531521523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445733649, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3851.541982029058, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 336}}
:::MLLOG {"namespace": "", "time_ms": 1621445733650, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 350, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445733650, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 350, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445734717, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3149.617214828668, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445734717, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5523810596026489, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445734717, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3149.617214828668, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 350}}
:::MLLOG {"namespace": "", "time_ms": 1621445734718, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 364, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445734718, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 364, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445735607, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3778.406072319934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445735607, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5732405960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445735607, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3778.406072319934, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 364}}
:::MLLOG {"namespace": "", "time_ms": 1621445735608, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 378, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445735608, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 378, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445736449, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3997.004256555004, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445736449, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5941001324503311, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445736449, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3997.004256555004, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 378}}
:::MLLOG {"namespace": "", "time_ms": 1621445736450, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 392, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445736450, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 392, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445737311, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3902.7802535599753, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445737311, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6149596688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445737311, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3902.7802535599753, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 392}}
:::MLLOG {"namespace": "", "time_ms": 1621445737312, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 406, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445737312, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 406, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445738163, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3946.896990941064, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445738164, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6358192052980133, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445738164, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3946.896990941064, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 406}}
:::MLLOG {"namespace": "", "time_ms": 1621445738164, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 420, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445738164, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 420, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445739035, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3858.9761961287186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445739035, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6566787417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445739036, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3858.9761961287186, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1621445739036, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 434, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445739036, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 434, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445739931, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3755.9870216886197, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445739931, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6775382781456953, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445739931, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3755.9870216886197, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 434}}
:::MLLOG {"namespace": "", "time_ms": 1621445739931, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 448, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445739932, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 448, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445740906, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3450.8662241770166, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445740906, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6983978145695363, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445740906, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3450.8662241770166, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 448}}
:::MLLOG {"namespace": "", "time_ms": 1621445740906, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 462, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445740906, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 462, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445741776, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3862.2303537621833, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445741777, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7192573509933775, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445741777, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3862.2303537621833, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 462}}
:::MLLOG {"namespace": "", "time_ms": 1621445741777, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 476, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445741777, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 476, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445742602, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4075.4618347884702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445742602, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7401168874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445742602, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4075.4618347884702, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 476}}
:::MLLOG {"namespace": "", "time_ms": 1621445742603, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 490, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445742603, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 490, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445743436, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4032.258799569331, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445743436, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7609764238410596, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445743437, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4032.258799569331, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 490}}
:::MLLOG {"namespace": "", "time_ms": 1621445743437, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 504, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445743437, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 504, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445744236, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4204.202644977505, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445744236, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7818359602649007, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445744236, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4204.202644977505, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 504}}
:::MLLOG {"namespace": "", "time_ms": 1621445744237, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 518, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445744237, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 518, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445745086, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3954.829648520986, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445745087, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8026954966887417, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445745087, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3954.829648520986, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 518}}
:::MLLOG {"namespace": "", "time_ms": 1621445745087, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 532, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445745087, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 532, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445745985, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3743.8657008799087, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445745985, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8235550331125828, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445745985, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3743.8657008799087, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 532}}
:::MLLOG {"namespace": "", "time_ms": 1621445745985, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 546, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445745986, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 546, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445746807, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4089.435537436854, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445746808, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445746808, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4089.435537436854, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 546}}
:::MLLOG {"namespace": "", "time_ms": 1621445746808, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 560, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445746808, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 560, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445747654, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3970.1779991435847, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445747655, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8652741059602649, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445747655, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3970.1779991435847, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1621445747655, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 574, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445747655, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 574, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445748546, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3772.6649068041147, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445748546, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.886133642384106, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445748546, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3772.6649068041147, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 574}}
:::MLLOG {"namespace": "", "time_ms": 1621445748546, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 588, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445748547, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 588, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445749400, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3939.1557383578815, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445749400, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9069931788079469, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445749400, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3939.1557383578815, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 588}}
:::MLLOG {"namespace": "", "time_ms": 1621445749400, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 602, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445749400, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 602, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445750314, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3678.450572210498, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445750315, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9278527152317881, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445750315, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3678.450572210498, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 602}}
:::MLLOG {"namespace": "", "time_ms": 1621445750315, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 616, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445750315, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 616, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445751158, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3984.5922983771666, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445751159, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9487122516556292, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445751159, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3984.5922983771666, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 616}}
:::MLLOG {"namespace": "", "time_ms": 1621445751159, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 630, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445751159, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 630, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445751997, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4012.985148705157, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445751998, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9695717880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445751998, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4012.985148705157, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 630}}
:::MLLOG {"namespace": "", "time_ms": 1621445751999, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 644, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445751999, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 644, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445752867, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3874.1408493449385, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445752867, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9904313245033113, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445752867, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3874.1408493449385, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 644}}
:::MLLOG {"namespace": "", "time_ms": 1621445752867, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 658, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445752867, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 658, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445753764, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3749.4037663081913, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445753765, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0112908609271523, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445753765, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3749.4037663081913, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 658}}
:::MLLOG {"namespace": "", "time_ms": 1621445753765, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 672, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445753765, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 672, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445754630, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3882.9299947099275, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445754631, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0321503973509933, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445754631, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3882.9299947099275, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 672}}
:::MLLOG {"namespace": "", "time_ms": 1621445754631, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 686, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445754631, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 686, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445755483, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3943.897055243087, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445755484, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0530099337748344, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445755485, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3943.897055243087, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 686}}
rank 0: cycle = 50: time to send the model = 0.044127464294433594
:::MLLOG {"namespace": "", "time_ms": 1621445755530, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 700, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445755530, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 700, "epoch_count": 14}}
rank 640: cycle = 50: time to receive the model = 0.053040504455566406
:::MLLOG {"namespace": "", "time_ms": 1621445755539, "event_type": "INTERVAL_START", "key": "eval_start", "value": 700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 700}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.731 s.
:::MLLOG {"namespace": "", "time_ms": 1621445756311, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8711123466491699, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 700}}
:::MLLOG {"namespace": "", "time_ms": 1621445756311, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 700}}
:::MLLOG {"namespace": "", "time_ms": 1621445756352, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4091.1889908107732, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445756353, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0738694701986755, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445756353, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4091.1889908107732, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 700}}
rank 0: cycle = 51: time to send the model = 0.04068875312805176
:::MLLOG {"namespace": "", "time_ms": 1621445756395, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 714, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445756395, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 714, "epoch_count": 14}}
rank 640: cycle = 51: time to receive the model = 0.053308725357055664
:::MLLOG {"namespace": "", "time_ms": 1621445756408, "event_type": "INTERVAL_START", "key": "eval_start", "value": 714, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 714}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445757173, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8781519532203674, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 714}}
:::MLLOG {"namespace": "", "time_ms": 1621445757173, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 714}}
:::MLLOG {"namespace": "", "time_ms": 1621445757224, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4054.532441037807, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445757227, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0947290066225166, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445757228, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4054.532441037807, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 714}}
rank 0: cycle = 52: time to send the model = 0.03921985626220703
:::MLLOG {"namespace": "", "time_ms": 1621445757268, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 728, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445757268, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 728, "epoch_count": 14}}
rank 640: cycle = 52: time to receive the model = 0.051200151443481445
:::MLLOG {"namespace": "", "time_ms": 1621445757280, "event_type": "INTERVAL_START", "key": "eval_start", "value": 728, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 728}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445758046, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8558189868927002, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 728}}
:::MLLOG {"namespace": "", "time_ms": 1621445758046, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 728}}
:::MLLOG {"namespace": "", "time_ms": 1621445758087, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4102.949867416324, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445758089, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1155885430463577, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445758089, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4102.949867416324, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 728}}
rank 0: cycle = 53: time to send the model = 0.03954935073852539
:::MLLOG {"namespace": "", "time_ms": 1621445758129, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 742, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445758130, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 742, "epoch_count": 14}}
rank 640: cycle = 53: time to receive the model = 0.0507965087890625
:::MLLOG {"namespace": "", "time_ms": 1621445758141, "event_type": "INTERVAL_START", "key": "eval_start", "value": 742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 742}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445758908, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8877434730529785, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 742}}
:::MLLOG {"namespace": "", "time_ms": 1621445758909, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 742}}
:::MLLOG {"namespace": "", "time_ms": 1621445758942, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4137.432770093227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445758944, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1364480794701988, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445758945, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4137.432770093227, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 742}}
rank 0: cycle = 54: time to send the model = 0.0444183349609375
:::MLLOG {"namespace": "", "time_ms": 1621445758990, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 756, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445758990, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 756, "epoch_count": 14}}
rank 640: cycle = 54: time to receive the model = 0.056790828704833984
:::MLLOG {"namespace": "", "time_ms": 1621445759002, "event_type": "INTERVAL_START", "key": "eval_start", "value": 756, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 756}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445759767, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8560458421707153, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 756}}
:::MLLOG {"namespace": "", "time_ms": 1621445759767, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 756}}
:::MLLOG {"namespace": "", "time_ms": 1621445759833, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3986.8072921411062, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445759834, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1573076158940396, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445759834, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3986.8072921411062, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 756}}
rank 0: cycle = 55: time to send the model = 0.038779497146606445
:::MLLOG {"namespace": "", "time_ms": 1621445759875, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 770, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445759875, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 770, "epoch_count": 14}}
rank 640: cycle = 55: time to receive the model = 0.04989504814147949
:::MLLOG {"namespace": "", "time_ms": 1621445759886, "event_type": "INTERVAL_START", "key": "eval_start", "value": 770, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 770}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445760654, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8550028800964355, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 770}}
:::MLLOG {"namespace": "", "time_ms": 1621445760655, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 770}}
:::MLLOG {"namespace": "", "time_ms": 1621445760717, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3994.248044873875, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445760719, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1781671523178807, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445760719, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3994.248044873875, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 770}}
rank 0: cycle = 56: time to send the model = 0.04297828674316406
:::MLLOG {"namespace": "", "time_ms": 1621445760763, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 784, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445760764, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 784, "epoch_count": 14}}
rank 640: cycle = 56: time to receive the model = 0.055992841720581055
:::MLLOG {"namespace": "", "time_ms": 1621445760776, "event_type": "INTERVAL_START", "key": "eval_start", "value": 784, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 784}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445761543, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8837531805038452, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 784}}
:::MLLOG {"namespace": "", "time_ms": 1621445761543, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 784}}
:::MLLOG {"namespace": "", "time_ms": 1621445761582, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4106.044811190881, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445761584, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1990266887417218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445761584, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4106.044811190881, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 784}}
rank 0: cycle = 57: time to send the model = 0.03822612762451172
:::MLLOG {"namespace": "", "time_ms": 1621445761622, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 798, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445761622, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 798, "epoch_count": 14}}
rank 640: cycle = 57: time to receive the model = 0.04841947555541992
:::MLLOG {"namespace": "", "time_ms": 1621445761632, "event_type": "INTERVAL_START", "key": "eval_start", "value": 798, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 798}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445762402, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8809161186218262, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 798}}
:::MLLOG {"namespace": "", "time_ms": 1621445762402, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 798}}
:::MLLOG {"namespace": "", "time_ms": 1621445762461, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4006.5745199483486, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445762463, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2198862251655629, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445762464, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4006.5745199483486, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 798}}
rank 0: cycle = 58: time to send the model = 0.0493471622467041
:::MLLOG {"namespace": "", "time_ms": 1621445762514, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 812, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445762514, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 812, "epoch_count": 14}}
rank 640: cycle = 58: time to receive the model = 0.05890989303588867
:::MLLOG {"namespace": "", "time_ms": 1621445762523, "event_type": "INTERVAL_START", "key": "eval_start", "value": 812, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 812}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445763292, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8703949451446533, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 812}}
:::MLLOG {"namespace": "", "time_ms": 1621445763292, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 812}}
:::MLLOG {"namespace": "", "time_ms": 1621445763301, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4273.514092455337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445763302, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.240745761589404, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445763302, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4273.514092455337, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 812}}
rank 0: cycle = 59: time to send the model = 0.04223036766052246
:::MLLOG {"namespace": "", "time_ms": 1621445763347, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 826, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445763347, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 826, "epoch_count": 14}}
rank 640: cycle = 59: time to receive the model = 0.05551743507385254
:::MLLOG {"namespace": "", "time_ms": 1621445763360, "event_type": "INTERVAL_START", "key": "eval_start", "value": 826, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 826}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445764128, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8821553587913513, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 826}}
:::MLLOG {"namespace": "", "time_ms": 1621445764128, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 826}}
:::MLLOG {"namespace": "", "time_ms": 1621445764157, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4151.31564389474, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445764159, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445764159, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4151.31564389474, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 826}}
rank 0: cycle = 60: time to send the model = 0.03944730758666992
:::MLLOG {"namespace": "", "time_ms": 1621445764199, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 840, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445764200, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 840, "epoch_count": 14}}
rank 640: cycle = 60: time to receive the model = 0.05018472671508789
:::MLLOG {"namespace": "", "time_ms": 1621445764210, "event_type": "INTERVAL_START", "key": "eval_start", "value": 840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 840}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445764980, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.876451849937439, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 840}}
:::MLLOG {"namespace": "", "time_ms": 1621445764981, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 840}}
:::MLLOG {"namespace": "", "time_ms": 1621445764985, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4277.609165398163, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445764987, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2824648344370861, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445764987, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4277.609165398163, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 840}}
rank 0: cycle = 61: time to send the model = 0.041320085525512695
:::MLLOG {"namespace": "", "time_ms": 1621445765031, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 854, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445765032, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 854, "epoch_count": 14}}
rank 640: cycle = 61: time to receive the model = 0.05458235740661621
:::MLLOG {"namespace": "", "time_ms": 1621445765045, "event_type": "INTERVAL_START", "key": "eval_start", "value": 854, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 854}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445765806, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4339.179652055519, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445765808, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3033243708609272, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445765808, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4339.179652055519, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 854}}
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445765814, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8791042566299438, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 854}}
:::MLLOG {"namespace": "", "time_ms": 1621445765815, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 854}}
rank 0: cycle = 62: time to send the model = 0.046479225158691406
:::MLLOG {"namespace": "", "time_ms": 1621445765862, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 868, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445765863, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 868, "epoch_count": 14}}
rank 640: cycle = 62: time to receive the model = 0.05510687828063965
:::MLLOG {"namespace": "", "time_ms": 1621445765870, "event_type": "INTERVAL_START", "key": "eval_start", "value": 868, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 868}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445766640, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8772757053375244, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 868}}
:::MLLOG {"namespace": "", "time_ms": 1621445766641, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 868}}
:::MLLOG {"namespace": "", "time_ms": 1621445766665, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4189.824877690278, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445766667, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3241839072847683, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445766667, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4189.824877690278, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 868}}
rank 0: cycle = 63: time to send the model = 0.04090738296508789
:::MLLOG {"namespace": "", "time_ms": 1621445766710, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 882, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445766710, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 882, "epoch_count": 14}}
rank 640: cycle = 63: time to receive the model = 0.050710439682006836
:::MLLOG {"namespace": "", "time_ms": 1621445766720, "event_type": "INTERVAL_START", "key": "eval_start", "value": 882, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 882}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445767486, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8847577571868896, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 882}}
:::MLLOG {"namespace": "", "time_ms": 1621445767487, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 882}}
:::MLLOG {"namespace": "", "time_ms": 1621445767518, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4160.526959995607, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445767520, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3450434437086094, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445767520, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4160.526959995607, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 882}}
rank 0: cycle = 64: time to send the model = 0.04395031929016113
:::MLLOG {"namespace": "", "time_ms": 1621445767565, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 896, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445767565, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 896, "epoch_count": 14}}
rank 640: cycle = 64: time to receive the model = 0.05612826347351074
:::MLLOG {"namespace": "", "time_ms": 1621445767577, "event_type": "INTERVAL_START", "key": "eval_start", "value": 896, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 896}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445768347, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8817682862281799, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 896}}
:::MLLOG {"namespace": "", "time_ms": 1621445768348, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 896}}
:::MLLOG {"namespace": "", "time_ms": 1621445768381, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4116.2724600176125, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445768383, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3659029801324505, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445768383, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4116.2724600176125, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 896}}
rank 0: cycle = 65: time to send the model = 0.0426332950592041
:::MLLOG {"namespace": "", "time_ms": 1621445768426, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 910, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445768427, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 910, "epoch_count": 14}}
rank 640: cycle = 65: time to receive the model = 0.05577588081359863
:::MLLOG {"namespace": "", "time_ms": 1621445768439, "event_type": "INTERVAL_START", "key": "eval_start", "value": 910, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 910}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445769208, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4300.845937990671, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445769209, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8740512728691101, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 910}}
:::MLLOG {"namespace": "", "time_ms": 1621445769210, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3867625165562913, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445769211, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 910}}
:::MLLOG {"namespace": "", "time_ms": 1621445769212, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4300.845937990671, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 910}}
rank 0: cycle = 66: time to send the model = 0.042508840560913086
:::MLLOG {"namespace": "", "time_ms": 1621445769257, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 924, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445769258, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 924, "epoch_count": 14}}
rank 640: cycle = 66: time to receive the model = 0.054894208908081055
:::MLLOG {"namespace": "", "time_ms": 1621445769270, "event_type": "INTERVAL_START", "key": "eval_start", "value": 924, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 924}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445770026, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4373.739256410463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445770028, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4076220529801324, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445770028, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4373.739256410463, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 924}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445770038, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8905850648880005, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 924}}
:::MLLOG {"namespace": "", "time_ms": 1621445770040, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 924}}
rank 0: cycle = 67: time to send the model = 0.03616595268249512
:::MLLOG {"namespace": "", "time_ms": 1621445770076, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 938, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445770077, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 938, "epoch_count": 14}}
rank 640: cycle = 67: time to receive the model = 0.04862618446350098
:::MLLOG {"namespace": "", "time_ms": 1621445770089, "event_type": "INTERVAL_START", "key": "eval_start", "value": 938, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 938}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445770857, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8651245832443237, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 938}}
:::MLLOG {"namespace": "", "time_ms": 1621445770857, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 938}}
:::MLLOG {"namespace": "", "time_ms": 1621445770865, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4268.266969049384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445770868, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4284815894039735, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445770869, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4268.266969049384, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 938}}
rank 0: cycle = 68: time to send the model = 0.04155707359313965
:::MLLOG {"namespace": "", "time_ms": 1621445770911, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 952, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445770911, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 952, "epoch_count": 14}}
rank 640: cycle = 68: time to receive the model = 0.054476261138916016
:::MLLOG {"namespace": "", "time_ms": 1621445770924, "event_type": "INTERVAL_START", "key": "eval_start", "value": 952, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 952}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445771692, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8706557154655457, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 952}}
:::MLLOG {"namespace": "", "time_ms": 1621445771693, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 952}}
:::MLLOG {"namespace": "", "time_ms": 1621445771693, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4298.206752090795, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445771695, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4493411258278146, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445771695, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4298.206752090795, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 952}}
rank 0: cycle = 69: time to send the model = 0.040729522705078125
:::MLLOG {"namespace": "", "time_ms": 1621445771736, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 966, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445771736, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 966, "epoch_count": 14}}
rank 640: cycle = 69: time to receive the model = 0.05318021774291992
:::MLLOG {"namespace": "", "time_ms": 1621445771748, "event_type": "INTERVAL_START", "key": "eval_start", "value": 966, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 966}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445772517, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8704185485839844, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 966}}
:::MLLOG {"namespace": "", "time_ms": 1621445772517, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 966}}
:::MLLOG {"namespace": "", "time_ms": 1621445772537, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4192.782868358176, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445772540, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4702006622516555, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445772541, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4192.782868358176, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 966}}
rank 0: cycle = 70: time to send the model = 0.04349565505981445
:::MLLOG {"namespace": "", "time_ms": 1621445772594, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 980, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445772594, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 980, "epoch_count": 14}}
rank 640: cycle = 70: time to receive the model = 0.0560605525970459
:::MLLOG {"namespace": "", "time_ms": 1621445772607, "event_type": "INTERVAL_START", "key": "eval_start", "value": 980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 980}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445773375, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8738383054733276, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 980}}
:::MLLOG {"namespace": "", "time_ms": 1621445773375, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 980}}
:::MLLOG {"namespace": "", "time_ms": 1621445773388, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4232.928210117258, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445773390, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4910601986754968, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445773390, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4232.928210117258, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 980}}
rank 0: cycle = 71: time to send the model = 0.040618896484375
:::MLLOG {"namespace": "", "time_ms": 1621445773431, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 994, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445773431, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 994, "epoch_count": 14}}
rank 640: cycle = 71: time to receive the model = 0.0521697998046875
:::MLLOG {"namespace": "", "time_ms": 1621445773443, "event_type": "INTERVAL_START", "key": "eval_start", "value": 994, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 994}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445774208, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8851460218429565, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 994}}
:::MLLOG {"namespace": "", "time_ms": 1621445774208, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 994}}
:::MLLOG {"namespace": "", "time_ms": 1621445774241, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4151.831749731615, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445774243, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445774244, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4151.831749731615, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 994}}
rank 0: cycle = 72: time to send the model = 0.03878426551818848
:::MLLOG {"namespace": "", "time_ms": 1621445774283, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1008, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445774284, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1008, "epoch_count": 14}}
rank 640: cycle = 72: time to receive the model = 0.05074596405029297
:::MLLOG {"namespace": "", "time_ms": 1621445774295, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1008, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1008}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445775066, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8765805959701538, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1008}}
:::MLLOG {"namespace": "", "time_ms": 1621445775066, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1008}}
:::MLLOG {"namespace": "", "time_ms": 1621445775093, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4151.66785387918, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445775095, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445775095, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4151.66785387918, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1008}}
rank 0: cycle = 73: time to send the model = 0.03932499885559082
:::MLLOG {"namespace": "", "time_ms": 1621445775136, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1022, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445775136, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1022, "epoch_count": 14}}
rank 640: cycle = 73: time to receive the model = 0.05171513557434082
:::MLLOG {"namespace": "", "time_ms": 1621445775148, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1022, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1022}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445775916, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8931541442871094, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1022}}
:::MLLOG {"namespace": "", "time_ms": 1621445775916, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1022}}
:::MLLOG {"namespace": "", "time_ms": 1621445775934, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4212.7775309945455, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445775936, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445775937, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4212.7775309945455, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1022}}
rank 0: cycle = 74: time to send the model = 0.044911861419677734
:::MLLOG {"namespace": "", "time_ms": 1621445775982, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1036, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445775983, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1036, "epoch_count": 14}}
rank 640: cycle = 74: time to receive the model = 0.05473589897155762
:::MLLOG {"namespace": "", "time_ms": 1621445775992, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1036, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1036}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445776759, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8822000622749329, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1036}}
:::MLLOG {"namespace": "", "time_ms": 1621445776759, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1036}}
:::MLLOG {"namespace": "", "time_ms": 1621445776768, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4279.934535460212, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445776770, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445776770, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4279.934535460212, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1036}}
rank 0: cycle = 75: time to send the model = 0.04020071029663086
:::MLLOG {"namespace": "", "time_ms": 1621445776812, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1050, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445776812, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1050, "epoch_count": 14}}
rank 640: cycle = 75: time to receive the model = 0.052819252014160156
:::MLLOG {"namespace": "", "time_ms": 1621445776824, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1050, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1050}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445777592, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8866348266601562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1050}}
:::MLLOG {"namespace": "", "time_ms": 1621445777592, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1050}}
:::MLLOG {"namespace": "", "time_ms": 1621445777603, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4246.155114387898, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445777606, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445777607, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4246.155114387898, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1050}}
rank 0: cycle = 76: time to send the model = 0.0396113395690918
:::MLLOG {"namespace": "", "time_ms": 1621445777647, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1064, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445777647, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1064, "epoch_count": 14}}
rank 640: cycle = 76: time to receive the model = 0.05249977111816406
:::MLLOG {"namespace": "", "time_ms": 1621445777659, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1064, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1064}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445778429, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8918020725250244, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1064}}
:::MLLOG {"namespace": "", "time_ms": 1621445778429, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1064}}
:::MLLOG {"namespace": "", "time_ms": 1621445778443, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4221.587264119151, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445778444, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445778445, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4221.587264119151, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1064}}
rank 0: cycle = 77: time to send the model = 0.03838992118835449
:::MLLOG {"namespace": "", "time_ms": 1621445778484, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1078, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445778485, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1078, "epoch_count": 14}}
rank 640: cycle = 77: time to receive the model = 0.05002093315124512
:::MLLOG {"namespace": "", "time_ms": 1621445778496, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1078, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1078}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445779263, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8805320262908936, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1078}}
:::MLLOG {"namespace": "", "time_ms": 1621445779263, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1078}}
:::MLLOG {"namespace": "", "time_ms": 1621445779296, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4141.67149077835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445779298, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445779299, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4141.67149077835, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1078}}
rank 0: cycle = 78: time to send the model = 0.04776310920715332
:::MLLOG {"namespace": "", "time_ms": 1621445779347, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1092, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445779348, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1092, "epoch_count": 14}}
rank 640: cycle = 78: time to receive the model = 0.060642242431640625
:::MLLOG {"namespace": "", "time_ms": 1621445779360, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1092}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445780119, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4355.00497989039, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445780121, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445780121, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4355.00497989039, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1092}}
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445780130, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8824774026870728, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1092}}
:::MLLOG {"namespace": "", "time_ms": 1621445780131, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1092}}
rank 0: cycle = 79: time to send the model = 0.036536216735839844
:::MLLOG {"namespace": "", "time_ms": 1621445780168, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1106, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445780169, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1106, "epoch_count": 14}}
rank 640: cycle = 79: time to receive the model = 0.049109697341918945
:::MLLOG {"namespace": "", "time_ms": 1621445780180, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1106, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1106}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445780940, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4356.022636827531, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445780942, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445780943, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4356.022636827531, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1106}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445780949, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.889827311038971, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1106}}
:::MLLOG {"namespace": "", "time_ms": 1621445780950, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1106}}
rank 0: cycle = 80: time to send the model = 0.03857731819152832
:::MLLOG {"namespace": "", "time_ms": 1621445780989, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1120, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445780990, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1120, "epoch_count": 14}}
rank 640: cycle = 80: time to receive the model = 0.05179166793823242
:::MLLOG {"namespace": "", "time_ms": 1621445781002, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1120}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445781756, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4388.444336771028, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445781757, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445781757, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4388.444336771028, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1120}}
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445781772, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8870920538902283, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1621445781773, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1120}}
rank 0: cycle = 81: time to send the model = 0.03563714027404785
:::MLLOG {"namespace": "", "time_ms": 1621445781809, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1134, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445781810, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1134, "epoch_count": 14}}
rank 640: cycle = 81: time to receive the model = 0.04943990707397461
:::MLLOG {"namespace": "", "time_ms": 1621445781823, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1134, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1134}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445782590, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8818686008453369, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1134}}
:::MLLOG {"namespace": "", "time_ms": 1621445782591, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1134}}
:::MLLOG {"namespace": "", "time_ms": 1621445782620, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4149.516392414493, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445782622, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445782623, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4149.516392414493, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1134}}
rank 0: cycle = 82: time to send the model = 0.04847431182861328
:::MLLOG {"namespace": "", "time_ms": 1621445782672, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1148, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445782672, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1148, "epoch_count": 14}}
rank 640: cycle = 82: time to receive the model = 0.060704708099365234
:::MLLOG {"namespace": "", "time_ms": 1621445782684, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1148, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1148}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445783452, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.886969804763794, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1148}}
:::MLLOG {"namespace": "", "time_ms": 1621445783453, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1148}}
:::MLLOG {"namespace": "", "time_ms": 1621445783476, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4177.757097780576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445783478, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445783478, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4177.757097780576, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1148}}
rank 0: cycle = 83: time to send the model = 0.03941822052001953
:::MLLOG {"namespace": "", "time_ms": 1621445783519, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1162, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445783519, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1162, "epoch_count": 14}}
rank 640: cycle = 83: time to receive the model = 0.05110788345336914
:::MLLOG {"namespace": "", "time_ms": 1621445783530, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1162, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1162}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445784298, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8925259113311768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1162}}
:::MLLOG {"namespace": "", "time_ms": 1621445784298, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1162}}
:::MLLOG {"namespace": "", "time_ms": 1621445784299, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4306.852568382997, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445784302, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445784302, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4306.852568382997, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1162}}
rank 0: cycle = 84: time to send the model = 0.03803300857543945
:::MLLOG {"namespace": "", "time_ms": 1621445784341, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1176, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445784341, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1176, "epoch_count": 14}}
rank 640: cycle = 84: time to receive the model = 0.049938201904296875
:::MLLOG {"namespace": "", "time_ms": 1621445784353, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1176, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1176}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.772 s.
:::MLLOG {"namespace": "", "time_ms": 1621445785126, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8817483186721802, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1176}}
:::MLLOG {"namespace": "", "time_ms": 1621445785126, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1176}}
:::MLLOG {"namespace": "", "time_ms": 1621445785131, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4257.704514878849, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445785132, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445785132, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4257.704514878849, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1176}}
rank 0: cycle = 85: time to send the model = 0.04112100601196289
:::MLLOG {"namespace": "", "time_ms": 1621445785174, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1190, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445785174, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1190, "epoch_count": 14}}
rank 640: cycle = 85: time to receive the model = 0.05134868621826172
:::MLLOG {"namespace": "", "time_ms": 1621445785185, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1190, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1190}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445785952, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8515989780426025, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1190}}
:::MLLOG {"namespace": "", "time_ms": 1621445785952, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1190}}
:::MLLOG {"namespace": "", "time_ms": 1621445785976, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4193.51646759195, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445785978, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445785979, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4193.51646759195, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1190}}
rank 0: cycle = 86: time to send the model = 0.04925894737243652
:::MLLOG {"namespace": "", "time_ms": 1621445786029, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1204, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445786029, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1204, "epoch_count": 14}}
rank 640: cycle = 86: time to receive the model = 0.059502601623535156
:::MLLOG {"namespace": "", "time_ms": 1621445786039, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1204, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1204}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.77 s.
:::MLLOG {"namespace": "", "time_ms": 1621445786810, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8786861300468445, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1204}}
:::MLLOG {"namespace": "", "time_ms": 1621445786810, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1204}}
:::MLLOG {"namespace": "", "time_ms": 1621445786823, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4232.6675889145245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445786825, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445786825, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4232.6675889145245, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1204}}
rank 0: cycle = 87: time to send the model = 0.04262375831604004
:::MLLOG {"namespace": "", "time_ms": 1621445786870, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1218, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445786870, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1218, "epoch_count": 14}}
rank 640: cycle = 87: time to receive the model = 0.05692791938781738
:::MLLOG {"namespace": "", "time_ms": 1621445786884, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1218}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445787635, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4394.439322277435, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445787637, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445787637, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4394.439322277435, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1218}}
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445787653, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8678814172744751, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1218}}
:::MLLOG {"namespace": "", "time_ms": 1621445787654, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1218}}
rank 0: cycle = 88: time to send the model = 0.03664374351501465
:::MLLOG {"namespace": "", "time_ms": 1621445787691, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1232, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445787693, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1232, "epoch_count": 14}}
rank 640: cycle = 88: time to receive the model = 0.0514528751373291
:::MLLOG {"namespace": "", "time_ms": 1621445787706, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1232, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1232}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.771 s.
:::MLLOG {"namespace": "", "time_ms": 1621445788479, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8836563229560852, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1232}}
:::MLLOG {"namespace": "", "time_ms": 1621445788479, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1232}}
:::MLLOG {"namespace": "", "time_ms": 1621445788536, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3983.2926294653494, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445788537, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445788538, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3983.2926294653494, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1232}}
rank 0: cycle = 89: time to send the model = 0.04107379913330078
:::MLLOG {"namespace": "", "time_ms": 1621445788579, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1246, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445788579, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1246, "epoch_count": 14}}
rank 640: cycle = 89: time to receive the model = 0.05346202850341797
:::MLLOG {"namespace": "", "time_ms": 1621445788591, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1246, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1246}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445789360, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8813717365264893, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1246}}
:::MLLOG {"namespace": "", "time_ms": 1621445789360, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1246}}
:::MLLOG {"namespace": "", "time_ms": 1621445789383, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4179.98878246434, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445789385, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445789386, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4179.98878246434, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1246}}
rank 0: cycle = 90: time to send the model = 0.04572868347167969
:::MLLOG {"namespace": "", "time_ms": 1621445789432, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1260, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445789432, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1260, "epoch_count": 14}}
rank 640: cycle = 90: time to receive the model = 0.058084964752197266
:::MLLOG {"namespace": "", "time_ms": 1621445789444, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1260}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445790212, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8934472799301147, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1621445790212, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1621445790228, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4222.610571581638, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445790230, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445790230, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4222.610571581638, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1260}}
rank 0: cycle = 91: time to send the model = 0.04038834571838379
:::MLLOG {"namespace": "", "time_ms": 1621445790274, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1274, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445790274, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1274, "epoch_count": 14}}
rank 640: cycle = 91: time to receive the model = 0.052046775817871094
:::MLLOG {"namespace": "", "time_ms": 1621445790285, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1274, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1274}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445791054, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8915143609046936, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1274}}
:::MLLOG {"namespace": "", "time_ms": 1621445791054, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1274}}
:::MLLOG {"namespace": "", "time_ms": 1621445791068, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4231.891000934791, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445791070, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445791071, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4231.891000934791, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1274}}
rank 0: cycle = 92: time to send the model = 0.04030871391296387
:::MLLOG {"namespace": "", "time_ms": 1621445791112, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1288, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445791112, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1288, "epoch_count": 14}}
rank 640: cycle = 92: time to receive the model = 0.05238485336303711
:::MLLOG {"namespace": "", "time_ms": 1621445791124, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1288, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1288}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445791875, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4406.947065456613, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445791877, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445791877, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4406.947065456613, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1288}}
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445791894, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8761051893234253, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1288}}
:::MLLOG {"namespace": "", "time_ms": 1621445791896, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1288}}
rank 0: cycle = 93: time to send the model = 0.03734111785888672
:::MLLOG {"namespace": "", "time_ms": 1621445791933, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1302, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445791934, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1302, "epoch_count": 14}}
rank 640: cycle = 93: time to receive the model = 0.04960155487060547
:::MLLOG {"namespace": "", "time_ms": 1621445791945, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1302, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1302}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445792713, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8975014686584473, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1302}}
:::MLLOG {"namespace": "", "time_ms": 1621445792713, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1302}}
:::MLLOG {"namespace": "", "time_ms": 1621445792736, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4189.523454486755, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445792739, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445792740, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4189.523454486755, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1302}}
rank 0: cycle = 94: time to send the model = 0.04388570785522461
:::MLLOG {"namespace": "", "time_ms": 1621445792784, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1316, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445792784, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1316, "epoch_count": 14}}
rank 640: cycle = 94: time to receive the model = 0.053681135177612305
:::MLLOG {"namespace": "", "time_ms": 1621445792794, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1316, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1316}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445793560, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8912050724029541, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1316}}
:::MLLOG {"namespace": "", "time_ms": 1621445793560, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1316}}
:::MLLOG {"namespace": "", "time_ms": 1621445793564, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4309.375878938769, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445793566, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445793566, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4309.375878938769, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1316}}
rank 0: cycle = 95: time to send the model = 0.04229283332824707
:::MLLOG {"namespace": "", "time_ms": 1621445793612, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1330, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445793612, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1330, "epoch_count": 14}}
rank 640: cycle = 95: time to receive the model = 0.05519580841064453
:::MLLOG {"namespace": "", "time_ms": 1621445793624, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1330, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1330}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445794391, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8900170922279358, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1330}}
:::MLLOG {"namespace": "", "time_ms": 1621445794391, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1330}}
:::MLLOG {"namespace": "", "time_ms": 1621445794419, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4161.700298524388, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445794422, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445794422, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4161.700298524388, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1330}}
rank 0: cycle = 96: time to send the model = 0.041864633560180664
:::MLLOG {"namespace": "", "time_ms": 1621445794464, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1344, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445794465, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1344, "epoch_count": 14}}
rank 640: cycle = 96: time to receive the model = 0.0550539493560791
:::MLLOG {"namespace": "", "time_ms": 1621445794478, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1344, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1344}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445795246, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8779119849205017, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1344}}
:::MLLOG {"namespace": "", "time_ms": 1621445795246, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1344}}
:::MLLOG {"namespace": "", "time_ms": 1621445795266, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4191.877451891688, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445795268, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445795268, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4191.877451891688, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1344}}
rank 0: cycle = 97: time to send the model = 0.039147138595581055
:::MLLOG {"namespace": "", "time_ms": 1621445795309, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1358, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445795309, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1358, "epoch_count": 14}}
rank 640: cycle = 97: time to receive the model = 0.05133795738220215
:::MLLOG {"namespace": "", "time_ms": 1621445795321, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1358, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1358}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445796085, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4331.831928309674, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445796087, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445796087, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4331.831928309674, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1358}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445796089, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8837606310844421, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1358}}
:::MLLOG {"namespace": "", "time_ms": 1621445796091, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1358}}
rank 0: cycle = 98: time to send the model = 0.047747135162353516
:::MLLOG {"namespace": "", "time_ms": 1621445796139, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1372, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445796140, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1372, "epoch_count": 14}}
rank 640: cycle = 98: time to receive the model = 0.05619192123413086
:::MLLOG {"namespace": "", "time_ms": 1621445796147, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1372}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445796908, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4375.7572776827665, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445796910, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445796910, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4375.7572776827665, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1372}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445796914, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.893476665019989, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1372}}
:::MLLOG {"namespace": "", "time_ms": 1621445796915, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1372}}
rank 0: cycle = 99: time to send the model = 0.038616180419921875
:::MLLOG {"namespace": "", "time_ms": 1621445796954, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1386, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445796955, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1386, "epoch_count": 14}}
rank 640: cycle = 99: time to receive the model = 0.05055809020996094
:::MLLOG {"namespace": "", "time_ms": 1621445796966, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1386}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445797732, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8919562101364136, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1386}}
:::MLLOG {"namespace": "", "time_ms": 1621445797732, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1386}}
:::MLLOG {"namespace": "", "time_ms": 1621445797741, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4274.539394364031, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445797743, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445797744, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4274.539394364031, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1386}}
rank 0: cycle = 100: time to send the model = 0.041109561920166016
:::MLLOG {"namespace": "", "time_ms": 1621445797785, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1400, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445797786, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1400, "epoch_count": 14}}
rank 640: cycle = 100: time to receive the model = 0.05383920669555664
:::MLLOG {"namespace": "", "time_ms": 1621445797798, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1400}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445798566, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8819471001625061, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1621445798566, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1621445798570, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4282.78298235724, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445798572, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445798572, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4282.78298235724, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1400}}
rank 0: cycle = 101: time to send the model = 0.04044151306152344
:::MLLOG {"namespace": "", "time_ms": 1621445798613, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1414, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445798613, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1414, "epoch_count": 14}}
rank 640: cycle = 101: time to receive the model = 0.05232691764831543
:::MLLOG {"namespace": "", "time_ms": 1621445798625, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1414, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1414}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445799392, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8971189856529236, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1414}}
:::MLLOG {"namespace": "", "time_ms": 1621445799393, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1414}}
:::MLLOG {"namespace": "", "time_ms": 1621445799408, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4227.111924034216, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445799410, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445799411, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4227.111924034216, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1414}}
rank 0: cycle = 102: time to send the model = 0.04778289794921875
:::MLLOG {"namespace": "", "time_ms": 1621445799459, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1428, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445799459, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1428, "epoch_count": 14}}
rank 640: cycle = 102: time to receive the model = 0.05724501609802246
:::MLLOG {"namespace": "", "time_ms": 1621445799468, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1428, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1428}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445800234, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8966821432113647, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1428}}
:::MLLOG {"namespace": "", "time_ms": 1621445800235, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1428}}
:::MLLOG {"namespace": "", "time_ms": 1621445800242, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4292.225504104655, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445800244, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445800244, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4292.225504104655, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1428}}
rank 0: cycle = 103: time to send the model = 0.03877854347229004
:::MLLOG {"namespace": "", "time_ms": 1621445800285, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1442, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445800285, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1442, "epoch_count": 14}}
rank 640: cycle = 103: time to receive the model = 0.04928112030029297
:::MLLOG {"namespace": "", "time_ms": 1621445800296, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1442, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1442}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445801064, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8927844762802124, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1442}}
:::MLLOG {"namespace": "", "time_ms": 1621445801064, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1442}}
:::MLLOG {"namespace": "", "time_ms": 1621445801078, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4240.299895924632, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445801080, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445801081, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4240.299895924632, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1442}}
rank 0: cycle = 104: time to send the model = 0.04259896278381348
:::MLLOG {"namespace": "", "time_ms": 1621445801124, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1456, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445801124, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1456, "epoch_count": 14}}
rank 640: cycle = 104: time to receive the model = 0.05563473701477051
:::MLLOG {"namespace": "", "time_ms": 1621445801137, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1456, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1456}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445801904, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.870078444480896, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1456}}
:::MLLOG {"namespace": "", "time_ms": 1621445801904, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1456}}
:::MLLOG {"namespace": "", "time_ms": 1621445801911, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4270.155173019795, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445801913, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445801913, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4270.155173019795, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1456}}
rank 0: cycle = 105: time to send the model = 0.04205179214477539
:::MLLOG {"namespace": "", "time_ms": 1621445801956, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1470, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445801956, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1470, "epoch_count": 14}}
rank 640: cycle = 105: time to receive the model = 0.054732561111450195
:::MLLOG {"namespace": "", "time_ms": 1621445801969, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1470, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1470}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445802738, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8910651206970215, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1470}}
:::MLLOG {"namespace": "", "time_ms": 1621445802738, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1470}}
:::MLLOG {"namespace": "", "time_ms": 1621445802742, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4275.544434183334, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445802745, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445802745, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4275.544434183334, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1470}}
rank 0: cycle = 106: time to send the model = 0.04887890815734863
:::MLLOG {"namespace": "", "time_ms": 1621445802794, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1484, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445802795, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1484, "epoch_count": 14}}
rank 640: cycle = 106: time to receive the model = 0.060950279235839844
:::MLLOG {"namespace": "", "time_ms": 1621445802806, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1484}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445803576, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.893346905708313, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1484}}
:::MLLOG {"namespace": "", "time_ms": 1621445803577, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1484}}
:::MLLOG {"namespace": "", "time_ms": 1621445803590, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4223.297692821522, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445803592, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445803592, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4223.297692821522, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1484}}
rank 0: cycle = 107: time to send the model = 0.042147159576416016
:::MLLOG {"namespace": "", "time_ms": 1621445803636, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1498, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445803636, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1498, "epoch_count": 14}}
rank 640: cycle = 107: time to receive the model = 0.05309414863586426
:::MLLOG {"namespace": "", "time_ms": 1621445803647, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1498, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1498}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445804414, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8983653783798218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1498}}
:::MLLOG {"namespace": "", "time_ms": 1621445804414, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1498}}
:::MLLOG {"namespace": "", "time_ms": 1621445804432, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4222.715586686974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445804434, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445804435, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4222.715586686974, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1498}}
rank 0: cycle = 108: time to send the model = 0.03923153877258301
:::MLLOG {"namespace": "", "time_ms": 1621445804475, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1512, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445804475, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1512, "epoch_count": 14}}
rank 640: cycle = 108: time to receive the model = 0.0519871711730957
:::MLLOG {"namespace": "", "time_ms": 1621445804487, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1512, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1512}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445805256, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8923686146736145, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1512}}
:::MLLOG {"namespace": "", "time_ms": 1621445805257, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1512}}
:::MLLOG {"namespace": "", "time_ms": 1621445805270, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4226.110512691951, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445805272, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445805272, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4226.110512691951, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1512}}
rank 0: cycle = 109: time to send the model = 0.038613080978393555
:::MLLOG {"namespace": "", "time_ms": 1621445805311, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1526, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445805312, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1526, "epoch_count": 14}}
rank 640: cycle = 109: time to receive the model = 0.05056571960449219
:::MLLOG {"namespace": "", "time_ms": 1621445805323, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1526, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1526}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445806089, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8760900497436523, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1526}}
:::MLLOG {"namespace": "", "time_ms": 1621445806090, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1526}}
:::MLLOG {"namespace": "", "time_ms": 1621445806127, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4123.6436479082395, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445806129, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445806129, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4123.6436479082395, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1526}}
rank 0: cycle = 110: time to send the model = 0.04768562316894531
:::MLLOG {"namespace": "", "time_ms": 1621445806177, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1540, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445806178, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1540, "epoch_count": 14}}
rank 640: cycle = 110: time to receive the model = 0.05761384963989258
:::MLLOG {"namespace": "", "time_ms": 1621445806187, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1540}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445806954, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8882147073745728, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1621445806954, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1621445806959, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4299.215084282894, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445806961, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445806961, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4299.215084282894, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1540}}
rank 0: cycle = 111: time to send the model = 0.04076981544494629
:::MLLOG {"namespace": "", "time_ms": 1621445807003, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1554, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445807004, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1554, "epoch_count": 14}}
rank 640: cycle = 111: time to receive the model = 0.05272674560546875
:::MLLOG {"namespace": "", "time_ms": 1621445807015, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1554, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1554}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445807774, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4364.860941280537, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445807776, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445807777, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4364.860941280537, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1554}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445807783, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8955073356628418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1554}}
:::MLLOG {"namespace": "", "time_ms": 1621445807785, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1554}}
rank 0: cycle = 112: time to send the model = 0.036092281341552734
:::MLLOG {"namespace": "", "time_ms": 1621445807821, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1568, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445807822, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1568, "epoch_count": 14}}
rank 640: cycle = 112: time to receive the model = 0.05030632019042969
:::MLLOG {"namespace": "", "time_ms": 1621445807835, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1568, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1568}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445808602, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8892670273780823, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1568}}
:::MLLOG {"namespace": "", "time_ms": 1621445808602, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1568}}
:::MLLOG {"namespace": "", "time_ms": 1621445808636, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4127.684885811702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445808638, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445808638, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4127.684885811702, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1568}}
rank 0: cycle = 113: time to send the model = 0.038245201110839844
:::MLLOG {"namespace": "", "time_ms": 1621445808676, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1582, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445808677, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1582, "epoch_count": 14}}
rank 640: cycle = 113: time to receive the model = 0.05078530311584473
:::MLLOG {"namespace": "", "time_ms": 1621445808689, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1582, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1582}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445809454, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8769928216934204, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1582}}
:::MLLOG {"namespace": "", "time_ms": 1621445809454, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1582}}
:::MLLOG {"namespace": "", "time_ms": 1621445809460, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4290.326878448271, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445809462, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445809463, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4290.326878448271, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1582}}
rank 0: cycle = 114: time to send the model = 0.04536581039428711
:::MLLOG {"namespace": "", "time_ms": 1621445809509, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1596, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445809509, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1596, "epoch_count": 14}}
rank 640: cycle = 114: time to receive the model = 0.05486130714416504
:::MLLOG {"namespace": "", "time_ms": 1621445809518, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1596, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1596}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445810284, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8860579133033752, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1596}}
:::MLLOG {"namespace": "", "time_ms": 1621445810284, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1596}}
:::MLLOG {"namespace": "", "time_ms": 1621445810300, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4249.778791003999, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445810301, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445810301, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4249.778791003999, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1596}}
rank 0: cycle = 115: time to send the model = 0.03975415229797363
:::MLLOG {"namespace": "", "time_ms": 1621445810354, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1610, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445810355, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1610, "epoch_count": 14}}
rank 640: cycle = 115: time to receive the model = 0.051909446716308594
:::MLLOG {"namespace": "", "time_ms": 1621445810367, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1610, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1610}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445811134, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8961402177810669, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1610}}
:::MLLOG {"namespace": "", "time_ms": 1621445811134, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1610}}
:::MLLOG {"namespace": "", "time_ms": 1621445811171, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4115.178667320757, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445811174, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445811174, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4115.178667320757, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1610}}
rank 0: cycle = 116: time to send the model = 0.03988909721374512
:::MLLOG {"namespace": "", "time_ms": 1621445811215, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1624, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445811215, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1624, "epoch_count": 14}}
rank 640: cycle = 116: time to receive the model = 0.05277872085571289
:::MLLOG {"namespace": "", "time_ms": 1621445811228, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1624, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1624}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445811976, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4415.296142303452, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445811978, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445811978, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4415.296142303452, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1624}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445811996, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8873844742774963, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1624}}
:::MLLOG {"namespace": "", "time_ms": 1621445811997, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1624}}
rank 0: cycle = 117: time to send the model = 0.03646254539489746
:::MLLOG {"namespace": "", "time_ms": 1621445812034, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1638, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445812035, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1638, "epoch_count": 14}}
rank 640: cycle = 117: time to receive the model = 0.04971742630004883
:::MLLOG {"namespace": "", "time_ms": 1621445812047, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1638, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1638}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445812814, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8902021646499634, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1638}}
:::MLLOG {"namespace": "", "time_ms": 1621445812815, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1638}}
:::MLLOG {"namespace": "", "time_ms": 1621445812836, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4192.731725602899, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445812839, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445812839, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4192.731725602899, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1638}}
rank 0: cycle = 118: time to send the model = 0.04989337921142578
:::MLLOG {"namespace": "", "time_ms": 1621445812890, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1652, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445812890, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1652, "epoch_count": 14}}
rank 640: cycle = 118: time to receive the model = 0.05952262878417969
:::MLLOG {"namespace": "", "time_ms": 1621445812899, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1652, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1652}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445813656, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4388.377377385482, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445813658, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445813658, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4388.377377385482, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1652}}
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445813669, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8976542353630066, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1652}}
:::MLLOG {"namespace": "", "time_ms": 1621445813670, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1652}}
rank 0: cycle = 119: time to send the model = 0.036469459533691406
:::MLLOG {"namespace": "", "time_ms": 1621445813707, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1666, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445813708, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1666, "epoch_count": 14}}
rank 640: cycle = 119: time to receive the model = 0.04980897903442383
:::MLLOG {"namespace": "", "time_ms": 1621445813720, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1666, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1666}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445814480, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4349.449914016273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445814483, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445814483, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4349.449914016273, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1666}}
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445814487, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8882608413696289, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1666}}
:::MLLOG {"namespace": "", "time_ms": 1621445814488, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1666}}
rank 0: cycle = 120: time to send the model = 0.04099130630493164
:::MLLOG {"namespace": "", "time_ms": 1621445814529, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1680, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445814531, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1680, "epoch_count": 14}}
rank 640: cycle = 120: time to receive the model = 0.05419754981994629
:::MLLOG {"namespace": "", "time_ms": 1621445814543, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1680}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445815308, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.892220139503479, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1621445815308, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1621445815328, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4213.162919735961, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445815330, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445815330, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4213.162919735961, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1680}}
rank 0: cycle = 121: time to send the model = 0.04034829139709473
:::MLLOG {"namespace": "", "time_ms": 1621445815371, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1694, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445815371, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1694, "epoch_count": 14}}
rank 640: cycle = 121: time to receive the model = 0.05220317840576172
:::MLLOG {"namespace": "", "time_ms": 1621445815383, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1694, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1694}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445816150, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.885504961013794, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1694}}
:::MLLOG {"namespace": "", "time_ms": 1621445816150, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1694}}
:::MLLOG {"namespace": "", "time_ms": 1621445816152, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4305.988000679529, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445816154, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445816154, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4305.988000679529, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1694}}
rank 0: cycle = 122: time to send the model = 0.04960298538208008
:::MLLOG {"namespace": "", "time_ms": 1621445816204, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1708, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445816205, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1708, "epoch_count": 14}}
rank 640: cycle = 122: time to receive the model = 0.059748172760009766
:::MLLOG {"namespace": "", "time_ms": 1621445816214, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1708, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1708}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445816983, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8941149115562439, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1708}}
:::MLLOG {"namespace": "", "time_ms": 1621445816983, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1708}}
:::MLLOG {"namespace": "", "time_ms": 1621445816990, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4277.511788844912, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445816992, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445816992, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4277.511788844912, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1708}}
rank 0: cycle = 123: time to send the model = 0.04193902015686035
:::MLLOG {"namespace": "", "time_ms": 1621445817037, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1722, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445817037, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1722, "epoch_count": 14}}
rank 640: cycle = 123: time to receive the model = 0.05446338653564453
:::MLLOG {"namespace": "", "time_ms": 1621445817049, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1722}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445817817, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.904529333114624, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1722}}
:::MLLOG {"namespace": "", "time_ms": 1621445817818, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1722}}
:::MLLOG {"namespace": "", "time_ms": 1621445817824, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4269.270354438049, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445817826, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445817826, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4269.270354438049, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1722}}
rank 0: cycle = 124: time to send the model = 0.042160749435424805
:::MLLOG {"namespace": "", "time_ms": 1621445817869, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1736, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445817869, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1736, "epoch_count": 14}}
rank 640: cycle = 124: time to receive the model = 0.05537605285644531
:::MLLOG {"namespace": "", "time_ms": 1621445817882, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1736, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1736}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445818646, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4323.647988454614, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445818648, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445818648, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4323.647988454614, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1736}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445818650, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9022431373596191, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1736}}
:::MLLOG {"namespace": "", "time_ms": 1621445818651, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1736}}
rank 0: cycle = 125: time to send the model = 0.037778615951538086
:::MLLOG {"namespace": "", "time_ms": 1621445818689, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1750, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445818691, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1750, "epoch_count": 14}}
rank 640: cycle = 125: time to receive the model = 0.050859689712524414
:::MLLOG {"namespace": "", "time_ms": 1621445818702, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1750, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1750}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445819470, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8928881883621216, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1750}}
:::MLLOG {"namespace": "", "time_ms": 1621445819470, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1750}}
:::MLLOG {"namespace": "", "time_ms": 1621445819535, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3978.3944043909846, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445819538, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445819538, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3978.3944043909846, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1750}}
rank 0: cycle = 126: time to send the model = 0.04766583442687988
:::MLLOG {"namespace": "", "time_ms": 1621445819586, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1764, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445819587, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1764, "epoch_count": 14}}
rank 640: cycle = 126: time to receive the model = 0.06110644340515137
:::MLLOG {"namespace": "", "time_ms": 1621445819600, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1764, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1764}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445820368, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8869656324386597, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1764}}
:::MLLOG {"namespace": "", "time_ms": 1621445820368, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1764}}
:::MLLOG {"namespace": "", "time_ms": 1621445820477, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3774.2602827040605, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445820479, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445820479, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3774.2602827040605, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1764}}
rank 0: cycle = 127: time to send the model = 0.04026293754577637
:::MLLOG {"namespace": "", "time_ms": 1621445820520, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1778, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445820520, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1778, "epoch_count": 14}}
rank 640: cycle = 127: time to receive the model = 0.05189967155456543
:::MLLOG {"namespace": "", "time_ms": 1621445820532, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1778, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1778}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.77 s.
:::MLLOG {"namespace": "", "time_ms": 1621445821303, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8930312395095825, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1778}}
:::MLLOG {"namespace": "", "time_ms": 1621445821303, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1778}}
:::MLLOG {"namespace": "", "time_ms": 1621445821376, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3926.820882210098, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445821379, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445821380, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3926.820882210098, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1778}}
rank 0: cycle = 128: time to send the model = 0.03861236572265625
:::MLLOG {"namespace": "", "time_ms": 1621445821419, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1792, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445821419, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1792, "epoch_count": 14}}
rank 640: cycle = 128: time to receive the model = 0.05074048042297363
:::MLLOG {"namespace": "", "time_ms": 1621445821431, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1792, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1792}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445822201, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8885776400566101, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1792}}
:::MLLOG {"namespace": "", "time_ms": 1621445822201, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1792}}
:::MLLOG {"namespace": "", "time_ms": 1621445822265, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3971.254250126384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445822267, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445822267, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3971.254250126384, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1792}}
rank 0: cycle = 129: time to send the model = 0.03998589515686035
:::MLLOG {"namespace": "", "time_ms": 1621445822308, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1806, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445822308, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1806, "epoch_count": 14}}
rank 640: cycle = 129: time to receive the model = 0.05108809471130371
:::MLLOG {"namespace": "", "time_ms": 1621445822319, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1806, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1806}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445823086, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8946095108985901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1806}}
:::MLLOG {"namespace": "", "time_ms": 1621445823086, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1806}}
:::MLLOG {"namespace": "", "time_ms": 1621445823187, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3824.481219069784, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445823189, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445823190, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3824.481219069784, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1806}}
rank 0: cycle = 130: time to send the model = 0.04599595069885254
:::MLLOG {"namespace": "", "time_ms": 1621445823236, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1820, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445823236, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1820, "epoch_count": 14}}
rank 640: cycle = 130: time to receive the model = 0.05574297904968262
:::MLLOG {"namespace": "", "time_ms": 1621445823246, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1820}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445824013, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8811582326889038, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1621445824013, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1621445824093, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3922.635787771989, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445824095, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445824095, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3922.635787771989, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1820}}
rank 0: cycle = 131: time to send the model = 0.03777647018432617
:::MLLOG {"namespace": "", "time_ms": 1621445824134, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1834, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445824134, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1834, "epoch_count": 14}}
rank 640: cycle = 131: time to receive the model = 0.0498356819152832
:::MLLOG {"namespace": "", "time_ms": 1621445824146, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1834, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1834}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445824913, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8908812999725342, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1834}}
:::MLLOG {"namespace": "", "time_ms": 1621445824914, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1834}}
:::MLLOG {"namespace": "", "time_ms": 1621445824959, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4073.3638865123594, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445824962, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445824963, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4073.3638865123594, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1834}}
rank 0: cycle = 132: time to send the model = 0.043939828872680664
:::MLLOG {"namespace": "", "time_ms": 1621445825007, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1848, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445825007, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1848, "epoch_count": 14}}
rank 640: cycle = 132: time to receive the model = 0.05653500556945801
:::MLLOG {"namespace": "", "time_ms": 1621445825019, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1848, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1848}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445825788, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8966876864433289, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1848}}
:::MLLOG {"namespace": "", "time_ms": 1621445825788, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1848}}
:::MLLOG {"namespace": "", "time_ms": 1621445825869, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3899.487646612686, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445825870, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445825870, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3899.487646612686, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1848}}
rank 0: cycle = 133: time to send the model = 0.04131197929382324
:::MLLOG {"namespace": "", "time_ms": 1621445825913, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1862, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445825913, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1862, "epoch_count": 14}}
rank 640: cycle = 133: time to receive the model = 0.0535435676574707
:::MLLOG {"namespace": "", "time_ms": 1621445825925, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1862, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1862}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445826693, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8971281051635742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1862}}
:::MLLOG {"namespace": "", "time_ms": 1621445826693, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1862}}
:::MLLOG {"namespace": "", "time_ms": 1621445826842, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3616.679397325381, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445826844, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445826844, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3616.679397325381, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1862}}
rank 0: cycle = 134: time to send the model = 0.04413485527038574
:::MLLOG {"namespace": "", "time_ms": 1621445826894, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1876, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445826894, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1876, "epoch_count": 14}}
rank 640: cycle = 134: time to receive the model = 0.056627750396728516
:::MLLOG {"namespace": "", "time_ms": 1621445826906, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1876, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1876}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445827674, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8898663520812988, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1876}}
:::MLLOG {"namespace": "", "time_ms": 1621445827675, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1876}}
:::MLLOG {"namespace": "", "time_ms": 1621445827758, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3889.735402653536, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445827759, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445827759, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3889.735402653536, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1876}}
rank 0: cycle = 135: time to send the model = 0.04046773910522461
:::MLLOG {"namespace": "", "time_ms": 1621445827803, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1890, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445827803, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1890, "epoch_count": 14}}
rank 640: cycle = 135: time to receive the model = 0.05175948143005371
:::MLLOG {"namespace": "", "time_ms": 1621445827814, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1890, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1890}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445828579, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8981561660766602, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1890}}
:::MLLOG {"namespace": "", "time_ms": 1621445828579, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1890}}
:::MLLOG {"namespace": "", "time_ms": 1621445828590, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4269.847255945517, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445828592, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445828593, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4269.847255945517, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1890}}
rank 0: cycle = 136: time to send the model = 0.04300999641418457
:::MLLOG {"namespace": "", "time_ms": 1621445828637, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1904, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445828637, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1904, "epoch_count": 14}}
rank 640: cycle = 136: time to receive the model = 0.05573725700378418
:::MLLOG {"namespace": "", "time_ms": 1621445828649, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1904, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1904}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445829415, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8929722309112549, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1904}}
:::MLLOG {"namespace": "", "time_ms": 1621445829416, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1904}}
:::MLLOG {"namespace": "", "time_ms": 1621445829461, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4077.3260023874564, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445829463, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445829463, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4077.3260023874564, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1904}}
rank 0: cycle = 137: time to send the model = 0.0394282341003418
:::MLLOG {"namespace": "", "time_ms": 1621445829504, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1918, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445829504, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1918, "epoch_count": 14}}
rank 640: cycle = 137: time to receive the model = 0.051146745681762695
:::MLLOG {"namespace": "", "time_ms": 1621445829516, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1918, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1918}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445830281, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4323.617479575899, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445830284, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8969435095787048, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1918}}
:::MLLOG {"namespace": "", "time_ms": 1621445830284, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445830285, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1918}}
:::MLLOG {"namespace": "", "time_ms": 1621445830286, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4323.617479575899, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1918}}
rank 0: cycle = 138: time to send the model = 0.04262685775756836
:::MLLOG {"namespace": "", "time_ms": 1621445830330, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1932, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445830331, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1932, "epoch_count": 14}}
rank 640: cycle = 138: time to receive the model = 0.05134248733520508
:::MLLOG {"namespace": "", "time_ms": 1621445830339, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1932, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1932}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445831108, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9059295654296875, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1932}}
:::MLLOG {"namespace": "", "time_ms": 1621445831109, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1932}}
:::MLLOG {"namespace": "", "time_ms": 1621445831114, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4288.099802069371, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445831116, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445831116, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4288.099802069371, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1932}}
rank 0: cycle = 139: time to send the model = 0.0419306755065918
:::MLLOG {"namespace": "", "time_ms": 1621445831161, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1946, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445831161, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1946, "epoch_count": 14}}
rank 640: cycle = 139: time to receive the model = 0.05443739891052246
:::MLLOG {"namespace": "", "time_ms": 1621445831173, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1946, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1946}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445831933, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4353.993178996202, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445831935, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445831935, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4353.993178996202, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1946}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445831940, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8935537338256836, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1946}}
:::MLLOG {"namespace": "", "time_ms": 1621445831942, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1946}}
rank 0: cycle = 140: time to send the model = 0.03709983825683594
:::MLLOG {"namespace": "", "time_ms": 1621445831979, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1960, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445831980, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1960, "epoch_count": 14}}
rank 640: cycle = 140: time to receive the model = 0.04977679252624512
:::MLLOG {"namespace": "", "time_ms": 1621445831992, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1960}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445832759, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8971438407897949, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1621445832760, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1621445832780, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4204.637898740416, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445832781, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445832781, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4204.637898740416, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1960}}
rank 0: cycle = 141: time to send the model = 0.04012799263000488
:::MLLOG {"namespace": "", "time_ms": 1621445832822, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1974, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445832822, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1974, "epoch_count": 14}}
rank 640: cycle = 141: time to receive the model = 0.05137896537780762
:::MLLOG {"namespace": "", "time_ms": 1621445832833, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1974}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445833600, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8995642066001892, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1974}}
:::MLLOG {"namespace": "", "time_ms": 1621445833600, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1974}}
:::MLLOG {"namespace": "", "time_ms": 1621445833618, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4221.578411954377, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445833620, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445833620, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4221.578411954377, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1974}}
rank 0: cycle = 142: time to send the model = 0.04853940010070801
:::MLLOG {"namespace": "", "time_ms": 1621445833669, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1988, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445833669, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1988, "epoch_count": 14}}
rank 640: cycle = 142: time to receive the model = 0.05805397033691406
:::MLLOG {"namespace": "", "time_ms": 1621445833678, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1988, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1988}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445834444, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8930237889289856, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1988}}
:::MLLOG {"namespace": "", "time_ms": 1621445834445, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1988}}
:::MLLOG {"namespace": "", "time_ms": 1621445834478, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4151.133447601329, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445834480, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445834480, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4151.133447601329, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1988}}
rank 0: cycle = 143: time to send the model = 0.03934836387634277
:::MLLOG {"namespace": "", "time_ms": 1621445834521, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2002, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445834521, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2002, "epoch_count": 14}}
rank 640: cycle = 143: time to receive the model = 0.04980015754699707
:::MLLOG {"namespace": "", "time_ms": 1621445834531, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2002, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2002}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445835301, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9029374122619629, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2002}}
:::MLLOG {"namespace": "", "time_ms": 1621445835301, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2002}}
:::MLLOG {"namespace": "", "time_ms": 1621445835344, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4081.1670057295596, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445835347, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445835347, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4081.1670057295596, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2002}}
rank 0: cycle = 144: time to send the model = 0.04216456413269043
:::MLLOG {"namespace": "", "time_ms": 1621445835390, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2016, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445835390, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2016, "epoch_count": 14}}
rank 640: cycle = 144: time to receive the model = 0.054993391036987305
:::MLLOG {"namespace": "", "time_ms": 1621445835403, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2016, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2016}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445836168, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8980274200439453, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2016}}
:::MLLOG {"namespace": "", "time_ms": 1621445836169, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2016}}
:::MLLOG {"namespace": "", "time_ms": 1621445836176, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4278.422107998964, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445836177, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445836177, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4278.422107998964, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2016}}
rank 0: cycle = 145: time to send the model = 0.03971219062805176
:::MLLOG {"namespace": "", "time_ms": 1621445836217, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2030, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445836218, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2030, "epoch_count": 14}}
rank 640: cycle = 145: time to receive the model = 0.05066680908203125
:::MLLOG {"namespace": "", "time_ms": 1621445836228, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2030, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2030}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445836994, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8943833708763123, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2030}}
:::MLLOG {"namespace": "", "time_ms": 1621445836995, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2030}}
:::MLLOG {"namespace": "", "time_ms": 1621445837030, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4138.01468476727, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445837032, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445837033, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4138.01468476727, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2030}}
rank 0: cycle = 146: time to send the model = 0.04705476760864258
:::MLLOG {"namespace": "", "time_ms": 1621445837080, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2044, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445837081, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2044, "epoch_count": 14}}
rank 640: cycle = 146: time to receive the model = 0.059508323669433594
:::MLLOG {"namespace": "", "time_ms": 1621445837093, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2044, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2044}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445837852, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4358.765677467963, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445837853, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445837853, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4358.765677467963, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2044}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445837861, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9053714275360107, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2044}}
:::MLLOG {"namespace": "", "time_ms": 1621445837863, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2044}}
rank 0: cycle = 147: time to send the model = 0.03590202331542969
:::MLLOG {"namespace": "", "time_ms": 1621445837907, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2058, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445837908, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2058, "epoch_count": 14}}
rank 640: cycle = 147: time to receive the model = 0.04974699020385742
:::MLLOG {"namespace": "", "time_ms": 1621445837921, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2058, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2058}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445838689, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8942984938621521, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2058}}
:::MLLOG {"namespace": "", "time_ms": 1621445838689, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2058}}
:::MLLOG {"namespace": "", "time_ms": 1621445838712, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4184.440675550488, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445838714, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445838715, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4184.440675550488, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2058}}
rank 0: cycle = 148: time to send the model = 0.04077649116516113
:::MLLOG {"namespace": "", "time_ms": 1621445838756, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2072, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445838756, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2072, "epoch_count": 14}}
rank 640: cycle = 148: time to receive the model = 0.05378127098083496
:::MLLOG {"namespace": "", "time_ms": 1621445838769, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2072, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2072}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445839534, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8968436121940613, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2072}}
:::MLLOG {"namespace": "", "time_ms": 1621445839534, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2072}}
:::MLLOG {"namespace": "", "time_ms": 1621445839541, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4282.136221461513, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445839543, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445839543, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4282.136221461513, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2072}}
rank 0: cycle = 149: time to send the model = 0.040338993072509766
:::MLLOG {"namespace": "", "time_ms": 1621445839584, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2086, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445839584, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2086, "epoch_count": 14}}
rank 640: cycle = 149: time to receive the model = 0.05148029327392578
:::MLLOG {"namespace": "", "time_ms": 1621445839595, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2086, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2086}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445840363, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8998072147369385, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2086}}
:::MLLOG {"namespace": "", "time_ms": 1621445840363, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2086}}
:::MLLOG {"namespace": "", "time_ms": 1621445840391, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4166.428608594877, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445840393, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445840394, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4166.428608594877, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2086}}
rank 0: cycle = 150: time to send the model = 0.04972124099731445
:::MLLOG {"namespace": "", "time_ms": 1621445840444, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2100, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445840444, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2100, "epoch_count": 14}}
rank 640: cycle = 150: time to receive the model = 0.059305429458618164
:::MLLOG {"namespace": "", "time_ms": 1621445840453, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2100}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445841221, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8959336876869202, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1621445841221, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1621445841230, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4278.536412242084, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445841231, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445841231, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4278.536412242084, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2100}}
rank 0: cycle = 151: time to send the model = 0.040360212326049805
:::MLLOG {"namespace": "", "time_ms": 1621445841273, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2114, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445841273, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2114, "epoch_count": 14}}
rank 640: cycle = 151: time to receive the model = 0.051270246505737305
:::MLLOG {"namespace": "", "time_ms": 1621445841284, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2114, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2114}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445842049, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9045150876045227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2114}}
:::MLLOG {"namespace": "", "time_ms": 1621445842049, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2114}}
:::MLLOG {"namespace": "", "time_ms": 1621445842060, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4269.496698552634, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445842063, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445842064, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4269.496698552634, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2114}}
rank 0: cycle = 152: time to send the model = 0.03972363471984863
:::MLLOG {"namespace": "", "time_ms": 1621445842104, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2128, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445842104, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2128, "epoch_count": 14}}
rank 640: cycle = 152: time to receive the model = 0.050615549087524414
:::MLLOG {"namespace": "", "time_ms": 1621445842115, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2128, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2128}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445842876, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4358.502810338781, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445842877, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445842877, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4358.502810338781, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2128}}
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445842884, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8977581858634949, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2128}}
:::MLLOG {"namespace": "", "time_ms": 1621445842885, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2128}}
rank 0: cycle = 153: time to send the model = 0.038126230239868164
:::MLLOG {"namespace": "", "time_ms": 1621445842926, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2142, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445842927, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2142, "epoch_count": 14}}
rank 640: cycle = 153: time to receive the model = 0.05028271675109863
:::MLLOG {"namespace": "", "time_ms": 1621445842938, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2142, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2142}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445843706, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9042384624481201, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2142}}
:::MLLOG {"namespace": "", "time_ms": 1621445843707, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2142}}
:::MLLOG {"namespace": "", "time_ms": 1621445843745, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4108.614922818037, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445843747, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445843747, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4108.614922818037, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2142}}
rank 0: cycle = 154: time to send the model = 0.04878377914428711
:::MLLOG {"namespace": "", "time_ms": 1621445843797, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2156, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445843797, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2156, "epoch_count": 14}}
rank 640: cycle = 154: time to receive the model = 0.05996870994567871
:::MLLOG {"namespace": "", "time_ms": 1621445843808, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2156, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2156}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445844562, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4393.153010600343, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445844563, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445844563, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4393.153010600343, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2156}}
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445844578, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.903191328048706, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2156}}
:::MLLOG {"namespace": "", "time_ms": 1621445844580, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2156}}
rank 0: cycle = 155: time to send the model = 0.036773681640625
:::MLLOG {"namespace": "", "time_ms": 1621445844617, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2170, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445844618, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2170, "epoch_count": 14}}
rank 640: cycle = 155: time to receive the model = 0.05055499076843262
:::MLLOG {"namespace": "", "time_ms": 1621445844630, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2170, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2170}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445845395, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8998056054115295, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2170}}
:::MLLOG {"namespace": "", "time_ms": 1621445845395, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2170}}
:::MLLOG {"namespace": "", "time_ms": 1621445845438, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4097.879433403643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445845440, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445845441, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4097.879433403643, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2170}}
rank 0: cycle = 156: time to send the model = 0.04273676872253418
:::MLLOG {"namespace": "", "time_ms": 1621445845484, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2184, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445845485, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2184, "epoch_count": 14}}
rank 640: cycle = 156: time to receive the model = 0.05482792854309082
:::MLLOG {"namespace": "", "time_ms": 1621445845496, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2184, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2184}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445846266, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9027485251426697, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2184}}
:::MLLOG {"namespace": "", "time_ms": 1621445846266, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2184}}
:::MLLOG {"namespace": "", "time_ms": 1621445846272, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4269.650626259958, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445846273, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445846273, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4269.650626259958, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2184}}
rank 0: cycle = 157: time to send the model = 0.03848671913146973
:::MLLOG {"namespace": "", "time_ms": 1621445846313, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2198, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445846314, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2198, "epoch_count": 14}}
rank 640: cycle = 157: time to receive the model = 0.05030465126037598
:::MLLOG {"namespace": "", "time_ms": 1621445846325, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2198, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2198}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445847094, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.899725615978241, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2198}}
:::MLLOG {"namespace": "", "time_ms": 1621445847094, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2198}}
:::MLLOG {"namespace": "", "time_ms": 1621445847113, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4202.908705054187, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445847116, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445847116, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4202.908705054187, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2198}}
rank 0: cycle = 158: time to send the model = 0.04976963996887207
:::MLLOG {"namespace": "", "time_ms": 1621445847167, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2212, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445847167, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2212, "epoch_count": 14}}
rank 640: cycle = 158: time to receive the model = 0.060158491134643555
:::MLLOG {"namespace": "", "time_ms": 1621445847177, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2212, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2212}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445847943, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9010292291641235, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2212}}
:::MLLOG {"namespace": "", "time_ms": 1621445847943, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2212}}
:::MLLOG {"namespace": "", "time_ms": 1621445847950, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4293.268960575748, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445847951, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445847951, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4293.268960575748, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2212}}
rank 0: cycle = 159: time to send the model = 0.04214119911193848
:::MLLOG {"namespace": "", "time_ms": 1621445847994, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 2226, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445847995, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 2226, "epoch_count": 14}}
rank 640: cycle = 159: time to receive the model = 0.05433917045593262
:::MLLOG {"namespace": "", "time_ms": 1621445848007, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2226, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 2226}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445848772, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4325.3385877521705, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445848774, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445848774, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4325.3385877521705, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 2226}}
EVALUATION TIME: 0.768 s.
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
:::MLLOG {"namespace": "", "time_ms": 1621445848776, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9094072580337524, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 2226}}
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
:::MLLOG {"namespace": "", "time_ms": 1621445848777, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 2226}}
STOP TRAINING TRIGGERED AFTER EVAL
:::MLLOG {"namespace": "", "time_ms": 1621445848778, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 102, "status": "success"}}
rank 0: cycle = 160: time to send the model = 0.03999829292297363
rank 640: cycle = 160: time to receive the model = 0.05275750160217285
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
+ set +x
+ ret_code=0
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ set +x
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
+ ret_code=0
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
+ set +x
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
+ set +x
+ ret_code=0
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
+ ret_code=0
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:51 AM
RESULT,image_segmentation,,549,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
+ set +x
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
+ ret_code=0
+ set +x
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
+ ret_code=0
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:52 AM
RESULT,image_segmentation,,550,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:53 AM
RESULT,image_segmentation,,551,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:54 AM
RESULT,image_segmentation,,552,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
ENDING TIMING RUN AT 2021-05-19 10:37:55 AM
RESULT,image_segmentation,,553,nvidia,2021-05-19 10:28:42 AM
