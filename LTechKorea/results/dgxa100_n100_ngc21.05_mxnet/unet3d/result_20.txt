+ echo 'Beginning trial 8 of 10'
Beginning trial 8 of 10
+ '[' 1 -eq 1 ']'
+ srun --ntasks=100 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on luna-0046
Clearing cache on luna-0380
Clearing cache on luna-0043
Clearing cache on luna-0344
Clearing cache on luna-0122
Clearing cache on luna-0347
Clearing cache on luna-0338
Clearing cache on luna-0299
Clearing cache on luna-0059
Clearing cache on luna-0052
Clearing cache on luna-0049
Clearing cache on luna-0110
Clearing cache on luna-0113
Clearing cache on luna-0119
Clearing cache on luna-0339
Clearing cache on luna-0060
Clearing cache on luna-0300
Clearing cache on luna-0345
Clearing cache on luna-0041
Clearing cache on luna-0111
Clearing cache on luna-0044
Clearing cache on luna-0047
Clearing cache on luna-0050
Clearing cache on luna-0294
Clearing cache on luna-0120
Clearing cache on luna-0342
Clearing cache on luna-0346
Clearing cache on luna-0109
Clearing cache on luna-0058
Clearing cache on luna-0125
Clearing cache on luna-0118
Clearing cache on luna-0045
Clearing cache on luna-0055
Clearing cache on luna-0051
Clearing cache on luna-0042
Clearing cache on luna-0295
Clearing cache on luna-0115
Clearing cache on luna-0121
Clearing cache on luna-0340
Clearing cache on luna-0126
Clearing cache on luna-0351
Clearing cache on luna-0124
Clearing cache on luna-0291
Clearing cache on luna-0388
Clearing cache on luna-0292
Clearing cache on luna-0337
Clearing cache on luna-0048
Clearing cache on luna-0298
Clearing cache on luna-0379
Clearing cache on luna-0286
Clearing cache on luna-0370
Clearing cache on luna-0289
Clearing cache on luna-0112
Clearing cache on luna-0352
Clearing cache on luna-0382
Clearing cache on luna-0373
Clearing cache on luna-0376
Clearing cache on luna-0355
Clearing cache on luna-0385
Clearing cache on luna-0350
Clearing cache on luna-0281
Clearing cache on luna-0056
Clearing cache on luna-0293
Clearing cache on luna-0374
Clearing cache on luna-0341
Clearing cache on luna-0116
Clearing cache on luna-0353
Clearing cache on luna-0383
Clearing cache on luna-0356
Clearing cache on luna-0401
Clearing cache on luna-0284
Clearing cache on luna-0386
Clearing cache on luna-0296
Clearing cache on luna-0348
Clearing cache on luna-0057
Clearing cache on luna-0054
Clearing cache on luna-0127
Clearing cache on luna-0297
Clearing cache on luna-0378
Clearing cache on luna-0288
Clearing cache on luna-0402
Clearing cache on luna-0114
Clearing cache on luna-0387
Clearing cache on luna-0369
Clearing cache on luna-0372
Clearing cache on luna-0381
Clearing cache on luna-0371
Clearing cache on luna-0384
Clearing cache on luna-0354
Clearing cache on luna-0375
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
Clearing cache on luna-0285
Clearing cache on luna-0283
Clearing cache on luna-0349
Clearing cache on luna-0128
Clearing cache on luna-0343
Clearing cache on luna-0117
Clearing cache on luna-0282
Clearing cache on luna-0377
Clearing cache on luna-0290
Clearing cache on luna-0287
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --mpi=pmix --ntasks=800 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/lustre/fsw/mlperf/mlperft-unet3d/dataset/:/data,/lustre/fsw/mlperf-ci/23360857/results:/results,/lustre/fsw/mlperf/mlperft-unet3d/rachitg/logs/single_node:/profile_dir ./run_and_time.sh
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 0 ']'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' -n 3 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ DATASET_DIR=/data
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 5 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ TARGET_DIR=
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 5 ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 3 ']'
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ DATASET_DIR=/data
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
running benchmark
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 6 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ '[' -n 4 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 2 ']'
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=selene
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 5 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ DATASET_DIR=/data
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' -n 7 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ '[' -n 2 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 3 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 1 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
+ LR=1.5
running benchmark
+ declare -a CMD
+ '[' -n 5 ']'
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
running benchmark
+ '[' -n 0 ']'
+ '[' -n 1 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 5 ']'
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
running benchmark
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 6 ']'
+ TARGET_DIR=
+ BATCH_SIZE=1
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
running benchmark
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
+ LR=1.5
+ cluster=
running benchmark
+ declare -a CMD
running benchmark
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ DATASET_DIR=/data
running benchmark
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
running benchmark
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ BATCH_SIZE=1
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
running benchmark
+ '[' -n 7 ']'
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ BATCH_SIZE=1
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' -n 3 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR=1.5
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ MAX_EPOCHS=7000
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ '[' -n 5 ']'
running benchmark
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ cluster=
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ echo 'running benchmark'
running benchmark
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ echo 'running benchmark'
running benchmark
+ OPTIMIZER=nag
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ SEED=-1
running benchmark
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ OPTIMIZER=nag
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
running benchmark
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ EVALUATE_EVERY=14
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
+ declare -a CMD
+ echo 'running benchmark'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
running benchmark
+ EVALUATE_EVERY=14
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ LR=1.5
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ MAX_EPOCHS=7000
+ declare -a CMD
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ EVALUATE_EVERY=14
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 2 ']'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ SEED=-1
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
running benchmark
+ cluster=
+ BATCH_SIZE=1
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ declare -a CMD
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ '[' -n 5 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ declare -a CMD
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ DATASET_DIR=/data
+ cluster=
+ OPTIMIZER=nag
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
+ '[' -n 0 ']'
running benchmark
+ '[' -n 7 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ cluster=
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ SEED=-1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ PROFILING_PREFIX=
+ cluster=
+ echo 'running benchmark'
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' -n 7 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ SEED=-1
running benchmark
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 4 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ '[' -n 6 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
running benchmark
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' -n 6 ']'
running benchmark
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
running benchmark
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 5 ']'
+ '[' -n 6 ']'
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ '[' -n 7 ']'
running benchmark
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ OPTIMIZER=nag
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ declare -a CMD
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=
running benchmark
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 4 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ MAX_EPOCHS=7000
+ cluster=selene
running benchmark
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ SEED=-1
running benchmark
+ '[' -n 3 ']'
running benchmark
+ OPTIMIZER=nag
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' '' = apiLog.sh ']'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ START_EVAL_AT=700
running benchmark
+ BATCH_SIZE=1
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ MAX_EPOCHS=7000
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ '[' -n 7 ']'
+ '[' -n 7 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ SEED=-1
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ LR=1.5
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 0 ']'
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
running benchmark
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
running benchmark
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
+ '[' -n 1 ']'
+ declare -a CMD
+ START_EVAL_AT=700
+ cluster=
running benchmark
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 6 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 6 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ OPTIMIZER=nag
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
running benchmark
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ '[' -n 5 ']'
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ cluster=
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 7 ']'
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ declare -a CMD
+ VAL_BATCH_SIZE=1
running benchmark
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ declare -a CMD
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
+ TARGET_DIR=
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 1 ']'
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
running benchmark
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ cluster=
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ declare -a CMD
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' -n 0 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
running benchmark
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ cluster=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ cluster=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ LR=1.5
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
+ START_EVAL_AT=700
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ MAX_EPOCHS=7000
+ declare -a CMD
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ '[' -n 5 ']'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 5 ']'
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ cluster=
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ BATCH_SIZE=1
+ START_EVAL_AT=700
running benchmark
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ '[' -n 1 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
running benchmark
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ declare -a CMD
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ '[' -n 4 ']'
+ TARGET_DIR=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 3 ']'
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
running benchmark
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' -n 2 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 7 ']'
+ '[' -n 6 ']'
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 0 ']'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ cluster=
+ '[' 800 -gt 100 ']'
+ '[' -n 4 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ '[' -n 5 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' -n 3 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
running benchmark
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ '[' -n 2 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ TARGET_DIR=
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ MAX_EPOCHS=7000
+ '[' -n 0 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 5 ']'
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ cluster=
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ '[' -n 0 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ '[' -n 7 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ DATASET_DIR=/data
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ TARGET_DIR=
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ DATASET_DIR=/data
running benchmark
+ '[' -n 4 ']'
running benchmark
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ cluster=
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
running benchmark
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
running benchmark
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ BATCH_SIZE=1
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
running benchmark
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ SEED=-1
+ declare -a CMD
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
+ echo 'running benchmark'
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ '[' -n 0 ']'
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ cluster=
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' -n 7 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ '[' -n 0 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ cluster=
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ echo 'running benchmark'
+ cluster=selene
+ MAX_EPOCHS=7000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ MAX_EPOCHS=7000
+ SEED=-1
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ declare -a CMD
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
running benchmark
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
running benchmark
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ '[' -n 1 ']'
+ cluster=
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ cluster=
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ declare -a CMD
+ '[' 800 -gt 100 ']'
running benchmark
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ EVALUATE_EVERY=14
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ DATASET_DIR=/data
running benchmark
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
running benchmark
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 3 ']'
+ '[' -n 7 ']'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ echo 'running benchmark'
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ cluster=
+ '[' -n 6 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 1 ']'
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ '[' -n 1 ']'
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=
running benchmark
+ '[' -n 5 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ LR=1.5
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ cluster=
+ BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 2 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 2 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 3 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=
+ LR=1.5
+ declare -a CMD
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ '[' -n 6 ']'
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ SEED=-1
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
running benchmark
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 3 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=selene
+ '[' '' = apiLog.sh ']'
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ TARGET_DIR=
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' -n 1 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
running benchmark
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' -n 0 ']'
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ cluster=
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 7 ']'
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
running benchmark
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
running benchmark
+ START_EVAL_AT=700
+ '[' -n 6 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 3 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 7 ']'
+ cluster=selene
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 3 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 0 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' -n 1 ']'
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 1 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ TARGET_DIR=
+ SEED=-1
running benchmark
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
running benchmark
+ declare -a CMD
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 7 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' -n 4 ']'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 1 ']'
+ SEED=-1
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' '' = apiLog.sh ']'
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
running benchmark
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ '[' -n 3 ']'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ declare -a CMD
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 0 ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ '[' -n 2 ']'
+ declare -a CMD
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
+ PROFILING_PREFIX=
running benchmark
+ '[' -n 3 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ '[' -n 1 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 6 ']'
+ MAX_EPOCHS=7000
running benchmark
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ '[' -n 1 ']'
+ START_EVAL_AT=700
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ echo 'running benchmark'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
+ TARGET_DIR=
running benchmark
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 3 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=
+ declare -a CMD
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ cluster=
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ cluster=
+ PROFILING_PREFIX=
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ '[' -n 6 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ cluster=
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ '[' -n 7 ']'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
running benchmark
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ QUALITY_THRESHOLD=0.908
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ EVALUATE_EVERY=14
+ cluster=
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ SEED=-1
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 2 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
running benchmark
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ PROFILING_PREFIX=
running benchmark
+ START_EVAL_AT=700
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
running benchmark
+ '[' -n 2 ']'
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ TARGET_DIR=
+ '[' -n 3 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
running benchmark
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 7 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ DATASET_DIR=/data
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 1 ']'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ '[' -n 0 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
running benchmark
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
running benchmark
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
running benchmark
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ EVALUATE_EVERY=14
+ '[' -n 2 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
running benchmark
+ declare -a CMD
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 5 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 6 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ '[' -n 2 ']'
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
running benchmark
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
running benchmark
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
running benchmark
+ BATCH_SIZE=1
+ '[' -n 7 ']'
+ '[' -n 1 ']'
+ '[' -n 0 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' -n 3 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ cluster=selene
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 5 ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 0 ']'
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 7 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ MAX_EPOCHS=7000
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' '' = apiLog.sh ']'
running benchmark
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ '[' -n 6 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ BATCH_SIZE=1
running benchmark
+ '[' -n 2 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ '[' -n 2 ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
+ VAL_BATCH_SIZE=1
running benchmark
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 6 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ EVALUATE_EVERY=14
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 5 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 0 ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 6 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ '[' -n 6 ']'
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ cluster=
running benchmark
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ '[' -n 1 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 5 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ '[' -n 7 ']'
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
running benchmark
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
running benchmark
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ '[' -n 0 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
+ DATASET_DIR=/data
running benchmark
+ '[' -n 3 ']'
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 0 ']'
+ '[' -n 1 ']'
running benchmark
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 5 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ '[' -n 5 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 7 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ '[' -n 5 ']'
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 4 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR=1.5
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
running benchmark
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 0 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' -n 7 ']'
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 3 ']'
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' -n 2 ']'
+ QUALITY_THRESHOLD=0.908
running benchmark
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=
+ START_EVAL_AT=700
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 0 ']'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 6 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ cluster=
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
running benchmark
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 6 ']'
+ declare -a CMD
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 3 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ declare -a CMD
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 3 ']'
+ LR=1.5
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ '[' -n 5 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ cluster=
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ SEED=-1
+ MAX_EPOCHS=7000
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 3 ']'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 1 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
running benchmark
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
+ SEED=-1
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 7 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ DATASET_DIR=/data
+ '[' -n 6 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' -n 6 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 6 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
running benchmark
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=selene
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ SEED=-1
+ '[' -n 7 ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' -n 3 ']'
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ cluster=
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 5 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ '[' -n 3 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=selene
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ SEED=-1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ '[' -n 5 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
running benchmark
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 2 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 6 ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ SEED=-1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ '[' -n 6 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ '[' -n 4 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 2 ']'
+ SEED=-1
+ cluster=
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
running benchmark
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 3 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
running benchmark
+ cluster=
+ TARGET_DIR=
+ '[' -n 7 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 0 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
running benchmark
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 5 ']'
+ DATASET_DIR=/data
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
running benchmark
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
running benchmark
+ LR=1.5
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ declare -a CMD
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ declare -a CMD
+ '[' -n 4 ']'
running benchmark
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ '[' -n 4 ']'
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ SEED=-1
+ '[' -n 1 ']'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ EVALUATE_EVERY=14
+ '[' -n 2 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' 800 -gt 100 ']'
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ cluster=
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 6 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ EVALUATE_EVERY=14
+ VAL_BATCH_SIZE=1
+ LR=1.5
running benchmark
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' -n 3 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ SEED=-1
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ EVALUATE_EVERY=14
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' -n 2 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ '[' 800 -gt 100 ']'
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ SEED=-1
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 6 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ TARGET_DIR=
+ START_EVAL_AT=700
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ '[' -n 2 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ OPTIMIZER=nag
+ cluster=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ DATASET_DIR=/data
+ '[' -n 3 ']'
+ SEED=-1
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
running benchmark
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ TARGET_DIR=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ '[' -n 6 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 2 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 3 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ cluster=
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ declare -a CMD
running benchmark
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 0 ']'
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
running benchmark
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
running benchmark
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=selene
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ declare -a CMD
+ START_EVAL_AT=700
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ '[' -n 7 ']'
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 3 ']'
+ START_EVAL_AT=700
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 0 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' -n 7 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ DATASET_DIR=/data
+ LR=1.5
+ MAX_EPOCHS=7000
+ SEED=-1
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ LR_WARMUP_EPOCHS=1000
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ declare -a CMD
+ '[' -n 6 ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 1 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 5 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:17 AM
running benchmark
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
running benchmark
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 3 ']'
running benchmark
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
running benchmark
+ '[' -n 6 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ DATASET_DIR=/data
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
running benchmark
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 4 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ TARGET_DIR=
running benchmark
+ '[' -n 1 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
running benchmark
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ BATCH_SIZE=1
+ '[' -n 3 ']'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
running benchmark
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ '[' -n 4 ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ SEED=-1
+ '[' -n 2 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ cluster=selene
+ LR=1.5
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 0 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
running benchmark
+ '[' -n 2 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' -n 7 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 0 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
running benchmark
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ '[' -n 3 ']'
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
running benchmark
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ EVALUATE_EVERY=14
+ cluster=
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
running benchmark
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ declare -a CMD
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ '[' -n 6 ']'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
+ '[' 800 -gt 100 ']'
+ '[' -n 7 ']'
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ SEED=-1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 0 ']'
+ SEED=-1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
running benchmark
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 5 ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
running benchmark
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ '[' -n 2 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ OPTIMIZER=nag
running benchmark
+ cluster=
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 4 ']'
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 1 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' -n 1 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ PROFILING_PREFIX=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ '[' -n 4 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ LR=1.5
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ MAX_EPOCHS=7000
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ TARGET_DIR=
+ declare -a CMD
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ SEED=-1
running benchmark
+ '[' -n 7 ']'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
running benchmark
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
running benchmark
+ '[' -n 5 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
running benchmark
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ cluster=
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 5 ']'
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 1 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ cluster=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ DATASET_DIR=/data
+ declare -a CMD
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' -n 1 ']'
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 3 ']'
+ '[' -n 7 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 4 ']'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ SEED=-1
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ cluster=
+ DATASET_DIR=/data
+ cluster=
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ OPTIMIZER=nag
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ OPTIMIZER=nag
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' '' = apiLog.sh ']'
+ cluster=
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ TARGET_DIR=
+ OPTIMIZER=nag
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ TARGET_DIR=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ '[' -n 6 ']'
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ '[' -n 3 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ EVALUATE_EVERY=14
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 0 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ LR=1.5
+ SEED=-1
+ TARGET_DIR=
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' -n 5 ']'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 6 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ cluster=selene
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ DATASET_DIR=/data
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 4 ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 7 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
+ '[' -n 3 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ '[' -n 1 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ VAL_BATCH_SIZE=1
+ START_EVAL_AT=700
+ LR=1.5
+ EVALUATE_EVERY=14
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
running benchmark
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 1 ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ '[' -n 0 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 6 ']'
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ cluster=
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ '[' -n 6 ']'
+ EVALUATE_EVERY=14
+ '[' -n 2 ']'
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ '[' -n 0 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' -n 1 ']'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ VAL_BATCH_SIZE=1
+ cluster=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 7 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ SEED=-1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 5 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' -n 0 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ SEED=-1
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
running benchmark
+ VAL_BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ EVALUATE_EVERY=14
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ PROFILING_PREFIX=
running benchmark
+ TARGET_DIR=
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 0 ']'
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ EVALUATE_EVERY=14
running benchmark
+ '[' -n 3 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 1 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ EVALUATE_EVERY=14
+ cluster=
+ TARGET_DIR=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 2 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ declare -a CMD
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ START_EVAL_AT=700
+ '[' -n 4 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ cluster=
+ SEED=-1
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ declare -a CMD
+ PROFILING_PREFIX=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ DATASET_DIR=/data
+ SEED=-1
+ LR_WARMUP_EPOCHS=1000
+ SEED=-1
+ QUALITY_THRESHOLD=0.908
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ OPTIMIZER=nag
+ EVALUATE_EVERY=14
+ BATCH_SIZE=1
+ TARGET_DIR=
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ '[' -n 6 ']'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ cluster=
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ LR_WARMUP_EPOCHS=1000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ DATASET_DIR=/data
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' -n 2 ']'
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ QUALITY_THRESHOLD=0.908
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ '[' -n 3 ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
running benchmark
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 2 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ PROFILING_PREFIX=
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ declare -a CMD
+ '[' -n 7 ']'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ cluster=
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
running benchmark
+ declare -a CMD
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
running benchmark
+ '[' -n 5 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' -n 2 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
running benchmark
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 4 ']'
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ cluster=
+ PROFILING_PREFIX=
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ '[' '' = apiLog.sh ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ '[' '' = apiLog.sh ']'
running benchmark
+ PROFILING_PREFIX=
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 3 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ cluster=selene
running benchmark
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' '' = apiLog.sh ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ echo 'running benchmark'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ SEED=-1
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ OPTIMIZER=nag
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ BATCH_SIZE=1
+ PROFILING_PREFIX=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ START_EVAL_AT=700
+ declare -a CMD
+ EVALUATE_EVERY=14
+ SEED=-1
+ OPTIMIZER=nag
+ TARGET_DIR=
+ BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ VAL_BATCH_SIZE=1
+ PROFILING_PREFIX=
+ LR=1.5
+ declare -a CMD
+ MAX_EPOCHS=7000
+ '[' -n 2 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ QUALITY_THRESHOLD=0.908
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ TARGET_DIR=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ '[' -n 4 ']'
+ DATASET_DIR=/data
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ SEED=-1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' 800 -gt 100 ']'
+ echo 'running benchmark'
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ '[' -n 1 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ SEED=-1
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 4 ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ MAX_EPOCHS=7000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 6 ']'
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ MAX_EPOCHS=7000
+ PROFILING_PREFIX=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 4 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ START_EVAL_AT=700
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 5 ']'
+ echo 'running benchmark'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR=1.5
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ LR_WARMUP_EPOCHS=1000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ QUALITY_THRESHOLD=0.908
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ SEED=-1
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ declare -a CMD
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ TARGET_DIR=
+ '[' -n 6 ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ cluster=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ BATCH_SIZE=1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' -n 0 ']'
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' 800 -gt 100 ']'
+ LR_WARMUP_EPOCHS=1000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
+ DATASET_DIR=/data
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' -n 4 ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=selene
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ declare -a CMD
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ '[' -n 1 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' 800 -gt 100 ']'
+ cluster=
+ QUALITY_THRESHOLD=0.908
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ EVALUATE_EVERY=14
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ '[' -n 6 ']'
+ '[' '' = apiLog.sh ']'
+ declare -a CMD
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ '[' 800 -gt 100 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ cluster=
+ '[' -n 0 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ LR=1.5
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ SEED=-1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ PROFILING_PREFIX=
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ '[' -n 6 ']'
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ echo 'running benchmark'
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ VAL_BATCH_SIZE=1
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ declare -a CMD
+ PROFILING_PREFIX=
+ '[' '' = apiLog.sh ']'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ declare -a CMD
+ DATASET_DIR=/data
+ declare -a CMD
+ SEED=-1
+ echo 'running benchmark'
+ '[' -n 5 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
+ SEED=-1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ OPTIMIZER=nag
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ echo 'running benchmark'
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' -n 0 ']'
+ PROFILING_PREFIX=
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ LR_WARMUP_EPOCHS=1000
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
running benchmark
+ START_EVAL_AT=700
+ PROFILING_PREFIX=
+ EVALUATE_EVERY=14
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 2 ']'
+ TARGET_DIR=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=
+ PROFILING_PREFIX=
+ declare -a CMD
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ DATASET_DIR=/data
+ '[' 800 -gt 100 ']'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ DATASET_DIR=/data
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' -n 4 ']'
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
running benchmark
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ OPTIMIZER=nag
+ START_EVAL_AT=700
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ LR=1.5
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ TARGET_DIR=
+ START_EVAL_AT=700
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ SEED=-1
+ declare -a CMD
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ VAL_BATCH_SIZE=1
+ '[' -n 3 ']'
running benchmark
+ LR=1.5
+ '[' 800 -gt 100 ']'
+ MAX_EPOCHS=7000
+ cluster=
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ '[' -n 7 ']'
+ '[' -n 7 ']'
+ DATASET_DIR=/data
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ SEED=-1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ OPTIMIZER=nag
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ '[' '' = apiLog.sh ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ MAX_EPOCHS=7000
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 0 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ START_EVAL_AT=700
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ SEED=-1
+ OPTIMIZER=nag
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ DATASET_DIR=/data
+ QUALITY_THRESHOLD=0.908
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ '[' -n 6 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ cluster=
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ echo 'running benchmark'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ DATASET_DIR=/data
+ EVALUATE_EVERY=14
+ SEED=-1
+ TARGET_DIR=
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ '[' -n 6 ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ cluster=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ VAL_BATCH_SIZE=1
+ '[' '' = apiLog.sh ']'
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' 800 -gt 100 ']'
+ cluster=
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ LR_WARMUP_EPOCHS=1000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ echo 'running benchmark'
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ PROFILING_PREFIX=
+ declare -a CMD
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ LR=1.5
+ SEED=-1
+ OPTIMIZER=nag
+ DATASET_DIR=/data
+ SEED=-1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ LR=1.5
+ MAX_EPOCHS=7000
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ START_EVAL_AT=700
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ PROFILING_PREFIX=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ echo 'running benchmark'
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 5 ']'
+ SEED=-1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ '[' 800 -gt 100 ']'
+ cluster=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ '[' '' = apiLog.sh ']'
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ QUALITY_THRESHOLD=0.908
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ DATASET_DIR=/data
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ SEED=-1
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ '[' -n 5 ']'
+ EVALUATE_EVERY=14
+ '[' 800 -gt 100 ']'
+ TARGET_DIR=
+ cluster=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ declare -a CMD
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 0 ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ '[' '' = apiLog.sh ']'
+ cluster=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ echo 'running benchmark'
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ DATASET_DIR=/data
+ '[' '' = apiLog.sh ']'
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ OPTIMIZER=nag
+ QUALITY_THRESHOLD=0.908
+ BATCH_SIZE=1
+ START_EVAL_AT=700
+ VAL_BATCH_SIZE=1
+ EVALUATE_EVERY=14
+ LR=1.5
+ TARGET_DIR=
+ MAX_EPOCHS=7000
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
+ declare -a CMD
+ declare -a CMD
+ '[' -n 1 ']'
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ LR_WARMUP_EPOCHS=1000
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ '[' '' = apiLog.sh ']'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ PROFILING_PREFIX=
+ MAX_EPOCHS=7000
+ declare -a CMD
+ LR_WARMUP_EPOCHS=1000
+ '[' -n 3 ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ PROFILING_PREFIX=
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 0 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ '[' -n 5 ']'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ '[' 800 -gt 100 ']'
+ cluster=
+ PROFILING_PREFIX=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ declare -a CMD
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' -n 2 ']'
+ echo 'running benchmark'
+ '[' 800 -gt 100 ']'
+ DATASET_DIR=/data
+ cluster=
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ VAL_BATCH_SIZE=1
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ LR=1.5
+ MAX_EPOCHS=7000
+ '[' -n 0 ']'
+ LR_WARMUP_EPOCHS=1000
+ '[' '' = apiLog.sh ']'
+ QUALITY_THRESHOLD=0.908
+ '[' 800 -gt 100 ']'
+ cluster=
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ PROFILING_PREFIX=
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 1 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ VAL_BATCH_SIZE=1
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ MAX_EPOCHS=7000
+ LR=1.5
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ '[' '' = apiLog.sh ']'
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' '' = apiLog.sh ']'
+ '[' -n 4 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 4 ']'
+ '[' -n 5 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 7 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ LR_WARMUP_EPOCHS=1000
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ QUALITY_THRESHOLD=0.908
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ TARGET_DIR=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ PROFILING_PREFIX=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ declare -a CMD
+ '[' -n 2 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ EVALUATE_EVERY=14
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' -n 3 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ echo 'running benchmark'
running benchmark
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
running benchmark
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ BATCH_SIZE=1
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ SEED=-1
+ MAX_EPOCHS=7000
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ LR_WARMUP_EPOCHS=1000
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ QUALITY_THRESHOLD=0.908
+ MAX_EPOCHS=7000
+ START_EVAL_AT=700
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ EVALUATE_EVERY=14
+ START_EVAL_AT=700
+ TARGET_DIR=
+ EVALUATE_EVERY=14
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ PROFILING_PREFIX=
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ declare -a CMD
+ declare -a CMD
+ '[' -n 6 ']'
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ '[' -n 0 ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ '[' '' = apiLog.sh ']'
num_sockets = 2 num_nodes=8 cores_per_socket=64
STARTING TIMING RUN AT 2021-05-19 10:16:18 AM
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
running benchmark
+ echo 'running benchmark'
+ DATASET_DIR=/data
+ SEED=-1
+ OPTIMIZER=nag
+ BATCH_SIZE=1
+ VAL_BATCH_SIZE=1
+ LR=1.5
+ MAX_EPOCHS=7000
+ LR_WARMUP_EPOCHS=1000
+ QUALITY_THRESHOLD=0.908
+ START_EVAL_AT=700
+ EVALUATE_EVERY=14
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ TARGET_DIR=
+ ASYNC_PARAMS=' --nodes_for_eval 20 -sgs 8 -ucl'
+ PROFILING_PREFIX=
+ declare -a CMD
+ '[' -n 1 ']'
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ '[' 800 -gt 100 ']'
+ cluster=
+ [[ DGXA100_static_100x8x1 == DGX2* ]]
+ [[ DGXA100_static_100x8x1 == DGXA100* ]]
+ cluster=selene
+ CMD=('./bind.sh' "--cluster=${cluster}" '--ib=single' '--cpu=exclusive' '--' ${PROFILING_PREFIX} 'python' '-u')
+ '[' '' = apiLog.sh ']'
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ ./bind.sh --cluster=selene --ib=single --cpu=exclusive -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=8 cores_per_socket=64
+ exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u main.py --data_dir /data --epochs 7000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 14 --start_eval_at 700 --lr_warmup_epochs 1000 --optimizer nag --learning_rate 1.5 --static_cast -sls 1024 -gpf 256 --loss_scale_inc_cycles 70 -ced --warmup --val_batch_size 1 --nodes_for_eval 20 -sgs 8 -ucl --num_workers 4 --input_batch_multiplier 4
:::MLLOG {"namespace": "", "time_ms": 1621444580168, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 30}}
:::MLLOG {"namespace": "", "time_ms": 1621444580212, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 31}}
:::MLLOG {"namespace": "", "time_ms": 1621444580212, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 101}}
:::MLLOG {"namespace": "", "time_ms": 1621444580213, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "nvidia", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 106}}
:::MLLOG {"namespace": "", "time_ms": 1621444580213, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 110}}
:::MLLOG {"namespace": "", "time_ms": 1621444580213, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 114}}
:::MLLOG {"namespace": "", "time_ms": 1621444580213, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "100xNVIDIA DGX A100", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 118}}
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[10:16:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[luna-0041:0:2687192 - context.c:581] INFO job (ID: 17873379307941242705) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0041:0:2687192 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x1f caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0041:0:2687192 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x5e caps:0x16
[luna-0041:0:2687192 - comm.c:385] INFO [group#:0] group id:17 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x831600000017) mlid:c02b
[luna-0041:0:2687192 - comm.c:385] INFO [group#:1] group id:17 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0041:0:2687196 - context.c:581] INFO job (ID: 17873379012195150365) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0041:0:2687196 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x28 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0041:0:2687196 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x67 caps:0x16
[luna-0041:0:2687196 - comm.c:385] INFO [group#:0] group id:18 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x841600000018) mlid:c02c
[luna-0041:0:2687196 - comm.c:385] INFO [group#:1] group id:18 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0041:0:2687197 - context.c:581] INFO job (ID: 17873378517655542015) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0041:0:2687197 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x21 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0041:0:2687197 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x60 caps:0x16
[luna-0041:0:2687197 - comm.c:385] INFO [group#:0] group id:19 tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x851600000019) mlid:c02d
[luna-0041:0:2687197 - comm.c:385] INFO [group#:1] group id:19 tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0041:0:2687173 - context.c:581] INFO job (ID: 17873379140894977352) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0041:0:2687173 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x2a caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0041:0:2687173 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x69 caps:0x16
[luna-0041:0:2687173 - comm.c:385] INFO [group#:0] group id:1a tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x86160000001a) mlid:c02e
[luna-0041:0:2687173 - comm.c:385] INFO [group#:1] group id:1a tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0041:0:2687193 - context.c:581] INFO job (ID: 17873378915719206308) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0041:0:2687193 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x23 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0041:0:2687193 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x62 caps:0x16
[luna-0041:0:2687193 - comm.c:385] INFO [group#:0] group id:1b tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x87160000001b) mlid:c02f
[luna-0041:0:2687193 - comm.c:385] INFO [group#:1] group id:1b tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0041:0:2687190 - context.c:581] INFO job (ID: 17873378679132028094) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0041:0:2687190 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x29 caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0041:0:2687190 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x68 caps:0x16
[luna-0041:0:2687190 - comm.c:385] INFO [group#:0] group id:1c tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x88160000001c) mlid:c030
[luna-0041:0:2687190 - comm.c:385] INFO [group#:1] group id:1c tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0041:0:2687191 - context.c:581] INFO job (ID: 17873378912011703851) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0041:0:2687191 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x2c caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0041:0:2687191 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x6b caps:0x16
[luna-0041:0:2687191 - comm.c:385] INFO [group#:0] group id:1d tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x89160000001d) mlid:c031
[luna-0041:0:2687191 - comm.c:385] INFO [group#:1] group id:1d tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[luna-0041:0:2687170 - context.c:581] INFO job (ID: 17873378794258665245) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[luna-0041:0:2687170 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x2f caps:0x6 quota: ( osts:33 user_data_per_ost:1024 max_groups:33 max_qps:1 max_group_channels:1)
[luna-0041:0:2687170 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x6e caps:0x16
[luna-0041:0:2687170 - comm.c:385] INFO [group#:0] group id:1e tree idx:0 tree_type:LLT rail_idx:0 group size:80 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x8a160000001e) mlid:c032
[luna-0041:0:2687170 - comm.c:385] INFO [group#:1] group id:1e tree idx:1 tree_type:SAT rail_idx:0 group size:80 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
Using random master seed: 1825866167. Worker seeds 640: [1419588600, 1677577651, 3012595960, 881539949, 191137698, 1781923871, 2653742984, 1128161539, 2410295715, 61083237, 1505338519, 939543375, 2166437881, 987371995, 2533083440, 3530439642, 103365897, 273365654, 1305038340, 70369248, 978252189, 4012420157, 2893215478, 1016277187, 295921757, 3524250001, 1834506271, 2933156008, 4056222689, 2865289562, 4156550347, 3421744540, 3638471113, 3326699530, 765935555, 1291281132, 612371951, 1265742050, 3595908836, 2757871282, 4053393182, 2721255526, 3203193152, 2414734938, 921399250, 4195564681, 1125792376, 3282927369, 4222905439, 4257837226, 721326782, 620891188, 741726846, 2215573025, 3714089830, 2950327647, 3399875040, 10242790, 2927228885, 732610490, 1834148297, 2960438223, 254043836, 3403952889, 1016001597, 3008439242, 3901159291, 2660335557, 2441447616, 2944435832, 2720512944, 2005076636, 31620646, 2988259462, 3041329163, 1539646298, 1827802660, 3389560285, 3989553535, 3064130385, 1515688052, 1856149383, 3078898[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
8, 2700806585, 383704306, 351042938, 849191629, 2239834506, 1558528454, 1235528305, 1763591784, 288956167, 2426062097, 817886388, 3310736686, 1845357280, 2594690839, 3738186382, 1511539168, 987653111, 1592781064, 876520897, 1467494303, 73443173, 1671341212, 1174391469, 2711787625, 2832893214, 3175689000, 3406673619, 3386539544, 465131750, 2390889797, 2255533839, 2077642423, 3013563809, 790096626, 2339045225, 1743747387, 2315380773, 3365416986, 1407923541, 1345517728, 4040736524, 354412628, 4028420656, 1326448996, 3453670607, 91629783, 2445316333, 663420418, 1420115304, 1380224357, 1888950445, 3652418323, 1005011915, 3622337538, 2235041759, 920071506, 3200757605, 2996165265, 3581617748, 1133650405, 4161578491, 377401346, 2848230376, 2078579752, 256494101, 608047278, 2221888199, 4146228649, 1081255, 1453851392, 4101559879, 2126640451, 3371577348, 4000836318, 4163369459, 1141092185, 3183642134, 3014628655, 2768988757, 635101041, 3899495340, 1528087195, 2825887514, 784835730, 591811064, 507762129, 2369342631, 923[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
806733, 201765528, 3521886868, 1634088368, 1511699465, 2744146310, 3892136305, 2105925989, 288448649, 1326218655, 2940057567, 846330764, 3883332332, 2673714481, 589566868, 3147803251, 2625314649, 364327689, 1491090877, 2197408691, 197936410, 3341140167, 924473935, 1215439383, 792529023, 3629865396, 2079703708, 3687045699, 3391148839, 2657575462, 4121402334, 1529386052, 259778646, 1779267012, 4221604201, 1006902736, 3921878304, 2535344473, 409280274, 1139926032, 2079084343, 2010228982, 2870392959, 3550542537, 4221640160, 948013780, 861103132, 3393158471, 1898566479, 2711143465, 4014833630, 1084616482, 2634268632, 2145948047, 945559477, 3864276739, 190268968, 2152295562, 1715214840, 2422043730, 1509175522, 3362690940, 2539549405, 3480248236, 2201018584, 3965989568, 1812683583, 2376836362, 3520153186, 2112761988, 1520375685, 284270834, 962123909, 1168528070, 2941616678, 2514237165, 722443010, 3097979393, 3458101168, 2253971667, 3159588360, 299134182, 4030740513, 500657179, 4035330015, 4126137115, 348841942, 2748[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 9. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 13. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 8. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 11. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 12. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 15. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 10. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 14. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 18. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 21. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 16. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 17. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 22. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 19. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 23. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 20. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 31. SEED 1419588600
RANK 30. SEED 1419588600
RANK 28. SEED 1419588600
RANK 26. SEED 1419588600
RANK 27. SEED 1419588600
RANK 24. SEED 1419588600
RANK 25. SEED 1419588600
RANK 36. SEED 1419588600
RANK 33. SEED 1419588600
RANK 34. SEED 1419588600
RANK 37. SEED 1419588600
RANK 38. SEED 1419588600
RANK 39. SEED 1419588600
RANK 35. SEED 1419588600
RANK 32. SEED 1419588600
RANK 45. SEED 1419588600
RANK 46. SEED 1419588600
RANK 47. SEED 1419588600
RANK 43. SEED 1419588600
RANK 44. SEED 1419588600
RANK 41. SEED 1419588600
RANK 42. SEED 1419588600
RANK 40. SEED 1419588600
RANK 49. SEED 1419588600
RANK 55. SEED 1419588600
RANK 51. SEED 1419588600
RANK 52. SEED 1419588600
RANK 53. SEED 1419588600
RANK 48. SEED 1419588600
RANK 54. SEED 1419588600
RANK 50. SEED 1419588600
RANK 58. SEED 1419588600
RANK 56. SEED 1419588600
RANK 60. SEED 1419588600
RANK 63. SEED 1419588600
RANK 59. SEED 1419588600
RANK 61. SEED 1419588600
RANK 62. SEED 1419588600
RANK 57. SEED 1419588600
RANK 68. SEED 1419588600
RANK 70. SEED 1419588600
RANK 65. SEED 1419588600
RANK 69. SEED 1419588600
RANK 71. SEED 1419588600
RANK 64. SEED 1419588600
RANK 66. SEED 1419588600
RANK 67. SEED 1419588600
RANK 74. SEED 1419588600
RANK 76. SEED 1419588600
RANK 78. SEED 1419588600
RANK 72. SEED 1419588600
RANK 77. SEED 1419588600
RANK 79. SEED 1419588600
RANK 73. SEED 1419588600
RANK 75. SEED 1419588600
RANK 29. SEED 1419588600
RANK 80. SEED 1419588600
RANK 84. SEED 1419588600
RANK 85. SEED 1419588600
RANK 86. SEED 1419588600
RANK 87. SEED 1419588600
RANK 81. SEED 1419588600
RANK 82. SEED 1419588600
RANK 83. SEED 1419588600
RANK 92. SEED 1419588600
RANK 93. SEED 1419588600
RANK 95. SEED 1419588600
RANK 91. SEED 1419588600
RANK 94. SEED 1419588600
RANK 88. SEED 1419588600
RANK 90. SEED 1419588600
RANK 89. SEED 1419588600
RANK 100. SEED 1419588600
RANK 99. SEED 1419588600
RANK 103. SEED 1419588600
RANK 102. SEED 1419588600
RANK 98. SEED 1419588600
RANK 101. SEED 1419588600
RANK 96. SEED 1419588600
RANK 97. SEED 1419588600
RANK 104. SEED 1419588600
RANK 106. SEED 1419588600
RANK 109. SEED 1419588600
RANK 110. SEED 1419588600
RANK 108. SEED 1419588600
RANK 105. SEED 1419588600
RANK 107. SEED 1419588600
RANK 111. SEED 1419588600
RANK 112. SEED 1419588600
RANK 114. SEED 1419588600
RANK 116. SEED 1419588600
RANK 118. SEED 1419588600
RANK 119. SEED 1419588600
RANK 115. SEED 1419588600
RANK 113. SEED 1419588600
RANK 117. SEED 1419588600
RANK 120. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 122. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 123. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 121. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 125. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 126. SEED 1419588600
[10:21:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
RANK 127. SEED 1419588600
RANK 124. SEED 1419588600
RANK 130. SEED 1419588600
RANK 131. SEED 1419588600
RANK 133. SEED 1419588600
RANK 134. SEED 1419588600
RANK 135. SEED 1419588600
RANK 132. SEED 1419588600
RANK 129. SEED 1419588600
RANK 128. SEED 1419588600
RANK 140. SEED 1419588600
RANK 143. SEED 1419588600
RANK 139. SEED 1419588600
RANK 136. SEED 1419588600
RANK 137. SEED 1419588600
RANK 141. SEED 1419588600
RANK 142. SEED 1419588600
RANK 138. SEED 1419588600
RANK 151. SEED 1419588600
RANK 146. SEED 1419588600
RANK 149. SEED 1419588600
RANK 144. SEED 1419588600
RANK 145. SEED 1419588600
RANK 150. SEED 1419588600
RANK 148. SEED 1419588600
RANK 147. SEED 1419588600
RANK 155. SEED 1419588600
RANK 152. SEED 1419588600
RANK 158. SEED 1419588600
RANK 157. SEED 1419588600
RANK 159. SEED 1419588600
RANK 154. SEED 1419588600
RANK 156. SEED 1419588600
RANK 153. SEED 1419588600
RANK 162. SEED 1419588600
RANK 164. SEED 1419588600
RANK 163. SEED 1419588600
RANK 165. SEED 1419588600
RANK 167. SEED 1419588600
RANK 160. SEED 1419588600
RANK 161. SEED 1419588600
RANK 166. SEED 1419588600
RANK 174. SEED 1419588600
RANK 171. SEED 1419588600
RANK 168. SEED 1419588600
RANK 175. SEED 1419588600
RANK 173. SEED 1419588600
RANK 169. SEED 1419588600
RANK 170. SEED 1419588600
RANK 172. SEED 1419588600
RANK 183. SEED 1419588600
RANK 176. SEED 1419588600
RANK 177. SEED 1419588600
RANK 182. SEED 1419588600
RANK 178. SEED 1419588600
RANK 179. SEED 1419588600
RANK 180. SEED 1419588600
RANK 181. SEED 1419588600
531212, 3251326549, 1582652652, 3814056253, 3279018076, 4184246474, 3498459573, 1545287955, 3580007790, 1072970017, 1535653382, 2849300611, 4019490268, 1933537147, 897918246, 936509917, 2396962776, 1969814457, 4139146221, 3392179693, 4100370524, 3506952774, 233626983, 1695274851, 934738875, 3122793807, 1470360274, 2515835181, 1014216063, 3973958178, 1799650241, 2445105528, 3969383517, 2413583237, 399930974, 1019641499, 3709149170, 3247282999, 2376213198, 2185842537, 3467920482, 3266351205, 3977350481, 3426974402, 1771468157, 175947442, 1622359190, 50546869, 3358399710, 2575269839, 4059552174, 629649285, 2514451045, 3764908775, 4263842906, 3578596915, 3936855665, 2145568610, 507793494, 689228032, 1538406295, 3965635460, 4038645261, 4043477108, 4028705028, 1878424874, 587098533, 1169064061, 3344475229, 4082343631, 2586713375, 1760444120, 1033268382, 272765777, 832428585, 1151815821, 4095871053, 4209428541, 824686578, 2392936282, 241009362, 2000745264, 2105936547, 3238613300, 1406264412, 644279901, 1269454360, 1572064889, 1657118217, 47884185, 1127559418, 3699455105, 2670514289, 2748170466, 2650714967, 228669740, 1176863147, 2013070309, 1054197660, 3726878816, 1358913949, 1498967897, 3898223235, 2999404630, 830917037, 2538903198, 803030270, 1549564891, 3557455084, 2761413282, 1548232438, 1212241695, 3174216809, 176843581, 3500519646, 4255647634, 4125638192, 1144389947, 4067211634, 3113382018, 3440689750, 2957546409, 909253730, 3776012990, 3367618163, 2479365322, 3560737619, 5257318, 3684184685, 4189852888, 3137630366, 2569198651, 914136045, 2954153651, 1213627558, 3908630738, 1807239056, 243760891, 3889413272, 936460695, 1072177991, 4082117933, 1452004863, 908878413, 1578784775, 1913407517, 4236331556, 2582116055, 3300426002, 1120982716, 1727577152, 2510099111, 2606199188, 3312019194, 2499076034, 896507389, 2390509822, 639024046, 3908281718, 4103505539, 2397438840, 1360636091, 4264096010, 1777910559, 4074901568, 1794603745, 158409341, 2648456234, 1922283321, 3212807500, 2367709033, 1020085953, 4232090035, 3797303933, 1024331946, 4170682481, 2087268854, 2623142605, 2473098784, 670308476, 3358468932, 1296657768, 3564921106, 1328940094, 515291006, 2162451710, 194453847, 859671070, 1572477257, 119734285, 2926042272, 2377480272, 3461555329, 3544925569, 1693546804, 203164606, 1622232718, 30536248, 1872560018, 707380237, 1434921952, 1393510014, 3776206456, 3477147953, 1277237839, 1842163550, 4098602618, 1447616255, 175358058, 778058231, 1729067999, 3278697553, 3707652027, 2804926060, 1923704583, 1295803587, 2894225313, 306492225, 1367629535, 4239032147, 117429954, 945258954, 2075526379, 6039795, 145996241, 2663751284, 3746591275, 1217870658, 3778737363, 1972547074, 1778815910, 2370499832, 3742459159, 584012464, 1504119700, 839005137, 2856794247, 3811493196, 1955612697, 2433579977, 1500764791, 4267129566, 1081305200, 2370172879, 2028741686, 3311639354, 1540070409, 2794651410, 1414751577, 2695126317, 4073226102, 194887177, 2777253420, 1071610212, 3376060377, 2744952817, 3399934633, 2441313755, 1561340660, 3966915134, 1325211817, 560482022, 2367699556, 2953741121, 3803108550, 3698639346, 4118819143, 1737323716, 3698569970, 1370607583, 40928129, 967617970, 498423672, 4197826465, 2628192913, 2818464342, 2870572695, 4155204958, 740612152, 3805898136, 3173111007, 3906229509, 3610033844, 180313725, 2614358351, 4012201607, 2233786147, 588028716, 1867779566, 1568280616, 2130816464, 1855446963, 2010768664, 1263653934, 3853966584, 1085825487, 3599291022, 3712311558, 3692882346, 2859565077, 3387051314, 3662819862, 1819876077, 3430095470, 610899203, 1794826, 504919566, 3224532883, 6748311, 102323693, 3871133952, 1864524387, 22151383, 2248072138, 3065327273, 2190962400, 4120725814, 4103884509, 2317189681, 392984991, 4164929339, 1067062989, 808111666, 632010929, 533211454, 217992932, 29109948, 410560429, 1479310214, 981151328, 1176256639, 1966665778, 3823234057, 1796354825, 3120184195, 3232798123, 1560018241, 1824167975, 2467670528, 1936977001, 2884994152, 4086749584, 4078211371, 1602768034, 1831105119, 2037430929, 3326679348, 3981011444, 307679585, 3178336109, 910568446, 668562986, 2537584504, 3478719600, 2300483246, 524569767, 3680726046, 1918622363, 3295126896, 3602803528, 1528816037, 2856597354, 2939311923, 2140862277, 2789186173, 3232297877, 4181310070, 2657331022, 3910359394, 1749428389, 1160722866, 2377052870, 774571340, 614708410, 3014601204, 3677157952, 19751467, 2669142244, 2784793872, 309726679, 3025287861, 1088710443, 385491422]
RANK 185. SEED 1419588600
RANK 190. SEED 1419588600
RANK 0. SEED 1419588600
RANK 189. SEED 1419588600
:::MLLOG {"namespace": "", "time_ms": 1621444901146, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1419588600, "metadata": {"file": "main.py", "lineno": 57}}
RANK 191. SEED 1419588600
RANK 2. SEED 1419588600
:::MLLOG {"namespace": "", "time_ms": 1621444901146, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
RANK 3. SEED 1419588600
RANK 5. SEED 1419588600
RANK 4. SEED 1419588600
RANK 6. SEED 1419588600
RANK 7. SEED 1419588600
:::MLLOG {"namespace": "", "time_ms": 1621444901146, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 125}}
RANK 188. SEED 1419588600
:::MLLOG {"namespace": "", "time_ms": 1621444901146, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1000, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 126}}
:::MLLOG {"namespace": "", "time_ms": 1621444901147, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
RANK 1. SEED 1419588600
:::MLLOG {"namespace": "", "time_ms": 1621444901147, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 129}}
:::MLLOG {"namespace": "", "time_ms": 1621444901147, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 130}}
RANK 184. SEED 1419588600
:::MLLOG {"namespace": "", "time_ms": 1621444901147, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 131}}
:::MLLOG {"namespace": "", "time_ms": 1621444901147, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
:::MLLOG {"namespace": "", "time_ms": 1621444901147, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 133}}
:::MLLOG {"namespace": "", "time_ms": 1621444901147, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 134}}
:::MLLOG {"namespace": "", "time_ms": 1621444901147, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 135}}
RANK 186. SEED 1419588600
RANK 187. SEED 1419588600
RANK 196. SEED 1419588600
RANK 193. SEED 1419588600
RANK 197. SEED 1419588600
RANK 194. SEED 1419588600
RANK 198. SEED 1419588600
RANK 199. SEED 1419588600
RANK 195. SEED 1419588600
RANK 192. SEED 1419588600
RANK 201. SEED 1419588600
RANK 200. SEED 1419588600
RANK 202. SEED 1419588600
RANK 203. SEED 1419588600
RANK 206. SEED 1419588600
RANK 204. SEED 1419588600
RANK 205. SEED 1419588600
RANK 207. SEED 1419588600
RANK 208. SEED 1419588600
RANK 210. SEED 1419588600
RANK 214. SEED 1419588600
RANK 209. SEED 1419588600
RANK 213. SEED 1419588600
RANK 211. SEED 1419588600
RANK 212. SEED 1419588600
RANK 215. SEED 1419588600
RANK 222. SEED 1419588600
RANK 219. SEED 1419588600
RANK 220. SEED 1419588600
RANK 218. SEED 1419588600
RANK 221. SEED 1419588600
RANK 223. SEED 1419588600
RANK 216. SEED 1419588600
RANK 217. SEED 1419588600
RANK 228. SEED 1419588600
RANK 231. SEED 1419588600
RANK 225. SEED 1419588600
RANK 227. SEED 1419588600
RANK 229. SEED 1419588600
RANK 230. SEED 1419588600
RANK 226. SEED 1419588600
RANK 224. SEED 1419588600
RANK 236. SEED 1419588600
RANK 239. SEED 1419588600
RANK 233. SEED 1419588600
RANK 234. SEED 1419588600
RANK 232. SEED 1419588600
RANK 235. SEED 1419588600
RANK 238. SEED 1419588600
RANK 237. SEED 1419588600
RANK 242. SEED 1419588600
RANK 246. SEED 1419588600
RANK 240. SEED 1419588600
RANK 243. SEED 1419588600
RANK 244. SEED 1419588600
RANK 247. SEED 1419588600
RANK 241. SEED 1419588600
RANK 245. SEED 1419588600
RANK 249. SEED 1419588600
RANK 248. SEED 1419588600
RANK 250. SEED 1419588600
RANK 252. SEED 1419588600
RANK 251. SEED 1419588600
RANK 255. SEED 1419588600
RANK 253. SEED 1419588600
RANK 254. SEED 1419588600
RANK 263. SEED 1419588600
RANK 256. SEED 1419588600
RANK 257. SEED 1419588600
RANK 259. SEED 1419588600
RANK 261. SEED 1419588600
RANK 262. SEED 1419588600
RANK 258. SEED 1419588600
RANK 260. SEED 1419588600
RANK 266. SEED 1419588600
RANK 268. SEED 1419588600
RANK 265. SEED 1419588600
RANK 269. SEED 1419588600
RANK 270. SEED 1419588600
RANK 267. SEED 1419588600
RANK 264. SEED 1419588600
RANK 271. SEED 1419588600
RANK 272. SEED 1419588600
RANK 277. SEED 1419588600
RANK 278. SEED 1419588600
RANK 273. SEED 1419588600
RANK 274. SEED 1419588600
RANK 276. SEED 1419588600
RANK 279. SEED 1419588600
RANK 275. SEED 1419588600
RANK 283. SEED 1419588600
RANK 286. SEED 1419588600
RANK 284. SEED 1419588600
RANK 280. SEED 1419588600
RANK 287. SEED 1419588600
RANK 281. SEED 1419588600
RANK 282. SEED 1419588600
RANK 285. SEED 1419588600
RANK 294. SEED 1419588600
RANK 292. SEED 1419588600
RANK 293. SEED 1419588600
RANK 291. SEED 1419588600
RANK 288. SEED 1419588600
RANK 295. SEED 1419588600
RANK 289. SEED 1419588600
RANK 290. SEED 1419588600
RANK 296. SEED 1419588600
RANK 300. SEED 1419588600
RANK 298. SEED 1419588600
RANK 299. SEED 1419588600
RANK 302. SEED 1419588600
RANK 297. SEED 1419588600
RANK 303. SEED 1419588600
RANK 301. SEED 1419588600
RANK 304. SEED 1419588600
RANK 306. SEED 1419588600
RANK 305. SEED 1419588600
RANK 307. SEED 1419588600
RANK 308. SEED 1419588600
RANK 309. SEED 1419588600
RANK 311. SEED 1419588600
RANK 310. SEED 1419588600
RANK 318. SEED 1419588600
RANK 314. SEED 1419588600
RANK 319. SEED 1419588600
RANK 312. SEED 1419588600
RANK 313. SEED 1419588600
RANK 315. SEED 1419588600
RANK 316. SEED 1419588600
RANK 317. SEED 1419588600
RANK 322. SEED 1419588600
RANK 324. SEED 1419588600
RANK 327. SEED 1419588600
RANK 320. SEED 1419588600
RANK 325. SEED 1419588600
RANK 326. SEED 1419588600
RANK 321. SEED 1419588600
RANK 323. SEED 1419588600
RANK 331. SEED 1419588600
RANK 335. SEED 1419588600
RANK 330. SEED 1419588600
RANK 332. SEED 1419588600
RANK 333. SEED 1419588600
RANK 328. SEED 1419588600
RANK 334. SEED 1419588600
RANK 329. SEED 1419588600
RANK 340. SEED 1419588600
RANK 336. SEED 1419588600
RANK 338. SEED 1419588600
RANK 337. SEED 1419588600
RANK 341. SEED 1419588600
RANK 343. SEED 1419588600
RANK 339. SEED 1419588600
RANK 346. SEED 1419588600
RANK 349. SEED 1419588600
RANK 350. SEED 1419588600
RANK 351. SEED 1419588600
RANK 347. SEED 1419588600
RANK 348. SEED 1419588600
RANK 344. SEED 1419588600
RANK 345. SEED 1419588600
RANK 356. SEED 1419588600
RANK 357. SEED 1419588600
RANK 354. SEED 1419588600
RANK 355. SEED 1419588600
RANK 358. SEED 1419588600
RANK 353. SEED 1419588600
RANK 352. SEED 1419588600
RANK 359. SEED 1419588600
RANK 342. SEED 1419588600
RANK 367. SEED 1419588600
RANK 360. SEED 1419588600
RANK 362. SEED 1419588600
RANK 363. SEED 1419588600
RANK 364. SEED 1419588600
RANK 365. SEED 1419588600
RANK 361. SEED 1419588600
RANK 366. SEED 1419588600
RANK 374. SEED 1419588600
RANK 371. SEED 1419588600
RANK 372. SEED 1419588600
RANK 368. SEED 1419588600
RANK 369. SEED 1419588600
RANK 370. SEED 1419588600
RANK 375. SEED 1419588600
RANK 373. SEED 1419588600
RANK 379. SEED 1419588600
RANK 377. SEED 1419588600
RANK 380. SEED 1419588600
RANK 381. SEED 1419588600
RANK 382. SEED 1419588600
RANK 383. SEED 1419588600
RANK 378. SEED 1419588600
RANK 376. SEED 1419588600
RANK 388. SEED 1419588600
RANK 391. SEED 1419588600
RANK 387. SEED 1419588600
RANK 390. SEED 1419588600
RANK 384. SEED 1419588600
RANK 386. SEED 1419588600
RANK 385. SEED 1419588600
RANK 389. SEED 1419588600
RANK 394. SEED 1419588600
RANK 397. SEED 1419588600
RANK 396. SEED 1419588600
RANK 398. SEED 1419588600
RANK 399. SEED 1419588600
RANK 395. SEED 1419588600
RANK 393. SEED 1419588600
RANK 392. SEED 1419588600
RANK 402. SEED 1419588600
RANK 401. SEED 1419588600
RANK 404. SEED 1419588600
RANK 400. SEED 1419588600
RANK 406. SEED 1419588600
RANK 405. SEED 1419588600
RANK 407. SEED 1419588600
RANK 403. SEED 1419588600
RANK 413. SEED 1419588600
RANK 415. SEED 1419588600
RANK 412. SEED 1419588600
RANK 414. SEED 1419588600
RANK 410. SEED 1419588600
RANK 408. SEED 1419588600
RANK 409. SEED 1419588600
RANK 411. SEED 1419588600
RANK 416. SEED 1419588600
RANK 419. SEED 1419588600
RANK 420. SEED 1419588600
RANK 423. SEED 1419588600
RANK 421. SEED 1419588600
RANK 417. SEED 1419588600
RANK 418. SEED 1419588600
RANK 422. SEED 1419588600
RANK 426. SEED 1419588600
RANK 425. SEED 1419588600
RANK 424. SEED 1419588600
RANK 429. SEED 1419588600
RANK 427. SEED 1419588600
RANK 430. SEED 1419588600
RANK 431. SEED 1419588600
RANK 428. SEED 1419588600
RANK 434. SEED 1419588600
RANK 433. SEED 1419588600
RANK 435. SEED 1419588600
RANK 436. SEED 1419588600
RANK 438. SEED 1419588600
RANK 437. SEED 1419588600
RANK 439. SEED 1419588600
RANK 432. SEED 1419588600
RANK 445. SEED 1419588600
RANK 440. SEED 1419588600
RANK 442. SEED 1419588600
RANK 441. SEED 1419588600
RANK 444. SEED 1419588600
RANK 446. SEED 1419588600
RANK 443. SEED 1419588600
RANK 447. SEED 1419588600
RANK 452. SEED 1419588600
RANK 453. SEED 1419588600
RANK 454. SEED 1419588600
RANK 448. SEED 1419588600
RANK 451. SEED 1419588600
RANK 455. SEED 1419588600
RANK 450. SEED 1419588600
RANK 449. SEED 1419588600
RANK 458. SEED 1419588600
RANK 459. SEED 1419588600
RANK 456. SEED 1419588600
RANK 461. SEED 1419588600
RANK 457. SEED 1419588600
RANK 460. SEED 1419588600
RANK 463. SEED 1419588600
RANK 462. SEED 1419588600
RANK 466. SEED 1419588600
RANK 464. SEED 1419588600
RANK 469. SEED 1419588600
RANK 468. SEED 1419588600
RANK 465. SEED 1419588600
RANK 470. SEED 1419588600
RANK 467. SEED 1419588600
RANK 474. SEED 1419588600
RANK 473. SEED 1419588600
RANK 472. SEED 1419588600
RANK 475. SEED 1419588600
RANK 476. SEED 1419588600
RANK 477. SEED 1419588600
RANK 478. SEED 1419588600
RANK 479. SEED 1419588600
RANK 486. SEED 1419588600
RANK 485. SEED 1419588600
RANK 487. SEED 1419588600
RANK 484. SEED 1419588600
RANK 481. SEED 1419588600
RANK 482. SEED 1419588600
RANK 483. SEED 1419588600
RANK 480. SEED 1419588600
RANK 493. SEED 1419588600
RANK 489. SEED 1419588600
RANK 490. SEED 1419588600
RANK 494. SEED 1419588600
RANK 495. SEED 1419588600
RANK 492. SEED 1419588600
RANK 488. SEED 1419588600
RANK 491. SEED 1419588600
RANK 501. SEED 1419588600
RANK 503. SEED 1419588600
RANK 499. SEED 1419588600
RANK 497. SEED 1419588600
RANK 500. SEED 1419588600
RANK 502. SEED 1419588600
RANK 498. SEED 1419588600
RANK 496. SEED 1419588600
RANK 508. SEED 1419588600
RANK 505. SEED 1419588600
RANK 506. SEED 1419588600
RANK 507. SEED 1419588600
RANK 509. SEED 1419588600
RANK 504. SEED 1419588600
RANK 510. SEED 1419588600
RANK 511. SEED 1419588600
RANK 516. SEED 1419588600
RANK 519. SEED 1419588600
RANK 513. SEED 1419588600
RANK 514. SEED 1419588600
RANK 518. SEED 1419588600
RANK 512. SEED 1419588600
RANK 515. SEED 1419588600
RANK 517. SEED 1419588600
RANK 521. SEED 1419588600
RANK 524. SEED 1419588600
RANK 522. SEED 1419588600
RANK 525. SEED 1419588600
RANK 527. SEED 1419588600
RANK 520. SEED 1419588600
RANK 526. SEED 1419588600
RANK 523. SEED 1419588600
RANK 533. SEED 1419588600
RANK 529. SEED 1419588600
RANK 530. SEED 1419588600
RANK 532. SEED 1419588600
RANK 531. SEED 1419588600
RANK 534. SEED 1419588600
RANK 535. SEED 1419588600
RANK 528. SEED 1419588600
RANK 537. SEED 1419588600
RANK 541. SEED 1419588600
RANK 542. SEED 1419588600
RANK 471. SEED 1419588600
RANK 540. SEED 1419588600
RANK 539. SEED 1419588600
RANK 538. SEED 1419588600
RANK 543. SEED 1419588600
RANK 536. SEED 1419588600
RANK 544. SEED 1419588600
RANK 546. SEED 1419588600
RANK 549. SEED 1419588600
RANK 550. SEED 1419588600
RANK 545. SEED 1419588600
RANK 548. SEED 1419588600
RANK 551. SEED 1419588600
RANK 547. SEED 1419588600
RANK 553. SEED 1419588600
RANK 552. SEED 1419588600
RANK 555. SEED 1419588600
RANK 554. SEED 1419588600
RANK 556. SEED 1419588600
RANK 558. SEED 1419588600
RANK 559. SEED 1419588600
RANK 557. SEED 1419588600
RANK 560. SEED 1419588600
RANK 565. SEED 1419588600
RANK 563. SEED 1419588600
RANK 567. SEED 1419588600
RANK 562. SEED 1419588600
RANK 566. SEED 1419588600
RANK 564. SEED 1419588600
RANK 561. SEED 1419588600
RANK 570. SEED 1419588600
RANK 575. SEED 1419588600
RANK 573. SEED 1419588600
RANK 574. SEED 1419588600
RANK 568. SEED 1419588600
RANK 569. SEED 1419588600
RANK 572. SEED 1419588600
RANK 571. SEED 1419588600
RANK 576. SEED 1419588600
RANK 577. SEED 1419588600
RANK 579. SEED 1419588600
RANK 578. SEED 1419588600
RANK 581. SEED 1419588600
RANK 580. SEED 1419588600
RANK 583. SEED 1419588600
RANK 582. SEED 1419588600
RANK 588. SEED 1419588600
RANK 589. SEED 1419588600
RANK 584. SEED 1419588600
RANK 586. SEED 1419588600
RANK 585. SEED 1419588600
RANK 591. SEED 1419588600
RANK 587. SEED 1419588600
RANK 590. SEED 1419588600
RANK 598. SEED 1419588600
RANK 592. SEED 1419588600
RANK 593. SEED 1419588600
RANK 595. SEED 1419588600
RANK 599. SEED 1419588600
RANK 594. SEED 1419588600
RANK 597. SEED 1419588600
RANK 596. SEED 1419588600
RANK 602. SEED 1419588600
RANK 605. SEED 1419588600
RANK 606. SEED 1419588600
RANK 607. SEED 1419588600
RANK 601. SEED 1419588600
RANK 603. SEED 1419588600
RANK 600. SEED 1419588600
RANK 604. SEED 1419588600
RANK 612. SEED 1419588600
RANK 608. SEED 1419588600
RANK 613. SEED 1419588600
RANK 614. SEED 1419588600
RANK 615. SEED 1419588600
RANK 611. SEED 1419588600
RANK 609. SEED 1419588600
RANK 610. SEED 1419588600
RANK 616. SEED 1419588600
RANK 617. SEED 1419588600
RANK 620. SEED 1419588600
RANK 621. SEED 1419588600
RANK 619. SEED 1419588600
RANK 618. SEED 1419588600
RANK 623. SEED 1419588600
RANK 622. SEED 1419588600
RANK 630. SEED 1419588600
RANK 626. SEED 1419588600
RANK 629. SEED 1419588600
RANK 624. SEED 1419588600
RANK 627. SEED 1419588600
RANK 628. SEED 1419588600
RANK 631. SEED 1419588600
RANK 625. SEED 1419588600
RANK 635. SEED 1419588600
RANK 636. SEED 1419588600
RANK 639. SEED 1419588600
RANK 637. SEED 1419588600
RANK 632. SEED 1419588600
RANK 633. SEED 1419588600
RANK 634. SEED 1419588600
RANK 638. SEED 1419588600
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[10:21:42] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
:::MLLOG {"namespace": "", "time_ms": 1621444925885, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 99}}
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
MODEL WARMED UP
:::MLLOG {"namespace": "", "time_ms": 1621444925895, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 101}}
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 10, VAL CASES ['00207', '00162']
RANK 2, VAL CASES ['00169', '00206']
RANK 11, VAL CASES ['00128', '00061']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 10, VAL CASES ['00207', '00162']
RANK 18, VAL CASES ['00176']
RANK 3, VAL CASES ['00086', '00078', '00160']
RANK 18, VAL CASES ['00176']
RANK 10, VAL CASES ['00207', '00162']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 10, VAL CASES ['00207', '00162']
RANK 8, VAL CASES ['00189', '00056']
RANK 10, VAL CASES ['00207', '00162']
RANK 8, VAL CASES ['00189', '00056']
RANK 11, VAL CASES ['00128', '00061']
RANK 11, VAL CASES ['00128', '00061']
RANK 11, VAL CASES ['00128', '00061']
RANK 17, VAL CASES ['00084']
RANK 8, VAL CASES ['00189', '00056']
RANK 10, VAL CASES ['00207', '00162']
RANK 11, VAL CASES ['00128', '00061']
RANK 2, VAL CASES ['00169', '00206']
RANK 2, VAL CASES ['00169', '00206']
RANK 2, VAL CASES ['00169', '00206']
RANK 2, VAL CASES ['00169', '00206']
RANK 2, VAL CASES ['00169', '00206']
RANK 10, VAL CASES ['00207', '00162']
RANK 8, VAL CASES ['00189', '00056']
RANK 11, VAL CASES ['00128', '00061']
RANK 18, VAL CASES ['00176']
RANK 12, VAL CASES ['00066', '00065']
RANK 10, VAL CASES ['00207', '00162']
RANK 8, VAL CASES ['00189', '00056']
RANK 11, VAL CASES ['00128', '00061']
RANK 8, VAL CASES ['00189', '00056']
RANK 8, VAL CASES ['00189', '00056']
RANK 11, VAL CASES ['00128', '00061']
RANK 8, VAL CASES ['00189', '00056']
RANK 13, VAL CASES ['00044', '00070']
RANK 13, VAL CASES ['00044', '00070']
RANK 12, VAL CASES ['00066', '00065']
RANK 2, VAL CASES ['00169', '00206']
RANK 9, VAL CASES ['00198', '00203']
RANK 18, VAL CASES ['00176']
RANK 18, VAL CASES ['00176']
RANK 18, VAL CASES ['00176']
RANK 17, VAL CASES ['00084']
RANK 18, VAL CASES ['00176']
RANK 18, VAL CASES ['00176']
RANK 2, VAL CASES ['00169', '00206']
RANK 12, VAL CASES ['00066', '00065']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 16, VAL CASES ['00185']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 9, VAL CASES ['00198', '00203']
RANK 5, VAL CASES ['00092', '00049', '00087']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 15, VAL CASES ['00005', '00024']
RANK 17, VAL CASES ['00084']
RANK 19, VAL CASES ['00125']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 12, VAL CASES ['00066', '00065']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 16, VAL CASES ['00185']
RANK 15, VAL CASES ['00005', '00024']
RANK 1, VAL CASES ['00000', '00003']
RANK 17, VAL CASES ['00084']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 1, VAL CASES ['00000', '00003']
RANK 17, VAL CASES ['00084']
RANK 17, VAL CASES ['00084']
RANK 17, VAL CASES ['00084']
RANK 17, VAL CASES ['00084']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
RANK 0, VAL CASES ['00052', '00157', '00187']
:::MLLOG {"namespace": "", "time_ms": 1621444925962, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 104}}
:::MLLOG {"namespace": "", "time_ms": 1621444925962, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 105}}
RANK 9, VAL CASES ['00198', '00203']
RANK 9, VAL CASES ['00198', '00203']
RANK 9, VAL CASES ['00198', '00203']
RANK 16, VAL CASES ['00185']
RANK 9, VAL CASES ['00198', '00203']
RANK 9, VAL CASES ['00198', '00203']
RANK 16, VAL CASES ['00185']
RANK 19, VAL CASES ['00125']
RANK 16, VAL CASES ['00185']
RANK 16, VAL CASES ['00185']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 16, VAL CASES ['00185']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 19, VAL CASES ['00125']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 19, VAL CASES ['00125']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 19, VAL CASES ['00125']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 19, VAL CASES ['00125']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 19, VAL CASES ['00125']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 13, VAL CASES ['00044', '00070']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 9, VAL CASES ['00198', '00203']
RANK 4, VAL CASES ['00111', '00161', '00112']
RANK 13, VAL CASES ['00044', '00070']
RANK 19, VAL CASES ['00125']
RANK 13, VAL CASES ['00044', '00070']
RANK 16, VAL CASES ['00185']
RANK 13, VAL CASES ['00044', '00070']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 13, VAL CASES ['00044', '00070']
RANK 6, VAL CASES ['00006', '00080', '00041']
RANK 13, VAL CASES ['00044', '00070']
RANK 14, VAL CASES ['00034', '00076']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 14, VAL CASES ['00034', '00076']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 14, VAL CASES ['00034', '00076']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 14, VAL CASES ['00034', '00076']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 14, VAL CASES ['00034', '00076']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 14, VAL CASES ['00034', '00076']
RANK 7, VAL CASES ['00171', '00012', '00138']
RANK 14, VAL CASES ['00034', '00076']
RANK 14, VAL CASES ['00034', '00076']
RANK 7, VAL CASES ['00171', '00012', '00138']
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
EVALUATION TIME: 14.48 s.
EVAL WARMUP done at epoch 14, cycle 1. Score: 0.006580981891602278
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1621444953040, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 80, "metadata": {"file": "main.py", "lineno": 107}}
:::MLLOG {"namespace": "", "time_ms": 1621444953040, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 108}}
:::MLLOG {"namespace": "", "time_ms": 1621444953040, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 24}}
:::MLLOG {"namespace": "", "time_ms": 1621444953041, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1, "epoch_count": 14}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1621444957467, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 759.0136076056572, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444957468, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.03089264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444957468, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 759.0136076056572, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1621444957468, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 14, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444957469, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 14, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444960547, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1091.478748677364, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444960548, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.05175218543046358, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444960548, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1091.478748677364, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444960548, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 28, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444960548, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 28, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444963580, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1108.4654653728753, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444963580, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.07261172185430464, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444963580, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1108.4654653728753, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 28}}
:::MLLOG {"namespace": "", "time_ms": 1621444963580, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 42, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444963581, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 42, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444966175, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1295.1238278476508, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444966176, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0934712582781457, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444966176, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1295.1238278476508, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 42}}
:::MLLOG {"namespace": "", "time_ms": 1621444966176, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 56, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444966177, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 56, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444967492, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2555.4146637601175, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444967492, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.11433079470198675, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444967492, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2555.4146637601175, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 56}}
:::MLLOG {"namespace": "", "time_ms": 1621444967492, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 70, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444967493, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 70, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444968774, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2623.396811982152, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444968774, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.13519033112582782, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444968774, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2623.396811982152, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 70}}
:::MLLOG {"namespace": "", "time_ms": 1621444968774, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 84, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444968774, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 84, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444970025, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2687.8825979013595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444970025, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.15604986754966885, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444970025, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2687.8825979013595, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 84}}
:::MLLOG {"namespace": "", "time_ms": 1621444970025, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 98, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444970026, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 98, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444971433, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2387.2145541397226, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444971434, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.1769094039735099, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444971434, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2387.2145541397226, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 98}}
:::MLLOG {"namespace": "", "time_ms": 1621444971434, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 112, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444971434, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 112, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444972486, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3196.1298258791767, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444972486, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.197768940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444972486, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3196.1298258791767, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 112}}
:::MLLOG {"namespace": "", "time_ms": 1621444972486, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 126, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444972486, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 126, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444973579, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3075.30019331833, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444973580, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.21862847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444973580, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3075.30019331833, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 126}}
:::MLLOG {"namespace": "", "time_ms": 1621444973580, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 140, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444973580, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 140, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444974761, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2847.0300616845743, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444974761, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.2394880132450331, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444974761, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2847.0300616845743, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1621444974761, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 154, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444974762, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 154, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444976012, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2687.431028663289, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444976013, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26034754966887413, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444976013, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2687.431028663289, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 154}}
:::MLLOG {"namespace": "", "time_ms": 1621444976013, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 168, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444976013, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 168, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444977000, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3406.3050109890855, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444977001, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.2812070860927152, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444977001, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3406.3050109890855, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 168}}
:::MLLOG {"namespace": "", "time_ms": 1621444977001, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 182, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444977001, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 182, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444978053, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3194.0276874359456, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444978054, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3020666225165563, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444978054, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3194.0276874359456, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 182}}
:::MLLOG {"namespace": "", "time_ms": 1621444978054, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 196, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444978054, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 196, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444979159, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3041.985432517467, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444979159, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32292615894039733, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444979160, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3041.985432517467, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 196}}
:::MLLOG {"namespace": "", "time_ms": 1621444979160, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 210, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444979160, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 210, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444980211, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3198.509837903202, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444980211, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3437856953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444980211, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3198.509837903202, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 210}}
:::MLLOG {"namespace": "", "time_ms": 1621444980211, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 224, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444980212, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 224, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444981143, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3609.3359197122954, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444981144, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36464523178807945, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444981144, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3609.3359197122954, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 224}}
:::MLLOG {"namespace": "", "time_ms": 1621444981144, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 238, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444981144, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 238, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444982232, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3089.172695066087, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444982233, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3855047682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444982233, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3089.172695066087, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 238}}
:::MLLOG {"namespace": "", "time_ms": 1621444982233, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 252, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444982233, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 252, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444983370, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2956.2191739328255, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444983370, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4063643046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444983370, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2956.2191739328255, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 252}}
:::MLLOG {"namespace": "", "time_ms": 1621444983370, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 266, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444983371, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 266, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444984327, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3513.6091525768547, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444984328, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444984328, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3513.6091525768547, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 266}}
:::MLLOG {"namespace": "", "time_ms": 1621444984328, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 280, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444984328, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 280, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444985227, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3737.2128386575814, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444985228, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4480833774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444985228, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3737.2128386575814, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1621444985228, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 294, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444985228, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 294, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444986255, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3274.0837772235086, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444986255, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.46894291390728476, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444986255, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3274.0837772235086, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 294}}
:::MLLOG {"namespace": "", "time_ms": 1621444986255, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 308, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444986256, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 308, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444987232, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3441.033164922164, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444987233, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4898024503311258, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444987233, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3441.033164922164, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 308}}
:::MLLOG {"namespace": "", "time_ms": 1621444987233, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 322, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444987233, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 322, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444988136, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3722.143455930476, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444988137, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5106619867549669, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444988137, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3722.143455930476, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 322}}
:::MLLOG {"namespace": "", "time_ms": 1621444988137, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 336, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444988137, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 336, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444989017, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3819.202607262166, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444989017, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.531521523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444989018, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3819.202607262166, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 336}}
:::MLLOG {"namespace": "", "time_ms": 1621444989018, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 350, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444989018, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 350, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444990019, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3356.3038522021, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444990020, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5523810596026489, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444990020, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3356.3038522021, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 350}}
:::MLLOG {"namespace": "", "time_ms": 1621444990020, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 364, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444990020, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 364, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444990943, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3639.900562300818, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444990944, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5732405960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444990944, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3639.900562300818, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 364}}
:::MLLOG {"namespace": "", "time_ms": 1621444990944, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 378, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444990944, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 378, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444991776, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4039.315697136337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444991777, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5941001324503311, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444991777, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4039.315697136337, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 378}}
:::MLLOG {"namespace": "", "time_ms": 1621444991777, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 392, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444991777, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 392, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444992679, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3726.711510344483, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444992679, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6149596688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444992680, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3726.711510344483, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 392}}
:::MLLOG {"namespace": "", "time_ms": 1621444992680, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 406, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444992680, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 406, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444993561, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3814.938974723378, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444993561, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6358192052980133, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444993562, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3814.938974723378, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 406}}
:::MLLOG {"namespace": "", "time_ms": 1621444993562, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 420, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444993562, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 420, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444994429, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3874.7725002550123, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444994429, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6566787417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444994429, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3874.7725002550123, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1621444994430, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 434, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444994430, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 434, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444995328, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3739.13547727046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444995329, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6775382781456953, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444995329, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3739.13547727046, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 434}}
:::MLLOG {"namespace": "", "time_ms": 1621444995329, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 448, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444995330, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 448, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444996297, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3472.23770217551, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444996298, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6983978145695363, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444996298, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3472.23770217551, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 448}}
:::MLLOG {"namespace": "", "time_ms": 1621444996298, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 462, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444996298, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 462, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444997154, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3926.6075315374355, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444997155, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7192573509933775, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444997155, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3926.6075315374355, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 462}}
:::MLLOG {"namespace": "", "time_ms": 1621444997155, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 476, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444997155, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 476, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444997991, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4019.350982373491, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444997992, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7401168874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444997992, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4019.350982373491, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 476}}
:::MLLOG {"namespace": "", "time_ms": 1621444997992, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 490, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444997992, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 490, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444998863, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3858.8884933730405, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444998864, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7609764238410596, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444998864, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3858.8884933730405, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 490}}
:::MLLOG {"namespace": "", "time_ms": 1621444998864, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 504, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444998864, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 504, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444999704, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4001.049725874438, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621444999705, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7818359602649007, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621444999705, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4001.049725874438, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 504}}
:::MLLOG {"namespace": "", "time_ms": 1621444999705, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 518, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621444999705, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 518, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445000543, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4010.701030076996, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445000544, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8026954966887417, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445000544, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4010.701030076996, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 518}}
:::MLLOG {"namespace": "", "time_ms": 1621445000544, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 532, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445000544, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 532, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445001419, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3840.5263695754725, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445001420, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8235550331125828, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445001420, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3840.5263695754725, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 532}}
:::MLLOG {"namespace": "", "time_ms": 1621445001420, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 546, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445001420, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 546, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445002284, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3891.3926672772714, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445002285, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445002285, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3891.3926672772714, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 546}}
:::MLLOG {"namespace": "", "time_ms": 1621445002285, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 560, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445002285, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 560, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445003115, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4045.767731663604, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445003116, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8652741059602649, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445003116, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4045.767731663604, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1621445003116, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 574, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445003116, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 574, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445004019, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3720.7627467012985, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445004020, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.886133642384106, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445004020, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3720.7627467012985, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 574}}
:::MLLOG {"namespace": "", "time_ms": 1621445004020, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 588, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445004020, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 588, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445004918, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3740.746303876447, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445004919, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9069931788079469, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445004919, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3740.746303876447, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 588}}
:::MLLOG {"namespace": "", "time_ms": 1621445004919, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 602, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445004919, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 602, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445005823, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3718.6361999190985, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445005824, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9278527152317881, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445005824, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3718.6361999190985, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 602}}
:::MLLOG {"namespace": "", "time_ms": 1621445005824, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 616, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445005824, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 616, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445006655, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4043.8847270616398, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445006655, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9487122516556292, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445006656, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4043.8847270616398, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 616}}
:::MLLOG {"namespace": "", "time_ms": 1621445006656, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 630, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445006656, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 630, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445007479, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4081.016913813913, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445007480, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9695717880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445007480, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4081.016913813913, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 630}}
:::MLLOG {"namespace": "", "time_ms": 1621445007480, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 644, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445007480, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 644, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445008315, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4028.520778258523, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445008315, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9904313245033113, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445008315, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4028.520778258523, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 644}}
:::MLLOG {"namespace": "", "time_ms": 1621445008315, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 658, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445008315, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 658, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445009220, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3713.7717751097107, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445009221, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0112908609271523, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445009221, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3713.7717751097107, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 658}}
:::MLLOG {"namespace": "", "time_ms": 1621445009221, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 672, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445009221, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 672, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445010118, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3746.8209508186696, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445010118, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0321503973509933, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445010119, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3746.8209508186696, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 672}}
:::MLLOG {"namespace": "", "time_ms": 1621445010119, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 686, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445010119, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 686, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445011003, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3799.3174586999107, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445011005, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0530099337748344, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445011005, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3799.3174586999107, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 686}}
rank 0: cycle = 50: time to send the model = 0.04418039321899414
:::MLLOG {"namespace": "", "time_ms": 1621445011050, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 700, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445011050, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 700, "epoch_count": 14}}
rank 640: cycle = 50: time to receive the model = 0.049561500549316406
:::MLLOG {"namespace": "", "time_ms": 1621445011055, "event_type": "INTERVAL_START", "key": "eval_start", "value": 700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 700}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.731 s.
:::MLLOG {"namespace": "", "time_ms": 1621445011827, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.868614137172699, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 700}}
:::MLLOG {"namespace": "", "time_ms": 1621445011828, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 700}}
:::MLLOG {"namespace": "", "time_ms": 1621445011862, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4138.63200906379, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445011864, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0738694701986755, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445011864, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4138.63200906379, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 700}}
rank 0: cycle = 51: time to send the model = 0.0396726131439209
:::MLLOG {"namespace": "", "time_ms": 1621445011906, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 714, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445011906, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 714, "epoch_count": 14}}
rank 640: cycle = 51: time to receive the model = 0.05014181137084961
:::MLLOG {"namespace": "", "time_ms": 1621445011916, "event_type": "INTERVAL_START", "key": "eval_start", "value": 714, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 714}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445012684, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8897650241851807, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 714}}
:::MLLOG {"namespace": "", "time_ms": 1621445012684, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 714}}
:::MLLOG {"namespace": "", "time_ms": 1621445012687, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4303.731496795913, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445012689, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0947290066225166, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445012690, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4303.731496795913, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 714}}
rank 0: cycle = 52: time to send the model = 0.04986834526062012
:::MLLOG {"namespace": "", "time_ms": 1621445012741, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 728, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445012741, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 728, "epoch_count": 14}}
rank 640: cycle = 52: time to receive the model = 0.05666542053222656
:::MLLOG {"namespace": "", "time_ms": 1621445012747, "event_type": "INTERVAL_START", "key": "eval_start", "value": 728, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 728}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445013514, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8641512393951416, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 728}}
:::MLLOG {"namespace": "", "time_ms": 1621445013514, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 728}}
:::MLLOG {"namespace": "", "time_ms": 1621445013580, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4003.6617800092217, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445013582, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1155885430463577, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445013582, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4003.6617800092217, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 728}}
rank 0: cycle = 53: time to send the model = 0.041320085525512695
:::MLLOG {"namespace": "", "time_ms": 1621445013625, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 742, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445013626, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 742, "epoch_count": 14}}
rank 640: cycle = 53: time to receive the model = 0.05192995071411133
:::MLLOG {"namespace": "", "time_ms": 1621445013636, "event_type": "INTERVAL_START", "key": "eval_start", "value": 742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 742}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445014401, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.897860050201416, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 742}}
:::MLLOG {"namespace": "", "time_ms": 1621445014401, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 742}}
:::MLLOG {"namespace": "", "time_ms": 1621445014406, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4307.226400718112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445014408, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1364480794701988, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445014409, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4307.226400718112, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 742}}
rank 0: cycle = 54: time to send the model = 0.04398655891418457
:::MLLOG {"namespace": "", "time_ms": 1621445014453, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 756, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445014454, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 756, "epoch_count": 14}}
rank 640: cycle = 54: time to receive the model = 0.05224776268005371
:::MLLOG {"namespace": "", "time_ms": 1621445014462, "event_type": "INTERVAL_START", "key": "eval_start", "value": 756, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 756}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.781 s.
:::MLLOG {"namespace": "", "time_ms": 1621445015244, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8744597434997559, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 756}}
:::MLLOG {"namespace": "", "time_ms": 1621445015245, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 756}}
:::MLLOG {"namespace": "", "time_ms": 1621445015274, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4096.982378412793, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445015276, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1573076158940396, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445015276, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4096.982378412793, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 756}}
rank 0: cycle = 55: time to send the model = 0.03909015655517578
:::MLLOG {"namespace": "", "time_ms": 1621445015317, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 770, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445015317, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 770, "epoch_count": 14}}
rank 640: cycle = 55: time to receive the model = 0.049011945724487305
:::MLLOG {"namespace": "", "time_ms": 1621445015327, "event_type": "INTERVAL_START", "key": "eval_start", "value": 770, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 770}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445016096, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8738774657249451, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 770}}
:::MLLOG {"namespace": "", "time_ms": 1621445016096, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 770}}
:::MLLOG {"namespace": "", "time_ms": 1621445016150, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4032.746879047309, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445016152, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1781671523178807, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445016153, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4032.746879047309, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 770}}
rank 0: cycle = 56: time to send the model = 0.04514169692993164
:::MLLOG {"namespace": "", "time_ms": 1621445016198, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 784, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445016199, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 784, "epoch_count": 14}}
rank 640: cycle = 56: time to receive the model = 0.05269455909729004
:::MLLOG {"namespace": "", "time_ms": 1621445016206, "event_type": "INTERVAL_START", "key": "eval_start", "value": 784, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 784}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445016976, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.893150806427002, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 784}}
:::MLLOG {"namespace": "", "time_ms": 1621445016976, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 784}}
:::MLLOG {"namespace": "", "time_ms": 1621445016987, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4263.6492089193525, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445016989, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1990266887417218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445016989, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4263.6492089193525, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 784}}
rank 0: cycle = 57: time to send the model = 0.04024362564086914
:::MLLOG {"namespace": "", "time_ms": 1621445017032, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 798, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445017032, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 798, "epoch_count": 14}}
rank 640: cycle = 57: time to receive the model = 0.051843881607055664
:::MLLOG {"namespace": "", "time_ms": 1621445017043, "event_type": "INTERVAL_START", "key": "eval_start", "value": 798, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 798}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.783 s.
:::MLLOG {"namespace": "", "time_ms": 1621445017827, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8786169290542603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 798}}
:::MLLOG {"namespace": "", "time_ms": 1621445017828, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 798}}
:::MLLOG {"namespace": "", "time_ms": 1621445017845, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4134.223641021595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445017847, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2198862251655629, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445017847, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4134.223641021595, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 798}}
rank 0: cycle = 58: time to send the model = 0.04809713363647461
:::MLLOG {"namespace": "", "time_ms": 1621445017896, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 812, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445017896, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 812, "epoch_count": 14}}
rank 640: cycle = 58: time to receive the model = 0.054924726486206055
:::MLLOG {"namespace": "", "time_ms": 1621445017902, "event_type": "INTERVAL_START", "key": "eval_start", "value": 812, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 812}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.788 s.
:::MLLOG {"namespace": "", "time_ms": 1621445018692, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8673795461654663, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 812}}
:::MLLOG {"namespace": "", "time_ms": 1621445018693, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 812}}
:::MLLOG {"namespace": "", "time_ms": 1621445018714, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4106.1321445741005, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445018716, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.240745761589404, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445018716, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4106.1321445741005, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 812}}
rank 0: cycle = 59: time to send the model = 0.04067182540893555
:::MLLOG {"namespace": "", "time_ms": 1621445018760, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 826, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445018760, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 826, "epoch_count": 14}}
rank 640: cycle = 59: time to receive the model = 0.05202126502990723
:::MLLOG {"namespace": "", "time_ms": 1621445018771, "event_type": "INTERVAL_START", "key": "eval_start", "value": 826, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 826}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445019543, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4290.324266218867, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
EVALUATION TIME: 0.772 s.
:::MLLOG {"namespace": "", "time_ms": 1621445019544, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.881816029548645, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 826}}
:::MLLOG {"namespace": "", "time_ms": 1621445019544, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 826}}
:::MLLOG {"namespace": "", "time_ms": 1621445019546, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445019548, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4290.324266218867, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 826}}
rank 0: cycle = 60: time to send the model = 0.05175638198852539
:::MLLOG {"namespace": "", "time_ms": 1621445019601, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 840, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445019601, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 840, "epoch_count": 14}}
rank 640: cycle = 60: time to receive the model = 0.059880733489990234
:::MLLOG {"namespace": "", "time_ms": 1621445019609, "event_type": "INTERVAL_START", "key": "eval_start", "value": 840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 840}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445020384, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4293.199642600486, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445020385, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2824648344370861, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445020386, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4293.199642600486, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 840}}
EVALUATION TIME: 0.785 s.
:::MLLOG {"namespace": "", "time_ms": 1621445020395, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8920278549194336, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 840}}
:::MLLOG {"namespace": "", "time_ms": 1621445020396, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 840}}
rank 0: cycle = 61: time to send the model = 0.038245201110839844
:::MLLOG {"namespace": "", "time_ms": 1621445020435, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 854, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445020436, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 854, "epoch_count": 14}}
rank 640: cycle = 61: time to receive the model = 0.04957079887390137
:::MLLOG {"namespace": "", "time_ms": 1621445020446, "event_type": "INTERVAL_START", "key": "eval_start", "value": 854, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 854}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445021216, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8924975395202637, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 854}}
:::MLLOG {"namespace": "", "time_ms": 1621445021216, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 854}}
:::MLLOG {"namespace": "", "time_ms": 1621445021220, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4286.616803167742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445021222, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3033243708609272, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445021222, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4286.616803167742, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 854}}
rank 0: cycle = 62: time to send the model = 0.05886673927307129
:::MLLOG {"namespace": "", "time_ms": 1621445021282, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 868, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445021282, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 868, "epoch_count": 14}}
rank 640: cycle = 62: time to receive the model = 0.07371735572814941
:::MLLOG {"namespace": "", "time_ms": 1621445021297, "event_type": "INTERVAL_START", "key": "eval_start", "value": 868, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 868}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445022064, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8842333555221558, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 868}}
:::MLLOG {"namespace": "", "time_ms": 1621445022065, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 868}}
:::MLLOG {"namespace": "", "time_ms": 1621445022070, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4262.825107509367, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445022072, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3241839072847683, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445022072, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4262.825107509367, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 868}}
rank 0: cycle = 63: time to send the model = 0.0421144962310791
:::MLLOG {"namespace": "", "time_ms": 1621445022115, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 882, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445022115, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 882, "epoch_count": 14}}
rank 640: cycle = 63: time to receive the model = 0.05386018753051758
:::MLLOG {"namespace": "", "time_ms": 1621445022126, "event_type": "INTERVAL_START", "key": "eval_start", "value": 882, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 882}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445022891, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.882104754447937, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 882}}
:::MLLOG {"namespace": "", "time_ms": 1621445022892, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 882}}
:::MLLOG {"namespace": "", "time_ms": 1621445022912, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4216.034142643542, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445022915, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3450434437086094, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445022915, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4216.034142643542, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 882}}
rank 0: cycle = 64: time to send the model = 0.042940616607666016
:::MLLOG {"namespace": "", "time_ms": 1621445022959, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 896, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445022960, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 896, "epoch_count": 14}}
rank 640: cycle = 64: time to receive the model = 0.04892301559448242
:::MLLOG {"namespace": "", "time_ms": 1621445022965, "event_type": "INTERVAL_START", "key": "eval_start", "value": 896, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 896}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445023736, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8207363486289978, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 896}}
:::MLLOG {"namespace": "", "time_ms": 1621445023736, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 896}}
:::MLLOG {"namespace": "", "time_ms": 1621445023764, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4175.995491196187, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445023766, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3659029801324505, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445023766, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4175.995491196187, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 896}}
rank 0: cycle = 65: time to send the model = 0.039465904235839844
:::MLLOG {"namespace": "", "time_ms": 1621445023807, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 910, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445023807, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 910, "epoch_count": 14}}
rank 640: cycle = 65: time to receive the model = 0.050446510314941406
:::MLLOG {"namespace": "", "time_ms": 1621445023818, "event_type": "INTERVAL_START", "key": "eval_start", "value": 910, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 910}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445024587, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8780674338340759, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 910}}
:::MLLOG {"namespace": "", "time_ms": 1621445024587, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 910}}
:::MLLOG {"namespace": "", "time_ms": 1621445024611, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4182.597705707003, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445024613, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3867625165562913, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445024614, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4182.597705707003, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 910}}
rank 0: cycle = 66: time to send the model = 0.04549860954284668
:::MLLOG {"namespace": "", "time_ms": 1621445024660, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 924, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445024660, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 924, "epoch_count": 14}}
rank 640: cycle = 66: time to receive the model = 0.05438590049743652
:::MLLOG {"namespace": "", "time_ms": 1621445024668, "event_type": "INTERVAL_START", "key": "eval_start", "value": 924, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 924}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445025437, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8979840278625488, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 924}}
:::MLLOG {"namespace": "", "time_ms": 1621445025437, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 924}}
:::MLLOG {"namespace": "", "time_ms": 1621445025485, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4072.02214452888, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445025487, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4076220529801324, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445025487, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4072.02214452888, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 924}}
rank 0: cycle = 67: time to send the model = 0.039611101150512695
:::MLLOG {"namespace": "", "time_ms": 1621445025527, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 938, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445025527, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 938, "epoch_count": 14}}
rank 640: cycle = 67: time to receive the model = 0.05164480209350586
:::MLLOG {"namespace": "", "time_ms": 1621445025539, "event_type": "INTERVAL_START", "key": "eval_start", "value": 938, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 938}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.782 s.
:::MLLOG {"namespace": "", "time_ms": 1621445026322, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8937234878540039, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 938}}
:::MLLOG {"namespace": "", "time_ms": 1621445026322, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 938}}
:::MLLOG {"namespace": "", "time_ms": 1621445026324, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4216.21198962107, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445026326, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4284815894039735, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445026327, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4216.21198962107, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 938}}
rank 0: cycle = 68: time to send the model = 0.04702353477478027
:::MLLOG {"namespace": "", "time_ms": 1621445026375, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 952, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445026375, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 952, "epoch_count": 14}}
rank 640: cycle = 68: time to receive the model = 0.05349874496459961
:::MLLOG {"namespace": "", "time_ms": 1621445026381, "event_type": "INTERVAL_START", "key": "eval_start", "value": 952, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 952}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445027148, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8874548673629761, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 952}}
:::MLLOG {"namespace": "", "time_ms": 1621445027149, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 952}}
:::MLLOG {"namespace": "", "time_ms": 1621445027165, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4257.325081821318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445027166, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4493411258278146, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445027166, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4257.325081821318, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 952}}
rank 0: cycle = 69: time to send the model = 0.04022717475891113
:::MLLOG {"namespace": "", "time_ms": 1621445027208, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 966, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445027209, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 966, "epoch_count": 14}}
rank 640: cycle = 69: time to receive the model = 0.05137133598327637
:::MLLOG {"namespace": "", "time_ms": 1621445027220, "event_type": "INTERVAL_START", "key": "eval_start", "value": 966, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 966}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.765 s.
:::MLLOG {"namespace": "", "time_ms": 1621445027986, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8868039846420288, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 966}}
:::MLLOG {"namespace": "", "time_ms": 1621445027986, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 966}}
:::MLLOG {"namespace": "", "time_ms": 1621445028024, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4121.588627310027, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445028027, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4702006622516555, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445028028, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4121.588627310027, "iterations": 3, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 966}}
rank 0: cycle = 70: time to send the model = 0.04885745048522949
:::MLLOG {"namespace": "", "time_ms": 1621445028078, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 980, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445028078, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 980, "epoch_count": 14}}
rank 640: cycle = 70: time to receive the model = 0.05471539497375488
:::MLLOG {"namespace": "", "time_ms": 1621445028083, "event_type": "INTERVAL_START", "key": "eval_start", "value": 980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 980}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445028845, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4381.097843718893, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445028846, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4910601986754968, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445028847, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4381.097843718893, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 980}}
EVALUATION TIME: 0.768 s.
:::MLLOG {"namespace": "", "time_ms": 1621445028853, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8931196331977844, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 980}}
:::MLLOG {"namespace": "", "time_ms": 1621445028854, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 980}}
rank 0: cycle = 71: time to send the model = 0.036977529525756836
:::MLLOG {"namespace": "", "time_ms": 1621445028891, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 994, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445028892, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 994, "epoch_count": 14}}
rank 640: cycle = 71: time to receive the model = 0.04885435104370117
:::MLLOG {"namespace": "", "time_ms": 1621445028903, "event_type": "INTERVAL_START", "key": "eval_start", "value": 994, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 994}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445029673, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9040282964706421, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 994}}
:::MLLOG {"namespace": "", "time_ms": 1621445029673, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 994}}
:::MLLOG {"namespace": "", "time_ms": 1621445029706, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4130.596918596574, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445029709, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445029710, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4130.596918596574, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 994}}
rank 0: cycle = 72: time to send the model = 0.05043959617614746
:::MLLOG {"namespace": "", "time_ms": 1621445029761, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1008, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445029761, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1008, "epoch_count": 14}}
rank 640: cycle = 72: time to receive the model = 0.05698561668395996
:::MLLOG {"namespace": "", "time_ms": 1621445029767, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1008, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1008}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445030536, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8934693336486816, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1008}}
:::MLLOG {"namespace": "", "time_ms": 1621445030536, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1008}}
:::MLLOG {"namespace": "", "time_ms": 1621445030555, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4235.750057932934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445030556, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445030556, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4235.750057932934, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1008}}
rank 0: cycle = 73: time to send the model = 0.03885149955749512
:::MLLOG {"namespace": "", "time_ms": 1621445030596, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1022, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445030596, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1022, "epoch_count": 14}}
rank 640: cycle = 73: time to receive the model = 0.04953813552856445
:::MLLOG {"namespace": "", "time_ms": 1621445030606, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1022, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1022}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.778 s.
:::MLLOG {"namespace": "", "time_ms": 1621445031386, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8737319707870483, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1022}}
:::MLLOG {"namespace": "", "time_ms": 1621445031386, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1022}}
:::MLLOG {"namespace": "", "time_ms": 1621445031393, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4214.591740120449, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445031395, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445031395, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4214.591740120449, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1022}}
rank 0: cycle = 74: time to send the model = 0.04631328582763672
:::MLLOG {"namespace": "", "time_ms": 1621445031442, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1036, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445031442, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1036, "epoch_count": 14}}
rank 640: cycle = 74: time to receive the model = 0.05096626281738281
:::MLLOG {"namespace": "", "time_ms": 1621445031447, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1036, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1036}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445032215, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.894751787185669, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1036}}
:::MLLOG {"namespace": "", "time_ms": 1621445032215, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1036}}
:::MLLOG {"namespace": "", "time_ms": 1621445032229, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4268.2398221332205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445032231, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445032231, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4268.2398221332205, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1036}}
rank 0: cycle = 75: time to send the model = 0.038410186767578125
:::MLLOG {"namespace": "", "time_ms": 1621445032271, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1050, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445032272, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1050, "epoch_count": 14}}
rank 640: cycle = 75: time to receive the model = 0.04894876480102539
:::MLLOG {"namespace": "", "time_ms": 1621445032282, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1050, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1050}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445033044, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4351.4643888437395, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445033046, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445033047, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4351.4643888437395, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1050}}
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445033052, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8961564898490906, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1050}}
:::MLLOG {"namespace": "", "time_ms": 1621445033054, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1050}}
rank 0: cycle = 76: time to send the model = 0.046961069107055664
:::MLLOG {"namespace": "", "time_ms": 1621445033101, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1064, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445033103, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1064, "epoch_count": 14}}
rank 640: cycle = 76: time to receive the model = 0.05019259452819824
:::MLLOG {"namespace": "", "time_ms": 1621445033105, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1064, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1064}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445033875, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8779038190841675, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1064}}
:::MLLOG {"namespace": "", "time_ms": 1621445033875, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1064}}
:::MLLOG {"namespace": "", "time_ms": 1621445033880, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4324.584687879936, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445033882, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445033882, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4324.584687879936, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1064}}
rank 0: cycle = 77: time to send the model = 0.04471111297607422
:::MLLOG {"namespace": "", "time_ms": 1621445033928, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1078, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445033928, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1078, "epoch_count": 14}}
rank 640: cycle = 77: time to receive the model = 0.059461355209350586
:::MLLOG {"namespace": "", "time_ms": 1621445033943, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1078, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1078}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.763 s.
:::MLLOG {"namespace": "", "time_ms": 1621445034707, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8892199993133545, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1078}}
:::MLLOG {"namespace": "", "time_ms": 1621445034707, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1078}}
:::MLLOG {"namespace": "", "time_ms": 1621445034723, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4231.001643120674, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445034725, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445034725, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4231.001643120674, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1078}}
rank 0: cycle = 78: time to send the model = 0.04861617088317871
:::MLLOG {"namespace": "", "time_ms": 1621445034774, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1092, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445034774, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1092, "epoch_count": 14}}
rank 640: cycle = 78: time to receive the model = 0.056252479553222656
:::MLLOG {"namespace": "", "time_ms": 1621445034781, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1092}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445035549, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8724730014801025, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1092}}
:::MLLOG {"namespace": "", "time_ms": 1621445035550, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1092}}
:::MLLOG {"namespace": "", "time_ms": 1621445035563, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4259.1315311808485, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445035565, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445035565, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4259.1315311808485, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1092}}
rank 0: cycle = 79: time to send the model = 0.03893756866455078
:::MLLOG {"namespace": "", "time_ms": 1621445035606, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1106, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445035606, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1106, "epoch_count": 14}}
rank 640: cycle = 79: time to receive the model = 0.04955887794494629
:::MLLOG {"namespace": "", "time_ms": 1621445035617, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1106, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1106}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445036387, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8855512142181396, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1106}}
:::MLLOG {"namespace": "", "time_ms": 1621445036387, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1106}}
:::MLLOG {"namespace": "", "time_ms": 1621445036389, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4292.919777690793, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445036391, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445036391, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4292.919777690793, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1106}}
rank 0: cycle = 80: time to send the model = 0.04067683219909668
:::MLLOG {"namespace": "", "time_ms": 1621445036432, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1120, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445036432, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1120, "epoch_count": 14}}
rank 640: cycle = 80: time to receive the model = 0.04990196228027344
:::MLLOG {"namespace": "", "time_ms": 1621445036441, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1120}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.781 s.
:::MLLOG {"namespace": "", "time_ms": 1621445037223, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8926652669906616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1621445037224, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1621445037243, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4146.73746565439, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445037244, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445037244, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4146.73746565439, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1120}}
rank 0: cycle = 81: time to send the model = 0.03916025161743164
:::MLLOG {"namespace": "", "time_ms": 1621445037285, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1134, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445037286, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1134, "epoch_count": 14}}
rank 640: cycle = 81: time to receive the model = 0.04822421073913574
:::MLLOG {"namespace": "", "time_ms": 1621445037294, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1134, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1134}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.771 s.
:::MLLOG {"namespace": "", "time_ms": 1621445038066, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8917769193649292, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1134}}
:::MLLOG {"namespace": "", "time_ms": 1621445038067, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1134}}
:::MLLOG {"namespace": "", "time_ms": 1621445038117, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4044.0680746195717, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445038119, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445038120, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4044.0680746195717, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1134}}
rank 0: cycle = 82: time to send the model = 0.04775834083557129
:::MLLOG {"namespace": "", "time_ms": 1621445038169, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1148, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445038169, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1148, "epoch_count": 14}}
rank 640: cycle = 82: time to receive the model = 0.05639457702636719
:::MLLOG {"namespace": "", "time_ms": 1621445038177, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1148, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1148}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445038948, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8934664726257324, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1148}}
:::MLLOG {"namespace": "", "time_ms": 1621445038948, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1148}}
:::MLLOG {"namespace": "", "time_ms": 1621445038951, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4298.309006102725, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445038952, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445038952, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4298.309006102725, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1148}}
rank 0: cycle = 83: time to send the model = 0.04039931297302246
:::MLLOG {"namespace": "", "time_ms": 1621445038996, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1162, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445038997, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1162, "epoch_count": 14}}
rank 640: cycle = 83: time to receive the model = 0.050649166107177734
:::MLLOG {"namespace": "", "time_ms": 1621445039007, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1162, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1162}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445039763, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4385.146625211745, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445039765, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445039766, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4385.146625211745, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1162}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445039775, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8962850570678711, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1162}}
:::MLLOG {"namespace": "", "time_ms": 1621445039776, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1162}}
rank 0: cycle = 84: time to send the model = 0.047782182693481445
:::MLLOG {"namespace": "", "time_ms": 1621445039824, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1176, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445039825, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1176, "epoch_count": 14}}
rank 640: cycle = 84: time to receive the model = 0.056203365325927734
:::MLLOG {"namespace": "", "time_ms": 1621445039832, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1176, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1176}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445040600, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8923790454864502, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1176}}
:::MLLOG {"namespace": "", "time_ms": 1621445040600, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1176}}
:::MLLOG {"namespace": "", "time_ms": 1621445040610, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4281.392102572142, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445040612, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445040612, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4281.392102572142, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1176}}
rank 0: cycle = 85: time to send the model = 0.040978431701660156
:::MLLOG {"namespace": "", "time_ms": 1621445040654, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1190, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445040655, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1190, "epoch_count": 14}}
rank 640: cycle = 85: time to receive the model = 0.0515437126159668
:::MLLOG {"namespace": "", "time_ms": 1621445040665, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1190, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1190}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445041432, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9021729826927185, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1190}}
:::MLLOG {"namespace": "", "time_ms": 1621445041433, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1190}}
:::MLLOG {"namespace": "", "time_ms": 1621445041458, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4180.90023294367, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445041461, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445041461, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4180.90023294367, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1190}}
rank 0: cycle = 86: time to send the model = 0.0479891300201416
:::MLLOG {"namespace": "", "time_ms": 1621445041510, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1204, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445041510, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1204, "epoch_count": 14}}
rank 640: cycle = 86: time to receive the model = 0.05269312858581543
:::MLLOG {"namespace": "", "time_ms": 1621445041514, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1204, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1204}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.785 s.
:::MLLOG {"namespace": "", "time_ms": 1621445042301, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8875206708908081, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1204}}
:::MLLOG {"namespace": "", "time_ms": 1621445042301, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1204}}
:::MLLOG {"namespace": "", "time_ms": 1621445042312, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4188.400349982881, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445042314, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445042314, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4188.400349982881, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1204}}
rank 0: cycle = 87: time to send the model = 0.040581464767456055
:::MLLOG {"namespace": "", "time_ms": 1621445042355, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1218, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445042355, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1218, "epoch_count": 14}}
rank 640: cycle = 87: time to receive the model = 0.050234317779541016
:::MLLOG {"namespace": "", "time_ms": 1621445042365, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1218}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445043133, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8918589353561401, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1218}}
:::MLLOG {"namespace": "", "time_ms": 1621445043133, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1218}}
:::MLLOG {"namespace": "", "time_ms": 1621445043143, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4268.512599702082, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445043145, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445043146, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4268.512599702082, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1218}}
rank 0: cycle = 88: time to send the model = 0.04563117027282715
:::MLLOG {"namespace": "", "time_ms": 1621445043192, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1232, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445043193, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1232, "epoch_count": 14}}
rank 640: cycle = 88: time to receive the model = 0.05011701583862305
:::MLLOG {"namespace": "", "time_ms": 1621445043197, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1232, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1232}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.77 s.
:::MLLOG {"namespace": "", "time_ms": 1621445043968, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8989198207855225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1232}}
:::MLLOG {"namespace": "", "time_ms": 1621445043968, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1232}}
:::MLLOG {"namespace": "", "time_ms": 1621445043994, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4191.052192539895, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445043996, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445043996, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4191.052192539895, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1232}}
rank 0: cycle = 89: time to send the model = 0.0412898063659668
:::MLLOG {"namespace": "", "time_ms": 1621445044038, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1246, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445044038, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1246, "epoch_count": 14}}
rank 640: cycle = 89: time to receive the model = 0.05219745635986328
:::MLLOG {"namespace": "", "time_ms": 1621445044049, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1246, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1246}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445044816, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8989919424057007, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1246}}
:::MLLOG {"namespace": "", "time_ms": 1621445044816, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1246}}
:::MLLOG {"namespace": "", "time_ms": 1621445044840, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4187.86391284593, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445044843, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445044844, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4187.86391284593, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1246}}
rank 0: cycle = 90: time to send the model = 0.043790340423583984
:::MLLOG {"namespace": "", "time_ms": 1621445044888, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1260, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445044888, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1260, "epoch_count": 14}}
rank 640: cycle = 90: time to receive the model = 0.053049564361572266
:::MLLOG {"namespace": "", "time_ms": 1621445044897, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1260}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445045662, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4344.271885721684, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445045663, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445045663, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4344.271885721684, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1260}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445045665, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9055739045143127, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1621445045667, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1260}}
rank 0: cycle = 91: time to send the model = 0.03884720802307129
:::MLLOG {"namespace": "", "time_ms": 1621445045706, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1274, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445045707, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1274, "epoch_count": 14}}
rank 640: cycle = 91: time to receive the model = 0.0485224723815918
:::MLLOG {"namespace": "", "time_ms": 1621445045715, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1274, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1274}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445046484, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8989117741584778, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1274}}
:::MLLOG {"namespace": "", "time_ms": 1621445046484, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1274}}
:::MLLOG {"namespace": "", "time_ms": 1621445046493, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4276.546053510001, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445046495, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445046496, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4276.546053510001, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1274}}
rank 0: cycle = 92: time to send the model = 0.04440760612487793
:::MLLOG {"namespace": "", "time_ms": 1621445046541, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1288, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445046541, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1288, "epoch_count": 14}}
rank 640: cycle = 92: time to receive the model = 0.05139017105102539
:::MLLOG {"namespace": "", "time_ms": 1621445046548, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1288, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1288}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445047299, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4434.3836419885165, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445047301, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445047301, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4434.3836419885165, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1288}}
EVALUATION TIME: 0.766 s.
:::MLLOG {"namespace": "", "time_ms": 1621445047315, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9078391790390015, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1288}}
:::MLLOG {"namespace": "", "time_ms": 1621445047316, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1288}}
rank 0: cycle = 93: time to send the model = 0.035858869552612305
:::MLLOG {"namespace": "", "time_ms": 1621445047352, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1302, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445047353, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1302, "epoch_count": 14}}
rank 640: cycle = 93: time to receive the model = 0.050397634506225586
:::MLLOG {"namespace": "", "time_ms": 1621445047367, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1302, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1302}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.778 s.
:::MLLOG {"namespace": "", "time_ms": 1621445048146, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.906265139579773, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1302}}
:::MLLOG {"namespace": "", "time_ms": 1621445048146, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1302}}
:::MLLOG {"namespace": "", "time_ms": 1621445048194, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 3996.4635897971066, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445048196, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445048197, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 3996.4635897971066, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1302}}
rank 0: cycle = 94: time to send the model = 0.0588839054107666
:::MLLOG {"namespace": "", "time_ms": 1621445048256, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1316, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445048257, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1316, "epoch_count": 14}}
rank 640: cycle = 94: time to receive the model = 0.07386922836303711
:::MLLOG {"namespace": "", "time_ms": 1621445048271, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1316, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1316}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.764 s.
:::MLLOG {"namespace": "", "time_ms": 1621445049037, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8765168190002441, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1316}}
:::MLLOG {"namespace": "", "time_ms": 1621445049037, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1316}}
:::MLLOG {"namespace": "", "time_ms": 1621445049071, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4124.670719671826, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445049073, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445049073, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4124.670719671826, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1316}}
rank 0: cycle = 95: time to send the model = 0.039168596267700195
:::MLLOG {"namespace": "", "time_ms": 1621445049112, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1330, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445049113, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1330, "epoch_count": 14}}
rank 640: cycle = 95: time to receive the model = 0.0493471622467041
:::MLLOG {"namespace": "", "time_ms": 1621445049123, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1330, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1330}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445049872, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4424.4949329569245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445049874, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445049875, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4424.4949329569245, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1330}}
EVALUATION TIME: 0.767 s.
:::MLLOG {"namespace": "", "time_ms": 1621445049891, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9025084972381592, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1330}}
:::MLLOG {"namespace": "", "time_ms": 1621445049892, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1330}}
rank 0: cycle = 96: time to send the model = 0.04957270622253418
:::MLLOG {"namespace": "", "time_ms": 1621445049942, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1344, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445049943, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1344, "epoch_count": 14}}
rank 640: cycle = 96: time to receive the model = 0.05370593070983887
:::MLLOG {"namespace": "", "time_ms": 1621445049946, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1344, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1344}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.769 s.
:::MLLOG {"namespace": "", "time_ms": 1621445050716, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8710950016975403, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1344}}
:::MLLOG {"namespace": "", "time_ms": 1621445050716, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1344}}
:::MLLOG {"namespace": "", "time_ms": 1621445050756, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4131.506333348089, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445050758, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445050758, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4131.506333348089, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1344}}
rank 0: cycle = 97: time to send the model = 0.038536787033081055
:::MLLOG {"namespace": "", "time_ms": 1621445050798, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1358, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445050798, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1358, "epoch_count": 14}}
rank 640: cycle = 97: time to receive the model = 0.049355268478393555
:::MLLOG {"namespace": "", "time_ms": 1621445050809, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1358, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1358}}
EVALUATION FROM CACHE
EVALUATION TIME: 0.771 s.
:::MLLOG {"namespace": "", "time_ms": 1621445051581, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9035969972610474, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1358}}
:::MLLOG {"namespace": "", "time_ms": 1621445051581, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1358}}
:::MLLOG {"namespace": "", "time_ms": 1621445051582, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4287.390130174512, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
:::MLLOG {"namespace": "", "time_ms": 1621445051585, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
:::MLLOG {"namespace": "", "time_ms": 1621445051586, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4287.390130174512, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1358}}
rank 0: cycle = 98: time to send the model = 0.047893524169921875
:::MLLOG {"namespace": "", "time_ms": 1621445051635, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 114, "first_epoch_num": 1372, "epoch_count": 14}}
:::MLLOG {"namespace": "", "time_ms": 1621445051636, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 32, "first_epoch_num": 1372, "epoch_count": 14}}
rank 640: cycle = 98: time to receive the model = 0.05554366111755371
:::MLLOG {"namespace": "", "time_ms": 1621445051643, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 88, "epoch_num": 1372}}
EVALUATION FROM CACHE
:::MLLOG {"namespace": "", "time_ms": 1621445052412, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4328.235848022238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 62}}
EVALUATION TIME: 0.768 s.
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
:::MLLOG {"namespace": "", "time_ms": 1621445052412, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9082353711128235, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 91, "epoch_num": 1372}}
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
:::MLLOG {"namespace": "", "time_ms": 1621445052413, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 96, "epoch_num": 1372}}
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
STOP TRAINING TRIGGERED AFTER EVAL
:::MLLOG {"namespace": "", "time_ms": 1621445052414, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 63}}
STOP TRAINING TRIGGERED AFTER EVAL
:::MLLOG {"namespace": "", "time_ms": 1621445052415, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 102, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1621445052415, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4328.235848022238, "iterations": 3, "loss_scale": 2048.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 64, "step": 1372}}
rank 0: cycle = 99: time to send the model = 0.037993431091308594
rank 640: cycle = 99: time to receive the model = 0.04914522171020508
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
+ set +x
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
+ set +x
+ ret_code=0
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
+ set +x
+ set +x
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
+ ret_code=0
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
+ set +x
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ ret_code=0
+ set +x
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
+ set +x
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
+ set +x
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:35 AM
RESULT,image_segmentation,,497,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,498,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:36 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,499,nvidia,2021-05-19 10:16:18 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:37 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,501,nvidia,2021-05-19 10:16:17 AM
ENDING TIMING RUN AT 2021-05-19 10:24:38 AM
RESULT,image_segmentation,,500,nvidia,2021-05-19 10:16:18 AM
