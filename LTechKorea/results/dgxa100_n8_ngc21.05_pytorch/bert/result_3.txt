+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
srun: Job 1417030 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Step created for job 1417030
Clearing cache on luna-0009
Clearing cache on luna-0005
Clearing cache on luna-0001
Clearing cache on luna-0003
Clearing cache on luna-0006
Clearing cache on luna-0002
Clearing cache on luna-0008
Clearing cache on luna-0004
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=language_model python -c '
import mlperf_logger
mlperf_logger.log_event(key=mlperf_logger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1621400274508, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400274536, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400274540, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400274551, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400274561, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400274562, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400274570, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400274576, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ '[' 0 -eq 0 ']'
+ srun -l --mpi=none --ntasks=64 --ntasks-per-node=8 --container-name=language_model --container-mounts=/raid/datasets/bert/hdf5/v1p0_ref/4096_shards_uncompressed:/workspace/data,/raid/datasets/bert/hdf5/v1p0_ref/4096_shards_uncompressed:/workspace/data_phase2,/lustre/fsw/mlperf-ci/23336639/ci_checkpoints:/results,/raid/datasets/bert/checkpoints/checkpoint_phase1:/workspace/phase1,/raid/datasets/bert/hdf5/v1p0_ref/eval_uncompressed:/workspace/evaldata,/lustre/fsw/mlperf/mlperft-bert/unit_test:/workspace/unit_test_data sh -c '/workspace/bert/run_and_time.sh "    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=${SLURM_LOCALID}     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16" 4987 '
51: Run vars: id 1417030 gpus 8 mparams
55: Run vars: id 1417030 gpus 8 mparams
50: Run vars: id 1417030 gpus 8 mparams
49: Run vars: id 1417030 gpus 8 mparams
54: Run vars: id 1417030 gpus 8 mparams
53: Run vars: id 1417030 gpus 8 mparams
51: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
48: Run vars: id 1417030 gpus 8 mparams
51: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
51: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
52: Run vars: id 1417030 gpus 8 mparams
51: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
51: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
55: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
55: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
55: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
55: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
55: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
50: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
49: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
50: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
50: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
49: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
49: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
50: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
50: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
49: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
49: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
54: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
54: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
54: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
54: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
54: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 4: Run vars: id 1417030 gpus 8 mparams
53: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
48: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
53: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
53: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
53: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
53: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
48: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
48: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
52: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
48: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
48: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
52: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
52: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
52: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
52: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 7: Run vars: id 1417030 gpus 8 mparams
 1: Run vars: id 1417030 gpus 8 mparams
 6: Run vars: id 1417030 gpus 8 mparams
 5: Run vars: id 1417030 gpus 8 mparams
 2: Run vars: id 1417030 gpus 8 mparams
 4: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
 0: Run vars: id 1417030 gpus 8 mparams
 4: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 4: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
59: Run vars: id 1417030 gpus 8 mparams
 4: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
 4: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
62: Run vars: id 1417030 gpus 8 mparams
 3: Run vars: id 1417030 gpus 8 mparams
60: Run vars: id 1417030 gpus 8 mparams
56: Run vars: id 1417030 gpus 8 mparams
58: Run vars: id 1417030 gpus 8 mparams
 7: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
 7: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 7: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
 1: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
61: Run vars: id 1417030 gpus 8 mparams
57: Run vars: id 1417030 gpus 8 mparams
 7: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
39: Run vars: id 1417030 gpus 8 mparams
34: Run vars: id 1417030 gpus 8 mparams
59: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
33: Run vars: id 1417030 gpus 8 mparams
59: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
59: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
35: Run vars: id 1417030 gpus 8 mparams
36: Run vars: id 1417030 gpus 8 mparams
59: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
59: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
62: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
63: Run vars: id 1417030 gpus 8 mparams
62: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
62: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
62: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
62: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
32: Run vars: id 1417030 gpus 8 mparams
38: Run vars: id 1417030 gpus 8 mparams
60: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
60: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
37: Run vars: id 1417030 gpus 8 mparams
60: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
60: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
60: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
56: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
58: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
56: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
56: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
58: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
58: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
56: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
56: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
58: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
58: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
34: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
61: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
57: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
34: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
34: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
61: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
39: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
61: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
57: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
57: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
39: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
61: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
39: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
34: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
61: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
34: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
57: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
57: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
39: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
39: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
33: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
36: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
33: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
33: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
36: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
36: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
33: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
33: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
35: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
36: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
36: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
35: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
35: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
35: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
35: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
32: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
38: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
32: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
32: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
63: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
63: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
37: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
38: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
38: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
63: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
32: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
32: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
37: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
63: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
37: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
63: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
38: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
38: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
37: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
37: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
19: Run vars: id 1417030 gpus 8 mparams
23: Run vars: id 1417030 gpus 8 mparams
20: Run vars: id 1417030 gpus 8 mparams
22: Run vars: id 1417030 gpus 8 mparams
16: Run vars: id 1417030 gpus 8 mparams
18: Run vars: id 1417030 gpus 8 mparams
21: Run vars: id 1417030 gpus 8 mparams
19: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
19: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
19: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
17: Run vars: id 1417030 gpus 8 mparams
19: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
19: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
23: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
23: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
23: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
23: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
23: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
20: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
20: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
20: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
20: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
20: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
22: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
22: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
22: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
18: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
22: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
22: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
16: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
21: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
18: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
18: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
16: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
16: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
21: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
21: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
18: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
18: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
17: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
16: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
16: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
21: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
21: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
17: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
17: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
17: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
17: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
43: Run vars: id 1417030 gpus 8 mparams
47: Run vars: id 1417030 gpus 8 mparams
11: Run vars: id 1417030 gpus 8 mparams
44: Run vars: id 1417030 gpus 8 mparams
15: Run vars: id 1417030 gpus 8 mparams
42: Run vars: id 1417030 gpus 8 mparams
46: Run vars: id 1417030 gpus 8 mparams
 9: Run vars: id 1417030 gpus 8 mparams
12: Run vars: id 1417030 gpus 8 mparams
43: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
10: Run vars: id 1417030 gpus 8 mparams
43: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
43: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
 8: Run vars: id 1417030 gpus 8 mparams
45: Run vars: id 1417030 gpus 8 mparams
43: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
43: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
41: Run vars: id 1417030 gpus 8 mparams
13: Run vars: id 1417030 gpus 8 mparams
14: Run vars: id 1417030 gpus 8 mparams
47: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
47: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
47: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
47: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
47: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
11: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
11: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
11: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
11: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
11: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
15: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
15: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
15: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
 9: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
12: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
 9: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 9: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
15: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
15: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
12: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
12: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
 9: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
44: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
 9: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
12: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
12: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
46: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
10: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
44: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
10: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
44: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
42: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
46: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
10: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
46: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
44: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
44: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
10: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
42: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
42: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
10: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
46: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
46: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
45: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
42: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
42: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
45: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
45: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
41: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
45: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
 8: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
45: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
41: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
41: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
41: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
41: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
13: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
14: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
 8: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 8: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
13: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
13: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
 8: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
 8: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
14: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
14: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
13: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
13: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
14: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
14: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 7: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 1: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 1: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
 1: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
 1: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 5: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
 6: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
 5: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 5: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
 2: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
 5: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
 5: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 6: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 6: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
 2: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 2: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
 6: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
 6: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 2: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
 2: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 0: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
 0: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 0: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
 0: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
 0: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 3: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
 3: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 3: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
 3: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
 3: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
27: Run vars: id 1417030 gpus 8 mparams
24: Run vars: id 1417030 gpus 8 mparams
26: Run vars: id 1417030 gpus 8 mparams
30: Run vars: id 1417030 gpus 8 mparams
40: Run vars: id 1417030 gpus 8 mparams
29: Run vars: id 1417030 gpus 8 mparams
28: Run vars: id 1417030 gpus 8 mparams
31: Run vars: id 1417030 gpus 8 mparams
25: Run vars: id 1417030 gpus 8 mparams
27: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
27: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
27: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
27: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
27: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
24: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
24: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
24: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
26: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
24: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
40: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
40: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
24: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
26: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
26: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
30: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
26: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
26: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
30: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
40: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
30: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
40: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
30: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
30: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
40: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
29: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
28: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
29: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
29: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
31: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
28: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
28: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
29: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
29: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
31: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
31: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
28: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
28: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
25: STARTING TIMING RUN AT 2021-05-18 09:57:55 PM
31: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
31: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
25: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
25: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987'
25: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
25: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
51: num_sockets = 2 num_nodes=8 cores_per_socket=64
51: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
51: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 4: num_sockets = 2 num_nodes=8 cores_per_socket=64
 4: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
 4: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
43: num_sockets = 2 num_nodes=8 cores_per_socket=64
43: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
43: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
27: num_sockets = 2 num_nodes=8 cores_per_socket=64
27: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
27: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
19: num_sockets = 2 num_nodes=8 cores_per_socket=64
19: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
19: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
47: num_sockets = 2 num_nodes=8 cores_per_socket=64
47: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
47: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
34: num_sockets = 2 num_nodes=8 cores_per_socket=64
34: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
34: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
50: num_sockets = 2 num_nodes=8 cores_per_socket=64
50: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
50: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
55: num_sockets = 2 num_nodes=8 cores_per_socket=64
55: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
55: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
23: num_sockets = 2 num_nodes=8 cores_per_socket=64
59: num_sockets = 2 num_nodes=8 cores_per_socket=64
 1: num_sockets = 2 num_nodes=8 cores_per_socket=64
59: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
59: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
23: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
23: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 1: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
 1: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
39: num_sockets = 2 num_nodes=8 cores_per_socket=64
39: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
39: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
36: num_sockets = 2 num_nodes=8 cores_per_socket=64
36: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
36: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
33: num_sockets = 2 num_nodes=8 cores_per_socket=64
33: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
33: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
32: num_sockets = 2 num_nodes=8 cores_per_socket=64
32: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
32: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
11: num_sockets = 2 num_nodes=8 cores_per_socket=64
11: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
11: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 9: num_sockets = 2 num_nodes=8 cores_per_socket=64
 9: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
 9: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
24: num_sockets = 2 num_nodes=8 cores_per_socket=64
24: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
24: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 7: num_sockets = 2 num_nodes=8 cores_per_socket=64
 7: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
 7: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
35: num_sockets = 2 num_nodes=8 cores_per_socket=64
38: num_sockets = 2 num_nodes=8 cores_per_socket=64
37: num_sockets = 2 num_nodes=8 cores_per_socket=64
35: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
35: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
38: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
38: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
37: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
37: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
60: num_sockets = 2 num_nodes=8 cores_per_socket=64
60: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
60: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
53: num_sockets = 2 num_nodes=8 cores_per_socket=64
53: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
53: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
49: num_sockets = 2 num_nodes=8 cores_per_socket=64
49: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
49: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
52: num_sockets = 2 num_nodes=8 cores_per_socket=64
54: num_sockets = 2 num_nodes=8 cores_per_socket=64
48: num_sockets = 2 num_nodes=8 cores_per_socket=64
52: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
52: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
54: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
54: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
48: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
48: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
41: num_sockets = 2 num_nodes=8 cores_per_socket=64
44: num_sockets = 2 num_nodes=8 cores_per_socket=64
41: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
41: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
44: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
44: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 6: num_sockets = 2 num_nodes=8 cores_per_socket=64
 6: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
 6: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
62: num_sockets = 2 num_nodes=8 cores_per_socket=64
62: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
62: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 2: num_sockets = 2 num_nodes=8 cores_per_socket=64
 5: num_sockets = 2 num_nodes=8 cores_per_socket=64
 0: num_sockets = 2 num_nodes=8 cores_per_socket=64
 3: num_sockets = 2 num_nodes=8 cores_per_socket=64
 2: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
 2: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 5: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
 5: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 0: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
 0: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 3: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
 3: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
58: num_sockets = 2 num_nodes=8 cores_per_socket=64
58: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
58: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
40: num_sockets = 2 num_nodes=8 cores_per_socket=64
45: num_sockets = 2 num_nodes=8 cores_per_socket=64
46: num_sockets = 2 num_nodes=8 cores_per_socket=64
42: num_sockets = 2 num_nodes=8 cores_per_socket=64
40: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
40: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
45: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
45: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
46: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
46: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
42: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
42: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
56: num_sockets = 2 num_nodes=8 cores_per_socket=64
61: num_sockets = 2 num_nodes=8 cores_per_socket=64
57: num_sockets = 2 num_nodes=8 cores_per_socket=64
63: num_sockets = 2 num_nodes=8 cores_per_socket=64
56: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
56: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
61: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
61: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
57: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
57: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
12: num_sockets = 2 num_nodes=8 cores_per_socket=64
63: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
63: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
20: num_sockets = 2 num_nodes=8 cores_per_socket=64
12: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
12: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
20: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
20: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
30: num_sockets = 2 num_nodes=8 cores_per_socket=64
30: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
30: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
22: num_sockets = 2 num_nodes=8 cores_per_socket=64
22: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
22: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
18: num_sockets = 2 num_nodes=8 cores_per_socket=64
18: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
18: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
16: num_sockets = 2 num_nodes=8 cores_per_socket=64
17: num_sockets = 2 num_nodes=8 cores_per_socket=64
21: num_sockets = 2 num_nodes=8 cores_per_socket=64
16: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
16: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
17: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
17: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
21: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
21: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
15: num_sockets = 2 num_nodes=8 cores_per_socket=64
 8: num_sockets = 2 num_nodes=8 cores_per_socket=64
10: num_sockets = 2 num_nodes=8 cores_per_socket=64
15: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
15: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
 8: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
 8: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
14: num_sockets = 2 num_nodes=8 cores_per_socket=64
10: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
10: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
13: num_sockets = 2 num_nodes=8 cores_per_socket=64
14: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
14: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
26: num_sockets = 2 num_nodes=8 cores_per_socket=64
13: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
13: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
26: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
26: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
28: num_sockets = 2 num_nodes=8 cores_per_socket=64
25: num_sockets = 2 num_nodes=8 cores_per_socket=64
29: num_sockets = 2 num_nodes=8 cores_per_socket=64
31: num_sockets = 2 num_nodes=8 cores_per_socket=64
28: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
28: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
25: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
25: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
31: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
31: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
29: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
29: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4987
51: :::MLLOG {"namespace": "", "time_ms": 1621400277252, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 4: :::MLLOG {"namespace": "", "time_ms": 1621400277266, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
27: :::MLLOG {"namespace": "", "time_ms": 1621400277300, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 1: :::MLLOG {"namespace": "", "time_ms": 1621400277307, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
43: :::MLLOG {"namespace": "", "time_ms": 1621400277313, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
55: :::MLLOG {"namespace": "", "time_ms": 1621400277344, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
50: :::MLLOG {"namespace": "", "time_ms": 1621400277347, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
47: :::MLLOG {"namespace": "", "time_ms": 1621400277370, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
19: :::MLLOG {"namespace": "", "time_ms": 1621400277382, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
34: :::MLLOG {"namespace": "", "time_ms": 1621400277397, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
24: :::MLLOG {"namespace": "", "time_ms": 1621400277396, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 6: :::MLLOG {"namespace": "", "time_ms": 1621400277397, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
26: :::MLLOG {"namespace": "", "time_ms": 1621400277401, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 7: :::MLLOG {"namespace": "", "time_ms": 1621400277405, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
59: :::MLLOG {"namespace": "", "time_ms": 1621400277412, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
11: :::MLLOG {"namespace": "", "time_ms": 1621400277428, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
44: :::MLLOG {"namespace": "", "time_ms": 1621400277436, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
23: :::MLLOG {"namespace": "", "time_ms": 1621400277438, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
49: :::MLLOG {"namespace": "", "time_ms": 1621400277443, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
36: :::MLLOG {"namespace": "", "time_ms": 1621400277453, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 9: :::MLLOG {"namespace": "", "time_ms": 1621400277467, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
54: :::MLLOG {"namespace": "", "time_ms": 1621400277493, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
46: :::MLLOG {"namespace": "", "time_ms": 1621400277498, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
16: :::MLLOG {"namespace": "", "time_ms": 1621400277507, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
30: :::MLLOG {"namespace": "", "time_ms": 1621400277510, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
48: :::MLLOG {"namespace": "", "time_ms": 1621400277522, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 2: :::MLLOG {"namespace": "", "time_ms": 1621400277524, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
60: :::MLLOG {"namespace": "", "time_ms": 1621400277524, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
58: :::MLLOG {"namespace": "", "time_ms": 1621400277530, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 5: :::MLLOG {"namespace": "", "time_ms": 1621400277537, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
14: :::MLLOG {"namespace": "", "time_ms": 1621400277540, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
29: :::MLLOG {"namespace": "", "time_ms": 1621400277546, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
37: :::MLLOG {"namespace": "", "time_ms": 1621400277547, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
53: :::MLLOG {"namespace": "", "time_ms": 1621400277546, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 3: :::MLLOG {"namespace": "", "time_ms": 1621400277557, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
52: :::MLLOG {"namespace": "", "time_ms": 1621400277562, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400277564, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
33: :::MLLOG {"namespace": "", "time_ms": 1621400277573, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
28: :::MLLOG {"namespace": "", "time_ms": 1621400277574, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
42: :::MLLOG {"namespace": "", "time_ms": 1621400277586, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
31: :::MLLOG {"namespace": "", "time_ms": 1621400277586, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
63: :::MLLOG {"namespace": "", "time_ms": 1621400277600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
41: :::MLLOG {"namespace": "", "time_ms": 1621400277599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
25: :::MLLOG {"namespace": "", "time_ms": 1621400277604, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
45: :::MLLOG {"namespace": "", "time_ms": 1621400277609, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
17: :::MLLOG {"namespace": "", "time_ms": 1621400277611, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
40: :::MLLOG {"namespace": "", "time_ms": 1621400277615, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
18: :::MLLOG {"namespace": "", "time_ms": 1621400277627, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
32: :::MLLOG {"namespace": "", "time_ms": 1621400277639, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
20: :::MLLOG {"namespace": "", "time_ms": 1621400277641, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
12: :::MLLOG {"namespace": "", "time_ms": 1621400277648, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
39: :::MLLOG {"namespace": "", "time_ms": 1621400277654, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
21: :::MLLOG {"namespace": "", "time_ms": 1621400277662, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
61: :::MLLOG {"namespace": "", "time_ms": 1621400277670, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
22: :::MLLOG {"namespace": "", "time_ms": 1621400277675, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
15: :::MLLOG {"namespace": "", "time_ms": 1621400277680, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
38: :::MLLOG {"namespace": "", "time_ms": 1621400277685, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
62: :::MLLOG {"namespace": "", "time_ms": 1621400277684, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
35: :::MLLOG {"namespace": "", "time_ms": 1621400277693, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
57: :::MLLOG {"namespace": "", "time_ms": 1621400277696, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
56: :::MLLOG {"namespace": "", "time_ms": 1621400277704, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
13: :::MLLOG {"namespace": "", "time_ms": 1621400277706, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
10: :::MLLOG {"namespace": "", "time_ms": 1621400277715, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 8: :::MLLOG {"namespace": "", "time_ms": 1621400277722, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
52: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
 0: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
59: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
28: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
58: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400278644, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 66}}
32: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
 7: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400278644, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 71}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400278644, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 75}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400278644, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 79}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400278644, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xNVIDIA DGX A100", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 83}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400278644, "event_type": "POINT_IN_TIME", "key": "seed", "value": 4987, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1006}}
12: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400278644, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 3072, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400278644, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 48, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1010}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400278645, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1012}}
54: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400278645, "event_type": "POINT_IN_TIME", "key": "max_predictions_per_seq", "value": 76, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1014}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400278645, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 1271.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400278645, "event_type": "POINT_IN_TIME", "key": "num_warmup_steps", "value": 100.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1018}}
 0: parsed args:
 0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=0, dwu_num_ag_pg=2, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=175000, eval_iter_start_samples=175000, exchange_padding=True, fp16=True, fused_dropout_add=False, fused_gelu_bias=True, fused_mha=True, gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_d
 0: ir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.0015, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=1271.0, min_samples_to_start_checkpoints=3000000, n_gpu=64, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.83, opt_lamb_beta_2=0.925, output_dir='/results', pad=False, phase2=True, resume_from_checkpoint=False, seed=4987, skip_checkpoint=True, start_warmup_step=-25.0, target_mlm_accuracy=0.72, train_batch_size=48, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_steps=100.0, weight_decay_rate=0.01)
33: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
42: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
23: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
 5: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
63: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
14: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
39: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
61: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
38: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
10: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
55: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
18: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
22: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
43: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
56: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
 3: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
46: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
24: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
53: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
50: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
27: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
48: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
26: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
36: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
 8: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
37: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
34: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
 4: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
20: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
25: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
19: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
30: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
13: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
35: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
51: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
49: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
44: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
 1: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
 9: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
41: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
31: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
40: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
16: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
 2: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
17: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
45: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
29: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
 6: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
11: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
60: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
21: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
62: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
15: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
57: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
47: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400284714, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0015, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 669}}
 0: [luna-0001:0:2832938 - context.c:581] INFO job (ID: 17873238447670360624) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 0: [luna-0001:0:2832938 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 0: [luna-0001:0:2832938 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 0: [luna-0001:0:2832938 - comm.c:385] INFO [group#:0] group id:8 tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x370f00000008) mlid:c00b
 0: [luna-0001:0:2832938 - comm.c:385] INFO [group#:1] group id:8 tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 1: [luna-0001:0:2832931 - context.c:581] INFO job (ID: 17873238306157253618) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 1: [luna-0001:0:2832931 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 1: [luna-0001:0:2832931 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 1: [luna-0001:0:2832931 - comm.c:385] INFO [group#:0] group id:9 tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x390f00000009) mlid:c00d
 1: [luna-0001:0:2832931 - comm.c:385] INFO [group#:1] group id:9 tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 2: [luna-0001:0:2832936 - context.c:581] INFO job (ID: 17873237748099447814) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 2: [luna-0001:0:2832936 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 2: [luna-0001:0:2832936 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 2: [luna-0001:0:2832936 - comm.c:385] INFO [group#:0] group id:a tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x3b0f0000000a) mlid:c017
 2: [luna-0001:0:2832936 - comm.c:385] INFO [group#:1] group id:a tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 3: [luna-0001:0:2832942 - context.c:581] INFO job (ID: 17873238255199854290) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 3: [luna-0001:0:2832942 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 3: [luna-0001:0:2832942 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 3: [luna-0001:0:2832942 - comm.c:385] INFO [group#:0] group id:b tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x3d0f0000000b) mlid:c019
 3: [luna-0001:0:2832942 - comm.c:385] INFO [group#:1] group id:b tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 4: [luna-0001:0:2832922 - context.c:581] INFO job (ID: 17873238211259401560) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 4: [luna-0001:0:2832922 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 4: [luna-0001:0:2832922 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 4: [luna-0001:0:2832922 - comm.c:385] INFO [group#:0] group id:c tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x3e0f0000000c) mlid:c01a
 4: [luna-0001:0:2832922 - comm.c:385] INFO [group#:1] group id:c tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 5: [luna-0001:0:2832935 - context.c:581] INFO job (ID: 17873237851231789367) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 5: [luna-0001:0:2832935 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 5: [luna-0001:0:2832935 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 5: [luna-0001:0:2832935 - comm.c:385] INFO [group#:0] group id:d tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x3f0f0000000d) mlid:c01b
 5: [luna-0001:0:2832935 - comm.c:385] INFO [group#:1] group id:d tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 6: [luna-0001:0:2832937 - context.c:581] INFO job (ID: 17873238643306376915) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 6: [luna-0001:0:2832937 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 6: [luna-0001:0:2832937 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 6: [luna-0001:0:2832937 - comm.c:385] INFO [group#:0] group id:e tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x400f0000000e) mlid:c01c
 6: [luna-0001:0:2832937 - comm.c:385] INFO [group#:1] group id:e tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 7: [luna-0001:0:2832930 - context.c:581] INFO job (ID: 17873238280858963614) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 7: [luna-0001:0:2832930 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 7: [luna-0001:0:2832930 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 7: [luna-0001:0:2832930 - comm.c:385] INFO [group#:0] group id:f tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x420f0000000f) mlid:c01e
 7: [luna-0001:0:2832930 - comm.c:385] INFO [group#:1] group id:f tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 0: :::MLLOG {"namespace": "", "time_ms": 1621400294456, "event_type": "POINT_IN_TIME", "key": "opt_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 699}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400294457, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.83, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 702}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400294457, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.925, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 703}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400294457, "event_type": "POINT_IN_TIME", "key": "opt_lamb_weight_decay_rate", "value": 0.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400294461, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 100.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 86}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400294461, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 1.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 87}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400294461, "event_type": "POINT_IN_TIME", "key": "start_warmup_step", "value": -25.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 88}}
 2: Torch distributed is available.
 2: Torch distributed is initialized.
61: Torch distributed is available.
61: Torch distributed is initialized.
47: Torch distributed is available.
47: Torch distributed is initialized.
28: Torch distributed is available.
28: Torch distributed is initialized.
20: Torch distributed is available.
20: Torch distributed is initialized.
14: Torch distributed is available.
14: Torch distributed is initialized.
43: Torch distributed is available.
43: Torch distributed is initialized.
41: Torch distributed is available.
41: Torch distributed is initialized.
18: Torch distributed is available.
18: Torch distributed is initialized.
 4: Torch distributed is available.
 4: Torch distributed is initialized.
35: Torch distributed is available.
35: Torch distributed is initialized.
 1: Torch distributed is available.
 1: Torch distributed is initialized.
 5: Torch distributed is available.
 5: Torch distributed is initialized.
38: Torch distributed is available.
38: Torch distributed is initialized.
 7: Torch distributed is available.
 7: Torch distributed is initialized.
57: Torch distributed is available.
57: Torch distributed is initialized.
60: Torch distributed is available.
60: Torch distributed is initialized.
56: Torch distributed is available.
56: Torch distributed is initialized.
62: Torch distributed is available.
62: Torch distributed is initialized.
19: Torch distributed is available.
19: Torch distributed is initialized.
17: Torch distributed is available.
17: Torch distributed is initialized.
27: Torch distributed is available.
27: Torch distributed is initialized.
44: Torch distributed is available.
44: Torch distributed is initialized.
 0: Torch distributed is available.
 0: Torch distributed is initialized.
24: Torch distributed is available.
24: Torch distributed is initialized.
33: Torch distributed is available.
33: Torch distributed is initialized.
46: Torch distributed is available.
46: Torch distributed is initialized.
 3: Torch distributed is available.
 3: Torch distributed is initialized.
45: Torch distributed is available.
45: Torch distributed is initialized.
11: Torch distributed is available.
11: Torch distributed is initialized.
59: Torch distributed is available.
59: Torch distributed is initialized.
 6: Torch distributed is available.
 6: Torch distributed is initialized.
21: Torch distributed is available.
21: Torch distributed is initialized.
 9: Torch distributed is available.
 9: Torch distributed is initialized.
40: Torch distributed is available.
40: Torch distributed is initialized.
58: Torch distributed is available.
58: Torch distributed is initialized.
63: Torch distributed is available.
63: Torch distributed is initialized.
16: Torch distributed is available.
16: Torch distributed is initialized.
13: Torch distributed is available.
13: Torch distributed is initialized.
42: Torch distributed is available.
42: Torch distributed is initialized.
23: Torch distributed is available.
23: Torch distributed is initialized.
26: Torch distributed is available.
26: Torch distributed is initialized.
36: Torch distributed is available.
36: Torch distributed is initialized.
22: Torch distributed is available.
22: Torch distributed is initialized.
51: Torch distributed is available.
51: Torch distributed is initialized.
50: Torch distributed is available.
50: Torch distributed is initialized.
25: Torch distributed is available.
25: Torch distributed is initialized.
30: Torch distributed is available.
30: Torch distributed is initialized.
34: Torch distributed is available.
34: Torch distributed is initialized.
29: Torch distributed is available.
29: Torch distributed is initialized.
12: Torch distributed is available.
12: Torch distributed is initialized.
31: Torch distributed is available.
31: Torch distributed is initialized.
32: Torch distributed is available.
32: Torch distributed is initialized.
49: Torch distributed is available.
49: Torch distributed is initialized.
 8: Torch distributed is available.
 8: Torch distributed is initialized.
37: Torch distributed is available.
37: Torch distributed is initialized.
54: Torch distributed is available.
54: Torch distributed is initialized.
15: Torch distributed is available.
15: Torch distributed is initialized.
39: Torch distributed is available.
39: Torch distributed is initialized.
10: Torch distributed is available.
10: Torch distributed is initialized.
52: Torch distributed is available.
52: Torch distributed is initialized.
53: Torch distributed is available.
53: Torch distributed is initialized.
48: Torch distributed is available.
48: Torch distributed is initialized.
55: Torch distributed is available.
55: Torch distributed is initialized.
 0: :::MLLOG {"namespace": "", "time_ms": 1621400319225, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400319355, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1265}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400319378, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1276, "epoch_num": 1}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400319379, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1278, "first_epoch_num": 1, "epoch_count": 1}}
 0: parsed args:
 0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=0, dwu_num_ag_pg=2, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=175000, eval_iter_start_samples=175000, exchange_padding=True, fp16=True, fused_dropout_add=False, fused_gelu_bias=True, fused_mha=True, gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_d
 0: ir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.0015, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=1271.0, min_samples_to_start_checkpoints=3000000, n_gpu=64, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.83, opt_lamb_beta_2=0.925, output_dir='/results', pad=False, phase2=True, resume_from_checkpoint=False, resume_step=0, seed=4987, skip_checkpoint=True, start_warmup_step=-25.0, target_mlm_accuracy=0.72, train_batch_size=48, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_steps=100.0, weight_decay_rate=0.01)
 0: epoch: 1
 0: :::MLLOG {"namespace": "", "time_ms": 1621400332599, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.37061893939971924, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 57, 'eval_loss': 4.143877983093262, 'eval_mlm_accuracy': 0.37061893939971924}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400343333, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.38069283962249756, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 114, 'eval_loss': 4.044554233551025, 'eval_mlm_accuracy': 0.38069283962249756}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400354265, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.4025289714336395, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 171, 'eval_loss': 3.845395565032959, 'eval_mlm_accuracy': 0.4025289714336395}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400365136, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.43015867471694946, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 228, 'eval_loss': 3.575857400894165, 'eval_mlm_accuracy': 0.43015867471694946}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400375889, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5140331983566284, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 285, 'eval_loss': 2.854300022125244, 'eval_mlm_accuracy': 0.5140331983566284}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400386638, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6324447989463806, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 342, 'eval_loss': 1.9108048677444458, 'eval_mlm_accuracy': 0.6324447989463806}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400397420, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6957021355628967, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 399, 'eval_loss': 1.4646377563476562, 'eval_mlm_accuracy': 0.6957021355628967}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400408344, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7060539126396179, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 456, 'eval_loss': 1.3967925310134888, 'eval_mlm_accuracy': 0.7060539126396179}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400419129, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7101427912712097, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 513, 'eval_loss': 1.3672964572906494, 'eval_mlm_accuracy': 0.7101427912712097}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400429886, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7116933465003967, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 570, 'eval_loss': 1.3602792024612427, 'eval_mlm_accuracy': 0.7116933465003967}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400440722, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.713993489742279, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 627, 'eval_loss': 1.349339485168457, 'eval_mlm_accuracy': 0.713993489742279}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400451606, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7150326371192932, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 684, 'eval_loss': 1.3380496501922607, 'eval_mlm_accuracy': 0.7150326371192932}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400462378, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7165224552154541, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 741, 'eval_loss': 1.3342456817626953, 'eval_mlm_accuracy': 0.7165224552154541}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400473308, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7172486782073975, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 798, 'eval_loss': 1.3267706632614136, 'eval_mlm_accuracy': 0.7172486782073975}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400484416, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7177507877349854, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 855, 'eval_loss': 1.3252075910568237, 'eval_mlm_accuracy': 0.7177507877349854}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400495444, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7192732691764832, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 912, 'eval_loss': 1.3170740604400635, 'eval_mlm_accuracy': 0.7192732691764832}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400506378, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7199108004570007, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 969, 'eval_loss': 1.3146517276763916, 'eval_mlm_accuracy': 0.7199108004570007}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400517322, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7202237248420715, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 1026, 'eval_loss': 1.309776782989502, 'eval_mlm_accuracy': 0.7202237248420715}
 0: 0.720224 > 0.720000, Target MLM Accuracy reached at 1026
 0: (1, 1035.0) {'final_loss': 0.0}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400517382, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1567, "first_epoch_num": 1}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400517383, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1570, "epoch_num": 1}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400517383, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 3151872, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1574}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400517383, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 10000, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1577}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400517383, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1580, "status": "success"}}
 0: {'e2e_time': 239.8282070159912, 'training_sequences_per_second': 18100.279674823258, 'final_loss': 0.0, 'raw_train_time': 215.71556186676025}
60: ++ date +%s
60: + END=1621400526
60: ++ date '+%Y-%m-%d %r'
60: + END_FMT='2021-05-18 10:02:06 PM'
60: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:06 PM'
60: ENDING TIMING RUN AT 2021-05-18 10:02:06 PM
60: + RESULT=251
60: + RESULT_NAME=bert
60: RESULT,bert,4987,251,root,2021-05-18 09:57:55 PM
60: + echo 'RESULT,bert,4987,251,root,2021-05-18 09:57:55 PM'
60: + set +x
44: ++ date +%s
44: + END=1621400526
52: ++ date +%s
44: ++ date '+%Y-%m-%d %r'
52: + END=1621400526
44: + END_FMT='2021-05-18 10:02:06 PM'
44: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:06 PM'
52: ++ date '+%Y-%m-%d %r'
44: ENDING TIMING RUN AT 2021-05-18 10:02:06 PM
44: + RESULT=251
44: + RESULT_NAME=bert
44: RESULT,bert,4987,251,root,2021-05-18 09:57:55 PM
44: + echo 'RESULT,bert,4987,251,root,2021-05-18 09:57:55 PM'
44: + set +x
52: + END_FMT='2021-05-18 10:02:06 PM'
52: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:06 PM'
52: ENDING TIMING RUN AT 2021-05-18 10:02:06 PM
52: + RESULT=251
52: + RESULT_NAME=bert
52: RESULT,bert,4987,251,root,2021-05-18 09:57:55 PM
52: + echo 'RESULT,bert,4987,251,root,2021-05-18 09:57:55 PM'
52: + set +x
20: ++ date +%s
20: + END=1621400526
20: ++ date '+%Y-%m-%d %r'
20: + END_FMT='2021-05-18 10:02:06 PM'
20: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:06 PM'
20: ENDING TIMING RUN AT 2021-05-18 10:02:06 PM
20: + RESULT=251
20: + RESULT_NAME=bert
20: RESULT,bert,4987,251,root,2021-05-18 09:57:55 PM
20: + echo 'RESULT,bert,4987,251,root,2021-05-18 09:57:55 PM'
20: + set +x
12: ++ date +%s
12: + END=1621400526
12: ++ date '+%Y-%m-%d %r'
12: + END_FMT='2021-05-18 10:02:06 PM'
12: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:06 PM'
12: ENDING TIMING RUN AT 2021-05-18 10:02:06 PM
12: + RESULT=251
12: + RESULT_NAME=bert
12: RESULT,bert,4987,251,root,2021-05-18 09:57:55 PM
12: + echo 'RESULT,bert,4987,251,root,2021-05-18 09:57:55 PM'
12: + set +x
28: ++ date +%s
28: + END=1621400526
28: ++ date '+%Y-%m-%d %r'
28: + END_FMT='2021-05-18 10:02:06 PM'
28: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:06 PM'
28: ENDING TIMING RUN AT 2021-05-18 10:02:06 PM
28: + RESULT=251
28: + RESULT_NAME=bert
28: RESULT,bert,4987,251,root,2021-05-18 09:57:55 PM
28: + echo 'RESULT,bert,4987,251,root,2021-05-18 09:57:55 PM'
28: + set +x
 4: ++ date +%s
 4: + END=1621400526
 4: ++ date '+%Y-%m-%d %r'
 4: + END_FMT='2021-05-18 10:02:06 PM'
 4: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:06 PM'
 4: ENDING TIMING RUN AT 2021-05-18 10:02:06 PM
 4: + RESULT=251
 4: + RESULT_NAME=bert
 4: RESULT,bert,4987,251,root,2021-05-18 09:57:55 PM
 4: + echo 'RESULT,bert,4987,251,root,2021-05-18 09:57:55 PM'
 4: + set +x
27: ++ date +%s
27: + END=1621400527
27: ++ date '+%Y-%m-%d %r'
27: + END_FMT='2021-05-18 10:02:07 PM'
27: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:07 PM'
27: ENDING TIMING RUN AT 2021-05-18 10:02:07 PM
27: + RESULT=252
27: + RESULT_NAME=bert
27: RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM
27: + echo 'RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM'
27: + set +x
43: ++ date +%s
43: + END=1621400527
43: ++ date '+%Y-%m-%d %r'
43: + END_FMT='2021-05-18 10:02:07 PM'
43: ENDING TIMING RUN AT 2021-05-18 10:02:07 PM
43: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:07 PM'
43: + RESULT=252
43: + RESULT_NAME=bert
43: RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM
43: + echo 'RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM'
43: + set +x
11: ++ date +%s
11: + END=1621400527
11: ++ date '+%Y-%m-%d %r'
11: + END_FMT='2021-05-18 10:02:07 PM'
11: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:07 PM'
11: ENDING TIMING RUN AT 2021-05-18 10:02:07 PM
11: + RESULT=252
11: + RESULT_NAME=bert
11: RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM
11: + echo 'RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM'
11: + set +x
19: ++ date +%s
59: ++ date +%s
19: + END=1621400527
51: ++ date +%s
19: ++ date '+%Y-%m-%d %r'
59: + END=1621400527
59: ++ date '+%Y-%m-%d %r'
51: + END=1621400527
19: + END_FMT='2021-05-18 10:02:07 PM'
19: ENDING TIMING RUN AT 2021-05-18 10:02:07 PM
19: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:07 PM'
19: + RESULT=252
19: + RESULT_NAME=bert
19: RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM
19: + echo 'RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM'
19: + set +x
51: ++ date '+%Y-%m-%d %r'
59: + END_FMT='2021-05-18 10:02:07 PM'
59: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:07 PM'
59: ENDING TIMING RUN AT 2021-05-18 10:02:07 PM
59: + RESULT=252
59: + RESULT_NAME=bert
59: RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM
59: + echo 'RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM'
59: + set +x
51: + END_FMT='2021-05-18 10:02:07 PM'
51: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:07 PM'
51: ENDING TIMING RUN AT 2021-05-18 10:02:07 PM
51: + RESULT=252
51: + RESULT_NAME=bert
51: RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM
51: + echo 'RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM'
51: + set +x
 3: ++ date +%s
 3: + END=1621400527
 3: ++ date '+%Y-%m-%d %r'
 3: + END_FMT='2021-05-18 10:02:07 PM'
 3: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:07 PM'
 3: ENDING TIMING RUN AT 2021-05-18 10:02:07 PM
 3: + RESULT=252
 3: + RESULT_NAME=bert
 3: RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM
 3: + echo 'RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM'
 3: + set +x
29: ++ date +%s
29: + END=1621400527
29: ++ date '+%Y-%m-%d %r'
29: + END_FMT='2021-05-18 10:02:07 PM'
29: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:07 PM'
29: ENDING TIMING RUN AT 2021-05-18 10:02:07 PM
29: + RESULT=252
29: + RESULT_NAME=bert
29: + echo 'RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM'
29: RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM
29: + set +x
53: ++ date +%s
53: + END=1621400527
53: ++ date '+%Y-%m-%d %r'
53: + END_FMT='2021-05-18 10:02:08 PM'
53: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
53: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
53: + RESULT=252
53: + RESULT_NAME=bert
53: RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM
53: + echo 'RESULT,bert,4987,252,root,2021-05-18 09:57:55 PM'
53: + set +x
 5: ++ date +%s
 5: + END=1621400528
 5: ++ date '+%Y-%m-%d %r'
 5: + END_FMT='2021-05-18 10:02:08 PM'
 5: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
 5: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
 5: + RESULT=253
 5: + RESULT_NAME=bert
 5: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
 5: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
 5: + set +x
21: ++ date +%s
13: ++ date +%s
21: + END=1621400528
21: ++ date '+%Y-%m-%d %r'
13: + END=1621400528
13: ++ date '+%Y-%m-%d %r'
21: + END_FMT='2021-05-18 10:02:08 PM'
21: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
21: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
21: + RESULT=253
21: + RESULT_NAME=bert
21: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
21: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
21: + set +x
45: ++ date +%s
13: + END_FMT='2021-05-18 10:02:08 PM'
13: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
13: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
13: + RESULT=253
13: + RESULT_NAME=bert
13: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
13: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
13: + set +x
45: + END=1621400528
45: ++ date '+%Y-%m-%d %r'
45: + END_FMT='2021-05-18 10:02:08 PM'
45: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
45: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
45: + RESULT=253
45: + RESULT_NAME=bert
45: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
45: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
45: + set +x
61: ++ date +%s
61: + END=1621400528
61: ++ date '+%Y-%m-%d %r'
61: + END_FMT='2021-05-18 10:02:08 PM'
61: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
61: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
61: + RESULT=253
61: + RESULT_NAME=bert
61: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
61: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
61: + set +x
55: ++ date +%s
55: + END=1621400528
55: ++ date '+%Y-%m-%d %r'
55: + END_FMT='2021-05-18 10:02:08 PM'
55: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
55: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
55: + RESULT=253
55: + RESULT_NAME=bert
55: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
55: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
55: + set +x
31: ++ date +%s
63: ++ date +%s
31: + END=1621400528
31: ++ date '+%Y-%m-%d %r'
63: + END=1621400528
31: + END_FMT='2021-05-18 10:02:08 PM'
31: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
31: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
31: + RESULT=253
31: + RESULT_NAME=bert
31: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
31: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
31: + set +x
63: ++ date '+%Y-%m-%d %r'
63: + END_FMT='2021-05-18 10:02:08 PM'
63: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
63: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
63: + RESULT=253
63: + RESULT_NAME=bert
63: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
63: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
63: + set +x
47: ++ date +%s
47: + END=1621400528
47: ++ date '+%Y-%m-%d %r'
47: + END_FMT='2021-05-18 10:02:08 PM'
47: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
47: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
47: + RESULT=253
47: + RESULT_NAME=bert
47: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
47: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
47: + set +x
15: ++ date +%s
15: + END=1621400528
15: ++ date '+%Y-%m-%d %r'
15: + END_FMT='2021-05-18 10:02:08 PM'
15: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
15: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
15: + RESULT=253
15: + RESULT_NAME=bert
15: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
15: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
15: + set +x
 7: ++ date +%s
 7: + END=1621400528
 7: ++ date '+%Y-%m-%d %r'
 7: + END_FMT='2021-05-18 10:02:08 PM'
 7: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
 7: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
 7: + RESULT=253
 7: + RESULT_NAME=bert
 7: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
 7: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
 7: + set +x
23: ++ date +%s
23: + END=1621400528
23: ++ date '+%Y-%m-%d %r'
23: + END_FMT='2021-05-18 10:02:08 PM'
23: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
23: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
23: + RESULT=253
23: + RESULT_NAME=bert
23: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
23: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
23: + set +x
39: ++ date +%s
39: + END=1621400528
39: ++ date '+%Y-%m-%d %r'
39: + END_FMT='2021-05-18 10:02:08 PM'
39: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
39: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
39: + RESULT=253
39: + RESULT_NAME=bert
39: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
39: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
39: + set +x
49: ++ date +%s
49: + END=1621400528
49: ++ date '+%Y-%m-%d %r'
 9: ++ date +%s
49: + END_FMT='2021-05-18 10:02:08 PM'
49: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
49: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
49: + RESULT=253
49: + RESULT_NAME=bert
49: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
49: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
49: + set +x
 9: + END=1621400528
 9: ++ date '+%Y-%m-%d %r'
 9: + END_FMT='2021-05-18 10:02:08 PM'
 9: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
 9: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
 9: + RESULT=253
 9: + RESULT_NAME=bert
 9: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
 9: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
 9: + set +x
57: ++ date +%s
41: ++ date +%s
41: + END=1621400528
57: + END=1621400528
41: ++ date '+%Y-%m-%d %r'
57: ++ date '+%Y-%m-%d %r'
57: + END_FMT='2021-05-18 10:02:08 PM'
57: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
57: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
57: + RESULT=253
57: + RESULT_NAME=bert
57: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
57: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
57: + set +x
41: + END_FMT='2021-05-18 10:02:08 PM'
41: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
41: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
41: + RESULT=253
41: + RESULT_NAME=bert
41: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
41: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
41: + set +x
17: ++ date +%s
17: + END=1621400528
17: ++ date '+%Y-%m-%d %r'
17: + END_FMT='2021-05-18 10:02:08 PM'
17: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
17: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
17: + RESULT=253
17: + RESULT_NAME=bert
17: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
17: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
17: + set +x
 1: ++ date +%s
 1: + END=1621400528
 1: ++ date '+%Y-%m-%d %r'
 1: + END_FMT='2021-05-18 10:02:08 PM'
 1: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
 1: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
 1: + RESULT=253
 1: + RESULT_NAME=bert
 1: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
 1: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
 1: + set +x
25: ++ date +%s
25: + END=1621400528
25: ++ date '+%Y-%m-%d %r'
25: + END_FMT='2021-05-18 10:02:08 PM'
25: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
25: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
25: + RESULT=253
25: + RESULT_NAME=bert
25: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
25: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
25: + set +x
32: ++ date +%s
32: + END=1621400528
32: ++ date '+%Y-%m-%d %r'
32: + END_FMT='2021-05-18 10:02:08 PM'
32: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:08 PM'
32: ENDING TIMING RUN AT 2021-05-18 10:02:08 PM
32: + RESULT=253
32: + RESULT_NAME=bert
32: + echo 'RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM'
32: RESULT,bert,4987,253,root,2021-05-18 09:57:55 PM
32: + set +x
14: ++ date +%s
54: ++ date +%s
14: + END=1621400529
54: + END=1621400529
14: ++ date '+%Y-%m-%d %r'
54: ++ date '+%Y-%m-%d %r'
14: + END_FMT='2021-05-18 10:02:09 PM'
14: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
14: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
14: + RESULT=254
14: + RESULT_NAME=bert
14: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
14: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
14: + set +x
54: + END_FMT='2021-05-18 10:02:09 PM'
54: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
54: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
54: + RESULT=254
54: + RESULT_NAME=bert
54: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
54: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
54: + set +x
48: ++ date +%s
48: + END=1621400529
 8: ++ date +%s
48: ++ date '+%Y-%m-%d %r'
 8: + END=1621400529
48: + END_FMT='2021-05-18 10:02:09 PM'
48: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
48: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
48: + RESULT=254
48: + RESULT_NAME=bert
48: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
48: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
48: + set +x
 8: ++ date '+%Y-%m-%d %r'
 8: + END_FMT='2021-05-18 10:02:09 PM'
 8: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
 8: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
 8: + RESULT=254
 8: + RESULT_NAME=bert
 8: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
 8: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
 8: + set +x
46: ++ date +%s
46: + END=1621400529
46: ++ date '+%Y-%m-%d %r'
40: ++ date +%s
46: + END_FMT='2021-05-18 10:02:09 PM'
46: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
46: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
46: + RESULT=254
46: + RESULT_NAME=bert
46: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
46: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
46: + set +x
40: + END=1621400529
40: ++ date '+%Y-%m-%d %r'
40: + END_FMT='2021-05-18 10:02:09 PM'
40: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
40: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
40: + RESULT=254
40: + RESULT_NAME=bert
40: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
40: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
40: + set +x
22: ++ date +%s
16: ++ date +%s
22: + END=1621400529
22: ++ date '+%Y-%m-%d %r'
16: + END=1621400529
16: ++ date '+%Y-%m-%d %r'
22: + END_FMT='2021-05-18 10:02:09 PM'
22: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
22: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
22: + RESULT=254
22: + RESULT_NAME=bert
22: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
22: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
22: + set +x
62: ++ date +%s
 6: ++ date +%s
16: + END_FMT='2021-05-18 10:02:09 PM'
16: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
16: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
16: + RESULT=254
16: + RESULT_NAME=bert
16: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
16: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
16: + set +x
 6: + END=1621400529
62: + END=1621400529
 6: ++ date '+%Y-%m-%d %r'
62: ++ date '+%Y-%m-%d %r'
56: ++ date +%s
 6: + END_FMT='2021-05-18 10:02:09 PM'
 6: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
 6: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
 6: + RESULT=254
 6: + RESULT_NAME=bert
 6: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
 6: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
 6: + set +x
56: + END=1621400529
56: ++ date '+%Y-%m-%d %r'
56: + END_FMT='2021-05-18 10:02:09 PM'
56: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
56: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
56: + RESULT=254
56: + RESULT_NAME=bert
56: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
56: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
56: + set +x
 0: ++ date +%s
 0: + END=1621400529
 0: ++ date '+%Y-%m-%d %r'
 0: + END_FMT='2021-05-18 10:02:09 PM'
 0: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
 0: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
 0: + RESULT=254
 0: + RESULT_NAME=bert
 0: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
 0: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
 0: + set +x
30: ++ date +%s
30: + END=1621400529
30: ++ date '+%Y-%m-%d %r'
24: ++ date +%s
30: + END_FMT='2021-05-18 10:02:09 PM'
30: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
30: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
30: + RESULT=254
30: + RESULT_NAME=bert
30: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
30: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
30: + set +x
24: + END=1621400529
24: ++ date '+%Y-%m-%d %r'
62: + END_FMT='2021-05-18 10:02:09 PM'
62: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
62: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
62: + RESULT=254
62: + RESULT_NAME=bert
62: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
62: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
62: + set +x
24: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
24: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
24: + END_FMT='2021-05-18 10:02:09 PM'
24: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
24: + RESULT=254
24: + RESULT_NAME=bert
24: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
24: + set +x
36: ++ date +%s
36: + END=1621400529
36: ++ date '+%Y-%m-%d %r'
36: + END_FMT='2021-05-18 10:02:09 PM'
36: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
36: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
36: + RESULT=254
36: + RESULT_NAME=bert
36: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
36: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
36: + set +x
10: ++ date +%s
10: + END=1621400529
50: ++ date +%s
10: ++ date '+%Y-%m-%d %r'
50: + END=1621400529
10: + END_FMT='2021-05-18 10:02:09 PM'
50: ++ date '+%Y-%m-%d %r'
10: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
10: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
10: + RESULT=254
10: + RESULT_NAME=bert
10: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
10: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
10: + set +x
50: + END_FMT='2021-05-18 10:02:09 PM'
50: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
50: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
50: + RESULT=254
50: + RESULT_NAME=bert
50: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
50: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
50: + set +x
42: ++ date +%s
58: ++ date +%s
42: + END=1621400529
42: ++ date '+%Y-%m-%d %r'
58: + END=1621400529
58: ++ date '+%Y-%m-%d %r'
42: + END_FMT='2021-05-18 10:02:09 PM'
42: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
42: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
42: + RESULT=254
42: + RESULT_NAME=bert
42: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
42: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
42: + set +x
58: + END_FMT='2021-05-18 10:02:09 PM'
58: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
58: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
58: + RESULT=254
58: + RESULT_NAME=bert
58: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
58: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
58: + set +x
18: ++ date +%s
18: + END=1621400529
18: ++ date '+%Y-%m-%d %r'
18: + END_FMT='2021-05-18 10:02:09 PM'
18: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
18: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
18: + RESULT=254
18: + RESULT_NAME=bert
18: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
18: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
18: + set +x
26: ++ date +%s
26: + END=1621400529
26: ++ date '+%Y-%m-%d %r'
26: + END_FMT='2021-05-18 10:02:09 PM'
26: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
26: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
26: + RESULT=254
26: + RESULT_NAME=bert
26: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
26: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
26: + set +x
 2: ++ date +%s
 2: + END=1621400529
 2: ++ date '+%Y-%m-%d %r'
 2: + END_FMT='2021-05-18 10:02:09 PM'
 2: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:09 PM'
 2: ENDING TIMING RUN AT 2021-05-18 10:02:09 PM
 2: + RESULT=254
 2: + RESULT_NAME=bert
 2: RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM
 2: + echo 'RESULT,bert,4987,254,root,2021-05-18 09:57:55 PM'
 2: + set +x
35: ++ date +%s
35: + END=1621400530
35: ++ date '+%Y-%m-%d %r'
35: + END_FMT='2021-05-18 10:02:10 PM'
35: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:10 PM'
35: ENDING TIMING RUN AT 2021-05-18 10:02:10 PM
35: + RESULT=255
35: + RESULT_NAME=bert
35: RESULT,bert,4987,255,root,2021-05-18 09:57:55 PM
35: + echo 'RESULT,bert,4987,255,root,2021-05-18 09:57:55 PM'
35: + set +x
38: ++ date +%s
37: ++ date +%s
38: + END=1621400530
33: ++ date +%s
38: ++ date '+%Y-%m-%d %r'
33: + END=1621400530
37: + END=1621400530
33: ++ date '+%Y-%m-%d %r'
38: + END_FMT='2021-05-18 10:02:10 PM'
37: ++ date '+%Y-%m-%d %r'
38: ENDING TIMING RUN AT 2021-05-18 10:02:10 PM
38: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:10 PM'
38: + RESULT=255
38: + RESULT_NAME=bert
38: RESULT,bert,4987,255,root,2021-05-18 09:57:55 PM
38: + echo 'RESULT,bert,4987,255,root,2021-05-18 09:57:55 PM'
38: + set +x
33: + END_FMT='2021-05-18 10:02:10 PM'
33: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:10 PM'
33: ENDING TIMING RUN AT 2021-05-18 10:02:10 PM
33: + RESULT=255
33: + RESULT_NAME=bert
33: RESULT,bert,4987,255,root,2021-05-18 09:57:55 PM
33: + echo 'RESULT,bert,4987,255,root,2021-05-18 09:57:55 PM'
33: + set +x
37: + END_FMT='2021-05-18 10:02:10 PM'
37: ENDING TIMING RUN AT 2021-05-18 10:02:10 PM
37: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:10 PM'
37: + RESULT=255
37: + RESULT_NAME=bert
37: RESULT,bert,4987,255,root,2021-05-18 09:57:55 PM
37: + echo 'RESULT,bert,4987,255,root,2021-05-18 09:57:55 PM'
37: + set +x
34: ++ date +%s
34: + END=1621400530
34: ++ date '+%Y-%m-%d %r'
34: + END_FMT='2021-05-18 10:02:10 PM'
34: ENDING TIMING RUN AT 2021-05-18 10:02:10 PM
34: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:10 PM'
34: + RESULT=255
34: + RESULT_NAME=bert
34: RESULT,bert,4987,255,root,2021-05-18 09:57:55 PM
34: + echo 'RESULT,bert,4987,255,root,2021-05-18 09:57:55 PM'
34: + set +x
