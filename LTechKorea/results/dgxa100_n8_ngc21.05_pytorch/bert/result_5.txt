+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
srun: Job 1417032 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Step created for job 1417032
Clearing cache on luna-0174
Clearing cache on luna-0175
Clearing cache on luna-0178
Clearing cache on luna-0180
Clearing cache on luna-0179
Clearing cache on luna-0177
Clearing cache on luna-0183
Clearing cache on luna-0176
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=language_model python -c '
import mlperf_logger
mlperf_logger.log_event(key=mlperf_logger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1621400281984, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400281988, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400281989, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400282007, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400282009, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400282018, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400282018, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400282055, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ '[' 0 -eq 0 ']'
+ srun -l --mpi=none --ntasks=64 --ntasks-per-node=8 --container-name=language_model --container-mounts=/raid/datasets/bert/hdf5/v1p0_ref/4096_shards_uncompressed:/workspace/data,/raid/datasets/bert/hdf5/v1p0_ref/4096_shards_uncompressed:/workspace/data_phase2,/lustre/fsw/mlperf-ci/23336637/ci_checkpoints:/results,/raid/datasets/bert/checkpoints/checkpoint_phase1:/workspace/phase1,/raid/datasets/bert/hdf5/v1p0_ref/eval_uncompressed:/workspace/evaldata,/lustre/fsw/mlperf/mlperft-bert/unit_test:/workspace/unit_test_data sh -c '/workspace/bert/run_and_time.sh "    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=${SLURM_LOCALID}     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16" 4020 '
 4: Run vars: id 1417032 gpus 8 mparams
 7: Run vars: id 1417032 gpus 8 mparams
35: Run vars: id 1417032 gpus 8 mparams
 5: Run vars: id 1417032 gpus 8 mparams
 1: Run vars: id 1417032 gpus 8 mparams
 2: Run vars: id 1417032 gpus 8 mparams
 3: Run vars: id 1417032 gpus 8 mparams
34: Run vars: id 1417032 gpus 8 mparams
 4: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
 4: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 4: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
 4: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
 4: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
37: Run vars: id 1417032 gpus 8 mparams
33: Run vars: id 1417032 gpus 8 mparams
39: Run vars: id 1417032 gpus 8 mparams
38: Run vars: id 1417032 gpus 8 mparams
 7: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
32: Run vars: id 1417032 gpus 8 mparams
 7: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 7: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
36: Run vars: id 1417032 gpus 8 mparams
 7: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
 7: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
35: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
35: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
35: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
35: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
35: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 5: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
 5: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
34: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
34: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
34: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
37: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
34: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
34: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
37: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
37: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
37: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
37: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
32: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
32: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
32: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
33: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
38: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
32: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
32: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
39: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
33: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
33: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
36: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
38: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
38: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
39: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
39: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
36: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
36: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
33: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
33: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
38: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
38: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
39: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
39: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
36: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
36: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
19: Run vars: id 1417032 gpus 8 mparams
23: Run vars: id 1417032 gpus 8 mparams
22: Run vars: id 1417032 gpus 8 mparams
18: Run vars: id 1417032 gpus 8 mparams
20: Run vars: id 1417032 gpus 8 mparams
21: Run vars: id 1417032 gpus 8 mparams
16: Run vars: id 1417032 gpus 8 mparams
19: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
19: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
19: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
23: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
19: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
19: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
23: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
23: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
23: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
23: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
17: Run vars: id 1417032 gpus 8 mparams
22: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
18: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
22: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
22: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
18: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
18: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
22: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
22: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
18: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
18: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
20: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
20: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
20: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
20: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
20: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
21: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
16: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
21: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
21: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
16: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
16: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
21: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
21: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
16: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
16: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
59: Run vars: id 1417032 gpus 8 mparams
17: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
17: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
17: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
17: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
17: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
62: Run vars: id 1417032 gpus 8 mparams
61: Run vars: id 1417032 gpus 8 mparams
58: Run vars: id 1417032 gpus 8 mparams
60: Run vars: id 1417032 gpus 8 mparams
57: Run vars: id 1417032 gpus 8 mparams
56: Run vars: id 1417032 gpus 8 mparams
59: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
59: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
59: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
59: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
59: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
63: Run vars: id 1417032 gpus 8 mparams
62: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
62: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
62: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
62: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
62: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
61: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
60: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
61: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
61: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
60: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
60: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
61: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
61: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
58: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
58: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
58: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
60: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
60: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
58: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
58: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
56: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
57: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
56: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
56: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
57: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
57: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
56: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
56: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
57: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
57: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
63: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
63: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
63: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
63: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
63: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
51: Run vars: id 1417032 gpus 8 mparams
28: Run vars: id 1417032 gpus 8 mparams
26: Run vars: id 1417032 gpus 8 mparams
55: Run vars: id 1417032 gpus 8 mparams
49: Run vars: id 1417032 gpus 8 mparams
53: Run vars: id 1417032 gpus 8 mparams
54: Run vars: id 1417032 gpus 8 mparams
50: Run vars: id 1417032 gpus 8 mparams
48: Run vars: id 1417032 gpus 8 mparams
51: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
52: Run vars: id 1417032 gpus 8 mparams
51: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
51: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
51: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
51: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
28: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
28: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
28: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
26: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
47: Run vars: id 1417032 gpus 8 mparams
26: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
26: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
28: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
41: Run vars: id 1417032 gpus 8 mparams
28: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
44: Run vars: id 1417032 gpus 8 mparams
26: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
46: Run vars: id 1417032 gpus 8 mparams
26: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
24: Run vars: id 1417032 gpus 8 mparams
43: Run vars: id 1417032 gpus 8 mparams
11: Run vars: id 1417032 gpus 8 mparams
55: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
31: Run vars: id 1417032 gpus 8 mparams
29: Run vars: id 1417032 gpus 8 mparams
55: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
55: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
55: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
45: Run vars: id 1417032 gpus 8 mparams
55: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
40: Run vars: id 1417032 gpus 8 mparams
42: Run vars: id 1417032 gpus 8 mparams
30: Run vars: id 1417032 gpus 8 mparams
49: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
49: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
27: Run vars: id 1417032 gpus 8 mparams
49: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
25: Run vars: id 1417032 gpus 8 mparams
49: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
49: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
54: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
54: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
54: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
53: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
54: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
54: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
53: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
53: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
53: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
53: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
10: Run vars: id 1417032 gpus 8 mparams
13: Run vars: id 1417032 gpus 8 mparams
52: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
 9: Run vars: id 1417032 gpus 8 mparams
48: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
50: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
48: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
48: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
50: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
50: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
52: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
52: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
48: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
48: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
52: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
52: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
50: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
50: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 8: Run vars: id 1417032 gpus 8 mparams
24: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
24: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
24: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
46: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
24: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
41: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
24: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
15: Run vars: id 1417032 gpus 8 mparams
43: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
44: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
12: Run vars: id 1417032 gpus 8 mparams
46: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
46: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
47: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
43: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
43: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
41: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
41: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
44: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
44: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
47: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
47: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
11: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
46: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
46: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
43: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
43: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
14: Run vars: id 1417032 gpus 8 mparams
44: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
44: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
47: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
11: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
47: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
41: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
41: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
11: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
11: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
45: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
11: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
29: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
31: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
45: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
29: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
29: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
31: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
45: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
31: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
40: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
29: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
29: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
31: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
31: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
30: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
30: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
45: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
30: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
45: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
40: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
30: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
40: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
30: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
40: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
27: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
40: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
27: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
27: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
25: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
25: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
25: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
27: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
27: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
25: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
25: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
42: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
42: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
42: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
42: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
42: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
10: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
10: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
10: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
 9: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
10: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
10: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
13: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
 9: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 9: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
13: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
13: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
 9: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
 9: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
13: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
13: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 8: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
 8: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 8: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
15: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
 8: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
 8: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
15: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
15: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
15: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
15: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
12: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
12: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
12: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
14: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
14: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
14: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
12: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
12: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
14: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
14: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 5: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
 5: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
 5: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 0: Run vars: id 1417032 gpus 8 mparams
 1: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
 6: Run vars: id 1417032 gpus 8 mparams
 1: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 1: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
 2: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
 3: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
 1: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
 1: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 2: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 2: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
 3: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 3: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
 3: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
 3: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 2: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
 2: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 0: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
 6: STARTING TIMING RUN AT 2021-05-18 09:58:02 PM
 0: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 0: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
 6: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 6: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020'
 0: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
 0: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 6: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
 6: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 4: num_sockets = 2 num_nodes=8 cores_per_socket=64
 4: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
 4: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
35: num_sockets = 2 num_nodes=8 cores_per_socket=64
35: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
35: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
59: num_sockets = 2 num_nodes=8 cores_per_socket=64
59: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
59: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
51: num_sockets = 2 num_nodes=8 cores_per_socket=64
51: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
51: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
11: num_sockets = 2 num_nodes=8 cores_per_socket=64
11: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
11: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
62: num_sockets = 2 num_nodes=8 cores_per_socket=64
62: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
62: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
28: num_sockets = 2 num_nodes=8 cores_per_socket=64
28: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
28: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
26: num_sockets = 2 num_nodes=8 cores_per_socket=64
26: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
26: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 7: num_sockets = 2 num_nodes=8 cores_per_socket=64
 7: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
 7: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
10: num_sockets = 2 num_nodes=8 cores_per_socket=64
10: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
10: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
55: num_sockets = 2 num_nodes=8 cores_per_socket=64
13: num_sockets = 2 num_nodes=8 cores_per_socket=64
55: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
55: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
13: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
13: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
49: num_sockets = 2 num_nodes=8 cores_per_socket=64
49: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
49: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
53: num_sockets = 2 num_nodes=8 cores_per_socket=64
53: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
53: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
58: num_sockets = 2 num_nodes=8 cores_per_socket=64
60: num_sockets = 2 num_nodes=8 cores_per_socket=64
58: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
58: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
60: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
60: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
52: num_sockets = 2 num_nodes=8 cores_per_socket=64
52: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
52: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
63: num_sockets = 2 num_nodes=8 cores_per_socket=64
56: num_sockets = 2 num_nodes=8 cores_per_socket=64
57: num_sockets = 2 num_nodes=8 cores_per_socket=64
61: num_sockets = 2 num_nodes=8 cores_per_socket=64
63: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
63: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
56: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
56: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
61: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
61: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
57: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
57: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 5: num_sockets = 2 num_nodes=8 cores_per_socket=64
 5: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
 5: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
50: num_sockets = 2 num_nodes=8 cores_per_socket=64
50: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
50: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
54: num_sockets = 2 num_nodes=8 cores_per_socket=64
48: num_sockets = 2 num_nodes=8 cores_per_socket=64
54: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
54: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
48: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
48: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
23: num_sockets = 2 num_nodes=8 cores_per_socket=64
23: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
23: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
43: num_sockets = 2 num_nodes=8 cores_per_socket=64
43: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
43: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
24: num_sockets = 2 num_nodes=8 cores_per_socket=64
24: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
24: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
15: num_sockets = 2 num_nodes=8 cores_per_socket=64
 8: num_sockets = 2 num_nodes=8 cores_per_socket=64
 8: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
 8: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
15: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
15: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
14: num_sockets = 2 num_nodes=8 cores_per_socket=64
14: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
14: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 1: num_sockets = 2 num_nodes=8 cores_per_socket=64
12: num_sockets = 2 num_nodes=8 cores_per_socket=64
 9: num_sockets = 2 num_nodes=8 cores_per_socket=64
 1: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
 1: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
12: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
12: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 9: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
 9: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
29: num_sockets = 2 num_nodes=8 cores_per_socket=64
29: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
29: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 2: num_sockets = 2 num_nodes=8 cores_per_socket=64
 0: num_sockets = 2 num_nodes=8 cores_per_socket=64
 6: num_sockets = 2 num_nodes=8 cores_per_socket=64
 2: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
 2: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 3: num_sockets = 2 num_nodes=8 cores_per_socket=64
 0: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
 0: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 6: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
 6: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 3: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
 3: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
17: num_sockets = 2 num_nodes=8 cores_per_socket=64
17: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
17: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
32: num_sockets = 2 num_nodes=8 cores_per_socket=64
32: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
32: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
19: num_sockets = 2 num_nodes=8 cores_per_socket=64
21: num_sockets = 2 num_nodes=8 cores_per_socket=64
20: num_sockets = 2 num_nodes=8 cores_per_socket=64
46: num_sockets = 2 num_nodes=8 cores_per_socket=64
18: num_sockets = 2 num_nodes=8 cores_per_socket=64
19: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
19: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
46: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
46: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
20: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
20: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
16: num_sockets = 2 num_nodes=8 cores_per_socket=64
18: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
18: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
21: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
21: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
22: num_sockets = 2 num_nodes=8 cores_per_socket=64
37: num_sockets = 2 num_nodes=8 cores_per_socket=64
22: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
22: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
37: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
37: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
16: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
16: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
30: num_sockets = 2 num_nodes=8 cores_per_socket=64
31: num_sockets = 2 num_nodes=8 cores_per_socket=64
27: num_sockets = 2 num_nodes=8 cores_per_socket=64
25: num_sockets = 2 num_nodes=8 cores_per_socket=64
30: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
30: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
31: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
31: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
27: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
27: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
25: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
38: num_sockets = 2 num_nodes=8 cores_per_socket=64
25: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
38: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
38: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
34: num_sockets = 2 num_nodes=8 cores_per_socket=64
39: num_sockets = 2 num_nodes=8 cores_per_socket=64
33: num_sockets = 2 num_nodes=8 cores_per_socket=64
34: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
34: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
36: num_sockets = 2 num_nodes=8 cores_per_socket=64
36: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
36: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
39: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
39: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
33: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
33: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
44: num_sockets = 2 num_nodes=8 cores_per_socket=64
45: num_sockets = 2 num_nodes=8 cores_per_socket=64
40: num_sockets = 2 num_nodes=8 cores_per_socket=64
41: num_sockets = 2 num_nodes=8 cores_per_socket=64
47: num_sockets = 2 num_nodes=8 cores_per_socket=64
44: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
44: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
42: num_sockets = 2 num_nodes=8 cores_per_socket=64
45: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
45: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
47: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
47: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
40: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
40: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
41: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
41: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
42: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
42: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=4020
 4: :::MLLOG {"namespace": "", "time_ms": 1621400284724, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
35: :::MLLOG {"namespace": "", "time_ms": 1621400284771, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
59: :::MLLOG {"namespace": "", "time_ms": 1621400284784, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
51: :::MLLOG {"namespace": "", "time_ms": 1621400284804, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 6: :::MLLOG {"namespace": "", "time_ms": 1621400284807, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
11: :::MLLOG {"namespace": "", "time_ms": 1621400284811, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
62: :::MLLOG {"namespace": "", "time_ms": 1621400284844, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
32: :::MLLOG {"namespace": "", "time_ms": 1621400284847, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
28: :::MLLOG {"namespace": "", "time_ms": 1621400284868, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 1: :::MLLOG {"namespace": "", "time_ms": 1621400284870, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
13: :::MLLOG {"namespace": "", "time_ms": 1621400284875, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 7: :::MLLOG {"namespace": "", "time_ms": 1621400284882, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
10: :::MLLOG {"namespace": "", "time_ms": 1621400284892, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
60: :::MLLOG {"namespace": "", "time_ms": 1621400284897, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
54: :::MLLOG {"namespace": "", "time_ms": 1621400284903, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
33: :::MLLOG {"namespace": "", "time_ms": 1621400284905, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
26: :::MLLOG {"namespace": "", "time_ms": 1621400284916, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
53: :::MLLOG {"namespace": "", "time_ms": 1621400284940, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
58: :::MLLOG {"namespace": "", "time_ms": 1621400284943, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
49: :::MLLOG {"namespace": "", "time_ms": 1621400284954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
57: :::MLLOG {"namespace": "", "time_ms": 1621400284966, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 3: :::MLLOG {"namespace": "", "time_ms": 1621400284976, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
37: :::MLLOG {"namespace": "", "time_ms": 1621400284986, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400285006, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 2: :::MLLOG {"namespace": "", "time_ms": 1621400285017, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
38: :::MLLOG {"namespace": "", "time_ms": 1621400285020, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 5: :::MLLOG {"namespace": "", "time_ms": 1621400285025, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
12: :::MLLOG {"namespace": "", "time_ms": 1621400285026, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
27: :::MLLOG {"namespace": "", "time_ms": 1621400285031, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
50: :::MLLOG {"namespace": "", "time_ms": 1621400285043, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
14: :::MLLOG {"namespace": "", "time_ms": 1621400285042, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
56: :::MLLOG {"namespace": "", "time_ms": 1621400285048, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
36: :::MLLOG {"namespace": "", "time_ms": 1621400285050, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
15: :::MLLOG {"namespace": "", "time_ms": 1621400285056, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
24: :::MLLOG {"namespace": "", "time_ms": 1621400285063, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
39: :::MLLOG {"namespace": "", "time_ms": 1621400285062, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
23: :::MLLOG {"namespace": "", "time_ms": 1621400285065, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
34: :::MLLOG {"namespace": "", "time_ms": 1621400285070, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
48: :::MLLOG {"namespace": "", "time_ms": 1621400285074, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 8: :::MLLOG {"namespace": "", "time_ms": 1621400285076, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
43: :::MLLOG {"namespace": "", "time_ms": 1621400285082, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
61: :::MLLOG {"namespace": "", "time_ms": 1621400285083, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
52: :::MLLOG {"namespace": "", "time_ms": 1621400285087, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
31: :::MLLOG {"namespace": "", "time_ms": 1621400285088, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
63: :::MLLOG {"namespace": "", "time_ms": 1621400285089, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
55: :::MLLOG {"namespace": "", "time_ms": 1621400285096, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 9: :::MLLOG {"namespace": "", "time_ms": 1621400285099, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
30: :::MLLOG {"namespace": "", "time_ms": 1621400285116, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
17: :::MLLOG {"namespace": "", "time_ms": 1621400285127, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
29: :::MLLOG {"namespace": "", "time_ms": 1621400285149, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
47: :::MLLOG {"namespace": "", "time_ms": 1621400285165, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
25: :::MLLOG {"namespace": "", "time_ms": 1621400285176, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
46: :::MLLOG {"namespace": "", "time_ms": 1621400285180, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
19: :::MLLOG {"namespace": "", "time_ms": 1621400285194, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
41: :::MLLOG {"namespace": "", "time_ms": 1621400285259, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
20: :::MLLOG {"namespace": "", "time_ms": 1621400285287, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
18: :::MLLOG {"namespace": "", "time_ms": 1621400285303, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
45: :::MLLOG {"namespace": "", "time_ms": 1621400285311, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
40: :::MLLOG {"namespace": "", "time_ms": 1621400285341, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
22: :::MLLOG {"namespace": "", "time_ms": 1621400285345, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
21: :::MLLOG {"namespace": "", "time_ms": 1621400285356, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
16: :::MLLOG {"namespace": "", "time_ms": 1621400285364, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
42: :::MLLOG {"namespace": "", "time_ms": 1621400285365, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
44: :::MLLOG {"namespace": "", "time_ms": 1621400285375, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
19: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
 0: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
20: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
61: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
 2: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
16: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400286068, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 66}}
49: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
30: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400286069, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 71}}
58: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
25: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400286069, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 75}}
62: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400286069, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 79}}
63: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400286069, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xNVIDIA DGX A100", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 83}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400286069, "event_type": "POINT_IN_TIME", "key": "seed", "value": 4020, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1006}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400286069, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 3072, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1008}}
50: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400286069, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 48, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1010}}
47: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400286069, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1012}}
40: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
42: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400286069, "event_type": "POINT_IN_TIME", "key": "max_predictions_per_seq", "value": 76, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1014}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400286069, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 1271.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400286069, "event_type": "POINT_IN_TIME", "key": "num_warmup_steps", "value": 100.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1018}}
 0: parsed args:
 0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=0, dwu_num_ag_pg=2, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=175000, eval_iter_start_samples=175000, exchange_padding=True, fp16=True, fused_dropout_add=False, fused_gelu_bias=True, fused_mha=True, gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_d
 0: ir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.0015, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=1271.0, min_samples_to_start_checkpoints=3000000, n_gpu=64, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.83, opt_lamb_beta_2=0.925, output_dir='/results', pad=False, phase2=True, resume_from_checkpoint=False, seed=4020, skip_checkpoint=True, start_warmup_step=-25.0, target_mlm_accuracy=0.72, train_batch_size=48, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_steps=100.0, weight_decay_rate=0.01)
28: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
18: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
22: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
13: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
 9: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
55: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
10: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
29: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
33: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
34: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
12: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
 1: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
 3: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
57: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
14: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
17: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
32: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
 5: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
41: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
 7: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
59: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
 6: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
26: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
54: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
27: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
15: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
45: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
56: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
48: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
 8: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
44: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
21: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
53: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
 4: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
11: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
46: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
35: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
43: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
38: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
23: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
36: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
60: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
37: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
31: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
52: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
51: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
39: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
24: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400292105, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0015, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 669}}
 0: [luna-0174:0:920201 - context.c:581] INFO job (ID: 17873378911264772316) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 0: [luna-0174:0:920201 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 0: [luna-0174:0:920201 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 0: [luna-0174:0:920201 - comm.c:385] INFO [group#:0] group id:8 tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x410f00000008) mlid:c01d
 0: [luna-0174:0:920201 - comm.c:385] INFO [group#:1] group id:8 tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 1: [luna-0174:0:920178 - context.c:581] INFO job (ID: 17873378650155518528) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 1: [luna-0174:0:920178 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 1: [luna-0174:0:920178 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 1: [luna-0174:0:920178 - comm.c:385] INFO [group#:0] group id:9 tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x430f00000009) mlid:c01f
 1: [luna-0174:0:920178 - comm.c:385] INFO [group#:1] group id:9 tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 2: [luna-0174:0:920182 - context.c:581] INFO job (ID: 17873378814723447503) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 2: [luna-0174:0:920182 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 2: [luna-0174:0:920182 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 2: [luna-0174:0:920182 - comm.c:385] INFO [group#:0] group id:a tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x440f0000000a) mlid:c020
 2: [luna-0174:0:920182 - comm.c:385] INFO [group#:1] group id:a tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 3: [luna-0174:0:920181 - context.c:581] INFO job (ID: 17873379092012437393) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 3: [luna-0174:0:920181 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 3: [luna-0174:0:920181 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 3: [luna-0174:0:920181 - comm.c:385] INFO [group#:0] group id:b tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x450f0000000b) mlid:c021
 3: [luna-0174:0:920181 - comm.c:385] INFO [group#:1] group id:b tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 4: [luna-0174:0:920169 - context.c:581] INFO job (ID: 17873378617113620640) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 4: [luna-0174:0:920169 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 4: [luna-0174:0:920169 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 4: [luna-0174:0:920169 - comm.c:385] INFO [group#:0] group id:c tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x460f0000000c) mlid:c022
 4: [luna-0174:0:920169 - comm.c:385] INFO [group#:1] group id:c tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 5: [luna-0174:0:920174 - context.c:581] INFO job (ID: 17873379393844294587) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 5: [luna-0174:0:920174 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 5: [luna-0174:0:920174 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 5: [luna-0174:0:920174 - comm.c:385] INFO [group#:0] group id:d tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x470f0000000d) mlid:c023
 5: [luna-0174:0:920174 - comm.c:385] INFO [group#:1] group id:d tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 6: [luna-0174:0:920203 - context.c:581] INFO job (ID: 17873378538175013287) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 6: [luna-0174:0:920203 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 6: [luna-0174:0:920203 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 6: [luna-0174:0:920203 - comm.c:385] INFO [group#:0] group id:e tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x480f0000000e) mlid:c024
 6: [luna-0174:0:920203 - comm.c:385] INFO [group#:1] group id:e tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 7: [luna-0174:0:920172 - context.c:581] INFO job (ID: 17873379369139875486) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 7: [luna-0174:0:920172 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 7: [luna-0174:0:920172 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 7: [luna-0174:0:920172 - comm.c:385] INFO [group#:0] group id:f tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x490f0000000f) mlid:c025
 7: [luna-0174:0:920172 - comm.c:385] INFO [group#:1] group id:f tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 0: :::MLLOG {"namespace": "", "time_ms": 1621400301730, "event_type": "POINT_IN_TIME", "key": "opt_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 699}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400301730, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.83, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 702}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400301730, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.925, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 703}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400301730, "event_type": "POINT_IN_TIME", "key": "opt_lamb_weight_decay_rate", "value": 0.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 704}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400301735, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 100.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 86}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400301735, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 1.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 87}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400301735, "event_type": "POINT_IN_TIME", "key": "start_warmup_step", "value": -25.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 88}}
46: Torch distributed is available.
46: Torch distributed is initialized.
34: Torch distributed is available.
34: Torch distributed is initialized.
28: Torch distributed is available.
28: Torch distributed is initialized.
57: Torch distributed is available.
57: Torch distributed is initialized.
 2: Torch distributed is available.
 2: Torch distributed is initialized.
27: Torch distributed is available.
27: Torch distributed is initialized.
22: Torch distributed is available.
22: Torch distributed is initialized.
52: Torch distributed is available.
52: Torch distributed is initialized.
 7: Torch distributed is available.
 7: Torch distributed is initialized.
14: Torch distributed is available.
14: Torch distributed is initialized.
19: Torch distributed is available.
19: Torch distributed is initialized.
11: Torch distributed is available.
11: Torch distributed is initialized.
59: Torch distributed is available.
59: Torch distributed is initialized.
39: Torch distributed is available.
39: Torch distributed is initialized.
51: Torch distributed is available.
51: Torch distributed is initialized.
 5: Torch distributed is available.
 5: Torch distributed is initialized.
32: Torch distributed is available.
32: Torch distributed is initialized.
20: Torch distributed is available.
20: Torch distributed is initialized.
48: Torch distributed is available.
48: Torch distributed is initialized.
15: Torch distributed is available.
15: Torch distributed is initialized.
 4: Torch distributed is available.
 4: Torch distributed is initialized.
43: Torch distributed is available.
43: Torch distributed is initialized.
 3: Torch distributed is available.
 3: Torch distributed is initialized.
17: Torch distributed is available.
17: Torch distributed is initialized.
42: Torch distributed is available.
42: Torch distributed is initialized.
 0: Torch distributed is available.
 0: Torch distributed is initialized.
21: Torch distributed is available.
21: Torch distributed is initialized.
54: Torch distributed is available.
54: Torch distributed is initialized.
16: Torch distributed is available.
16: Torch distributed is initialized.
40: Torch distributed is available.
40: Torch distributed is initialized.
 8: Torch distributed is available.
 8: Torch distributed is initialized.
45: Torch distributed is available.
45: Torch distributed is initialized.
44: Torch distributed is available.
44: Torch distributed is initialized.
23: Torch distributed is available.
23: Torch distributed is initialized.
26: Torch distributed is available.
26: Torch distributed is initialized.
18: Torch distributed is available.
18: Torch distributed is initialized.
31: Torch distributed is available.
31: Torch distributed is initialized.
41: Torch distributed is available.
41: Torch distributed is initialized.
55: Torch distributed is available.
55: Torch distributed is initialized.
47: Torch distributed is available.
47: Torch distributed is initialized.
24: Torch distributed is available.
24: Torch distributed is initialized.
 1: Torch distributed is available.
 1: Torch distributed is initialized.
13: Torch distributed is available.
13: Torch distributed is initialized.
 6: Torch distributed is available.
 6: Torch distributed is initialized.
33: Torch distributed is available.
33: Torch distributed is initialized.
62: Torch distributed is available.
62: Torch distributed is initialized.
53: Torch distributed is available.
53: Torch distributed is initialized.
30: Torch distributed is available.
30: Torch distributed is initialized.
35: Torch distributed is available.
35: Torch distributed is initialized.
49: Torch distributed is available.
49: Torch distributed is initialized.
10: Torch distributed is available.
10: Torch distributed is initialized.
12: Torch distributed is available.
12: Torch distributed is initialized.
50: Torch distributed is available.
50: Torch distributed is initialized.
 9: Torch distributed is available.
 9: Torch distributed is initialized.
25: Torch distributed is available.
25: Torch distributed is initialized.
29: Torch distributed is available.
29: Torch distributed is initialized.
58: Torch distributed is available.
58: Torch distributed is initialized.
60: Torch distributed is available.
60: Torch distributed is initialized.
56: Torch distributed is available.
56: Torch distributed is initialized.
61: Torch distributed is available.
61: Torch distributed is initialized.
63: Torch distributed is available.
63: Torch distributed is initialized.
36: Torch distributed is available.
36: Torch distributed is initialized.
38: Torch distributed is available.
38: Torch distributed is initialized.
37: Torch distributed is available.
37: Torch distributed is initialized.
 0: :::MLLOG {"namespace": "", "time_ms": 1621400326151, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400326429, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1265}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400326449, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1276, "epoch_num": 1}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400326450, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1278, "first_epoch_num": 1, "epoch_count": 1}}
 0: parsed args:
 0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=0, dwu_num_ag_pg=2, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=175000, eval_iter_start_samples=175000, exchange_padding=True, fp16=True, fused_dropout_add=False, fused_gelu_bias=True, fused_mha=True, gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_d
 0: ir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.0015, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=1271.0, min_samples_to_start_checkpoints=3000000, n_gpu=64, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.83, opt_lamb_beta_2=0.925, output_dir='/results', pad=False, phase2=True, resume_from_checkpoint=False, resume_step=0, seed=4020, skip_checkpoint=True, start_warmup_step=-25.0, target_mlm_accuracy=0.72, train_batch_size=48, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_steps=100.0, weight_decay_rate=0.01)
 0: epoch: 1
 0: :::MLLOG {"namespace": "", "time_ms": 1621400339684, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.36869943141937256, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 57, 'eval_loss': 4.143335819244385, 'eval_mlm_accuracy': 0.36869943141937256}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400350629, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.380564421415329, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 114, 'eval_loss': 4.042288780212402, 'eval_mlm_accuracy': 0.380564421415329}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400361605, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.40577954053878784, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 171, 'eval_loss': 3.7966864109039307, 'eval_mlm_accuracy': 0.40577954053878784}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400373106, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.465744286775589, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 228, 'eval_loss': 3.257554054260254, 'eval_mlm_accuracy': 0.465744286775589}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400384105, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5713054537773132, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 285, 'eval_loss': 2.3904993534088135, 'eval_mlm_accuracy': 0.5713054537773132}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400395115, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6820670962333679, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 342, 'eval_loss': 1.562081217765808, 'eval_mlm_accuracy': 0.6820670962333679}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400406122, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.703468918800354, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 399, 'eval_loss': 1.4130104780197144, 'eval_mlm_accuracy': 0.703468918800354}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400417303, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7088701128959656, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 456, 'eval_loss': 1.3745754957199097, 'eval_mlm_accuracy': 0.7088701128959656}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400428289, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7120879888534546, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 513, 'eval_loss': 1.3594175577163696, 'eval_mlm_accuracy': 0.7120879888534546}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400439261, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7136385440826416, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 570, 'eval_loss': 1.3507362604141235, 'eval_mlm_accuracy': 0.7136385440826416}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400450330, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7148178219795227, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 627, 'eval_loss': 1.3429850339889526, 'eval_mlm_accuracy': 0.7148178219795227}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400461512, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7153829336166382, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 684, 'eval_loss': 1.337755560874939, 'eval_mlm_accuracy': 0.7153829336166382}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400472531, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.716907799243927, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 741, 'eval_loss': 1.3288594484329224, 'eval_mlm_accuracy': 0.716907799243927}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400483588, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7179352641105652, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 798, 'eval_loss': 1.3227695226669312, 'eval_mlm_accuracy': 0.7179352641105652}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400494298, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7186754941940308, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 855, 'eval_loss': 1.3191888332366943, 'eval_mlm_accuracy': 0.7186754941940308}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400505002, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.719331681728363, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 912, 'eval_loss': 1.3133597373962402, 'eval_mlm_accuracy': 0.719331681728363}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400515557, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7199224829673767, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 969, 'eval_loss': 1.3096051216125488, 'eval_mlm_accuracy': 0.7199224829673767}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400526128, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7204525470733643, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 1026, 'eval_loss': 1.306649923324585, 'eval_mlm_accuracy': 0.7204525470733643}
 0: 0.720453 > 0.720000, Target MLM Accuracy reached at 1026
 0: (1, 1035.0) {'final_loss': 0.0}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400526172, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1567, "first_epoch_num": 1}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400526173, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1570, "epoch_num": 1}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400526173, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 3151872, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1574}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400526173, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 10000, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1577}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400526173, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1580, "status": "success"}}
 0: {'e2e_time': 241.1751856803894, 'training_sequences_per_second': 17960.32682543886, 'final_loss': 0.0, 'raw_train_time': 217.39648938179016}
 2: ++ date +%s
 2: + END=1621400535
 2: ++ date '+%Y-%m-%d %r'
 2: + END_FMT='2021-05-18 10:02:15 PM'
 2: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:15 PM'
 2: ENDING TIMING RUN AT 2021-05-18 10:02:15 PM
 2: + RESULT=253
 2: + RESULT_NAME=bert
 2: RESULT,bert,4020,253,root,2021-05-18 09:58:02 PM
 2: + echo 'RESULT,bert,4020,253,root,2021-05-18 09:58:02 PM'
 2: + set +x
18: ++ date +%s
18: + END=1621400535
18: ++ date '+%Y-%m-%d %r'
18: + END_FMT='2021-05-18 10:02:15 PM'
18: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:15 PM'
18: ENDING TIMING RUN AT 2021-05-18 10:02:15 PM
18: + RESULT=253
18: + RESULT_NAME=bert
18: RESULT,bert,4020,253,root,2021-05-18 09:58:02 PM
18: + echo 'RESULT,bert,4020,253,root,2021-05-18 09:58:02 PM'
18: + set +x
42: ++ date +%s
42: + END=1621400535
42: ++ date '+%Y-%m-%d %r'
42: + END_FMT='2021-05-18 10:02:15 PM'
42: ENDING TIMING RUN AT 2021-05-18 10:02:15 PM
42: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:15 PM'
42: + RESULT=253
42: + RESULT_NAME=bert
42: RESULT,bert,4020,253,root,2021-05-18 09:58:02 PM
42: + echo 'RESULT,bert,4020,253,root,2021-05-18 09:58:02 PM'
42: + set +x
26: ++ date +%s
26: + END=1621400535
26: ++ date '+%Y-%m-%d %r'
26: + END_FMT='2021-05-18 10:02:15 PM'
26: ENDING TIMING RUN AT 2021-05-18 10:02:15 PM
26: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:15 PM'
26: + RESULT=253
26: + RESULT_NAME=bert
26: + echo 'RESULT,bert,4020,253,root,2021-05-18 09:58:02 PM'
26: RESULT,bert,4020,253,root,2021-05-18 09:58:02 PM
26: + set +x
58: ++ date +%s
58: + END=1621400535
58: ++ date '+%Y-%m-%d %r'
58: + END_FMT='2021-05-18 10:02:15 PM'
58: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:15 PM'
58: ENDING TIMING RUN AT 2021-05-18 10:02:15 PM
58: + RESULT=253
58: + RESULT_NAME=bert
58: RESULT,bert,4020,253,root,2021-05-18 09:58:02 PM
58: + echo 'RESULT,bert,4020,253,root,2021-05-18 09:58:02 PM'
58: + set +x
10: ++ date +%s
10: + END=1621400535
10: ++ date '+%Y-%m-%d %r'
10: + END_FMT='2021-05-18 10:02:15 PM'
10: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:15 PM'
10: ENDING TIMING RUN AT 2021-05-18 10:02:15 PM
10: + RESULT=253
10: + RESULT_NAME=bert
10: RESULT,bert,4020,253,root,2021-05-18 09:58:02 PM
10: + echo 'RESULT,bert,4020,253,root,2021-05-18 09:58:02 PM'
10: + set +x
50: ++ date +%s
50: + END=1621400535
50: ++ date '+%Y-%m-%d %r'
50: + END_FMT='2021-05-18 10:02:15 PM'
50: ENDING TIMING RUN AT 2021-05-18 10:02:15 PM
50: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:15 PM'
50: + RESULT=253
50: + RESULT_NAME=bert
50: RESULT,bert,4020,253,root,2021-05-18 09:58:02 PM
50: + echo 'RESULT,bert,4020,253,root,2021-05-18 09:58:02 PM'
50: + set +x
31: ++ date +%s
31: + END=1621400536
31: ++ date '+%Y-%m-%d %r'
31: + END_FMT='2021-05-18 10:02:16 PM'
31: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:16 PM'
31: ENDING TIMING RUN AT 2021-05-18 10:02:16 PM
31: + RESULT=254
31: + RESULT_NAME=bert
31: + echo 'RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM'
31: RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM
31: + set +x
55: ++ date +%s
55: + END=1621400536
55: ++ date '+%Y-%m-%d %r'
55: + END_FMT='2021-05-18 10:02:16 PM'
55: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:16 PM'
55: ENDING TIMING RUN AT 2021-05-18 10:02:16 PM
55: + RESULT=254
55: + RESULT_NAME=bert
55: RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM
55: + echo 'RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM'
55: + set +x
15: ++ date +%s
15: + END=1621400536
15: ++ date '+%Y-%m-%d %r'
15: + END_FMT='2021-05-18 10:02:16 PM'
15: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:16 PM'
15: ENDING TIMING RUN AT 2021-05-18 10:02:16 PM
15: + RESULT=254
15: + RESULT_NAME=bert
15: RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM
15: + echo 'RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM'
15: + set +x
47: ++ date +%s
47: + END=1621400536
47: ++ date '+%Y-%m-%d %r'
47: + END_FMT='2021-05-18 10:02:16 PM'
47: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:16 PM'
47: ENDING TIMING RUN AT 2021-05-18 10:02:16 PM
47: + RESULT=254
47: + RESULT_NAME=bert
47: RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM
47: + echo 'RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM'
47: + set +x
23: ++ date +%s
23: + END=1621400536
43: ++ date +%s
23: ++ date '+%Y-%m-%d %r'
43: + END=1621400536
23: + END_FMT='2021-05-18 10:02:16 PM'
23: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:16 PM'
23: ENDING TIMING RUN AT 2021-05-18 10:02:16 PM
23: + RESULT=254
23: + RESULT_NAME=bert
23: RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM
23: + echo 'RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM'
23: + set +x
43: ++ date '+%Y-%m-%d %r'
43: + END_FMT='2021-05-18 10:02:16 PM'
43: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:16 PM'
43: ENDING TIMING RUN AT 2021-05-18 10:02:16 PM
43: + RESULT=254
43: + RESULT_NAME=bert
43: RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM
43: + echo 'RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM'
43: + set +x
 7: ++ date +%s
 7: + END=1621400536
 7: ++ date '+%Y-%m-%d %r'
 3: ++ date +%s
 7: + END_FMT='2021-05-18 10:02:16 PM'
 7: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:16 PM'
 7: ENDING TIMING RUN AT 2021-05-18 10:02:16 PM
 7: + RESULT=254
 7: + RESULT_NAME=bert
 7: RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM
 7: + echo 'RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM'
 7: + set +x
 3: + END=1621400536
19: ++ date +%s
 3: ++ date '+%Y-%m-%d %r'
19: + END=1621400536
 3: + END_FMT='2021-05-18 10:02:16 PM'
 3: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:16 PM'
 3: ENDING TIMING RUN AT 2021-05-18 10:02:16 PM
 3: + RESULT=254
 3: + RESULT_NAME=bert
 3: RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM
 3: + echo 'RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM'
 3: + set +x
19: ++ date '+%Y-%m-%d %r'
19: + END_FMT='2021-05-18 10:02:16 PM'
19: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:16 PM'
19: ENDING TIMING RUN AT 2021-05-18 10:02:16 PM
19: + RESULT=254
19: + RESULT_NAME=bert
19: RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM
19: + echo 'RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM'
19: + set +x
63: ++ date +%s
63: + END=1621400536
63: ++ date '+%Y-%m-%d %r'
59: ++ date +%s
63: + END_FMT='2021-05-18 10:02:16 PM'
63: ENDING TIMING RUN AT 2021-05-18 10:02:16 PM
63: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:16 PM'
63: + RESULT=254
63: + RESULT_NAME=bert
63: RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM
63: + echo 'RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM'
63: + set +x
59: + END=1621400536
59: ++ date '+%Y-%m-%d %r'
59: + END_FMT='2021-05-18 10:02:16 PM'
59: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:16 PM'
59: ENDING TIMING RUN AT 2021-05-18 10:02:16 PM
59: + RESULT=254
59: + RESULT_NAME=bert
59: RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM
59: + echo 'RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM'
59: + set +x
27: ++ date +%s
27: + END=1621400536
27: ++ date '+%Y-%m-%d %r'
27: + END_FMT='2021-05-18 10:02:16 PM'
27: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:16 PM'
27: ENDING TIMING RUN AT 2021-05-18 10:02:16 PM
27: + RESULT=254
27: + RESULT_NAME=bert
27: RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM
27: + echo 'RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM'
27: + set +x
11: ++ date +%s
11: + END=1621400536
11: ++ date '+%Y-%m-%d %r'
11: + END_FMT='2021-05-18 10:02:16 PM'
11: ENDING TIMING RUN AT 2021-05-18 10:02:16 PM
11: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:16 PM'
11: + RESULT=254
11: + RESULT_NAME=bert
11: + echo 'RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM'
11: RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM
11: + set +x
51: ++ date +%s
51: + END=1621400536
51: ++ date '+%Y-%m-%d %r'
51: + END_FMT='2021-05-18 10:02:16 PM'
51: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:16 PM'
51: ENDING TIMING RUN AT 2021-05-18 10:02:16 PM
51: + RESULT=254
51: + RESULT_NAME=bert
51: + echo 'RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM'
51: RESULT,bert,4020,254,root,2021-05-18 09:58:02 PM
51: + set +x
21: ++ date +%s
21: + END=1621400537
21: ++ date '+%Y-%m-%d %r'
21: + END_FMT='2021-05-18 10:02:17 PM'
21: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
21: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
21: + RESULT=255
21: + RESULT_NAME=bert
21: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
21: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
21: + set +x
45: ++ date +%s
61: ++ date +%s
45: + END=1621400537
45: ++ date '+%Y-%m-%d %r'
61: + END=1621400537
61: ++ date '+%Y-%m-%d %r'
45: + END_FMT='2021-05-18 10:02:17 PM'
45: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
45: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
45: + RESULT=255
45: + RESULT_NAME=bert
45: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
45: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
45: + set +x
61: + END_FMT='2021-05-18 10:02:17 PM'
61: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
61: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
61: + RESULT=255
61: + RESULT_NAME=bert
61: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
61: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
61: + set +x
 5: ++ date +%s
 5: + END=1621400537
 5: ++ date '+%Y-%m-%d %r'
 5: + END_FMT='2021-05-18 10:02:17 PM'
 5: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
 5: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
 5: + RESULT=255
 5: + RESULT_NAME=bert
 5: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
 5: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
 5: + set +x
39: ++ date +%s
39: + END=1621400537
39: ++ date '+%Y-%m-%d %r'
39: + END_FMT='2021-05-18 10:02:17 PM'
39: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
39: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
39: + RESULT=255
39: + RESULT_NAME=bert
39: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
39: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
39: + set +x
53: ++ date +%s
53: + END=1621400537
53: ++ date '+%Y-%m-%d %r'
53: + END_FMT='2021-05-18 10:02:17 PM'
53: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
53: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
53: + RESULT=255
53: + RESULT_NAME=bert
53: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
53: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
53: + set +x
13: ++ date +%s
13: + END=1621400537
13: ++ date '+%Y-%m-%d %r'
13: + END_FMT='2021-05-18 10:02:17 PM'
13: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
13: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
13: + RESULT=255
13: + RESULT_NAME=bert
13: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
13: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
13: + set +x
29: ++ date +%s
29: + END=1621400537
29: ++ date '+%Y-%m-%d %r'
29: + END_FMT='2021-05-18 10:02:17 PM'
29: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
29: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
29: + RESULT=255
29: + RESULT_NAME=bert
29: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
29: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
29: + set +x
17: ++ date +%s
17: + END=1621400537
17: ++ date '+%Y-%m-%d %r'
17: + END_FMT='2021-05-18 10:02:17 PM'
17: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
17: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
17: + RESULT=255
17: + RESULT_NAME=bert
17: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
17: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
17: + set +x
41: ++ date +%s
41: + END=1621400537
41: ++ date '+%Y-%m-%d %r'
41: + END_FMT='2021-05-18 10:02:17 PM'
41: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
41: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
41: + RESULT=255
41: + RESULT_NAME=bert
41: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
41: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
41: + set +x
57: ++ date +%s
57: + END=1621400537
57: ++ date '+%Y-%m-%d %r'
57: + END_FMT='2021-05-18 10:02:17 PM'
57: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
57: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
57: + RESULT=255
57: + RESULT_NAME=bert
57: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
57: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
57: + set +x
 1: ++ date +%s
 1: + END=1621400537
 1: ++ date '+%Y-%m-%d %r'
 1: + END_FMT='2021-05-18 10:02:17 PM'
 1: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
 1: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
 1: + RESULT=255
 1: + RESULT_NAME=bert
 1: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
 1: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
 1: + set +x
 9: ++ date +%s
 9: + END=1621400537
 9: ++ date '+%Y-%m-%d %r'
 9: + END_FMT='2021-05-18 10:02:17 PM'
 9: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
 9: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
 9: + RESULT=255
 9: + RESULT_NAME=bert
 9: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
 9: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
 9: + set +x
25: ++ date +%s
25: + END=1621400537
25: ++ date '+%Y-%m-%d %r'
25: + END_FMT='2021-05-18 10:02:17 PM'
25: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
25: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
25: + RESULT=255
25: + RESULT_NAME=bert
25: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
25: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
25: + set +x
49: ++ date +%s
49: + END=1621400537
49: ++ date '+%Y-%m-%d %r'
49: + END_FMT='2021-05-18 10:02:17 PM'
49: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
49: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
49: + RESULT=255
49: + RESULT_NAME=bert
49: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
49: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
49: + set +x
32: ++ date +%s
32: + END=1621400537
32: ++ date '+%Y-%m-%d %r'
32: + END_FMT='2021-05-18 10:02:17 PM'
32: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
32: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
32: + RESULT=255
32: + RESULT_NAME=bert
32: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
32: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
32: + set +x
16: ++ date +%s
22: ++ date +%s
16: + END=1621400537
16: ++ date '+%Y-%m-%d %r'
22: + END=1621400537
22: ++ date '+%Y-%m-%d %r'
16: + END_FMT='2021-05-18 10:02:17 PM'
16: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
16: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
16: + RESULT=255
16: + RESULT_NAME=bert
16: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
16: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
16: + set +x
22: + END_FMT='2021-05-18 10:02:17 PM'
22: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
22: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
22: + RESULT=255
22: + RESULT_NAME=bert
22: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
22: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
22: + set +x
40: ++ date +%s
46: ++ date +%s
40: + END=1621400537
40: ++ date '+%Y-%m-%d %r'
46: + END=1621400537
46: ++ date '+%Y-%m-%d %r'
40: + END_FMT='2021-05-18 10:02:17 PM'
40: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
40: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
40: + RESULT=255
40: + RESULT_NAME=bert
40: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
40: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
40: + set +x
46: + END_FMT='2021-05-18 10:02:17 PM'
46: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
46: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
46: + RESULT=255
46: + RESULT_NAME=bert
46: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
46: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
46: + set +x
56: ++ date +%s
56: + END=1621400537
62: ++ date +%s
56: ++ date '+%Y-%m-%d %r'
62: + END=1621400537
56: + END_FMT='2021-05-18 10:02:17 PM'
56: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
56: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
56: + RESULT=255
56: + RESULT_NAME=bert
56: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
56: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
56: + set +x
62: ++ date '+%Y-%m-%d %r'
62: + END_FMT='2021-05-18 10:02:17 PM'
62: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
62: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
62: + RESULT=255
62: + RESULT_NAME=bert
62: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
62: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
62: + set +x
 0: ++ date +%s
 6: ++ date +%s
 0: + END=1621400537
 0: ++ date '+%Y-%m-%d %r'
 6: + END=1621400537
 6: ++ date '+%Y-%m-%d %r'
 0: + END_FMT='2021-05-18 10:02:17 PM'
 0: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
 0: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
 0: + RESULT=255
 0: + RESULT_NAME=bert
 0: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
 0: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
 0: + set +x
 6: + END_FMT='2021-05-18 10:02:17 PM'
 6: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
 6: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
 6: + RESULT=255
 6: + RESULT_NAME=bert
 6: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
 6: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
 6: + set +x
48: ++ date +%s
54: ++ date +%s
30: ++ date +%s
24: ++ date +%s
48: + END=1621400537
54: + END=1621400537
48: ++ date '+%Y-%m-%d %r'
54: ++ date '+%Y-%m-%d %r'
30: + END=1621400537
24: + END=1621400537
48: + END_FMT='2021-05-18 10:02:17 PM'
48: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
48: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
48: + RESULT=255
48: + RESULT_NAME=bert
48: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
48: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
48: + set +x
14: ++ date +%s
30: ++ date '+%Y-%m-%d %r'
24: ++ date '+%Y-%m-%d %r'
 8: ++ date +%s
54: + END_FMT='2021-05-18 10:02:17 PM'
54: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
54: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
54: + RESULT=255
54: + RESULT_NAME=bert
54: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
54: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
54: + set +x
24: + END_FMT='2021-05-18 10:02:17 PM'
 8: + END=1621400537
30: + END_FMT='2021-05-18 10:02:17 PM'
24: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
24: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
30: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
30: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
24: + RESULT=255
24: + RESULT_NAME=bert
24: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
24: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
24: + set +x
30: + RESULT=255
30: + RESULT_NAME=bert
30: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
30: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
30: + set +x
14: + END=1621400537
 8: ++ date '+%Y-%m-%d %r'
14: ++ date '+%Y-%m-%d %r'
14: + END_FMT='2021-05-18 10:02:17 PM'
14: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
14: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
14: + RESULT=255
14: + RESULT_NAME=bert
14: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
14: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
14: + set +x
 8: + END_FMT='2021-05-18 10:02:17 PM'
 8: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:17 PM'
 8: ENDING TIMING RUN AT 2021-05-18 10:02:17 PM
 8: + RESULT=255
 8: + RESULT_NAME=bert
 8: RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM
 8: + echo 'RESULT,bert,4020,255,root,2021-05-18 09:58:02 PM'
 8: + set +x
34: ++ date +%s
34: + END=1621400538
34: ++ date '+%Y-%m-%d %r'
34: + END_FMT='2021-05-18 10:02:18 PM'
34: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:18 PM'
34: ENDING TIMING RUN AT 2021-05-18 10:02:18 PM
34: + RESULT=256
34: + RESULT_NAME=bert
34: RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM
34: + echo 'RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM'
34: + set +x
20: ++ date +%s
20: + END=1621400538
20: ++ date '+%Y-%m-%d %r'
20: + END_FMT='2021-05-18 10:02:18 PM'
20: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:18 PM'
20: ENDING TIMING RUN AT 2021-05-18 10:02:18 PM
20: + RESULT=256
20: + RESULT_NAME=bert
20: RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM
20: + echo 'RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM'
20: + set +x
28: ++ date +%s
28: + END=1621400538
28: ++ date '+%Y-%m-%d %r'
44: ++ date +%s
28: + END_FMT='2021-05-18 10:02:18 PM'
28: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:18 PM'
28: ENDING TIMING RUN AT 2021-05-18 10:02:18 PM
28: + RESULT=256
28: + RESULT_NAME=bert
28: RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM
28: + echo 'RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM'
28: + set +x
44: + END=1621400538
44: ++ date '+%Y-%m-%d %r'
44: + END_FMT='2021-05-18 10:02:18 PM'
44: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:18 PM'
44: ENDING TIMING RUN AT 2021-05-18 10:02:18 PM
44: + RESULT=256
44: + RESULT_NAME=bert
44: RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM
44: + echo 'RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM'
44: + set +x
 4: ++ date +%s
 4: + END=1621400538
 4: ++ date '+%Y-%m-%d %r'
 4: + END_FMT='2021-05-18 10:02:18 PM'
 4: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:18 PM'
 4: ENDING TIMING RUN AT 2021-05-18 10:02:18 PM
 4: + RESULT=256
 4: + RESULT_NAME=bert
 4: RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM
 4: + echo 'RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM'
 4: + set +x
60: ++ date +%s
60: + END=1621400538
60: ++ date '+%Y-%m-%d %r'
60: + END_FMT='2021-05-18 10:02:18 PM'
60: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:18 PM'
60: ENDING TIMING RUN AT 2021-05-18 10:02:18 PM
60: + RESULT=256
60: + RESULT_NAME=bert
60: RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM
60: + echo 'RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM'
60: + set +x
12: ++ date +%s
12: + END=1621400538
12: ++ date '+%Y-%m-%d %r'
12: + END_FMT='2021-05-18 10:02:18 PM'
12: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:18 PM'
12: ENDING TIMING RUN AT 2021-05-18 10:02:18 PM
12: + RESULT=256
12: + RESULT_NAME=bert
12: RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM
12: + echo 'RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM'
12: + set +x
52: ++ date +%s
52: + END=1621400538
52: ++ date '+%Y-%m-%d %r'
52: + END_FMT='2021-05-18 10:02:18 PM'
52: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:18 PM'
52: ENDING TIMING RUN AT 2021-05-18 10:02:18 PM
52: + RESULT=256
52: + RESULT_NAME=bert
52: RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM
52: + echo 'RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM'
52: + set +x
35: ++ date +%s
35: + END=1621400538
35: ++ date '+%Y-%m-%d %r'
35: + END_FMT='2021-05-18 10:02:18 PM'
35: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:18 PM'
35: ENDING TIMING RUN AT 2021-05-18 10:02:18 PM
35: + RESULT=256
35: + RESULT_NAME=bert
35: RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM
35: + echo 'RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM'
35: + set +x
37: ++ date +%s
33: ++ date +%s
38: ++ date +%s
37: + END=1621400538
33: + END=1621400538
37: ++ date '+%Y-%m-%d %r'
33: ++ date '+%Y-%m-%d %r'
38: + END=1621400538
37: + END_FMT='2021-05-18 10:02:18 PM'
38: ++ date '+%Y-%m-%d %r'
37: ENDING TIMING RUN AT 2021-05-18 10:02:18 PM
37: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:18 PM'
37: + RESULT=256
37: + RESULT_NAME=bert
37: RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM
37: + echo 'RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM'
37: + set +x
33: + END_FMT='2021-05-18 10:02:18 PM'
33: ENDING TIMING RUN AT 2021-05-18 10:02:18 PM
33: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:18 PM'
33: + RESULT=256
33: + RESULT_NAME=bert
33: RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM
33: + echo 'RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM'
33: + set +x
38: + END_FMT='2021-05-18 10:02:18 PM'
38: ENDING TIMING RUN AT 2021-05-18 10:02:18 PM
38: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:18 PM'
38: + RESULT=256
38: + RESULT_NAME=bert
38: + echo 'RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM'
38: RESULT,bert,4020,256,root,2021-05-18 09:58:02 PM
38: + set +x
36: ++ date +%s
36: + END=1621400539
36: ++ date '+%Y-%m-%d %r'
36: + END_FMT='2021-05-18 10:02:19 PM'
36: + echo 'ENDING TIMING RUN AT 2021-05-18 10:02:19 PM'
36: ENDING TIMING RUN AT 2021-05-18 10:02:19 PM
36: + RESULT=257
36: + RESULT_NAME=bert
36: RESULT,bert,4020,257,root,2021-05-18 09:58:02 PM
36: + echo 'RESULT,bert,4020,257,root,2021-05-18 09:58:02 PM'
36: + set +x
