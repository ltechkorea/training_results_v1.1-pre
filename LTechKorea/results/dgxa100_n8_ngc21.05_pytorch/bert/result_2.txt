+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
srun: Job 1417029 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Step created for job 1417029
Clearing cache on luna-0471
Clearing cache on luna-0465
Clearing cache on luna-0470
Clearing cache on luna-0467
Clearing cache on luna-0469
Clearing cache on luna-0466
Clearing cache on luna-0468
Clearing cache on luna-0472
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=language_model python -c '
import mlperf_logger
mlperf_logger.log_event(key=mlperf_logger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1621400080970, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400080977, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400081006, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400081006, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400081008, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400081026, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400081028, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1621400081042, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ '[' 0 -eq 0 ']'
+ srun -l --mpi=none --ntasks=64 --ntasks-per-node=8 --container-name=language_model --container-mounts=/raid/datasets/bert/hdf5/v1p0_ref/4096_shards_uncompressed:/workspace/data,/raid/datasets/bert/hdf5/v1p0_ref/4096_shards_uncompressed:/workspace/data_phase2,/lustre/fsw/mlperf-ci/23336635/ci_checkpoints:/results,/raid/datasets/bert/checkpoints/checkpoint_phase1:/workspace/phase1,/raid/datasets/bert/hdf5/v1p0_ref/eval_uncompressed:/workspace/evaldata,/lustre/fsw/mlperf/mlperft-bert/unit_test:/workspace/unit_test_data sh -c '/workspace/bert/run_and_time.sh "    ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=${SLURM_LOCALID}     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16" 6879 '
 3: Run vars: id 1417029 gpus 8 mparams
 7: Run vars: id 1417029 gpus 8 mparams
 0: Run vars: id 1417029 gpus 8 mparams
 2: Run vars: id 1417029 gpus 8 mparams
 4: Run vars: id 1417029 gpus 8 mparams
 3: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
 3: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 3: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
 5: Run vars: id 1417029 gpus 8 mparams
 3: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
 3: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 6: Run vars: id 1417029 gpus 8 mparams
 7: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
 7: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 7: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
 7: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
 7: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 0: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
 0: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
51: Run vars: id 1417029 gpus 8 mparams
55: Run vars: id 1417029 gpus 8 mparams
52: Run vars: id 1417029 gpus 8 mparams
54: Run vars: id 1417029 gpus 8 mparams
49: Run vars: id 1417029 gpus 8 mparams
50: Run vars: id 1417029 gpus 8 mparams
48: Run vars: id 1417029 gpus 8 mparams
53: Run vars: id 1417029 gpus 8 mparams
51: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
51: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
51: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
51: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
51: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
55: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
55: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
55: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
55: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
55: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
52: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
52: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
52: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
52: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
52: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
54: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
27: Run vars: id 1417029 gpus 8 mparams
49: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
54: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
54: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
49: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
49: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
54: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
54: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
49: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
49: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
53: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
48: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
31: Run vars: id 1417029 gpus 8 mparams
50: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
53: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
53: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
48: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
48: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
50: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
50: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
53: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
53: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
48: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
48: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
50: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
30: Run vars: id 1417029 gpus 8 mparams
50: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
29: Run vars: id 1417029 gpus 8 mparams
26: Run vars: id 1417029 gpus 8 mparams
28: Run vars: id 1417029 gpus 8 mparams
24: Run vars: id 1417029 gpus 8 mparams
25: Run vars: id 1417029 gpus 8 mparams
27: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
27: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
27: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
27: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
27: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
31: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
31: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
31: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
30: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
31: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
31: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
30: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
30: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
30: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
30: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
29: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
29: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
29: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
29: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
29: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
26: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
24: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
26: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
26: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
28: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
24: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
24: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
28: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
28: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
26: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
26: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
24: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
24: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
28: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
28: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
25: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
25: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
25: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
25: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
25: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
59: Run vars: id 1417029 gpus 8 mparams
11: Run vars: id 1417029 gpus 8 mparams
61: Run vars: id 1417029 gpus 8 mparams
58: Run vars: id 1417029 gpus 8 mparams
 9: Run vars: id 1417029 gpus 8 mparams
10: Run vars: id 1417029 gpus 8 mparams
62: Run vars: id 1417029 gpus 8 mparams
12: Run vars: id 1417029 gpus 8 mparams
60: Run vars: id 1417029 gpus 8 mparams
63: Run vars: id 1417029 gpus 8 mparams
56: Run vars: id 1417029 gpus 8 mparams
43: Run vars: id 1417029 gpus 8 mparams
 8: Run vars: id 1417029 gpus 8 mparams
14: Run vars: id 1417029 gpus 8 mparams
59: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
59: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
59: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
47: Run vars: id 1417029 gpus 8 mparams
57: Run vars: id 1417029 gpus 8 mparams
13: Run vars: id 1417029 gpus 8 mparams
59: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
44: Run vars: id 1417029 gpus 8 mparams
59: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
45: Run vars: id 1417029 gpus 8 mparams
41: Run vars: id 1417029 gpus 8 mparams
46: Run vars: id 1417029 gpus 8 mparams
11: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
11: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
42: Run vars: id 1417029 gpus 8 mparams
11: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
11: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
11: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 9: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
61: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
 9: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
58: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
 9: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
61: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 9: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
62: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
61: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
 9: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
58: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
58: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
15: Run vars: id 1417029 gpus 8 mparams
62: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
62: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
61: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
61: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
58: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
58: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
62: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
62: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
10: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
12: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
10: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
10: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
10: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
10: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
12: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
60: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
12: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
60: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
60: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
12: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
12: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
60: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
60: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
56: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
63: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
43: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
56: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
47: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
56: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
43: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
63: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
43: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
63: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
56: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
56: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
63: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
47: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
63: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
47: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
43: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
43: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
44: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
57: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
 8: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
 8: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 8: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
13: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
14: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
14: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
14: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
13: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
47: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
13: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
57: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
47: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
57: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
44: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
44: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
45: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
40: Run vars: id 1417029 gpus 8 mparams
 8: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
 8: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
14: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
57: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
14: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
13: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
41: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
57: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
13: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
45: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
45: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
44: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
44: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
41: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
41: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
45: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
45: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
41: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
41: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
46: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
46: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
46: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
42: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
46: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
46: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
42: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
42: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
42: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
42: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
19: Run vars: id 1417029 gpus 8 mparams
34: Run vars: id 1417029 gpus 8 mparams
38: Run vars: id 1417029 gpus 8 mparams
15: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
15: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
15: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
35: Run vars: id 1417029 gpus 8 mparams
15: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
15: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
37: Run vars: id 1417029 gpus 8 mparams
36: Run vars: id 1417029 gpus 8 mparams
32: Run vars: id 1417029 gpus 8 mparams
23: Run vars: id 1417029 gpus 8 mparams
33: Run vars: id 1417029 gpus 8 mparams
16: Run vars: id 1417029 gpus 8 mparams
39: Run vars: id 1417029 gpus 8 mparams
20: Run vars: id 1417029 gpus 8 mparams
17: Run vars: id 1417029 gpus 8 mparams
18: Run vars: id 1417029 gpus 8 mparams
21: Run vars: id 1417029 gpus 8 mparams
22: Run vars: id 1417029 gpus 8 mparams
40: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
40: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
34: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
40: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
35: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
40: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
40: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
34: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
34: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
35: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
35: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
19: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
34: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
34: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
37: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
35: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
19: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
19: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=3     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
19: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --all
19: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
35: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
37: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
37: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
38: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
37: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
37: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
38: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
38: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
38: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
38: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
36: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
36: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
36: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
36: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
36: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
32: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
32: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
32: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
32: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
32: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
16: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
23: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
39: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
33: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
39: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
16: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
16: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
39: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
23: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
33: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
23: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=7     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
33: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
39: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
20: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
39: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
33: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
33: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
16: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
16: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
23: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --all
23: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
20: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
20: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
20: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
20: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
18: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
18: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
18: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
18: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
18: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
21: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
17: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
21: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
21: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
22: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
17: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
17: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
21: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
21: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
22: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
22: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
17: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
17: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
22: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
22: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 0: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=0     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
 0: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --all
 0: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 2: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
 2: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 2: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=2     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
 2: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --all
 2: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 4: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
 4: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 4: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=4     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
 5: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
 4: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --all
 4: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 6: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
 5: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 5: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=5     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
 6: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 6: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=6     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
 5: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --all
 5: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 6: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --all
 6: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 1: Run vars: id 1417029 gpus 8 mparams
 1: STARTING TIMING RUN AT 2021-05-18 09:54:41 PM
 1: + eval '     ./bind.sh --cpu=exclusive --ib=single --cluster=selene --     python -u /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=1.5e-3     --opt_lamb_beta_1=0.83     --opt_lamb_beta_2=0.925     --warmup_proportion=0.0     --warmup_steps=100     --start_warmup_step=-25     --max_steps=1271     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata     --cache_eval_data     --output_dir=/results     --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding     --distributed_lamb   --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blo
 1: cks=1      --gradient_accumulation_steps=1     --log_freq=0     --local_rank=1     --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879'
 1: ++ ./bind.sh --cpu=exclusive --ib=single --cluster=selene -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --all
 1: reduce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 3: num_sockets = 2 num_nodes=8 cores_per_socket=64
 3: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
 3: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
51: num_sockets = 2 num_nodes=8 cores_per_socket=64
51: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
51: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
59: num_sockets = 2 num_nodes=8 cores_per_socket=64
59: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
59: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
19: num_sockets = 2 num_nodes=8 cores_per_socket=64
19: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
19: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
27: num_sockets = 2 num_nodes=8 cores_per_socket=64
27: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
27: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
11: num_sockets = 2 num_nodes=8 cores_per_socket=64
11: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
11: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
52: num_sockets = 2 num_nodes=8 cores_per_socket=64
52: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
43: num_sockets = 2 num_nodes=8 cores_per_socket=64
52: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
43: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
43: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
35: num_sockets = 2 num_nodes=8 cores_per_socket=64
35: + exec numactl --physcpubind=48-63,176-191 --membind=3 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=3 --bert_config_path=/workspace/phase1/bert_config.json --allred
35: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
37: num_sockets = 2 num_nodes=8 cores_per_socket=64
37: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
37: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
10: num_sockets = 2 num_nodes=8 cores_per_socket=64
10: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
10: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
55: num_sockets = 2 num_nodes=8 cores_per_socket=64
55: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
55: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 9: num_sockets = 2 num_nodes=8 cores_per_socket=64
 9: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
 9: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
13: num_sockets = 2 num_nodes=8 cores_per_socket=64
13: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
13: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 8: num_sockets = 2 num_nodes=8 cores_per_socket=64
14: num_sockets = 2 num_nodes=8 cores_per_socket=64
15: num_sockets = 2 num_nodes=8 cores_per_socket=64
 8: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
 8: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
12: num_sockets = 2 num_nodes=8 cores_per_socket=64
14: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
14: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
15: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
15: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
12: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
12: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
34: num_sockets = 2 num_nodes=8 cores_per_socket=64
34: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
34: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
25: num_sockets = 2 num_nodes=8 cores_per_socket=64
25: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
25: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
53: num_sockets = 2 num_nodes=8 cores_per_socket=64
48: num_sockets = 2 num_nodes=8 cores_per_socket=64
53: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
53: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
50: num_sockets = 2 num_nodes=8 cores_per_socket=64
54: num_sockets = 2 num_nodes=8 cores_per_socket=64
48: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
48: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
49: num_sockets = 2 num_nodes=8 cores_per_socket=64
54: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
54: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
49: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
49: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
50: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
50: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
30: num_sockets = 2 num_nodes=8 cores_per_socket=64
30: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
30: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
29: num_sockets = 2 num_nodes=8 cores_per_socket=64
29: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
29: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
28: num_sockets = 2 num_nodes=8 cores_per_socket=64
31: num_sockets = 2 num_nodes=8 cores_per_socket=64
26: num_sockets = 2 num_nodes=8 cores_per_socket=64
24: num_sockets = 2 num_nodes=8 cores_per_socket=64
28: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
28: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
31: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
31: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
26: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
26: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
24: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
24: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 0: num_sockets = 2 num_nodes=8 cores_per_socket=64
 0: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
 0: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
60: num_sockets = 2 num_nodes=8 cores_per_socket=64
60: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
60: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
57: num_sockets = 2 num_nodes=8 cores_per_socket=64
57: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
57: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
58: num_sockets = 2 num_nodes=8 cores_per_socket=64
58: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
58: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
61: num_sockets = 2 num_nodes=8 cores_per_socket=64
56: num_sockets = 2 num_nodes=8 cores_per_socket=64
62: num_sockets = 2 num_nodes=8 cores_per_socket=64
63: num_sockets = 2 num_nodes=8 cores_per_socket=64
56: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
56: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
61: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
61: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
63: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
63: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
62: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
62: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
44: num_sockets = 2 num_nodes=8 cores_per_socket=64
44: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
44: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
22: num_sockets = 2 num_nodes=8 cores_per_socket=64
22: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
22: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 7: num_sockets = 2 num_nodes=8 cores_per_socket=64
 7: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
 7: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
41: num_sockets = 2 num_nodes=8 cores_per_socket=64
 2: num_sockets = 2 num_nodes=8 cores_per_socket=64
41: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
41: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 2: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
 2: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
32: num_sockets = 2 num_nodes=8 cores_per_socket=64
40: num_sockets = 2 num_nodes=8 cores_per_socket=64
32: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
32: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 1: num_sockets = 2 num_nodes=8 cores_per_socket=64
 6: num_sockets = 2 num_nodes=8 cores_per_socket=64
40: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
40: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
42: num_sockets = 2 num_nodes=8 cores_per_socket=64
45: num_sockets = 2 num_nodes=8 cores_per_socket=64
47: num_sockets = 2 num_nodes=8 cores_per_socket=64
46: num_sockets = 2 num_nodes=8 cores_per_socket=64
 1: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
 1: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 6: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
 6: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 4: num_sockets = 2 num_nodes=8 cores_per_socket=64
 5: num_sockets = 2 num_nodes=8 cores_per_socket=64
42: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
42: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
46: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
46: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
45: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
45: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
47: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
47: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 5: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
 5: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
 4: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
 4: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
36: num_sockets = 2 num_nodes=8 cores_per_socket=64
39: num_sockets = 2 num_nodes=8 cores_per_socket=64
17: num_sockets = 2 num_nodes=8 cores_per_socket=64
38: num_sockets = 2 num_nodes=8 cores_per_socket=64
33: num_sockets = 2 num_nodes=8 cores_per_socket=64
36: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
36: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
39: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
39: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
17: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
17: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
38: + exec numactl --physcpubind=96-111,224-239 --membind=6 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=6 --bert_config_path=/workspace/phase1/bert_config.json --allre
38: duce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
33: + exec numactl --physcpubind=16-31,144-159 --membind=1 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=1 --bert_config_path=/workspace/phase1/bert_config.json --allred
33: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
18: num_sockets = 2 num_nodes=8 cores_per_socket=64
20: num_sockets = 2 num_nodes=8 cores_per_socket=64
18: + exec numactl --physcpubind=32-47,160-175 --membind=2 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=2 --bert_config_path=/workspace/phase1/bert_config.json --allred
18: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
20: + exec numactl --physcpubind=64-79,192-207 --membind=4 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=4 --bert_config_path=/workspace/phase1/bert_config.json --allred
20: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
16: num_sockets = 2 num_nodes=8 cores_per_socket=64
21: num_sockets = 2 num_nodes=8 cores_per_socket=64
23: num_sockets = 2 num_nodes=8 cores_per_socket=64
16: + exec numactl --physcpubind=0-15,128-143 --membind=0 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=0 --bert_config_path=/workspace/phase1/bert_config.json --allredu
16: ce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
23: + exec numactl --physcpubind=112-127,240-255 --membind=7 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=7 --bert_config_path=/workspace/phase1/bert_config.json --allr
23: educe_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
21: + exec numactl --physcpubind=80-95,208-223 --membind=5 -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=1.5e-3 --opt_lamb_beta_1=0.83 --opt_lamb_beta_2=0.925 --warmup_proportion=0.0 --warmup_steps=100 --start_warmup_step=-25 --max_steps=1271 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --cache_eval_data --output_dir=/results --fp16 --fused_gelu_bias --fused_mha --dense_seq_output --unpad --unpad_fmha --exchange_padding --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --local_rank=5 --bert_config_path=/workspace/phase1/bert_config.json --allred
21: uce_post_accumulation --allreduce_post_accumulation_fp16 --seed=6879
51: :::MLLOG {"namespace": "", "time_ms": 1621400083702, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
59: :::MLLOG {"namespace": "", "time_ms": 1621400083707, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
19: :::MLLOG {"namespace": "", "time_ms": 1621400083719, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 3: :::MLLOG {"namespace": "", "time_ms": 1621400083742, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
52: :::MLLOG {"namespace": "", "time_ms": 1621400083746, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
60: :::MLLOG {"namespace": "", "time_ms": 1621400083775, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
27: :::MLLOG {"namespace": "", "time_ms": 1621400083794, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
22: :::MLLOG {"namespace": "", "time_ms": 1621400083802, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
11: :::MLLOG {"namespace": "", "time_ms": 1621400083826, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
43: :::MLLOG {"namespace": "", "time_ms": 1621400083843, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400083844, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
55: :::MLLOG {"namespace": "", "time_ms": 1621400083856, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
20: :::MLLOG {"namespace": "", "time_ms": 1621400083857, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 4: :::MLLOG {"namespace": "", "time_ms": 1621400083861, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
62: :::MLLOG {"namespace": "", "time_ms": 1621400083864, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
17: :::MLLOG {"namespace": "", "time_ms": 1621400083888, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
37: :::MLLOG {"namespace": "", "time_ms": 1621400083904, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 6: :::MLLOG {"namespace": "", "time_ms": 1621400083909, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
26: :::MLLOG {"namespace": "", "time_ms": 1621400083915, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
61: :::MLLOG {"namespace": "", "time_ms": 1621400083920, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
50: :::MLLOG {"namespace": "", "time_ms": 1621400083924, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 9: :::MLLOG {"namespace": "", "time_ms": 1621400083934, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
49: :::MLLOG {"namespace": "", "time_ms": 1621400083941, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
41: :::MLLOG {"namespace": "", "time_ms": 1621400083950, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
12: :::MLLOG {"namespace": "", "time_ms": 1621400083953, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
35: :::MLLOG {"namespace": "", "time_ms": 1621400083964, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
16: :::MLLOG {"namespace": "", "time_ms": 1621400083966, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
57: :::MLLOG {"namespace": "", "time_ms": 1621400083970, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
30: :::MLLOG {"namespace": "", "time_ms": 1621400083973, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
54: :::MLLOG {"namespace": "", "time_ms": 1621400083979, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
56: :::MLLOG {"namespace": "", "time_ms": 1621400083985, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
10: :::MLLOG {"namespace": "", "time_ms": 1621400083988, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
53: :::MLLOG {"namespace": "", "time_ms": 1621400083990, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
25: :::MLLOG {"namespace": "", "time_ms": 1621400083992, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 1: :::MLLOG {"namespace": "", "time_ms": 1621400083995, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
58: :::MLLOG {"namespace": "", "time_ms": 1621400083997, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
48: :::MLLOG {"namespace": "", "time_ms": 1621400083998, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
34: :::MLLOG {"namespace": "", "time_ms": 1621400084004, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
63: :::MLLOG {"namespace": "", "time_ms": 1621400084003, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
18: :::MLLOG {"namespace": "", "time_ms": 1621400084011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
42: :::MLLOG {"namespace": "", "time_ms": 1621400084024, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
21: :::MLLOG {"namespace": "", "time_ms": 1621400084022, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 7: :::MLLOG {"namespace": "", "time_ms": 1621400084025, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
23: :::MLLOG {"namespace": "", "time_ms": 1621400084030, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 5: :::MLLOG {"namespace": "", "time_ms": 1621400084037, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
24: :::MLLOG {"namespace": "", "time_ms": 1621400084045, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 2: :::MLLOG {"namespace": "", "time_ms": 1621400084046, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
14: :::MLLOG {"namespace": "", "time_ms": 1621400084058, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
28: :::MLLOG {"namespace": "", "time_ms": 1621400084061, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
46: :::MLLOG {"namespace": "", "time_ms": 1621400084064, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
29: :::MLLOG {"namespace": "", "time_ms": 1621400084073, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
31: :::MLLOG {"namespace": "", "time_ms": 1621400084081, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
47: :::MLLOG {"namespace": "", "time_ms": 1621400084081, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
 8: :::MLLOG {"namespace": "", "time_ms": 1621400084104, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
44: :::MLLOG {"namespace": "", "time_ms": 1621400084109, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
39: :::MLLOG {"namespace": "", "time_ms": 1621400084116, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
15: :::MLLOG {"namespace": "", "time_ms": 1621400084118, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
40: :::MLLOG {"namespace": "", "time_ms": 1621400084120, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
13: :::MLLOG {"namespace": "", "time_ms": 1621400084128, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
45: :::MLLOG {"namespace": "", "time_ms": 1621400084129, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
33: :::MLLOG {"namespace": "", "time_ms": 1621400084167, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
38: :::MLLOG {"namespace": "", "time_ms": 1621400084181, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
36: :::MLLOG {"namespace": "", "time_ms": 1621400084191, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
32: :::MLLOG {"namespace": "", "time_ms": 1621400084198, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 996}}
50: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
 0: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
58: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400085053, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 66}}
19: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
23: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
28: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
56: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400085053, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 71}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400085053, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 75}}
45: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400085053, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 79}}
 8: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400085053, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xNVIDIA DGX A100", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 83}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400085053, "event_type": "POINT_IN_TIME", "key": "seed", "value": 6879, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1006}}
 5: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
30: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400085053, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 3072, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1008}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400085053, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 48, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1010}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400085053, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1012}}
31: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400085054, "event_type": "POINT_IN_TIME", "key": "max_predictions_per_seq", "value": 76, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1014}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400085054, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 1271.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1016}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400085054, "event_type": "POINT_IN_TIME", "key": "num_warmup_steps", "value": 100.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1018}}
10: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
 0: parsed args:
 0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=0, dwu_num_ag_pg=2, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=175000, eval_iter_start_samples=175000, exchange_padding=True, fp16=True, fused_dropout_add=False, fused_gelu_bias=True, fused_mha=True, gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_d
 0: ir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.0015, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=1271.0, min_samples_to_start_checkpoints=3000000, n_gpu=64, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.83, opt_lamb_beta_2=0.925, output_dir='/results', pad=False, phase2=True, resume_from_checkpoint=False, seed=6879, skip_checkpoint=True, start_warmup_step=-25.0, target_mlm_accuracy=0.72, train_batch_size=48, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_steps=100.0, weight_decay_rate=0.01)
41: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
 6: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
32: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
 3: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
13: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
39: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
44: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
38: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
33: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
 4: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
52: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
11: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
26: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
21: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
63: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
53: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
57: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
49: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
60: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
27: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
55: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
61: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
25: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
12: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
35: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
 2: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
15: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
34: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
 7: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
17: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
14: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
62: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
 1: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
54: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
37: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
24: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
29: device: cuda:5 n_gpu: 64, distributed training: True, 16-bits training: True
22: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
16: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
48: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
40: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
51: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
42: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
43: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
46: device: cuda:6 n_gpu: 64, distributed training: True, 16-bits training: True
36: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
18: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
 9: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
20: device: cuda:4 n_gpu: 64, distributed training: True, 16-bits training: True
59: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
47: device: cuda:7 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1621400091078, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0015, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 669}}
 0: [luna-0465:0:3274483 - context.c:581] INFO job (ID: 17873379118809460825) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 0: [luna-0465:0:3274483 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 0: [luna-0465:0:3274483 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 0: [luna-0465:0:3274483 - comm.c:385] INFO [group#:0] group id:8 tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x120f00000008) mlid:c00e
 0: [luna-0465:0:3274483 - comm.c:385] INFO [group#:1] group id:8 tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 1: [luna-0465:0:3274553 - context.c:581] INFO job (ID: 17873378979221155493) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 1: [luna-0465:0:3274553 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 1: [luna-0465:0:3274553 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 1: [luna-0465:0:3274553 - comm.c:385] INFO [group#:0] group id:9 tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x130f00000009) mlid:c00f
 1: [luna-0465:0:3274553 - comm.c:385] INFO [group#:1] group id:9 tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 2: [luna-0465:0:3274486 - context.c:581] INFO job (ID: 17873378927270841997) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 2: [luna-0465:0:3274486 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 2: [luna-0465:0:3274486 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 2: [luna-0465:0:3274486 - comm.c:385] INFO [group#:0] group id:a tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x140f0000000a) mlid:c010
 2: [luna-0465:0:3274486 - comm.c:385] INFO [group#:1] group id:a tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 3: [luna-0465:0:3274473 - context.c:581] INFO job (ID: 17873378709936249820) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 3: [luna-0465:0:3274473 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 3: [luna-0465:0:3274473 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 3: [luna-0465:0:3274473 - comm.c:385] INFO [group#:0] group id:b tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x150f0000000b) mlid:c011
 3: [luna-0465:0:3274473 - comm.c:385] INFO [group#:1] group id:b tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 4: [luna-0465:0:3274487 - context.c:581] INFO job (ID: 17873379405834843706) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 4: [luna-0465:0:3274487 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 4: [luna-0465:0:3274487 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 4: [luna-0465:0:3274487 - comm.c:385] INFO [group#:0] group id:c tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x160f0000000c) mlid:c012
 4: [luna-0465:0:3274487 - comm.c:385] INFO [group#:1] group id:c tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 5: [luna-0465:0:3274488 - context.c:581] INFO job (ID: 17873379327443670129) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 5: [luna-0465:0:3274488 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 5: [luna-0465:0:3274488 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 5: [luna-0465:0:3274488 - comm.c:385] INFO [group#:0] group id:d tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x170f0000000d) mlid:c013
 5: [luna-0465:0:3274488 - comm.c:385] INFO [group#:1] group id:d tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 6: [luna-0465:0:3274490 - context.c:581] INFO job (ID: 17873378574949594188) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 6: [luna-0465:0:3274490 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 6: [luna-0465:0:3274490 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 6: [luna-0465:0:3274490 - comm.c:385] INFO [group#:0] group id:e tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x180f0000000e) mlid:c014
 6: [luna-0465:0:3274490 - comm.c:385] INFO [group#:1] group id:e tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 7: [luna-0465:0:3274479 - context.c:581] INFO job (ID: 17873378642837866595) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
 7: [luna-0465:0:3274479 - context.c:750] INFO tree_info: type:LLT tree idx:0 treeID:0x0 caps:0x6 quota: ( osts:83 user_data_per_ost:1024 max_groups:83 max_qps:1 max_group_channels:1)
 7: [luna-0465:0:3274479 - context.c:761] INFO tree_info: type:SAT tree idx:1 treeID:0x3f caps:0x16
 7: [luna-0465:0:3274479 - comm.c:385] INFO [group#:0] group id:f tree idx:0 tree_type:LLT rail_idx:0 group size:8 quota: (osts:8 user_data_per_ost:1024) mgid: (subnet prefix:0xff12a01bfe800000 interface id:0x190f0000000f) mlid:c015
 7: [luna-0465:0:3274479 - comm.c:385] INFO [group#:1] group id:f tree idx:1 tree_type:SAT rail_idx:0 group size:8 quota: (osts:64 user_data_per_ost:0) mgid: (subnet prefix:0x0 interface id:0x0) mlid:0
 0: :::MLLOG {"namespace": "", "time_ms": 1621400100572, "event_type": "POINT_IN_TIME", "key": "opt_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 699}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400100572, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.83, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 702}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400100572, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.925, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 703}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400100573, "event_type": "POINT_IN_TIME", "key": "opt_lamb_weight_decay_rate", "value": 0.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 704}}
46: Torch distributed is available.
46: Torch distributed is initialized.
13: Torch distributed is available.
13: Torch distributed is initialized.
37: Torch distributed is available.
37: Torch distributed is initialized.
19: Torch distributed is available.
19: Torch distributed is initialized.
 0: :::MLLOG {"namespace": "", "time_ms": 1621400100577, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 100.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 86}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400100577, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 1.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 87}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400100577, "event_type": "POINT_IN_TIME", "key": "start_warmup_step", "value": -25.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 88}}
44: Torch distributed is available.
44: Torch distributed is initialized.
 1: Torch distributed is available.
 1: Torch distributed is initialized.
54: Torch distributed is available.
54: Torch distributed is initialized.
20: Torch distributed is available.
20: Torch distributed is initialized.
32: Torch distributed is available.
32: Torch distributed is initialized.
57: Torch distributed is available.
57: Torch distributed is initialized.
16: Torch distributed is available.
16: Torch distributed is initialized.
 6: Torch distributed is available.
 6: Torch distributed is initialized.
51: Torch distributed is available.
51: Torch distributed is initialized.
55: Torch distributed is available.
55: Torch distributed is initialized.
 9: Torch distributed is available.
 9: Torch distributed is initialized.
 7: Torch distributed is available.
 7: Torch distributed is initialized.
 2: Torch distributed is available.
 2: Torch distributed is initialized.
45: Torch distributed is available.
45: Torch distributed is initialized.
 3: Torch distributed is available.
 3: Torch distributed is initialized.
43: Torch distributed is available.
43: Torch distributed is initialized.
50: Torch distributed is available.
50: Torch distributed is initialized.
10: Torch distributed is available.
10: Torch distributed is initialized.
53: Torch distributed is available.
53: Torch distributed is initialized.
58: Torch distributed is available.
58: Torch distributed is initialized.
36: Torch distributed is available.
36: Torch distributed is initialized.
48: Torch distributed is available.
48: Torch distributed is initialized.
18: Torch distributed is available.
18: Torch distributed is initialized.
12: Torch distributed is available.
12: Torch distributed is initialized.
62: Torch distributed is available.
62: Torch distributed is initialized.
23: Torch distributed is available.
23: Torch distributed is initialized.
30: Torch distributed is available.
30: Torch distributed is initialized.
21: Torch distributed is available.
21: Torch distributed is initialized.
25: Torch distributed is available.
25: Torch distributed is initialized.
41: Torch distributed is available.
41: Torch distributed is initialized.
 4: Torch distributed is available.
 4: Torch distributed is initialized.
 8: Torch distributed is available.
 8: Torch distributed is initialized.
22: Torch distributed is available.
22: Torch distributed is initialized.
 5: Torch distributed is available.
 5: Torch distributed is initialized.
52: Torch distributed is available.
52: Torch distributed is initialized.
49: Torch distributed is available.
49: Torch distributed is initialized.
61: Torch distributed is available.
61: Torch distributed is initialized.
26: Torch distributed is available.
26: Torch distributed is initialized.
56: Torch distributed is available.
56: Torch distributed is initialized.
17: Torch distributed is available.
17: Torch distributed is initialized.
60: Torch distributed is available.
60: Torch distributed is initialized.
40: Torch distributed is available.
40: Torch distributed is initialized.
39: Torch distributed is available.
39: Torch distributed is initialized.
59: Torch distributed is available.
59: Torch distributed is initialized.
63: Torch distributed is available.
63: Torch distributed is initialized.
34: Torch distributed is available.
34: Torch distributed is initialized.
14: Torch distributed is available.
14: Torch distributed is initialized.
42: Torch distributed is available.
42: Torch distributed is initialized.
47: Torch distributed is available.
47: Torch distributed is initialized.
35: Torch distributed is available.
35: Torch distributed is initialized.
 0: Torch distributed is available.
 0: Torch distributed is initialized.
29: Torch distributed is available.
29: Torch distributed is initialized.
38: Torch distributed is available.
38: Torch distributed is initialized.
11: Torch distributed is available.
11: Torch distributed is initialized.
33: Torch distributed is available.
33: Torch distributed is initialized.
15: Torch distributed is available.
15: Torch distributed is initialized.
28: Torch distributed is available.
28: Torch distributed is initialized.
31: Torch distributed is available.
31: Torch distributed is initialized.
24: Torch distributed is available.
24: Torch distributed is initialized.
27: Torch distributed is available.
27: Torch distributed is initialized.
 0: :::MLLOG {"namespace": "", "time_ms": 1621400125038, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1264}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400125247, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1265}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400125270, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1276, "epoch_num": 1}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400125271, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1278, "first_epoch_num": 1, "epoch_count": 1}}
 0: parsed args:
 0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=0, dwu_num_ag_pg=2, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=175000, eval_iter_start_samples=175000, exchange_padding=True, fp16=True, fused_dropout_add=False, fused_gelu_bias=True, fused_mha=True, gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_d
 0: ir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.0015, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=1271.0, min_samples_to_start_checkpoints=3000000, n_gpu=64, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.83, opt_lamb_beta_2=0.925, output_dir='/results', pad=False, phase2=True, resume_from_checkpoint=False, resume_step=0, seed=6879, skip_checkpoint=True, start_warmup_step=-25.0, target_mlm_accuracy=0.72, train_batch_size=48, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_steps=100.0, weight_decay_rate=0.01)
 0: epoch: 1
 0: :::MLLOG {"namespace": "", "time_ms": 1621400138336, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.37111398577690125, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 57, 'eval_loss': 4.149960041046143, 'eval_mlm_accuracy': 0.37111398577690125}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400148897, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.38181138038635254, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 114, 'eval_loss': 4.036741256713867, 'eval_mlm_accuracy': 0.38181138038635254}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400159425, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.40502527356147766, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 171, 'eval_loss': 3.8157126903533936, 'eval_mlm_accuracy': 0.40502527356147766}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400170131, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.43933120369911194, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 228, 'eval_loss': 3.4818358421325684, 'eval_mlm_accuracy': 0.43933120369911194}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400180829, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5182621479034424, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 285, 'eval_loss': 2.8308680057525635, 'eval_mlm_accuracy': 0.5182621479034424}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400191375, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6180741786956787, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 342, 'eval_loss': 2.0320236682891846, 'eval_mlm_accuracy': 0.6180741786956787}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400201927, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6835569143295288, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 399, 'eval_loss': 1.547446846961975, 'eval_mlm_accuracy': 0.6835569143295288}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400212656, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7040059566497803, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 456, 'eval_loss': 1.4061646461486816, 'eval_mlm_accuracy': 0.7040059566497803}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400223209, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.709446907043457, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 513, 'eval_loss': 1.3725131750106812, 'eval_mlm_accuracy': 0.709446907043457}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400233789, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7117493748664856, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 570, 'eval_loss': 1.35878586769104, 'eval_mlm_accuracy': 0.7117493748664856}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400244434, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7127324938774109, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 627, 'eval_loss': 1.3491584062576294, 'eval_mlm_accuracy': 0.7127324938774109}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400255129, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7144207954406738, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 684, 'eval_loss': 1.3409981727600098, 'eval_mlm_accuracy': 0.7144207954406738}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400265721, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7158733010292053, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 741, 'eval_loss': 1.33486807346344, 'eval_mlm_accuracy': 0.7158733010292053}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400276437, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7164056897163391, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 798, 'eval_loss': 1.3286075592041016, 'eval_mlm_accuracy': 0.7164056897163391}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400287551, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7173701524734497, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 855, 'eval_loss': 1.3239576816558838, 'eval_mlm_accuracy': 0.7173701524734497}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400298633, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7183789014816284, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 912, 'eval_loss': 1.3194446563720703, 'eval_mlm_accuracy': 0.7183789014816284}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400309590, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7186311483383179, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 969, 'eval_loss': 1.3130744695663452, 'eval_mlm_accuracy': 0.7186311483383179}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400320584, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.719775378704071, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 1026, 'eval_loss': 1.3094300031661987, 'eval_mlm_accuracy': 0.719775378704071}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400331817, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7206393480300903, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1441, "epoch_num": 1}}
 0: {'global_steps': 1083, 'eval_loss': 1.3054050207138062, 'eval_mlm_accuracy': 0.7206393480300903}
 0: 0.720639 > 0.720000, Target MLM Accuracy reached at 1083
 0: (1, 1092.0) {'final_loss': 0.0}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400331873, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1567, "first_epoch_num": 1}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400331874, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1570, "epoch_num": 1}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400331874, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 3326976, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1574}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400331874, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 10000, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1577}}
 0: :::MLLOG {"namespace": "", "time_ms": 1621400331874, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1580, "status": "success"}}
 0: {'e2e_time': 248.039133310318, 'training_sequences_per_second': 17409.30467994785, 'final_loss': 0.0, 'raw_train_time': 224.27730870246887}
45: ++ date +%s
45: + END=1621400340
45: ++ date '+%Y-%m-%d %r'
45: + END_FMT='2021-05-18 09:59:00 PM'
45: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:00 PM'
45: ENDING TIMING RUN AT 2021-05-18 09:59:00 PM
45: + RESULT=259
45: + RESULT_NAME=bert
45: + echo 'RESULT,bert,6879,259,root,2021-05-18 09:54:41 PM'
45: RESULT,bert,6879,259,root,2021-05-18 09:54:41 PM
45: + set +x
 5: ++ date +%s
13: ++ date +%s
 5: + END=1621400340
 5: ++ date '+%Y-%m-%d %r'
13: + END=1621400340
13: ++ date '+%Y-%m-%d %r'
 5: + END_FMT='2021-05-18 09:59:00 PM'
 5: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:00 PM'
 5: ENDING TIMING RUN AT 2021-05-18 09:59:00 PM
 5: + RESULT=259
 5: + RESULT_NAME=bert
 5: RESULT,bert,6879,259,root,2021-05-18 09:54:41 PM
 5: + echo 'RESULT,bert,6879,259,root,2021-05-18 09:54:41 PM'
 5: + set +x
61: ++ date +%s
13: + END_FMT='2021-05-18 09:59:00 PM'
13: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:00 PM'
13: ENDING TIMING RUN AT 2021-05-18 09:59:00 PM
13: + RESULT=259
13: + RESULT_NAME=bert
13: RESULT,bert,6879,259,root,2021-05-18 09:54:41 PM
13: + echo 'RESULT,bert,6879,259,root,2021-05-18 09:54:41 PM'
13: + set +x
61: + END=1621400340
61: ++ date '+%Y-%m-%d %r'
61: + END_FMT='2021-05-18 09:59:00 PM'
61: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:00 PM'
61: ENDING TIMING RUN AT 2021-05-18 09:59:00 PM
61: + RESULT=259
61: + RESULT_NAME=bert
61: RESULT,bert,6879,259,root,2021-05-18 09:54:41 PM
61: + echo 'RESULT,bert,6879,259,root,2021-05-18 09:54:41 PM'
61: + set +x
29: ++ date +%s
29: + END=1621400340
29: ++ date '+%Y-%m-%d %r'
29: + END_FMT='2021-05-18 09:59:00 PM'
29: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:00 PM'
29: ENDING TIMING RUN AT 2021-05-18 09:59:00 PM
29: + RESULT=259
29: + RESULT_NAME=bert
29: RESULT,bert,6879,259,root,2021-05-18 09:54:41 PM
29: + echo 'RESULT,bert,6879,259,root,2021-05-18 09:54:41 PM'
29: + set +x
 9: ++ date +%s
41: ++ date +%s
 9: + END=1621400341
 9: ++ date '+%Y-%m-%d %r'
41: + END=1621400341
41: ++ date '+%Y-%m-%d %r'
 9: + END_FMT='2021-05-18 09:59:01 PM'
 9: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:01 PM'
 9: ENDING TIMING RUN AT 2021-05-18 09:59:01 PM
 9: + RESULT=260
 9: + RESULT_NAME=bert
 9: RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM
 9: + echo 'RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM'
 9: + set +x
41: + END_FMT='2021-05-18 09:59:01 PM'
41: ENDING TIMING RUN AT 2021-05-18 09:59:01 PM
41: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:01 PM'
41: + RESULT=260
41: + RESULT_NAME=bert
41: + echo 'RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM'
41: RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM
41: + set +x
57: ++ date +%s
57: + END=1621400341
57: ++ date '+%Y-%m-%d %r'
57: + END_FMT='2021-05-18 09:59:01 PM'
57: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:01 PM'
57: ENDING TIMING RUN AT 2021-05-18 09:59:01 PM
57: + RESULT=260
57: + RESULT_NAME=bert
57: RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM
57: + echo 'RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM'
57: + set +x
 1: ++ date +%s
 1: + END=1621400341
 1: ++ date '+%Y-%m-%d %r'
 1: + END_FMT='2021-05-18 09:59:01 PM'
 1: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:01 PM'
 1: ENDING TIMING RUN AT 2021-05-18 09:59:01 PM
 1: + RESULT=260
 1: + RESULT_NAME=bert
 1: RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM
 1: + echo 'RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM'
 1: + set +x
25: ++ date +%s
25: + END=1621400341
25: ++ date '+%Y-%m-%d %r'
25: + END_FMT='2021-05-18 09:59:01 PM'
25: ENDING TIMING RUN AT 2021-05-18 09:59:01 PM
25: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:01 PM'
25: + RESULT=260
25: + RESULT_NAME=bert
25: RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM
25: + echo 'RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM'
25: + set +x
21: ++ date +%s
21: + END=1621400341
21: ++ date '+%Y-%m-%d %r'
21: + END_FMT='2021-05-18 09:59:01 PM'
21: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:01 PM'
21: ENDING TIMING RUN AT 2021-05-18 09:59:01 PM
21: + RESULT=260
21: RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM
21: + RESULT_NAME=bert
21: + echo 'RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM'
21: + set +x
17: ++ date +%s
17: + END=1621400341
17: ++ date '+%Y-%m-%d %r'
17: + END_FMT='2021-05-18 09:59:01 PM'
17: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:01 PM'
17: ENDING TIMING RUN AT 2021-05-18 09:59:01 PM
17: + RESULT=260
17: + RESULT_NAME=bert
17: RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM
17: + echo 'RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM'
17: + set +x
55: ++ date +%s
55: + END=1621400341
55: ++ date '+%Y-%m-%d %r'
55: + END_FMT='2021-05-18 09:59:01 PM'
55: ENDING TIMING RUN AT 2021-05-18 09:59:01 PM
55: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:01 PM'
55: + RESULT=260
55: + RESULT_NAME=bert
55: RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM
55: + echo 'RESULT,bert,6879,260,root,2021-05-18 09:54:41 PM'
55: + set +x
23: ++ date +%s
23: + END=1621400342
23: ++ date '+%Y-%m-%d %r'
23: + END_FMT='2021-05-18 09:59:02 PM'
23: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
23: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
23: + RESULT=261
23: + RESULT_NAME=bert
23: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
23: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
23: + set +x
11: ++ date +%s
15: ++ date +%s
11: + END=1621400342
15: + END=1621400342
11: ++ date '+%Y-%m-%d %r'
15: ++ date '+%Y-%m-%d %r'
11: + END_FMT='2021-05-18 09:59:02 PM'
11: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
11: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
11: + RESULT=261
11: + RESULT_NAME=bert
11: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
11: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
11: + set +x
15: + END_FMT='2021-05-18 09:59:02 PM'
15: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
15: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
15: + RESULT=261
15: + RESULT_NAME=bert
15: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
15: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
15: + set +x
47: ++ date +%s
47: + END=1621400342
47: ++ date '+%Y-%m-%d %r'
47: + END_FMT='2021-05-18 09:59:02 PM'
47: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
47: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
47: + RESULT=261
47: + RESULT_NAME=bert
47: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
47: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
47: + set +x
 7: ++ date +%s
 7: + END=1621400342
 7: ++ date '+%Y-%m-%d %r'
43: ++ date +%s
 7: + END_FMT='2021-05-18 09:59:02 PM'
 7: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
 7: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
 7: + RESULT=261
 7: + RESULT_NAME=bert
 7: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
 7: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
 7: + set +x
43: + END=1621400342
43: ++ date '+%Y-%m-%d %r'
59: ++ date +%s
63: ++ date +%s
63: + END=1621400342
43: + END_FMT='2021-05-18 09:59:02 PM'
43: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
43: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
43: + RESULT=261
43: + RESULT_NAME=bert
43: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
43: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
43: + set +x
59: + END=1621400342
63: ++ date '+%Y-%m-%d %r'
59: ++ date '+%Y-%m-%d %r'
63: + END_FMT='2021-05-18 09:59:02 PM'
63: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
63: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
63: + RESULT=261
63: + RESULT_NAME=bert
63: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
63: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
63: + set +x
59: + END_FMT='2021-05-18 09:59:02 PM'
59: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
59: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
59: + RESULT=261
59: + RESULT_NAME=bert
59: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
59: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
59: + set +x
 3: ++ date +%s
 3: + END=1621400342
 3: ++ date '+%Y-%m-%d %r'
 3: + END_FMT='2021-05-18 09:59:02 PM'
 3: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
 3: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
 3: + RESULT=261
 3: + RESULT_NAME=bert
 3: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
 3: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
 3: + set +x
19: ++ date +%s
19: + END=1621400342
19: ++ date '+%Y-%m-%d %r'
19: + END_FMT='2021-05-18 09:59:02 PM'
19: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
19: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
19: + RESULT=261
19: + RESULT_NAME=bert
19: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
19: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
19: + set +x
27: ++ date +%s
31: ++ date +%s
27: + END=1621400342
31: + END=1621400342
27: ++ date '+%Y-%m-%d %r'
31: ++ date '+%Y-%m-%d %r'
27: + END_FMT='2021-05-18 09:59:02 PM'
27: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
27: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
27: + RESULT=261
27: + RESULT_NAME=bert
27: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
27: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
27: + set +x
31: + END_FMT='2021-05-18 09:59:02 PM'
31: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
31: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
31: + RESULT=261
31: + RESULT_NAME=bert
31: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
31: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
31: + set +x
51: ++ date +%s
49: ++ date +%s
51: + END=1621400342
51: ++ date '+%Y-%m-%d %r'
49: + END=1621400342
49: ++ date '+%Y-%m-%d %r'
51: + END_FMT='2021-05-18 09:59:02 PM'
51: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
51: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
51: + RESULT=261
51: + RESULT_NAME=bert
51: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
51: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
51: + set +x
49: + END_FMT='2021-05-18 09:59:02 PM'
49: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
49: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
49: + RESULT=261
49: + RESULT_NAME=bert
49: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
49: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
49: + set +x
53: ++ date +%s
53: + END=1621400342
53: ++ date '+%Y-%m-%d %r'
53: + END_FMT='2021-05-18 09:59:02 PM'
53: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
53: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
53: + RESULT=261
53: + RESULT_NAME=bert
53: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
53: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
53: + set +x
39: ++ date +%s
39: + END=1621400342
39: ++ date '+%Y-%m-%d %r'
39: + END_FMT='2021-05-18 09:59:02 PM'
39: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
39: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
39: + RESULT=261
39: + RESULT_NAME=bert
39: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
39: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
39: + set +x
24: ++ date +%s
24: + END=1621400342
24: ++ date '+%Y-%m-%d %r'
24: + END_FMT='2021-05-18 09:59:02 PM'
24: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:02 PM'
24: ENDING TIMING RUN AT 2021-05-18 09:59:02 PM
24: + RESULT=261
24: + RESULT_NAME=bert
24: RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM
24: + echo 'RESULT,bert,6879,261,root,2021-05-18 09:54:41 PM'
24: + set +x
16: ++ date +%s
16: + END=1621400343
16: ++ date '+%Y-%m-%d %r'
16: + END_FMT='2021-05-18 09:59:03 PM'
16: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
16: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
16: + RESULT=262
16: + RESULT_NAME=bert
16: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
16: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
16: + set +x
32: ++ date +%s
32: + END=1621400343
32: ++ date '+%Y-%m-%d %r'
32: + END_FMT='2021-05-18 09:59:03 PM'
32: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
32: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
32: + RESULT=262
32: + RESULT_NAME=bert
32: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
32: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
32: + set +x
10: ++ date +%s
 8: ++ date +%s
12: ++ date +%s
 8: + END=1621400343
12: + END=1621400343
10: + END=1621400343
 8: ++ date '+%Y-%m-%d %r'
12: ++ date '+%Y-%m-%d %r'
10: ++ date '+%Y-%m-%d %r'
 8: + END_FMT='2021-05-18 09:59:03 PM'
 8: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
 8: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
 8: + RESULT=262
 8: + RESULT_NAME=bert
 8: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
 8: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
 8: + set +x
10: + END_FMT='2021-05-18 09:59:03 PM'
12: + END_FMT='2021-05-18 09:59:03 PM'
10: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
12: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
12: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
10: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
12: + RESULT=262
12: + RESULT_NAME=bert
10: + RESULT=262
10: + RESULT_NAME=bert
12: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
12: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
12: + set +x
10: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
10: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
10: + set +x
44: ++ date +%s
40: ++ date +%s
42: ++ date +%s
44: + END=1621400343
42: + END=1621400343
44: ++ date '+%Y-%m-%d %r'
40: + END=1621400343
42: ++ date '+%Y-%m-%d %r'
40: ++ date '+%Y-%m-%d %r'
42: + END_FMT='2021-05-18 09:59:03 PM'
44: + END_FMT='2021-05-18 09:59:03 PM'
42: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
42: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
42: + RESULT=262
44: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
44: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
42: + RESULT_NAME=bert
42: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
42: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
44: + RESULT=262
44: + RESULT_NAME=bert
42: + set +x
44: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
44: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
44: + set +x
40: + END_FMT='2021-05-18 09:59:03 PM'
40: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
40: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
40: + RESULT=262
40: + RESULT_NAME=bert
40: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
40: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
40: + set +x
 2: ++ date +%s
 0: ++ date +%s
 6: ++ date +%s
 0: + END=1621400343
 2: + END=1621400343
 6: + END=1621400343
 0: ++ date '+%Y-%m-%d %r'
 2: ++ date '+%Y-%m-%d %r'
 6: ++ date '+%Y-%m-%d %r'
 0: + END_FMT='2021-05-18 09:59:03 PM'
 2: + END_FMT='2021-05-18 09:59:03 PM'
 0: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
 0: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
 0: + RESULT=262
 0: + RESULT_NAME=bert
 2: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
 2: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
 2: + RESULT=262
 2: + RESULT_NAME=bert
 0: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
 0: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
 0: + set +x
 2: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
 2: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
 2: + set +x
 6: + END_FMT='2021-05-18 09:59:03 PM'
 6: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
 6: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
 6: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
 6: + RESULT=262
 6: + RESULT_NAME=bert
 6: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
 6: + set +x
26: ++ date +%s
28: ++ date +%s
28: + END=1621400343
26: + END=1621400343
60: ++ date +%s
28: ++ date '+%Y-%m-%d %r'
56: ++ date +%s
26: ++ date '+%Y-%m-%d %r'
58: ++ date +%s
28: + END_FMT='2021-05-18 09:59:03 PM'
56: + END=1621400343
60: + END=1621400343
28: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
28: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
28: + RESULT=262
28: + RESULT_NAME=bert
28: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
28: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
28: + set +x
26: + END_FMT='2021-05-18 09:59:03 PM'
58: + END=1621400343
26: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
56: ++ date '+%Y-%m-%d %r'
26: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
26: + RESULT=262
26: + RESULT_NAME=bert
26: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
26: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
26: + set +x
60: ++ date '+%Y-%m-%d %r'
58: ++ date '+%Y-%m-%d %r'
56: + END_FMT='2021-05-18 09:59:03 PM'
56: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
56: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
56: + RESULT=262
56: + RESULT_NAME=bert
56: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
56: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
56: + set +x
60: + END_FMT='2021-05-18 09:59:03 PM'
60: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
60: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
58: + END_FMT='2021-05-18 09:59:03 PM'
60: + RESULT=262
60: + RESULT_NAME=bert
60: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
60: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
60: + set +x
58: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
58: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
58: + RESULT=262
58: + RESULT_NAME=bert
58: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
58: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
58: + set +x
18: ++ date +%s
18: + END=1621400343
18: ++ date '+%Y-%m-%d %r'
18: + END_FMT='2021-05-18 09:59:03 PM'
18: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
18: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
18: + RESULT=262
18: + RESULT_NAME=bert
18: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
18: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
18: + set +x
50: ++ date +%s
50: + END=1621400343
50: ++ date '+%Y-%m-%d %r'
50: + END_FMT='2021-05-18 09:59:03 PM'
50: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
50: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
50: + RESULT=262
50: + RESULT_NAME=bert
50: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
50: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
50: + set +x
48: ++ date +%s
48: + END=1621400343
48: ++ date '+%Y-%m-%d %r'
48: + END_FMT='2021-05-18 09:59:03 PM'
48: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
48: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
48: + RESULT=262
48: + RESULT_NAME=bert
48: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
48: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
48: + set +x
20: ++ date +%s
20: + END=1621400343
20: ++ date '+%Y-%m-%d %r'
20: + END_FMT='2021-05-18 09:59:03 PM'
20: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
20: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
20: + RESULT=262
20: + RESULT_NAME=bert
20: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
20: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
20: + set +x
52: ++ date +%s
52: + END=1621400343
52: ++ date '+%Y-%m-%d %r'
52: + END_FMT='2021-05-18 09:59:03 PM'
52: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
52: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
52: + RESULT=262
52: + RESULT_NAME=bert
52: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
52: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
52: + set +x
14: ++ date +%s
14: + END=1621400343
14: ++ date '+%Y-%m-%d %r'
14: + END_FMT='2021-05-18 09:59:03 PM'
14: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
14: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
14: + RESULT=262
14: + RESULT_NAME=bert
14: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
14: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
14: + set +x
46: ++ date +%s
46: + END=1621400343
46: ++ date '+%Y-%m-%d %r'
46: + END_FMT='2021-05-18 09:59:03 PM'
46: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
46: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
46: + RESULT=262
46: + RESULT_NAME=bert
46: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
46: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
46: + set +x
30: ++ date +%s
30: + END=1621400343
30: ++ date '+%Y-%m-%d %r'
30: + END_FMT='2021-05-18 09:59:03 PM'
30: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
30: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
30: + RESULT=262
30: + RESULT_NAME=bert
30: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
30: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
30: + set +x
62: ++ date +%s
62: + END=1621400343
62: ++ date '+%Y-%m-%d %r'
62: + END_FMT='2021-05-18 09:59:03 PM'
62: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
62: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
62: + RESULT=262
62: + RESULT_NAME=bert
62: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
62: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
62: + set +x
 4: ++ date +%s
 4: + END=1621400343
 4: ++ date '+%Y-%m-%d %r'
 4: + END_FMT='2021-05-18 09:59:03 PM'
 4: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:03 PM'
 4: ENDING TIMING RUN AT 2021-05-18 09:59:03 PM
 4: + RESULT=262
 4: + RESULT_NAME=bert
 4: RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM
 4: + echo 'RESULT,bert,6879,262,root,2021-05-18 09:54:41 PM'
 4: + set +x
22: ++ date +%s
22: + END=1621400344
22: ++ date '+%Y-%m-%d %r'
22: + END_FMT='2021-05-18 09:59:04 PM'
22: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:04 PM'
22: ENDING TIMING RUN AT 2021-05-18 09:59:04 PM
22: + RESULT=263
22: + RESULT_NAME=bert
22: RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM
22: + echo 'RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM'
22: + set +x
54: ++ date +%s
54: + END=1621400344
54: ++ date '+%Y-%m-%d %r'
54: + END_FMT='2021-05-18 09:59:04 PM'
54: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:04 PM'
54: ENDING TIMING RUN AT 2021-05-18 09:59:04 PM
54: + RESULT=263
54: + RESULT_NAME=bert
54: RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM
54: + echo 'RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM'
54: + set +x
33: ++ date +%s
33: + END=1621400344
33: ++ date '+%Y-%m-%d %r'
33: + END_FMT='2021-05-18 09:59:04 PM'
33: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:04 PM'
33: ENDING TIMING RUN AT 2021-05-18 09:59:04 PM
33: + RESULT=263
33: + RESULT_NAME=bert
33: + echo 'RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM'
33: RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM
33: + set +x
37: ++ date +%s
37: + END=1621400344
35: ++ date +%s
37: ++ date '+%Y-%m-%d %r'
36: ++ date +%s
35: + END=1621400344
38: ++ date +%s
37: + END_FMT='2021-05-18 09:59:04 PM'
37: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:04 PM'
37: ENDING TIMING RUN AT 2021-05-18 09:59:04 PM
37: + RESULT=263
37: + RESULT_NAME=bert
37: RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM
37: + echo 'RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM'
37: + set +x
35: ++ date '+%Y-%m-%d %r'
36: + END=1621400344
36: ++ date '+%Y-%m-%d %r'
35: + END_FMT='2021-05-18 09:59:04 PM'
35: ENDING TIMING RUN AT 2021-05-18 09:59:04 PM
35: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:04 PM'
35: + RESULT=263
35: + RESULT_NAME=bert
35: + echo 'RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM'
35: RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM
35: + set +x
38: + END=1621400344
38: ++ date '+%Y-%m-%d %r'
36: + END_FMT='2021-05-18 09:59:04 PM'
36: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:04 PM'
36: ENDING TIMING RUN AT 2021-05-18 09:59:04 PM
36: + RESULT=263
36: + RESULT_NAME=bert
36: RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM
36: + echo 'RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM'
36: + set +x
38: + END_FMT='2021-05-18 09:59:04 PM'
38: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:04 PM'
38: ENDING TIMING RUN AT 2021-05-18 09:59:04 PM
38: + RESULT=263
38: + RESULT_NAME=bert
38: RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM
38: + echo 'RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM'
38: + set +x
34: ++ date +%s
34: + END=1621400344
34: ++ date '+%Y-%m-%d %r'
34: + END_FMT='2021-05-18 09:59:04 PM'
34: + echo 'ENDING TIMING RUN AT 2021-05-18 09:59:04 PM'
34: ENDING TIMING RUN AT 2021-05-18 09:59:04 PM
34: + RESULT=263
34: + RESULT_NAME=bert
34: RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM
34: + echo 'RESULT,bert,6879,263,root,2021-05-18 09:54:41 PM'
34: + set +x
